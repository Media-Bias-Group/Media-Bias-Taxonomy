{"paperId":{"0":"c0d2579463db52df8d3b303392729e77358aa9b9","1":"f28208f6847012f986c4ce63b34236284e65407c","2":"861a1e8f281809d5d6c26d6d8a18b648cbd50c69","3":"0e012c2bd18236445cfbc6e3e409eb02df4691fe","4":"2297c559ac3509b3ab456229f7032b2a0fbf23c1","5":"4ad766d33c9e63539f2394585419c992056ffc06","6":"1ce96d8dbf69199ebd043de6cfa25d7e48b8ab03","7":"d0cda85c030711aaa5383c80d5928a4d22f8d3bf","8":"3ca7a604e0d351e512bfda045d2837caeb9831df","9":"56441f4f3beb3276350d811c67307e28d5f61b43","10":"26f5da9bfffd101fb86f6ab16b1b7ff8ce6046c3","11":"e960beaf0e84bc20cbcfd67fb7aefe37db15e1a1","12":"7779b04aae43f65ff5cf4419c8042761fa37578c","13":"74b4612444691865b9bff96585bbdf176dbac45f","14":"98a25ab6f929583138e526f8dccea4b343865c0d","15":"a413a801b470955dbe5862984910a0431949921f","16":"8592983238261838603caf503def12d3396de710","17":"2ffa22885c2df0f14bb059a1234f3a9b2b0c3e5d","18":"306a70c6f9a8e5863efca4931f9481d9af270b15","19":"e85a50b523915b5fba3e3f1fdb743650f7d21bed","20":"339b2b711fb5b228d097b03ebc3e62a521779235","21":"4099c4d272c12081b562392606e6d567e4ae7031","22":"48689c4bb52a45c0bc97d1421d72d11bab6c346b","23":"59bb7f41e72bae283f8aa2222b346956ee197a7a","24":"e7a00d7bdc5f9e2d4aaa17a3d44ee1239f33fc30","25":"2f4a012aa325cdee5a5c779fe2133e146616a5d5","26":"0aa199ecfacdc0fb087c9fd8d602c402a74b4e31","27":"32948ae25dbd35f2d94a59c27f6bee935bd602b8","28":"a25800880aa6905f9cf2fb4e6aef54164f999cbd","29":"56d41f91193994eb80884ec83c1c1e74b7cc3058","30":"56a77b2810dfa3fedf22bdfda0eb33b5b2ca882f","31":"8371efc92fc65a883ae3eb19c8ca1eb2b30be09e","32":"00059087c954c1af6ece33115315e3e0ecc2f2c2","33":"0712334d1109248e52706f13aeff5281834727f8","34":"af0b84d24764fc5751af75a8f68fe535ef10d08b","35":"9c49a2178134517701befea536400c01a1cdefe7","36":"055fac05cd424e7b1bdcd359ff7980ca8d938ef3","37":"080ee4e93438f8b8cbdd894eef15af71f0c30097","38":"0ebb1d1fbf488fba8c18a5a6057a6ccd9e87510f","39":"0110df900ebf9cb6e77c0f4a326e5431c849359d","40":"cfc9a178c413d4960840379a12f552dc5cea6c6d","41":"19f288c459aa8e74170c8f8430f7c87760950fe4","42":"7a6aab74d2feeadaa9b13edbcd36b595ed38e4df","43":"d626fe7c303e9baa175649aaff0f365b158ebbbe","44":"278f7495e50db8b3d01112ba36223e8976f73b60","45":"07bcda1dff9bb696ea9cbc69303eee8bd3d85bd6","46":"a33b4a2002161a18bc7eb929566d77fd5178c2e9","47":"4072a2333682941d23755e9b7e1e3a6d899683c6","48":"43b184a9912ecb6de0454892c68c82200f77f234","49":"dc08d90005b12f66a12798fd79959a8f7f8c4885","50":"0d965ed237a3b4592ecefdb618c29f63adedff76","51":"f87fd4e849775c8b1b1caa8432ca80f09c383923","52":"e44b31118bcf73e0bf0065a74aab780ddeca1683","53":"68e686817f2c33cd09ba3805fa082348f18affd9","54":"7a6385947507c8187043ced97c87480134543a44","55":"afc79b2d49fcd87bf87916002566136f5490f821","56":"e3d3571533e43f42218bceaa8cfda9fdaedb89d0","57":"046c8a31b33412a3c48758078055661235aff50a","58":"d0e7b2150915c2f778873155a9b12ed74ab87834","59":"e24e44515b15e1326dd25ab092a152a067c63fc1","60":"daa19a47b5de20c7009c8be0b0f31ee1e32e2b38","61":"a875218fff0e8f00daa39ecdecc1ab52b9335a12","62":"dbcd4eb004b5dbdf2a22aafb225e9b3b62a4f7f9","63":"1a575075ba357723009a9a8905d5dccf9115ae6c","64":"d46cc155e033b09c530061afecebebc77542a0a2","65":"bbe109dbc96dab47a3fd049065b82115922d7a52","66":"b4793bc9c098e0f0705523efc06830a85c0c4a43","67":"055c04900d65bdcacdd0cc98a782e34f9bd7a544","68":"d68827abb1b848ca39978d04e44ff9bedf04061c","69":"5cfd70f5cfd8e4742cf8937c2e0cfb7f12f3acfe","70":"886d79423b7e5a5e20c4d13b0aa3a45851fd9487","71":"5f11dfa7cd146b456dceed19923f5ed6214fcc44","72":"06994c2810c2720b302153fc73f8c4459f05fda7","73":"0a2e38c925f29f8b02a36dbcb3aa6700f7d97852","74":"267f1de5ff863ab03f8c48c7ac3df1d422de7c3b","75":"7c4224f253709a0797a956383c884770b65cd5f1","76":"3e975d1ebc2f5acb4b980c8df8886889e3b7e0da","77":"a13a180aa995ce2a03d17ea1550813ef4336964b","78":"a8abe785f46ebdeec6768ab741162830ba66b4ec","79":"5b489e91cc8ab5735d914895b3df5d54284e91b9","80":"9b535d6350135af99398b057406d5f0840f4f04c","81":"02687a71c3b95b4fdb7b1f257b3c3c8346a38eeb","82":"1fc14493677e2f496c8c871f1542f3271184c6ae","83":"736bda6fee547a7a95e5127a746e897947e09185","84":"55db065bfc3394521eefbd3a8502314b7eda8a36","85":"b8ec7086dbdd6104d06076be7f5a0bba3562a48f","86":"2a88be4c0aec67911910e921ccfd8e7d783bd6ea","87":"3334415629c52e57f927fd8d80c4043c647afc78","88":"b1d383ad8e602391af5b9f6c1c937d9c799469bb","89":"20e1ddc105f0f145ea7647a9ea4b9c94a8aeab62","90":"9c14c9288772135f560d274a07723e26189e49bc","91":"aee6b8c768c3d060bad1c4bb3f1487c8daeda5f9","92":"fc8df4ad35282ccf19261e02de87d8e35c956537","93":"245bcbdfff19721c226059a5d5b1ae71b67e0572","94":"de196985c8284d54ef9db4cbfbbe830d3a028cc2","95":"16981cc4ddefd3ea7655754fd83a2a8ff2203a8b","96":"053dacc5d11fca880a550ddd98fdbfb149c129d1","97":"1be7d9cd613f51c53c3c3b5509e82358a8242677","98":"67820785cf3c849fce6ba1e401ab3e1c231c7e73","99":"877be06c2690b8cf9c5f2015cb38a19f5ca39544","100":"2ea64b7c7617f6cc1768373124ca0243d772a90f","101":"17f423a5e542a4bd4de0243548e127038dea6ab5","102":"c3114fe08b35c1f3d7f1eb04dc4803720aba8504","103":"f696ea202d5f2af57c66b6f9f2783f124399e0dd","104":"ee51e97d96a2a82e4504a78f57f56462e81e6b3d","105":"0a414eb148ba7b60fca26eccfd42e3f6913cfbb3","106":"f1e14322be0a7f32612f42e4e6b13f7de6c5d213","107":"dd89cb9f9be07459b0e2fb66dcde9a615db103b9","108":"47c416de8a8ee7082fae08c1d539bce14e576cd5","109":"822055e65da2dd1ff729f851e1266403745d55ac","110":"1cf28fa7d015d8dc08a643531d1932b6a063a7eb","111":"384859a38bb8112ad3d3ef7ccdf21469a869cebf","112":"62e2a439b5a519a4c50c98077b75a427ea4966dd","113":"6f26402680b489d3b231c051d1e927aed264f20d","114":"c842b46f715dae530c368ce97e5419e521f1769f","115":"434d211269bf82cd743b4f3dbbd3c377d763aa27","116":"137829c2f0547aab19d6f810d3478f8006ef4696","117":"e0b2972f6794a0d5959cdd367c51ff755e02d09e","118":"000064b18bd46acd77adf24ab4482fda6417c2ab","119":"e981ea39be14db75265251fe4dcbcc698dc534a3","120":"43b016cd8f426bd8e47838e4918670f72318ec90","121":"5b825f4260fc2b54f3879f1375c048830b1f164f","122":"521273a2719eeaca3fa3e58cc37f7769dd0ee120","123":"a2ce1fb96c0b78bee18bb2cb2c3d55dc48d54cbd","124":"4418af0d31e5ee653076ce684d68d0d91b345c52","125":"7074519c8a2d975509345b1301d14e4b8b36fcf0","126":"d04b8150fcc17015f6d52b8eabdb477b9652865a","127":"23cc8e927da962f5acc4c0bc5f5e3df42835976e","128":"1f4adafb2c55ed1029c05dccb68cfaaba8abe629","129":"50154080ccbaec1a3b4ba401bebd94b80225d21a","130":"c9762ba3ceeadf067a6c1da233b90a75faa187d5","131":"69accd35f2ae56aa71ceaa5abeb814fcedc8a58e","132":"540fe88124ea978dd5344d263d3c03accdd218cd","133":"004fbcb0f3248afcbc158d97d3b02f0ea42e137a","134":"f397df630e0708d411e76309b85f56440b853b86","135":"f05b9b663f1461ef2e20be5d2e8d2116a5a44f94","136":"dd20fc43fa2a3d32eb85d4520d3c34c7ce4e41b9","137":"847c38b08c9d596c2fbe15a95b7f5e608a0b9dc1","138":"9b4988a9ea035e5e67c227ef603d1bb53f8f69ab","139":"fa2a6af315a319f1ef5a95e8a0152ff88500dba1","140":"6e4f435f4106956e205e00582fee8cd80b80f626","141":"51adbb95234875a7021eacd4105b1fd07aaa6242","142":"b59b9289c5942ca224135a7d8064cd1a320a7400","143":"ad60516f670b13bf196a5ebf05c529eb78ddd3ca","144":"220e1a3ec7ed17c8ab8ade6e0d31c3db59aa896e","145":"d35d1ca234f7775eebf4d063511afcee7b798aae","146":"b9344e6a12a8e8ffed25bfaea3fd1f20b58ba153","147":"a6f8fd15058e3386aa02c95f88da7ad9ba7481d1","148":"3f8781992c33a4d45c1e4cd0b830fab4ae9d083b","149":"a52ad4f73f690c350c054a2463db9bc5f94e9360","150":"1465ac9b14117a2a5db5b08d451fd14895890a03","151":"5bec18a65a5b0d33952897ccb2b7d0a71f558b6d","152":"090379adc989ce81f5528f30779ccf346315175e","153":"9246a72d4267a6887f8225e73b9b58a0435d3c4e","154":"423a23c9f5188a66e630e64f06c6c6dfa3e9d4b9","155":"61a95df08985d9272ca23d337c3833328e7fa66d","156":"67565d01e1d517addd49c063a01eb14b9b0dffca","157":"b4c124ba7638c3effaaf7e61f07689aae1265af9","158":"ea87e61426b6072b622b11403ac2c18d35b5c0d7","159":"3dc3c7b4835830a3a372286bc496dded70fba6c1","160":"50ccfcc9cb9fd5315ffc6a5f0c6516f4f9fc5676","161":"6bf2e55b403b93f3786463dcf2d726a9a94be080","162":"ce719054d0a141dca6d1a60376c87e9042e443ec","163":"edbf580400b3db00f082fdb567bd9d7cf0efefeb","164":"99f6da372954b1de701cd0e836eac445107088c6","165":"7dfe02fffefee9d0fdf207054af6f39317bcaabf","166":"e5a599cf801b97952d5043eafb7d22bebd679e7c","167":"c4afa2b3eda95a1194313394901e0e96e24cefaa","168":"c4c96642359f1f96517b5aae8c13b42c0e25b996","169":"8b2cbb2f101b025c16e12d0d7628f65e5378e10d","170":"ebd5b2d28a6ec478d0f0eb2de194f694ff1c5232","171":"634cc3a29b4818ace36c955b3995ce8c13dffb85","172":"29ed5ab47631800c922f42ef1ff5165a1df56fc8","173":"3feacdc2cc1fd01fe533a150211dd4423433b133","174":"cff4d87fcd98c65b352e9dabe1e6f444d99e6aad","175":"60f016adc29f6f2e9b29031c9c2e8cbea00774d6","176":"4c4718539d1696954520aa3c43fdcd597558e815","177":"825eeae79a97825b69a4516a05e5a8975422609a","178":"c7222838952ec619b17952a7b061f77fdb8d486c","179":"e3e9d2bdcc3fefab7c294196c8b2e149727376ed","180":"ad9d93406f3cf3ffe5a640cb4d742f202339a511","181":"0ebf5a0208ec2d930673e5e852cab44f9e1c8811","182":"ae7d31774c81d955c8185402dd400a9594973f65","183":"b58abb51a5dae7fb753be4535e468a6f1f07f873","184":"73623dbc70ea2713e8e70c2b85f90ce48164a5ba","185":"337d7199c4edc4c8558043a51ef0712beaa3e137","186":"7ebe65c7ff53bfd1d1911259c988a6a615fb51d1","187":"ad9d1b39adee847a8be67aa1eed9a52e0242a34b","188":"426a5caf4b676db6e077fe79ec433efee45a0a60","189":"365bc3a263ea6447c6d041a324912c3420ca235b","190":"b16314c914d7b52262100c58e03a93eb724bf671","191":"c1d21cd3a58a8ee74fde2d4da35133c9e5f9035d","192":"d402bfeeee71b68a24d651f88b88d10cb8b7aaae","193":"10414a2f2f00028f2c725c3461b00c3a2ec98951","194":"a3da5fa82d316513ade2dc355ee058af58487751","195":"9eb4cd1a4b4717c97c47e3dc4563a75779ae9390","196":"fe976fcc6c6d6b47ce3c1f53f03f1a9318235f0b","197":"081bd8662cd8f7b3d67fbe4bea49b3da31edbfc7","198":"a6af5e3766e510fb67fc4632b34bb9ef702ebdb1","199":"13b48b0f190cde85e55341e49d8a40edacf41b87","200":"9817392064d6a340531d56b9e512fae993052bf0","201":"d2803635b4ab094f230481c74e7d680f333e1d14","202":"cd3d457c594bd52f6824b8f41fa62ce2f8aba2dc","203":"9b92723cf1b6ed2d096208ef3751ded0e9433a85","204":"e44616baa06dd24388d629ede70b06b2e79d3906","205":"82fd1d147e7d524d65196ea0ec2c041f5cc41927","206":"379132b019b02841acfaab31eb17c64b7b8ae6ea","207":"f0891d9af5c17237321e79930fd7256185a0b0c9","208":"de2bc64c653cef1a41675ddae38ce173e0871a50","209":"7b589eb32d2cc857f85c413f4039ca9a5b834707","210":"d618752d2e666d7b25f1bd6c7c3bd7c056e19d96","211":"d4ae9dff186553d98eef4a275762b4cb15e1e41d","212":"eef4df3a5232c7ce70123aaebb326ff9169a3c8c","213":"1d0612edb7e52c01611e0f7c898655bdb1262966","214":"371c799bde8b162e7f8fa2b2a0a8cfb29765f89f","215":"86be6c7ba5ca77a668e5d6ab342445b72ca24208","216":"c2eff53cc9db9eaca8d9ffe06f2d618b0e360c9d","217":"ed0e117152196693a42fd845740ca08ae1d5ef8a","218":"90b115737efb108a39e6134035b33b26941cc85f","219":"b72ccdf9072dd3358c44550ed0c52bd8eeed6ef0","220":"a0c0af7c0e1f14aa39b72a52d98dc058ea80df6a","221":"09fba948316e04f0e1641926948b67b0799c8e0d","222":"2b43db82f61a80f375a24564205814c7fc8fb368","223":"df157cb42b574c3f46b269504c18375bfa5bc5b1","224":"0fc05ff99b3de969261f4294e17fcd6ccffa19f4","225":"513892f6232f56b6ab35688b8aa59534cc81a928","226":"4e258110246003b6d47015c8de12a754eda31c3b","227":"14d35b1cc3db2304b795a7dd33e464aa6bb87581","228":"85ae9dbe1be0ef86d5f1985607c1e9de0547afc2","229":"d82038498cae2dbe60017544d4cfd326a1abcfe6","230":"4d7df81767737c81890411c7f1685bb232921cb7","231":"9b090ead7797e67c7cc79cf1144a1113a579bf9d","232":"92ba9c2588f2e9d9e1379a187c9b0adfcfe025a6","233":"c2ecc9073672a8d8bf21fe442dbf3f76356858ee","234":"6e358392f48bf4bd7c43e2bbe45832fcb684640b","235":"5daad753c9e154d4f328220437f8d7ebf9e2c1b9","236":"9fc8ededf4f46f19874b36a6aed48e8e54cfcfed","237":"4bf40263e1c7e3766d9b3ed334edee2fcfb0b14c","238":"01a75a8aa2a5c0df3a996affb03f3b8ff336c6df","239":"72ff295b03e0e223b59697eef967e6ce0d1f7618","240":"3e3eb188860292fc8d700236cdb076a4b2fe878a","241":"acf8a1040034820bf99379a3422815f4e0859ec9","242":"36d7998ec3e462e3907c6d3c1d13984234f7e8cc","243":"f7f36acdc79bd57fffe337c2baccb6e39b5be9f2","244":"25936b2fc79ca12aa35a759cbe866f13ab1e2a20","245":"4543a8564c58550a5e6ab4b6d89045c800a44aa0","246":"8eb6b7e4ddf3dd5f7cefd44350c58be696ecb6f5","247":"b8601c86905b0184b9387b042400609febb93d10","248":"5d22b241836e30d5b0d852b463951ab7e3245ea4","249":"f341da48986fd5d253bc6bee559e31f25c136c03","250":"11de73205f632acb422de5cadae7ed4571595bf5","251":"a17e342264d7531f23116cc5cb300f0480a1c816","252":"035a7a7cc24d1aee1865bb07eae0ba6520f65a66","253":"380c35590e2c112e620863689f481122d19e5f19","254":"060985340191174d6b041f59bed18104b3d66018","255":"dd2d81e91b051dba756df2fafb79dcb4aac7d057","256":"af4082b90c5d71bb1f27b6ae2d197feca4d4778a","257":"d77123b54dcc8014949584ab624e97298617bcad","258":"8948d2e7ef2cfd5cd9995eca4aaece7da67b31b4","259":"b4127311564e121dd991be80881641142c35a944","260":"0eeaf72692be70cb1afea945dcd43340b99772a3","261":"3447feb86edcb747e6ecd8cc2d8dd639c2fcc9e4","262":"4949b9f93789bd480f4c7099f409860c99cdacb5","263":"47f7ec3d0a5e6e83b6768ece35206a94dc81919c","264":"177e957f5cd93229c9794ea652c646d2557b4a69","265":"03db529f0bfae6d0b64b0feef565196327fe8d50","266":"6bae464ccb62a3bbbc972e036ddade42d1fd7a60","267":"ae9bf201f128cabaa4350b54ff6607525c736cd5","268":"49e65b12d8d11f2ccb5ddd7be72a8f746b2d1bc2","269":"ea9a516d5cb0b298f0df50e82b3e0400b72fcdff","270":"fa3d0599f8a082add349b5b09a208136489dae34","271":"32502aa3d32e7c495e39409e8f1565b5968f245c","272":"08066c80919620397e8e4e5372ff84caf401e675","273":"e47e6c814d2742527fdd352db13a5fd95b7ce24b","274":"bc69db360d720ebefdbb66dc02409142505e5212","275":"6191a5122d67dfbab421bc89540d264822dd8173","276":"d5513ae4aee1f0b27dc260585ec05211f1dce274","277":"974ffaf2775a8c32e405c551436a111714a5dc3c","278":"289fdb45f5076457e5739db57ab7d2004d7cbfa4","279":"9b9ac0169a8d7c4325fbdf0a1660d1b2ad17a80e","280":"16a2a1bf612f9f9719a7945485f7e73324d18783","281":"dd93a358c7e441855ba7fd46872099da6dc23b5a","282":"130373cc752e2c51a6cf14c6d1b2e5f7d9006987","283":"b5fcd192bb6a714433eab1b56bf968fae0f98979","284":"f5c25a0f61005bf18953249cd3e08094b69a5d98","285":"4f416b19d6c6d9fe42b6ced7af34627894627757","286":"36ec104c405b17b41ad6d9998572d3d757a5d331","287":"331a5bbc64d624fe45f85d5d0113cb0af00ec429","288":"10569a326b860e87f6ebb7bf569af9ea59cc252a","289":"1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1","290":"56d1003fd02346e93354ab55cd204485c268512a","291":"c122fa378a774ba202d418cf71c5c356cf2f902f","292":"3c54b796cc10cb530f77caa4d18e1c80ac863822","293":"754cb424e0f9cdcbe4be2e683d503a7e82130f75","294":"22ec1b3a190deef662a822ade2dc2f273b3ac208","295":"734647b1582bd01501cfb35b49aae1c1bb268932","296":"a15421b034d3c75043190bbe4de28540f403f99c","297":"53d0569d1aeba0701e2cf5e831bac151c82317e6","298":"12a562148ce22687c6544b054ae292434f9d50ee","299":"6c17c2cd03dcea90ff33418e9d2a80ddad600922","300":"c8922345e2aaf4e4a88cf2c2e91b8545ef54c6d2","301":"37864082f80fa5879d947cd294cec63e866ed581","302":"40e9deebb5f73a9bf907f0ca72d4524e952be854","303":"a6a08b716dd4decfb103435b44e76927fb73205a","304":"dfb92b8424c5e0f912f240b3bb9c746fe19e891e","305":"2f01034cf72fd91a5fa7a791100e273df89b7259","306":"1986be3bd1c14748fa7390ec87142d91ce4a6b05","307":"c722eb5cb5029dec57c471cfd9677e62d12c28b1","308":"732f76b0a2aa5d255d60cb6e29257d9fb292a6f4","309":"6dc68719e77f70e2e42fbbf35e9ca003dc939b42","310":"3b1ff258503d522807a63d390d5438314db04e8c","311":"9d33cc86a2059569ce990e8f715a7bf6b15c6dbf","312":"52de3b694153c980c8ae26e5132425ed0e1b41cf","313":"03936b36d2c8874fa56e70907d2df1fd85b038fa","314":"4b23d64e4964367ac9eec982f12035bf8baa85b8","315":"d7f2a424056b43718b25aa9dc1074923bd258be6","316":"2330f83d7521a92aacd70d448494dcfcf93f05bc","317":"4e92152bf0ad51e6b5e8754403f956aa2ba3e219","318":"e165faf18da54e5e1d6ded5665448ed91f792743","319":"1e8576a640352c9f3b1976a648b2c668eae7d3de","320":"4075ee946fbc9730e679e6c949b9de441f3c38e1","321":"2b71dc2cd458aa61f90d3a9f592db05a04d4b8ba","322":"1b8de5b0a1c9b3dc4c5a4e09b5b3f86283b4a375","323":"9f54586a6664e541c6b980e1ac8565b504a729bf","324":"22c742aad1210ad8f298f81de7edf41dc9814fca","325":"f43fa2e1f2bb4822160fa9c90be8902f359faa9c","326":"17be21b89ea8ac02273212badac6654f5b7ccf79","327":"33d77b39a6046526595b39dd372dac1db03de661","328":"b56f05ecdba31fa3a70c36c74a7e397fa573ef1b","329":"8994bce4b85a8b4087584661c49f8776f868f7dd","330":"d410c1507a86054a017154ad4d81cf8233ca9cd4","331":"8755c15fe073c6af03664b2a74aafef1fed5f198","332":"4fd961ec9a6af0c0d15e0a85471d0ff596342ac5","333":"c92ccde8efe40d1696dc7acdadaddc923c9d945d","334":"08db45d0e427cdde77cc16307a4d13bcb1cd3d55","335":"2adadfdff4d38484df7624e17a93c814864264fa","336":"458533b6fcf1944b6dcebb904a03215795db2ba8","337":"826383e18568c9c37b5fc5dd7e2913352db22b47","338":"b430a5384c82beb6102106fbea0a134425a08c23","339":"44e02e57b186dfef713b24beb44727d4b1048fe8","340":"7c81bd211b5df56094ee3bbf2929bb7feade753e","341":"6c8c9dc8da6a91531821a8687ada84ac3f1781bf","342":"9b3f7cf0550833208ee4dffaf45549b19dcfa867","343":"73395837a22eb00ce4106be3653460377bed7725","344":"a6721a2fd36f1d6432024a15385a26309379b078","345":"e3c4c9ac216a3bd8dfcee6e3f780975cb2fdf36b","346":"9007daf4171590d09672b563212f4bfacd785c7e","347":"bbe6639f3b89ab5b72d77ca268fb709a98410b44","348":"bbb9f5378eac3eb8245cbd0f998a95cef2954508","349":"86724befacdd9fd8748607f5b025aa59fb7ef010","350":"4d2af4f30df721caf857d66b8db521482f8c0606","351":"d4aa625b2ea90b3b884886cc80f995b8e766d1ee","352":"36e0edff4c7972853d12e4c20436e077397a8551","353":"874b18b8d8554ae5890f44d728315fcebc6faf02","354":"1e0eeb8cb3a0dca331e40f21c74eb619cde66183","355":"3e53f94215998a91b1f8124914cb6cd15f2a03c9","356":"c1dfb3db7a952a9cf7454967319bac3bf7b4bb5c","357":"cb66cbcab02f08a2492e0f53983cdd3ec06618f3","358":"a14bb8f09fac4c0e8e5acc53e43b5986cdf6998d","359":"5661835ded4431433206af57d80d13c567e3e555","360":"0c6caa6d9643dbeb39ed3bdd4b67153d51292e81","361":"589490604f143ee347b628a6d496eceb092bc5fa","362":"6a1d361136da6983b5335ad74274d0e2d0b6fa67","363":"8d1a392200066bc7ef2ac1c78ecea6d2d5ac630d","364":"7ab9d8246c2abac232e7904e98db6e6c95402851","365":"1161e9556092cf9bf2923e0b15d03b01be1ce929","366":"389b9d9f88c262fa65800318cf029aca1b37eb1f","367":"46b2e31094041d6f76fa9dd78121fb66a7e6b222","368":"33d2f8efd905eef4c76f6f72fec6f7e2a14be7d5","369":"d64192da0b6d43c91c902105c089b18b76f9fe77","370":"e54cb48aac19d8c7714fdc1af4c328dca49bb7f3","371":"18b5ce6a05295de48df6138fc412f27cc2cd78cf","372":"bbeed471a946eac19aeced258067f1534e1f1783","373":"f6282d4bbd942f7f08ceb549cb4ee647a22aaa50","374":"bec0e7ee888b9abaf8653777d71c9ad78f4c3027","375":"73c9d413f275a1520aedf4649be817e1a228cedd","376":"547311799835f6e5eaed4e07b39fb344c2542e66","377":"bf7757a4c88109c18265f53dc21786fa29178b27","378":"18bca3a5f684ad0f7a31b9845757e395bcad4052","379":"b029346bfa85fa2fc7a12498ae5f018922ce55f9","380":"0be8b1a085abbd83d49960437634104ff7d3d209","381":"f1acf5b35888c4dd90f1c949dfd103e3a7a342a7","382":"ccb2a2f0f63f59f4092e161cbfb62bf73e30c296","383":"a194297f3703bae8040ddfd0c08a60cdcaea2aeb","384":"422ff5da34fa241269ef7b3b56254030daa0b45a","385":"461420c80d3bdc156e5db7af13264a955a6a2010","386":"d8530a37603e0dbcbfdf49d2726fd8dbfe7c47e8","387":"2d22b0b3339b302d25f5d683950459d2fdfc34bd","388":"a2412fdebd53bd25476f834ae2b8aa8cb44cb1e1","389":"e02c114d6269f4781b0fa92f4e2c9376e7462906","390":"0090023afc66cd2741568599057f4e82b566137c","391":"4e20cb972bbb43bc7bcabb2f2c9fdf980a9445d2","392":"8963317176fa81e185fd7a8f8cd001d7e11a4868","393":"0e3384f5f301e5fb9a2eedd366763f076c41acff","394":"76733a6699ff63aab75ff87db7bef5665fa9ca1c","395":"825a609040ed9eb66a79c3efb51e2efbaa03fd78","396":"bf73676a952052453075f9db6034dd81a9c63561","397":"7f4db0ba14319eab5ccda83c331ef6e491b4e38f","398":"dcfbdcf6bd3e6bb4101cc3f8eb1ca122db1eab61","399":"7049da930167f40ab631187707de705feb8b1b93","400":"0a0019691463eea92a54df9631754efe2839319f","401":"02326a950eb469b9eb3cad70df05efd87ba6b07f","402":"4aab9b7a3486e73fd05bcac83d63a98e5243377b","403":"4e520a1cc111870c5b0bf0a3580bee2051b16062","404":"6a3cc30d5d6342d912851deb4362b8c47fa5ede3","405":"bb96dc3ce7c2196446c72e6d8c151abe578ee216","406":"ba783d92d0eaf6a7bff6ced7660150ce38016bbc","407":"3f9e4c99346d231ada37ada243bdbcb58c47387d","408":"581ba155f617dc99d27d3043400994bcf0640c78","409":"ce6945d32780c599d829c1995dfc1555ab33bdd1","410":"e5b60f6dc59073cc52523876f69a48adf480fd54","411":"b1d344488c54887fef5b590ad6e9928f9322d175","412":"7e59497190df5504852b90596b6ffa757e8a09c7","413":"b6148e42f1ab386bf3607e8fa291c398bf1f5204","414":"2500516ea6909f42e56a2520c7568c5f97b850fa","415":"3a3f07b74f556df8ec6cd1118043c30057a4e710","416":"322b44b346f921158e3ec64199e32f61adc4ea14","417":"ad774ebe0ad25baeab8bc47f3ab7a7abcc779898","418":"00569f007647ca81326750d191b2be1f4c7c946f","419":"7bcc043ad0a388c023fdb3227c71b6a672efc108","420":"6ae13ff2b6ea986dae80a0db3e3d6a284eb8b050","421":"8ae88a7131c61f65d4eb62787455b2b66a2247f6","422":"203381852858d7d8939e9da6e0e55a65fc96b0e4","423":"9bd0259da1e65a0d16561672277a2524b9a481e1","424":"1673c92875480c20951523df9731c90fc8319ad6","425":"1fefecf4d5174910b46d9497a7dae3cc70e4ba69","426":"0e0371817a2988ec1a4535934bb6251c5936dfd4","427":"0171661833b7d245582e1db7045c18d34c363421","428":"d636444a03000b93795d4a3e25fd1b1d37e17692","429":"25ba294cc30534579ae06aaab5f27bc6f83d5b42","430":"2b9a2888c9b20c3097c0b64c99254d4dae02514f","431":"425b1d26148558a36046d0d2cbe39e497520cd80","432":"93b0383c0906e54e9da706c8fc9aadb728a12f7a","433":"81af8dfaa3ecd2c970f5642ce547d6fd57c702d2","434":"bbd7a55c6e88ab71dd5c15ce952bfd2c46ca6c1f","435":"c548083e0764ddf04c35c8e4064da5171206428b","436":"98c562deff4a45afccbeb6081d7ad0a2c9a46c09","437":"090d2219fcc9137eb707f6380cfda8d425980d5b","438":"fb65e9d96e9f008a95994e688921cc91a4ea2d30","439":"0e37360430939764c009ec738439a1e5b4d8ad07","440":"155284d48fcac8243346b1698e6da17fa02532fa","441":"cc72ff48242b1b06fb52e17e2009144adbd3e992","442":"ba2bf60cee6aa0fec354803d073ed4cbfa4ee997","443":"2e1602c17383959d1b3d5aa65dbf6c5a7ff18ec8","444":"da31394e39bcdec42c02287702fbce0c00d94d6e","445":"4f628abdb2c2c32db950d5a16f74aed1779b5d9d","446":"70d208b0a52f32a7c0bb7715f717e0b19ef57085","447":"ed6cc6ebcb6646ef173951b4e6cb6d2a13996396","448":"a08599dcd02e6afc8c05e2310416d675ccd33597","449":"00956e6fe5700cda5bc930c1ef8b982d42ca26cf","450":"d274812705171203f1e8d0a767bec330d212a8f2","451":"65b18bc693536f124282e1585f28700ef3fd3295","452":"6fe6221c5aa6cdcf1613ee4d41ac20d7676357e9","453":"6580afff031fa614b8374b15d0585215dbec1e62","454":"9cd06ab2c446f4c23ed37cebef78bd534184acdd","455":"d6a69512cd242e32872b8c76dacb0af4a9b8b2d1","456":"1d513ee94daa2569b517d664b9333aa8b07b8a51","457":"2645244644c65d85931451ab12f2eb5564de2291","458":"2029444fa98d7d1a7f621dfe81330e9a7c5d2726","459":"84729df1775316bc38c66f423e53a63a3b81fe5d","460":"1442f135814c31f413128277a55762c6822eb546","461":"3e5a0b24e2066017ef6069a62ddce7fde8c85c52","462":"8d0f3d211e6c5a96ceedd6db3f23797eb657603a","463":"0a03bd6fa5dfc31d11700c0bfcd47305ec744a6b","464":"8bf80f049dc48982540597b3594d0445cc2a44c8","465":"942aab4a46ac63b993948dd2248d5d8416d06b69","466":"71d814f3c0fab9e2ea3223fee16c10c582a8268b","467":"11fa7b93618fed59f3fb2734449b53086ab1c0d7","468":"336609fcc8bd79faa6f8c0eb8a4432d89302a640","469":"98991c366c9fc5ecdcbe98d23061db6bbe608861","470":"92b55d1b93b80eaac3612ef8fca2677bd7d8740b","471":"84061ba075e2585108ed5c27963f237d6a90c9c7","472":"cb19373a5dec73f541e126ecfc787893ddb32e6f","473":"e8531c9735812e1e9ef2d0a73ec5c13f6e84ae3f","474":"0d2a9330e84d3bb82a5dcde88ff45443ac4e06b7","475":"86f7db76c94f48573c3e8f396934a48240b5326b","476":"9b7fdfb8782e42f224f6a7013cc3cda5dc04408d","477":"5670751022cf23f973028c9252b68afe7cbdb796","478":"1c671f5d9d7a4d784459885895c7ceb3bfda1e52","479":"9b32d19e46af00ec53d775f06e9c630b0d862084","480":"c0c969a54a6010ec902095bd1867b2c401ca5459","481":"47820ff88ec0ec723b586a04dbfce8e0b282277f","482":"c4492597c02d34c0cd64fb0096b9d0658dfaf88c","483":"24a699120f3247c88b097d62aec8e83ce7083ede","484":"c5cb74472783c13ac8181ed6ede0e392d526d9bd","485":"228a82bcad250b40b08c8e6b5c43dbf517cbd377","486":"aefcf7d4f3d966c58030c956449a13c308ce266f","487":"8056ee573f31749f63ba12a314c32faebba9d03e","488":"63c5d75af5e45be05c54e46bab07ed9d879d0894","489":"9c3633142561e8a40a67e6d110a88cda1ad32bb7","490":"ce72866ac641804785fa78085b0b06c117c012a4","491":"d50cc51b1b3d57a95bfd1b426d3c4619815e8d18","492":"f103c95e12291eef23f912877dcd534104bf0cfa","493":"29027dfe031bd1d685cf4b6c18e0e725e80da107","494":"305b869a7152fafb43270f448a117613f5acb32d","495":"3ea234b92cda5bf637fa4656f7f3c338b9c02366","496":"ea27e84e60cae4599335e59814d5521422c659a3","497":"322e3b6ef060a6bd6a041ea27c13701979b6fe8b","498":"163352c28deb856cbc1676a85f717c651c2d0b22","499":"da1e1290df1a9206b7af912a0268563fde3dc715","500":"0ce2db95b183f99c945394ff6e773c54beebb477","501":"783ebee9e8d09eb67166c8c21d11ad7bec676cd3","502":"7b881332aa2a236dc9be3f38610e00f4b42d8a33","503":"5bf1cb1c804afb81296f56becf9bb4ecee2cd090","504":"45b0a263930038e397394dea5abd9243bd30caf0","505":"7ad4d6821e4cd4a7519e82e46c55402c91f43355","506":"50f0e2fdbdc09495549424053c1bfb6b315610c2","507":"659ad17a0c2c40deaa784f4c44570ddfca422613","508":"0e92cb24b271b61980ef766dbcca489af1cc896a","509":"0ad792ca539bb62e9e29c35e459787b2c6d2e0d2","510":"5cee90b85b88e4de1d51b2963613a48b68916ac7","511":"c85eac363a2780e74fe638a4ef260d79cdf7dfd6","512":"0e45939bd8eae2e4897bdfccff859cd86ba32964","513":"8e8a312aeea66265b556b6d47295c82e6a0d33e1","514":"25821bd1b451053e1da2434dd6d9fa116af5404c","515":"2573edf113cb0f8191495bbcf0821fb76cd011e7","516":"cef6e6636daad076a3e8add2725d7ac76f4ef9cb","517":"dfa0e01dd7a92a295c3fc7a0e8d579fc1687a038","518":"d9bf8d9c73fc2b40db8ed17fb685f6d040050057","519":"477dcae2f6d5df0fd63c8bc37c1a4bbfdc9d9aca","520":"0082bff56884fa4dcf2c8439f1ff8e7c47f5c350","521":"c4da501c7183716dc4de01a9128c0b0b5609d7c5","522":"e164a302ab6d8ea8e16ff7cc324e16573f7f52c8","523":"9ae39b1b2a029bd0134c4e115136a7acd91d0fd3","524":"fbf95a25b8e350b18561c65e9c7e0c894aed164a","525":"2f8c88fafcb8417e64555f5a7c1b6c2d1d354cbf","526":"c128086627e3f04c8ce0c46ba72f81a3a8d9f4f6","527":"d918d0072fb677d35e0f2abf8afac6900442b3d4","528":"142087d3fda4b83272dc8ccf0c44f167717b5075","529":"aa7407a50c013b970171c95e598735b8e44c935b","530":"ca99973a761f961cb508cfabbae411c846604c7c","531":"b93a7da6fa6267d2a2a204717a83e832dd44e108","532":"895ac6ec9a12822e6b8ecb58f9737aed2ee35acb","533":"a7550d64f6d746681852aeba6d5536febfd5f0d3","534":"8fd2eca5fe7473d1c848c27346cefdb9bacb1301","535":"8fba8c41288ea0b2058c41d82f34992a52b34ba2","536":"c72779898ee3001c1cd72a3472611d593f90cef7","537":"d3ada3b13f0bccbc3bc7cffad3f030838bfbc6d0","538":"a5007d2e180385e67fe4c06eecf27d581dc7db0f","539":"a15a83214124ac3e55d8a1ef03c028a0e61564fb","540":"2732ca837cd54d765410656caf389ee969f32621","541":"0cf35b501d9e51fd21dfb4f72fc5765cfa891008","542":"4cadb4a6d1c728dd1c6a1df1fcd7a99a4e530deb","543":"4f1c897a05957932db2d0172d6ae5acef8115d4e","544":"ecc1a304e529528b656f90cfd5c4693da6aed031","545":"5ebef85aa9c97c0cbf60e095e82fcd15ba00a81d","546":"f29818f8c1790818ad871de01eff75ced3ccc68b","547":"a35a6d60f1853d52db3eb99fbb08c70e95a912ad","548":"303e604aa6e447a0e140ff110c1eec59966baceb","549":"ac6ef3da52f4ddb574446b6a96fa4701790be05d","550":"f5ccd96e87a117b73b5eef9d8c2f478a80b4f646","551":"5d94786428a83e3b4fa2f094458223f79398604e","552":"1faad55fe36893bbbdc8566151425e1b3caab0a3","553":"b8bd4ea53c1f5c47ca9e988b766c96905446cc28","554":"264cec8654087c131b483922b12edb9c416a97dd","555":"6887af19dc49c4f7c98c2f2130793da9d99aa585","556":"078b7993b74ad3ed6d3dc6cf7d416b88e8e75026","557":"8194def1ac2313190a53487a5f246c587796d857","558":"7747a7e83a7b44df463f5e8f81f68ecc0c038571","559":"a9ec36df50f789390692c8c520538c2ccc9d1028","560":"91d3100850e4cae3b8c52b27a3f9b9125654611b","561":"ecdf4e17862d162604e3cf8e532a6212ef4fa50d","562":"3f526fd08e84d725709317fa569da0504cfc7344","563":"f06c7fcd8575903259dd4ab398e167f0d1511dac","564":"eeafc2434bbd5f63995c206eb3eedc1a01550145","565":"93f205a9a655745dd866899cb4fc679cd60c9252","566":"c2097879a07ca4aca883311a60293af99887291c","567":"311caedb65fff281470100585d90f2c672a9f97f","568":"bfdf939c1b640c32bd9c9b0a075fa9e41b32a767","569":"b73a1d52f743e93087b6cb3254c7c57bc6069e30","570":"2c896f04663eb92f2e28f54fe939d22542a52a2a","571":"9a9d268cfbc2f0b973d5f64021326c4f4ca03491","572":"bbff27d942550cdecb5583ff206fa07b8bac1e1a","573":"7f12a305000d1b54d7fb65a30b0681b0cbc0bcaa","574":"9421641b3699e5682d6352c8e129e656177bceff","575":"bdfd9dbc612de159e42efe1688b3694c0a8e2365","576":"d64e886cf8d1c681284d3226b828b2ef661f2e22","577":"fdfd718572385f913da89bb1758db6dc9fbb0ee1","578":"381523408be14614d06753f172f01a268fac97d8","579":"2c4bde86a59e38e35305ed18b714a4dd21c6d4fc","580":"aef528766110ed9e0b4355b2f93ead16c68f4196","581":"ee6f891c5fe8f9ae0ce8346579bb1cee2b4a55f3","582":"4e2a346d596793741fa341179440a2d3e5b7f997","583":"35511226f4e0e8aa39ebbfd22844fbfbd0070799","584":"1511697652b846369874fc95721a6531446571d4","585":"98447518a6a2e6f2fc7043c090ac8eaab4dbd873","586":"162366bcdb4cc7a797efb78c07c3e9e7bb91066b","587":"80f6c9099cea17e9b21ac17b23fd37e78b2ffdda","588":"fed4fa066b8c56114ef62bc6b83dc25e5f5e78cd","589":"4ff28fd5025fb60bc6003cf1ca04a629ff634c2d","590":"f277c1ca350cae36975fc98be4730f67685f7dc6","591":"23a3e0a7e4bf1027844185a2ba6c8cf77c5eb0d0","592":"87954115b2a3e90387d7d299420afa7d6a5e2845","593":"66596207f5e6a5d8a456380a90048a9024cd18b4","594":"130dbac765282bd85c053dc9e5753aee75375a5c","595":"302263cee909b4dad7f4137bd6f0c117f8708bd3","596":"4179d8e2324ff8a3b3b94ae64f83268cf3fc9f49","597":"5d099e4edb6a5a4ce1a9388796de469393541785","598":"30e19cfa8ab5b4b1a116240de100e44288ab7db2","599":"461b4e2458517d8ffa52ffc63742a35158a383b6","600":"88192249582f78a48d4e581cc03f2f96261ca9a7","601":"2a8ec34500e2f90c5070fa34317b50939ac8f6f9","602":"d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3","603":"bca6b4dca4dbf282a7d4b0141d15d485f5ea274e","604":"8b80aef602b6b65d1fcef40423cd39cb6516d1b6","605":"696d9e4ad06e97527eaa3c95c78e8131a173e198","606":"3d2b0f22f8d2479102b77c9f0df1dbf1bd9f851e","607":"b3d2e8638b22a2ffebab9faa5268713e6ec1f2c1","608":"8e472406ad4ec2811a78296d5acfc7151edf1bff","609":"7a60f9516e9dee313855937d854a1931b42086fc","610":"48765ab4fefc240decbf0f81dd033439ab95096b","611":"c720dc32b9487fbe05ca04c387f8dd1726746f1c","612":"0b809bb69855b5bee3fdc96521c34d7a95d56913","613":"ab81213f73b7d8054b3f66d2a0bc4728d119d5fa","614":"069cb34a2f63797e7bf7e4f88f3d921e584e74f5","615":"eec2311b64672dc796c146ac39f24f26d311348a","616":"4cb1979846e6701f9b7a7f1bfed447ca3aaaae69","617":"b7aa030471b33ac682c4fecd9dba414b74e13504","618":"1a053536691a58ad65428f24bfe4362eef9fc6dc","619":"7bb9e11618932e0ef2d62f9cc0babf6a2878e067","620":"594d2c0fb1dc9fc0eefc5c50c9bc5ebc4dee110f","621":"8c5ba1c914eab16b705da03352fe69d5bcfc72ea","622":"18e56f63f1ef0bee7f7125fcfa1d46c931559ce2","623":"7a11eb364a56167e1fee9a52c5260f0ca9e32808","624":"742d581cba9c8716f30e7f8b1d45052e334a8a87","625":"62597cc93aa6604ee531ec9b7ab281b46633adbb","626":"06ac91f367b0c7af125e3a67417bfb52c62d14c2","627":"a167f78d44f5c496a51149a353bc01eec8965336","628":"7e95632e12fefef6ac58f671d90466b49a3c4bf1","629":"f6669bf41524a385a498cfde04a31019a5a4bf18","630":"172c881f7aa9e5bfd453dc9ee2bb2e2687103638","631":"f112ad62655e0d2cb8f6e795cad77cc375bb208a","632":"c6053887119a560818f1f3cd32df0c59737ee1d9","633":"186084b5df9eb0576aabddb7424833f716da4452","634":"6969b9811ed0c8c94e984ad4d0a4c0558cd94878","635":"1003e7dc2b77ac7676046bac71854bf6dd9a54ca","636":"6267e717e7e70a282e27cbb95ac6b3cb93403fae","637":"f8dffc53abb574eeeebdbf8dbb10052be70fd5d0","638":"adcaa8b63e7e3f10959e37ca0ff8cd71fdd6b74f","639":"64fd8f10fd15aeb511973f2a85374c34c694ffcf","640":"b7ff5bb5fe6ddf108280eecee662646c1e930440","641":"f2f7c987f262bd0aeb3d45d62fc419d8a2102b97","642":"5924f1b2dcebebee06b5e510a3a2962354b99809","643":"93aa2bdaec8ac048994bae6fb2fbe852dcdb28a0","644":"16962bb2d718e3bfdb7e4ead48193a8adb5f9e59","645":"622d7cf8f8609f6da854a3bbddbd4c19e7a4f266","646":"b455a956e845269c05089b8cb1bacee609412b8d","647":"0579777cd0b132a6454fcb1bd609eafef73876e1","648":"16aef42d9b453dad02a7aba750825bcb6e049bc1","649":"51a07653ed8ef7a0145be505bb257d317e2c6451","650":"ab42ab145f02ab3da5f01bd18fbb2111e611469e","651":"3aa6c163ad9e657eae11323a98e65449b7001b66","652":"08e6d7936377f381afad027291f6cb72531a9f62","653":"a136ad1eab71821964207ba89ef5d07696d54033","654":"85611149ed39ecba065ab89cc0fafc18929245b6","655":"02846c0c089d931fdfae92f0df4b1c979fe120a2","656":"5499b7ac2e023ffb124ee5e9dc1c434911d1a4d3","657":"3d5889713c530cd2559d9edd19fd9625ac0718d6","658":"c0e97f6fa973d226bbfa680aefea9ffcce3a08b3","659":"fb6fba73e1952b8f658761a350f02fb2d1d28c35","660":"93029e4f8a123e8bbd1eff27cc636dabf82dc0f0","661":"08835d8cd7396bb941697d2e68c285ba17757d0b","662":"5c3f78e2355b64c4ded503af766da9279380b748","663":"d2e5d458acce815f2ad5deaec21293467d9e9c22","664":"a19b9f68e6731b9457a3268b2e6d28c3964954c8","665":"a5a01357ecc2ac930f7263ea5c2796b377a97bb3","666":"d532d5c513325eddfdaa6d73060d1e9f7e7d63e0","667":"9dbec5d91ea20c0e3ecaf10bc4ff8d62402d803c","668":"b0e5a1ca466e5b4cef42da2bb500e8bda7f96e41","669":"6a5092a1cdf98022b1bcf5fbb8b7d36c1e440416","670":"be6a8364c591fefb3584cd712ac31f9f028ba69c","671":"d07975da0f6382d16d312ee409d88f0c35f15afe","672":"f57e2e7941398124ae85f337b3c396b892ce7560","673":"934e01d4c79de7b0414c60d442832e4ba96f5c32","674":"ef5913ac3d588f0de4b28a57f81a79cfecdbe4a4","675":"3726a87ba838eda5febf731457b0180d3d4a4f64","676":"25356a288cfd036271d13c16c534c9e6c160cf82","677":"ca4bc509c4cb7e66d4c77e1076f00a4b249d9ed2","678":"c88b564f6567841d9a57c6922b3fd9e01dc4fea6","679":"b5bac83950808b7cab76c884404b019277faba95","680":"6c76bedc6dbb4fc5715060bd54b3de668a032411","681":"9e825f22eaf5c9e8f3a11c4735939b0be2aa7178","682":"4043b9f526074db22024687c101c2dedc3fd9e45","683":"59a5d097baa8b31ea886f623869aa2c1f8f27f36","684":"cc3dc528115ca2687e42a829358d3c30b001fd9a","685":"4f2d6de514b2f67fcf3c3a8db6053dac51966a52","686":"1604795f2f2a39005971c38dd14846830a2b04ee","687":"c6ed86d93c136365d3f61bd237c75fe8421258f1","688":"bf13c1dc27a462136106efe81c95766198953815","689":"371eb0818fbc91a02d3ea51993691d80cef165b0","690":"1d96551197ec48eda05c1ce795b8c0a2d7c9f195","691":"475f29ad0e537ee7776b10b9326bbbbb435bd273","692":"1f06863f61beb5b0b7f32b4faa36b840d7444d1f","693":"44252c984de4c92c11bd661b8b0f0266bf906416","694":"48e5a6dd1303820fd56df7fb44c14c70608e7100","695":"52fb8bfd553abc2f8f488dbcfd559c787fd7baac","696":"056935031bc5cf0aeeaa0946320de26e14a1817e","697":"0458311cb0ec92112c964abb086990c362a40013","698":"1a9974e623287867c6debb2c794df207305715ff","699":"a1363625abac6360da491adb6c0e134d960ae294","700":"3915e31eb09cb1fbe5bf7c6f89495e9059af540e","701":"d568cd7d015462e7ebc795980e0b413650defff9","702":"ee3b952ea6e7ef2b2ed9e0ea705db30c8ed0b365","703":"116c57babe0ccd928048faac17d83c4b142e938c","704":"126853f3b04ce0a79a71ff6749c509bc3b810aa0","705":"9a8e2e39ee1cafd891b9b4afb4e58e441dcfdc0a","706":"bcbaf9d2eee6a266b2d2fbad48c2a089c1c36244","707":"6c7389c3c1edb1253cb3b2a51f8997e77f0f992f","708":"e5fc40dd94d6fa94aceec7c356bf953c493117e0","709":"f080e7f62cc50b8f1e922102414ca21a01647076","710":"0f1b97d8b7197a48b3ce22d139dbed8c5170ad59","711":"d8f6a7dfda0d4cbc358e86426de7f2817b1bb573","712":"8dd220d119a35af83567e0679bf2e8252a86be39","713":"47a49468ad06e9ea2e0f6bd0006a1f72c00ea590","714":"30303f35417a054f8b4fa70b7150f6fd3f7ff746","715":"e86bb957c089316fba5a9c43735bfa6d9ea42f4b","716":"bbf70ccfdc5e386bfcd62fb7b8d01aa3f84473e2","717":"8a07e79cbaeed972b2d392d4267aa611b81f88be","718":"e235ad7dcf6e97cd372f09724dc947c5b1efac79","719":"41fcef711faca9013fd0980a9f6ec1d23c9c76c8","720":"7a70764c4e1173ceab983a759ac3c665a88f2195","721":"4aea3547974399a32d7aa7c007b10bd665e93fab","722":"94cf3f2c4410fcb06a90abebd99f7113c69e1ed9","723":"8bf831e3398ce79badb8e2f2d4ef70638b054228","724":"ab9cc2c6a8d35d7a145cf608ff9dd7af87213253","725":"78d08b8ab4132defffe98ec7f80a51452203f70d","726":"4168df2c88c0f942b955ca4cc817f5aaf05d8fc5","727":"17f357f3c6fdd86f7e8a141d1e3b9acb2e59a89a","728":"d47a682723f710395454687319bb55635e653105","729":"bb55ce957aefacf775422bbff406f21d83be0545","730":"47f1fc1fd5c0be10e5446d1e65a2726cb243a30b","731":"41f9fd1c997473d8c50a4f7f61eb317ac7a6f25c","732":"83c64a66a0fff925e49a4395ae52d7dc450df5e7","733":"2760dd9cd9c0ca5df8bd9369a9bd9a43a05f5204","734":"756e84448d2b21e0aee58840dc2872fd359a5c7d","735":"61c425bdda0e053074e96c3e6761ff1d7e0dd469","736":"c9c6e84d5510f0eb34ec40ce74c954d4fbe2464e","737":"bd3f087d8f7003e9776078f8f52f4c728a734839","738":"a68e53c34f7c0c6a6d806e5dab0bba8e92c85f6a","739":"3dcf5d3776bdd19576a4b2841d561f35514f3349","740":"1ff029d6b207c1bd5d3eaaef9ba41fa81a1a1913","741":"330c88e277f24ac0dbb0e72f1dd8a60ce14948ce","742":"34be38f7f18f3fb4a58256ddf96365f2934551dd","743":"21f93750f737f1de1177a0e831c7e273851352c7","744":"febcbbf070f0da26ed51454d08b6383aab541663","745":"35f78de3f4f78f186ebfb83a495e7b16b8680e9c","746":"011869f932f89d047ce2bd36d73a95cc04888193","747":"45cdcd93de82c1c5cf23ab5dc6c9e4d87c9c7993","748":"e985f056638f5433c541f40f45810300e2210b6e","749":"8597f2fd702744315bfc6315cf315278f9a0b258","750":"6c5e40f3c6a1b057b36a73d9aaeb79bc937d4959","751":"39e8c02fbce5fcfaf9c2cb49bd21f697ce54f679","752":"f81d64a772d49bcc2eff837290742a955ea8e93b","753":"0903826c840078e12fd381e104bb598d70e6ed75","754":"a4e67bcbf912e13cebbb1241d05d1ca0a1df9df8","755":"623b1c61aa36048a38485a44551cb3fdcbcc827b","756":"213e3b93d0c911c56d4c90a4063e6bf2201c0150","757":"c4744a7c2bb298e4a52289a1e085c71cc3d37bc6","758":"e6fc6a23c057ce90c950adff480afceb07979386","759":"8500b01cbdb3c92b83cba6c4a4f6bc5eb46419b4","760":"6008c949b32267f53a51eb60cc8d00c57a3b82c1","761":"e9d87b6ffdcc812707ab1721a677fd6ce4c7d9c2","762":"bc5c077cc0437e5529aabad7880427fe9a8223ca","763":"908c6b1577a1f5309ae183daf2e24363039f22a8","764":"fbafd188d94d958c5f1b6f62e897ce02211cbc23","765":"1fbd1a1b5cadd4e83a516898ae47a222fd448be0","766":"b1b9b770acb5f42ecba3270732a0b8f6f4ac3ff5","767":"19a939c3ec496de2882f4c019a007a6331187e8d","768":"ce3b364b7e6358940ce97d8d5887a65e5024ca21","769":"4d5247af0cc487ad70813893ef945d46b2a34c11","770":"e79d1206292bc5e67ba19737d87d4b2ea4a37105","771":"ea667d3f5df2954c7365b8d1218889e2fc514829","772":"97ede42d86fabe465528893561dec04da6947bbb","773":"d48c92e3e34e64c26f0bee4c4dec3e5d809dd1d7","774":"e2d2f64b3bb200c2c3db5ddc367b06311c369341","775":"1b4a45b3d2f7573451048d695fbf81cfcee9253e","776":"7ea0e91c5d5dc73f2133bc46d7ebb6cb83034dae","777":"a729503f528d5f0be0f897aa1841e1ff8ffcb313","778":"e4a9c8f91acdc0620e25adce9d67f49c14e990b9","779":"5e9c85235210b59a16bdd84b444a904ae271f7e7","780":"edfe9dd16316618e694cd087d0d418dac91eb48c","781":"437727b6c00a5eb4944600091f66f41626d1002d","782":"43df433e74d45bf5a37e457298211d5d35264109","783":"039b1c1210c437f3b3ce6e0275ee2137bf5b951c","784":"67262b3ae544f51f7480650b064a740816e194c9","785":"e19b56cdce8eba05f82ca60e2152f9023c2bda58","786":"c0dd6f4ad8210f959a5fc50049a2da960165f741","787":"01f2b214962997260020279bd1fd1f8f372249d4","788":"80d26b206ee5621169e4175f2f1a6bfff464efbe","789":"5019dbe8d1da5f128f4f373d6849095cf18fd519","790":"a0278907a87ad05555297a678481f906da98bf73","791":"3a906b77fa218adc171fecb28bb81c24c14dcc7b","792":"0872f4a6e14c6da98424e6daefe4d9b626ba4d3d","793":"76c4f474db9f4b559af7a93fc3d5a56e8389e393","794":"3fd45fc420a882ab2fba3166ef08f376cc758ad0","795":"67d354cd3c40d263a8d9347a34562b03c756570f","796":"a27415b81a7989e0049bfd18714fb5d4f8f4e94b","797":"f5d1dbdaa6c8a44f388f3f7fe538403baefc1252","798":"d479b283c979e0da3ce6b12ff813f2200465f3a3","799":"cb332b26162ee33f73e03fa3fdfd94a0a3fa82cb","800":"2c88d7486f9871cb741ba3c7076b8adbb7fd5b68","801":"ad7129af0644dbcafa9aa2f111cb76526ea444a1","802":"3da9ea9cab33c9e52632e70e85e184c46d31d590","803":"ae5a42cd7624365fceae9283c0ed32198f5c2860","804":"6ff64171a2a6f4c9b74784796d4c8cf07668f39b","805":"c2f85cb1a4887ab078a58b0b4ae6d20b6ae0efb9","806":"3e8d5d777e2d4b329513a114bca0dee12d6e14d3","807":"1dd19753c01476612db6f668967ded7b859deb83","808":"ade992f2b154dadfa4c370f457da85eae08a18aa","809":"0a702c3d66a614e797093c43794c1cb1906c5057","810":"52722be14cf55c8599459cc32b40e3635cc4c368","811":"2475ba09351c957bc60f90774aaafe8d81aa5b8a","812":"1bbbe12b060f54a97a4e81fd23cbb7932ff9de53","813":"cae979ad6218066249a7f9e134a31b47bdb1f4b9","814":"ffbfce72f12aa0be619be5e49698c2657853409f","815":"db9b452f34e5dd6522acaad64e1d0d11868aa5d3","816":"034697983626566addc2c2832d9a176e66fe1bec","817":"3a8ca1d96345fc7b8291650149b183e3b569559e","818":"2468c0ccff91f48eb2111ad3e8d4080fec2f7ce7","819":"45af13e3e9d8ce9f368b8c7b13e231b581ea0443","820":"8bb24b335845441564e2f23d2656102b27d6dfca","821":"3b00f5cbdcf854992e43b5d31d7d17dd6d317aaa","822":"db27f121753a4517882da37f5366219fd36576da","823":"2e84295dbe37cdf9183e45ceef9962754002a9ca","824":"92443e393dc076df1382771a43707ad54ac4b313","825":"d879f0ede5587241ece22dddef408efc6dc62dcf","826":"50e7b940a3bf3b75cd4611eb8c7c6efbb61f2fdb","827":"61fb1ac7d49258b63882c4b7722a3716a169d745","828":"8ffc8ebfe66eb9fd60906998e8c7c1bf6b333622","829":"e853ef5d79b5584f4476e82c7a6b736c53a18bfc","830":"913ad51defbde43f6147d8b79244a5dc4d0a2071","831":"c815ac9e6f15fa5fe34c2d52d94b68113576e7e4","832":"35e082eabdbb35aa8890ea2d15e967ab0e48e8eb","833":"857b9342d773ac4e8a645857c7ea2ded93f430eb","834":"a63c2a4062e1d9ab75b36585bcdaa3446cf833eb","835":"2f42a79e76b6b4f8b8050c99d30f32aa9f906f89","836":"159d42b6ec043a3409b773ba2cb2c73e72fa1056","837":"0603f0f4017ef28473e1467ecf5a84893230e9c6","838":"0274b1ac36f9eb933c13faf8cb7e862ea219eb25","839":"499533050ea59697e5be630eb0b954717a3bff40","840":"a7cb7c67a181c35f2e2dd2767e21defc0af9c14a","841":"75ca384b69494c16ad7e814d069745be854082bb","842":"cfd2884eeb5031e3dfccd0292cdf3cabf7b901eb","843":"959f09931596459b6022aad4d253461ab0e75e33","844":"56c51fea80589e5dd75a3efe5bac023329b81a5b","845":"6a3fc1599bf6faa2d15006f8303b772e92c8c3bc","846":"e2eb9b0c04df959ff26ab0b9034bb24ff878f187","847":"c587f1a415b9b724fee5954d23d9ee2a16dd149e","848":"a3d652dd58c60c10582bb9d6b409dcf927bfd561","849":"f5780dec0e7532caaf520d943f6553293a4c9dec","850":"84174325955f55b3cc2878d1b15b430fecc856e7","851":"e74b55ce5957ee3df5c63e260e2f22696ffb6b54","852":"ad6a97b9a9019229f15174d98354e4ec87e4248f","853":"96dd86c4fe31d137fea73a3886ef849a84712408","854":"6018537da402776cc08c12a56f0064d0e41f992e","855":"2dfd336a2beb6af1f7facb5ad9ad0444467ae5fe","856":"e3f9dab374b133f46215fa77070a2229f5d39a9c","857":"744389b9a207724f68b966f0254915ae6577705d","858":"76ffc62996b7add5ac3255c105c32a62dcbed3f2","859":"88d073c4b9a148a32932368efd853bb45899fde8","860":"d4d26ccbf1e64e725b5bffc08ab28a72e271facb","861":"6e0bde6ebe84eeb745c42c5901332cdf307bfaab","862":"ee38fbbb9a7b38d707c6e98afe72be237fd33d16","863":"63052e581f1b272eefdbf109a230c7ec87e1f79a","864":"95f29543d5ee6f35219121ca5cb87018d2b52815","865":"b4befcf6681670eb01385d931c24ed3cf44d692a","866":"1d8dcf5e99557c7d6b7015a280e4043439ecd1a5","867":"944e44cf94dcddeb8727d70f58a86ae06c62e529","868":"75e94f79cd94636611e0421d63b9908e9a814597","869":"982e260e1ced1063f7b9227210601a34a7df21aa","870":"de06fe87e4d9f989a7509ca977623bd5aa163167","871":"328e3c9745911d84f6b075e6ca62d1ca00d856f6","872":"34fdd362440fdc1fe1509ba9d83cb0fcf4282db0","873":"e632d3f4c160704a7d2506a71ad9ec0481478dc3","874":"acc88786e83acc3a7fc0280bbe592706a8034c8f","875":"447a36764df662076e0be38e2ed14aed7f5bace6","876":"d33cef96c8d74161346e09a3275cfeaeb412d31b","877":"6d5bd04cd1c8d27a095bf41fdc71d8812ec75dd3","878":"35b67abd153fc7743a7c635313273b5577e8ee00","879":"740db108d536a8b6f53111407898f4ecaecf80ea","880":"2cc6faba2872e83cfd28434cd9d84e7eebf96f33","881":"2d829c524dd90d674b64a3b4efc3eb3292009702","882":"719ea70b55fbcd1dc5736d2edde796a04b10cbf2","883":"7150472d17a6353aa2e0af513be91cf9406729e1","884":"5aefdda20616a65ada0ba5dc360e5d4981633bbf","885":"206704d164acb4eb54e2f9258477b02e4a452b50","886":"4d9824620d4cd0a8cf032bbe495d7982dc1a7ac8","887":"1a21ed83b4c06d96db34e35df8b2db24fbdc4c26","888":"c874421f460d0ae1cbf740264866294d0dce757a","889":"87d76615c649357d76c6adb5d317ced97851a0fc","890":"a223becf074a6d9ff6f1bada0e0f6eb15fd69341","891":"2957bdd2bce3124f84935277231c2867a9a4ef4e","892":"bf86aa7492eaed91872191d51fed7cc9ac385442","893":"c552c158776ad85814ef4fbca5b040d443573dda","894":"03442d7517f345ace9640b44a1e056d7267f1a8b","895":"51819d708e00c0fe7ca3e8befc4f8665ac12ad0e","896":"40fe3388043ce73a93a14b33dafd533ac0baec55","897":"d6c70a2ce72ccc11461860c3a738a1f7ca8d7309","898":"47b44ee5c47d4fb569d4e997f71bb01fe5bdb373","899":"057e59cef6deef4220740c05ec058165344391b1","900":"f3be8fb277646ee961974111c04579e157b341fd","901":"80f92649dfdde7c4e1c0d46831412c3490b77fca","902":"5298ac1e6643a39912e0ef2a231ae2d3b6d47a0e","903":"13bda78db02c8be8ee01dcdb954385d0cf039050","904":"109c3c35e56365f245e5c2a85d5339706b3e34fc","905":"abb6fed2839d4aa79c93e133989a209d00b8862f","906":"6981c7de04c5481c36bfcbfdb3c3ea3776a22ed5","907":"d1c2702bbe0594665bde6fe81ef0e129182c9f98","908":"0b88eec9400ef4e0c5a204d26d9b6b467f0d3c3a","909":"e85b31bab22be578872fc08dcabb460caf7aed71","910":"c1c65e5a0f54b34296fbf824b86a3df4b50c4775","911":"8b8274529958ab3176a79291a36da1b80545791d","912":"ebea5f14666efb2ab1dbba1597cf177355109e66","913":"3852971e04b08a41c3856f19aaae3f318cd5e359","914":"657ec6e3d6332e41a2daa2352ecf2bda0bdb8038","915":"739be8b7a88921bc23eb6bb597fc8ce2b86b5cb3","916":"2d1e289a6b4d41341f24c4d72cfae660891397be","917":"85ef684e8f761e31cc8da9fcd6fe37c553d093f3","918":"378b834ab661464c6d3a518bf5f112579eacc3a5","919":"310feecccdd26690612788622c887bf1823a4dce","920":"1c650aeb2862c1e44a7bc21a2b856a0ea364dad6","921":"5f8943a8eb911e2c6976861422a35425b9de4c78","922":"33def44beac530f5a5e16e08e81d134d230ed632","923":"c2cad3c319f2e2bcd00d32a8903d0d595395efec","924":"50ca60adef5f4adf4f1ce18a8c0ab37c9232810b","925":"8aea804f26e2ed8321bb57e76fb3b0b0a0964506","926":"9b534639bcadc9ad232b338e760c523a4d74c8de","927":"f5bcabc298499a4b576a2883cfe641ed095896d9","928":"839c850367f7e7835fcaef588ae3309adf976c36","929":"ac382e3f9886570046eb1775697a4352a345cc85","930":"d72e2373c24b74f63a2c0d2a3f2fc494c82ba1a5","931":"38a91371928f8ec3ad0f0d3f71af06e1efc0ef9d","932":"6624ce2d2ec3b3119aad5664f66d72ca38679f35","933":"e5e851351cfb5ef6ab4b00e30545283dfa1959e4","934":"9c9c5596f8a7a41fc31e5376a4ce1de9b93671ae","935":"0f192e9c7a1e3fdc6e051fc502f74b04c53bb3a3","936":"66462bfd498cd8b1ea0883674114db2e528f02b8","937":"bbbc9b092f9a8921f5c6c0c68acb47c50acdf215","938":"3ec89e12fe08eb0c6a5e805be8e0bfc5926f6ad5","939":"6d77d7467f993780d02f3d8ea563959643d48f89","940":"c81ace13799f82e53a8c4cc8ccfb30ec2c0ccbf4","941":"8ab812155692852fa0791ee19a852493c633d4d2","942":"24797b500be4a205199a8cf108d096f79e7a4eb8","943":"b9b639522465cc606df878eee62e7f9c4bf19e62","944":"131315a2795054d85cdbc31fd31e2439b7b0a1bc","945":"18342afa1404e66a16fd04e53dcfd8337587fc20","946":"569829ab76a311b1f7f5b33d37ffff6a3fae6490","947":"ef2f72db7a4d97da8108ae85751eb13c4cc64c92","948":"f326e698768373b2dfdba9608f75841d55a9c6e5","949":"9649ce5d8b1546992304cba084de2ed6fa4a32ab","950":"abb90e08b106623961a2cbed107d2a7ec861b6f5","951":"637305a303d00dc57d9ce3435797b1f2282d81fb","952":"a3e6744f39b2fa2f133099832d84be8bb633c6cf","953":"9fac2ad81a561398506ce566d897f7169583b4f8","954":"3245c96d239994d5f2ab25b41196861977cbcee6","955":"f98e135986414cccf29aec593d547c0656e4d82c","956":"a609c93d72afa0721f9a7d03823e431e57233914","957":"3fb29d252cd7ef25936994d455c32e9d15e95c63","958":"3de0e65b87d59a21b35ea4d8b6173aab94b093b3","959":"59dc8b35813f2cb0a7d6663a0b7165495f41d6e7","960":"e697c495d35513c864e0123d5177210d56bf21a5","961":"4214ea56f7f145900e646556e125cba8dd5eb713","962":"0ef0b6d81b7304d475907098099fa1fd169c33c4","963":"515fd971491e165a30805f10079f2a18306cc57a","964":"da1a9266ef25c988b4cc30ab8adc0799b775b140","965":"330eb6a85a974e132f738353f85824f360a92f2c","966":"b0d1b2812c2499dbe635f0f33f0948ce9ad4cf89","967":"2aaae14aad0dc7612a1af5053207b3f3c6340772","968":"7244122d7a8039c7d35f431b581b1894725dc79c","969":"cb37918708c3cc8f1c5c06fd035bb60b4a55c2bd","970":"fabd293157b9c579fe4f166980d69cd792632763","971":"f3bc763fbf924ce363d06833c52f22ea9ab83c10","972":"141eb2166b7ce3f4bfcd1bcdfae068da0b25cba7","973":"67be8e7047ffb8a0d76bc6148a865cafd2b24199","974":"1639113de8f6deb89c458b1a5c68280b8c4c764b","975":"9ee68ae6997914df4e122729c4735e24e6840aee","976":"e245f15bdddac514454fecf32f2a3ecb069f6dec","977":"e85f83d76b443795a9aee58e51c6cd76834c59f9","978":"8f953e700223309674a2329a8fbe41f9f58f2f5b","979":"02fdee1a6130ac2af220b1331c738e95c89e19e9","980":"3ce573e678778ead8db852780d00075967962d83","981":"562dc3493879c6605d1981b173ec2020e4d6e903","982":"60c1f0796e68b594e3e3d726632c27ce54b8eb0b","983":"7e579e3d1b4f27da51625b985439433b9fa77280","984":"d6246cc6ace146bc8c1f4b004370386878b634fe","985":"fff6bb9e7e9cbbe951f6a5b823be4b05896696e5","986":"0399b9211e6ddb6a74a8a0bf54aca7ab5c8de296","987":"e9de3570a34c05df980ffa9b4e8eb1913ec2643d","988":"ce4876ed845d8e041111d674dbcfdd4b2957a8e6","989":"958c7ca303e1ce8f04bf7abdf106bf9044560afc","990":"1be329a8b514e9be985f6df42d2091ade2c42d85","991":"d6c7bf822a75d07ce318b4795e9aa1517d507e98","992":"cf9afb34557de5a524a3cebc6130da9bcf343b0f","993":"a61854cb81538a2edd667d84b6127d6b8b4501b2","994":"cc57fb7167266c37e52b5092fb01a4a736e5d2f7","995":"851a2d0f6295c294804095cf6735b8ccd204602b","996":"081a386a2a314b5bc2da6fd20ed3e7cafbcad76e","997":"edcb7cf5a4671041038fdcce918759477e376159","998":"22421f2dbe66d1981c695986450b943c849865a2","999":"44ced4b9c1536c1ec620d48d68aec7f8e982c12f","1000":"b8fe3db4399019577ad4e6aa8ab668ab40a93cf0","1001":"c167c000a53365c4456681c8246ebf5bb600ffc1","1002":"b7d01b084ae45eab1485cdcef0f229631ed9dbf4","1003":"5173e66b5ce4250878d57dcc45d9c51249660ca4","1004":"ae6f8134a17bf0e60116f740264dfc50e1417ed5","1005":"7d0a0d7f2a085b41981361f6e385c168258ffd5e","1006":"e0afc89232082d4c5002832ef939bc642ba51fe5","1007":"04f4e55e14150b7c48b0287ba77c7443df76ed45","1008":"79c5a02c387c90202e66d7a36942a94e0dba8c70","1009":"29f98ae6090278ae98a9b1c87d8a6b77384be317","1010":"7cf3d3a4a027be71d840717843a5934b164ab76d","1011":"afa0f48dab3884c0a6e309699bf67efa2f8d5b61","1012":"c7923f0e978310d7b7e38d7a1ba798b8bc50690a","1013":"c1614112a4f2846e7855cd07a4d5364cc7408007","1014":"eab593108645e7e8ff23b4eec38196b628acc178","1015":"807dd08fa07aa796e9a74e058f19b605adf908e1","1016":"e5d17d6ec61c72471002e74a0b219f3cddd41059","1017":"174d95f8a81b12e8301cf60ccfde65dd5361a205","1018":"4bbb23119c815e643e453b72f2ef10f46da58eb4","1019":"26602f1e36bb08e8cb87ac5751eeade227725e6a","1020":"6493cf6e3a393772f878457864a51edb8da875f6","1021":"abd834ca7c3bb61e9a5724ebb190458d95481f72","1022":"466659a2016dae35337d1e78aba54a7766ba9e63","1023":"769fec9ee0a3402746692b8794d48c75b31987bb","1024":"6c106e060e84509c91928de2c8baeb7c4a86af03","1025":"9386c51d138311a1eba74c7f6d337dfc22010641","1026":"36b1ce08de25a44c056ffe4605772e8a2167d9a9","1027":"358fd1d7cc7fc9076f0bcfcc73f8526d13401532","1028":"62e86916443a40f799424458e49b3490f5a6b64b","1029":"0c194f2f36f0a6407f0c140fa795af353f1517e6","1030":"474dc11c51ec1f9821feb46622d3b1d76d4843ee","1031":"3f4a9554ca87fe2e065bb6f1f4bc40199ef6652c","1032":"be1038136200672519c7681e00621228faaa9e2f","1033":"12145bc1223441a7e83b96bfa750f4efc4facfb1","1034":"9cbc11bc8654e4c09237892dc4f5985e0b35d0a5","1035":"20d712bfba1c252b0aaea51e9b291549ef1e6c85","1036":"467047589b16ae15270b7aaa641ff33c9446fe80","1037":"0f0221f460fd4539a61d002dc38c2d8794dbeaa6","1038":"ee6c929b5829c735170e3ef07038f60a9de12d1d","1039":"bfc1c20084484edad6e71f968955c6e982f81d82","1040":"bf41b3470eccf12eed5edea4cf41d526b613b229","1041":"628246d1682c1256f773c79f8647f0bce85defbd","1042":"4defc309ccc5c5c4d92a08a9c61295a6326d1813","1043":"58316f7eb6221fc6f42daaedbc0a7a633e75ff69","1044":"e36caccdeb4d85842e46363b0938ef0235a8db6c","1045":"581b496cb9f561e5e27d57b41866f64ad35de98d","1046":"96eb52eef56cd0579582edbe8494bd7b3c9fdd93","1047":"2879f6eb47af06a01727afd4c6f14a0ad63d0dd4","1048":"7d7afee3d2397d5e03934b5b362e34875e27ffe5","1049":"8a9fd5b7f37af3f36941e527b1d0761816fd1bef","1050":"62b1ce65ca6fa2e5ccf85f457c25eba6e0ec3356","1051":"17b70d213bea6d39ecfa1c14d8fc8319b0fe18dd","1052":"fc7f723cc1e4a390dbf286a38d642b8b07bdb22f","1053":"979a4428bde364415d21c6231609eb4564df84a8","1054":"dc1b3af105dd4621578f770981f6596f9b9eeaf1","1055":"9236a1560acc4b41335e19f2885d70f8518125c2","1056":"a2ba499d29f7285f98a9dae97db22e24f0fcee0e","1057":"6d954bd1cba2d59f79d18bb15d5f5e464df2a665","1058":"e9af86233f9c1f444c3c33465f505428411b97c1","1059":"1432d44f04d4beb2f6cc34af0a5ea44d005c61c0","1060":"5af1e8b2f546ab8dbac7a35e89e5a2b2af7968d7","1061":"99fe63245121726cbab65847718ec10d5ab9355e","1062":"6ef21d5bf92ca5bab0ba304a12454e6d48b6527a","1063":"ecb00a6e83b35e7e05cb8ae341a2fa88d2e6016a","1064":"4b72e2345e11bc766e008acf7f3ce60e1a2f0411","1065":"ae456fa5af4e277c2125c094059451efc4dae346","1066":"6fe83fde68c05d19b64149f8f49d579d2dc15e35","1067":"4bc99bf60b1683ddff1c36a4987c1ea550649884","1068":"3728ab7974f5a2f3392ea0ded15c5104400004fb","1069":"6f5d58f834d2d357742947dc215092fe2bbd0aa3","1070":"e624fe8bc5a4d93e0e921d31b7005e0807d762f5","1071":"799133257e92d81b70ae97fe3b5038c93ffadedf","1072":"fb83c9a38055079f97f9e9f0d771ab13f98adc83","1073":"19f008fdc597014e18d2ae56be95aa509df1b3ea","1074":"9bc916203b8c039eca8acd16a7d2bb0aefc1f50b","1075":"b1cc1e2d2f3576d38d176dfa190504e58f5ff096","1076":"5d4f9dee7237634ab172814b5b5457c78ba13c71","1077":"d82343c9eb0d8e8e9c47e9652350411abb6058b0","1078":"30beb9509665db59679f07728483181ec1c3925a","1079":"237a2b25e1ced676b0ebe8ccaa0cd4b7c5adac6b","1080":"2078f6d5a27aa724d9803a613c3f3ed6359eed76","1081":"465b79c0e2ce7d25bdf456ac5ea393fef33f1862","1082":"2941b843d309576971106d520fd4b848a113504f","1083":"c6f44fcc7c8ed53c49179a00d3279a78fd3f618c","1084":"03d57f7c0628deb1f1d09fc2061226b2fb5791e2","1085":"c00850a19bf0f3676f9deb5baaa9dceda3528db4","1086":"0135a2788939b55f3676dac35821d2f4ff113c9e","1087":"050fd52f62f84eb71bde9de27a7a56e1a55c9c4a","1088":"caf5b10072c03fc78b4d4a5c007c8e9e1feaa0d4","1089":"050666368e3f6b3e7736495d5c2033a7ccec3245","1090":"46b120147cf66325ea4c5dc23cf62c72b07d2f9f","1091":"69c2ed18eca8c132be2f96147ee4e10d27d509f9","1092":"5e2a6e5430cb77bcf01d75a383f867faaa2c7c4b","1093":"b2125d912941244c243a33e31b01e34467cea457","1094":"f665c28c6d5acb171774b85f85970a0428000eb8","1095":"dbdfd22ec8b71d48ff100819235eff56a4a374a3","1096":"28625648fae0a1ba915c5d2a19c312841afc1b1c","1097":"406bf6b19f3aa936f51d3c878cd6ea0e658d986c","1098":"7895137ad9283d3e62141c15502765f5d739035e","1099":"06fb506703d8015b67d8f0ecdf01d7b23cd99f22","1100":"1ed82cc306245ef20bc9415aa32b703e80d63a7c","1101":"cc27ec53160d88c25fc5096c0df65536eb780de4","1102":"c1243acc6a98733f872617f9aec3208dddac3a20","1103":"a12d22ff91ce159a0d3558ed5aaed115115beabd","1104":"a179b6fdbaf2fbad5d7fe3dc0cc34351bc586439","1105":"cebc111b8c2668094058d92871a24f27a12f68de","1106":"2f42ec0d6fe1172122333b36337f09ff5d3d400b","1107":"fc089a09074c84979d1f34e89341318a5bc26d3d","1108":"2107fae2a198ec3c9f9592cf1f189a724575c70b","1109":"49b290f26bbe9b9d88c16558f5863f7621ea3831","1110":"57eb5a5d584844e140ac51f17d5c3f5a24802daf","1111":"baecf8a1e649162482879a28f795976b7230a31e","1112":"21c391666b2c50270649338b73448d72d8d52bd0","1113":"3202064ed8beacef7ddf26908d80fff2c0bdbf2f","1114":"ef57ad148ec2eeef5eb3467f3e37e30042b2c7bd","1115":"d482a85b80b48a3a3d70e024905f1d84e6b704c4","1116":"ccd16db1499fe683d449dc1981a223ef652d0547","1117":"fb2ab2c0203bfc85f233e0d37ef27cdddb75fb48","1118":"1d260eb591a05369d622c3de3eee654c4cfa5d0b","1119":"b2239452680e97c503a90f62ccdc8137a893b1e9","1120":"b3ef7b901d530a043a2846c717525bd8cbae0ecd","1121":"6426093d36d870c03349ecfdcc77d4877ffd69cf","1122":"524d9597f08dc62de4226ed8ed3580568f27387b","1123":"63776fc90b28557ab7c44d7a87271fa523831fa1","1124":"33951c245b5fdfb9c47183f3510feeb12bc6d820","1125":"dd8785b26e9efe8bf23a96850e53b4f913b8ffa5","1126":"956b7233536f90eca3a0100bc5ee96b055b2e018","1127":"9dd4499768ffaffb13699bb60cb2f307219be7b8","1128":"74ca163326c1e8ca076bfd7d1355f58c9a772777","1129":"f9700e31a1d0ae34d4571ab056dfb268c1543349","1130":"142cd4a2a1bf744836b2143d795742a3f5e33bae","1131":"d1efc73871819d4be944e23cecf5c71498bca6ea","1132":"79723af0e87b274403df5bcfc299eebfbc741a23","1133":"e4521d118deb42ddbf910f7b56d94e08dc43737a","1134":"053b1d7b97eb2c91fc3921d589c160b0923c70b1","1135":"761e606b19c48d03b077d5b9c37652260d18f073","1136":"387b42c3f00dc456d46929a2d44cc2f2df367722","1137":"e3eaf3c461114bc34675b0aa33e48ac0be003451","1138":"61bee52afa721d13982289497f3408e54444f85b","1139":"83c369bf89d10f51eda020a94c78cc5ad9439ad4","1140":"3eeda31b131ae2c9586195b5ee7f66e6bf4a1cfc","1141":"f3d824579462eb6bd0f937a72ab3628d693298f6","1142":"11fd262d0b19a2aab6ee708de58c277c1a649100","1143":"d3a51e365df8835b9ef8df3622e214e45ce94a68","1144":"b9b6279ccdf5b240edf417d4b72d861305ebff76","1145":"75ecde2254629218efbefca7ffd528f9add2fcf6","1146":"2f3bfd8f11cc55aea33b61e23457572236664df8","1147":"219358576504cb077b3a272a915ddca118b37148","1148":"2fab3ce1cb9435270cd9ab1e738f301216468e08","1149":"80122c63a7e0fb4912930e5e17da563e4fb5aec3","1150":"4fe2a62f644e11a6fb86755bc24907ee1ec06106","1151":"6f750d835cb673cd00e0f0a8ecf654dd2c7e7bbd","1152":"0e04f9cd65f982f604e04df5582afcfc1b6faad9","1153":"93c330fb4bcf8128e40b6c5a0521a95e7de94f84","1154":"030839a20362e90b6029deb4919d337d100f1699","1155":"6cb3cb4e26d10a78f536a25d5ddd826d82ae89e4","1156":"8c2f5ed9efe3985ded8ee724dffc6ebf1f082493","1157":"1d9adfeca5715ec82e2c1aa149a861af93d2f504","1158":"1b8e778a47482e9e15b1fae6f1a12b45c789ca78","1159":"5ae312a92eac01c3d4e83ee6900d5a3d1953637e","1160":"08bce75dca134da0f41fd03086c63b3d098b44e3","1161":"f2366da1c6e7d8140b240011fda83c198313a917","1162":"67afb6a15a0bdf85b92d772c363e84518f338154","1163":"7257828fc353db18052636f862239b79736e89ac","1164":"e187661e7f32308b27c5819dba3516dbcb05d407","1165":"893fa2e6543173b41fa1fb8ba0a7c0fe2b3a3bbd","1166":"6fc4201b44ede5e46ed82920b60b2ea24eda21e4","1167":"659ed8f917a504831e0e4d5e69eef79060b2cee5","1168":"dc5bee57f5fdca7501fd953b62061c2918ed8ff0","1169":"4e47dceded52c76c900fb2fc6b54afb2255aadd9","1170":"1bb2239de17963cf786079d133be2c26b0d08799","1171":"624b3420a8bf55629590eee02abe2f9d861e9493","1172":"34ee9f67473de616957ae1a0783eaf6857d201a2","1173":"d1d5d969604f2bfdc1e2f6dbd33a00fe0b4ec1c7","1174":"6c6006eb1739888b8cf8958b6fcfc724f02efa12","1175":"21fa352ae23c3f4753339d6be150ff2af484fe53","1176":"73d3f057e32abf9ef3f23b785a460d4722d29101","1177":"b828f0e23681a37193dedadbd4a1b32c3032f801","1178":"e77081ffee14d951d0b3e80c09b7ddd25080531f","1179":"a7c878eb0873546ac7342509a1a2057c81aca5c6","1180":"293e5e43440824b3fa19ccedec3d25ec97b66b59","1181":"e209dad684babb640c2181ea065e956d03b2ebeb","1182":"4e9d4b3d89b4dec3d313c3295c70d3afff6ae50f","1183":"5744b9d04f8a37cc5081a18158025a9b4252a34f","1184":"8cbe65f2df03ca874792a0651ed29c7c04dc6e5b","1185":"de70887ce7770ea99afb61319d04887bc6e850aa","1186":"0b11343d4f247826e725a458465174aa2578e52a","1187":"318d7da35307221267b6ce6ead995cc812245abb","1188":"25586b8f46f773876e6e7f78d8dc70e48b8630a7","1189":"d1234bc63fae2840b7e4b3d6956665d5f96beaf9","1190":"508b55bed9187adabdd1db7c7bd0bca4b1c221bf","1191":"987a6f8b6c5610b5ddd014b0e935d9eadfd6c6e6","1192":"3a86c96e20544bc597fea6ff675a6caeb017a04d","1193":"e08716f95a8a3b8644bcc395493332c215af4384","1194":"0d2e7401ffbc02ba0fec5e82e0231096240c1c36","1195":"2efaa3fba38290c404ba19635cb6219d33903a32","1196":"08b769b0017cd515b2f3fa802fb460cfb2208a63","1197":"51c5568260ad615954e51ea3782658f4c02cf97b","1198":"f1c304409006816d3c571de2f56d3959560e71cb","1199":"2a37d287b5852fe5863aadee5c5fdeb6b0c56400","1200":"0dcf170200969c29476284619dcc438070abe488","1201":"0ccbc077ce72212523249af52ed91d79bc2a8d43","1202":"c02602b2df00d450fc4dbb99124e2304d8738b45","1203":"50daeb780c4cc7be9f71bb5c412e460daf4b2c29","1204":"9ebb28851b253817f9a0ea5ddc22b0fd9a934a2f","1205":"93c49dab92ac5629c694a943bdc85ddcacee478f","1206":"662d4a9d7ee2b3f546c2256fbc4cf3f148d0975e","1207":"1ab77a3b287a982bec1f2800e74c63fab044c228","1208":"cedc6a965d17ceaba7fcf8cb96c33059dadcc992","1209":"985799f90821b3f8a623f074e89646a21772b3c5","1210":"ddcd5aba9241ea0741aa1d0a848279bea8534700","1211":"a13e12001c86744691cac77cf76a60b13780ec62","1212":"714f89ff31f36ba21326ef186e1079bf6d60def6","1213":"b1a85444c8e36f9ea947b754d4c28112c39d2f05","1214":"151cf0fee24983e5b082919ac10f5c0bb85f90ad","1215":"04b19040f839acced222aae998aad49f39c22eca","1216":"3080c78504793228de18d3a35e81ddc087f5ac92","1217":"b1df58f7500672d9c502399bfff2082c3078cca0","1218":"7535722e0ed79a2d1a232699b839667206e44e49","1219":"564d2cba001b646797df22395cbfdf4a3ff77c7a","1220":"79412a99e05399d4e08f660fbe2976eb359ecb90","1221":"1c313e5815279cd1734d2888ecb06949d2cdef33","1222":"2f6a8419704b4365b9749f5078460d158dacbddc","1223":"6bd91f7a0a7d22b8cd07e12b3b0c08f4f570438f","1224":"0a075b88574b2c38de5fedfad77adebb5b86bed8","1225":"d1665aebe8167ea9a08dc98bc9375b2ff007a0e5","1226":"56b2cf80ddabc5cdfe1764983e5f7b2042b7ea45","1227":"a44f885f11ee044a74df02700dbbe809f9b8bb6a","1228":"04ebddfdb7071eca323b88121e0f710ba4d0db4a","1229":"39c4719baa2fc973aefba530f4ddcd3de7267905","1230":"9fd449fcd992cb8e2545fb93a30a1584f5590094","1231":"f9a376b2ba8af79f5e40b87712249c08bb01492f","1232":"264b76902a45d6bad17c46702867ee5df3ba3b89","1233":"37315eec3dbffa94c70ea0444b70cada867d2edf","1234":"58558a19deb9a48f4900c8460667debd5c2b0ecc","1235":"86328e0c84bf97ae9b0680c06c4886bc04fb63c1","1236":"c483351957d782ea50c89d61e126de03eacf984b","1237":"659934004e30eed9f898788d2e15a1a5f69a3293","1238":"7d44d849cc682f57469034338612ad950cc0fed8","1239":"71a631d7304e94e86a224b7f09796b41d42b35b3","1240":"636ea99bd965806a30fb75093a868f08ce904c4d","1241":"1cee732d31509174da6698d48bfa2dd6282d7912","1242":"c5fb7b0058edd59db171acd23dfee24333b64bc1","1243":"47d136cba4df34a32a8319676ce195ed0f51d774","1244":"b8241a76cbba63814401071a5302fd992e9fc7c9","1245":"d6644db83ecd9f03e0a3db904fd726d10e1eb474","1246":"10697fa73ca2fa833c6e32097a9195e95f6fdebd","1247":"b07d45f2b81e2d1c725fec614b4befbc87bb57de","1248":"24c62a9856b25a85078b4fe18eb5494f286b4b01","1249":"1c88b7980f190cfb275cc1be3d34a099d086abed","1250":"8feaa62983ef900910cccbd73387e0b0282fafdd","1251":"e4738c6151ce2087d0e5076a47200766fc4e0619","1252":"885aa7da53d1866d51f090904bbea832bde8c7a9","1253":"d5167d87ab6eaacfe81424e05c2282d75ad56368","1254":"b9c58fc0fe1cd789352fb3464d3f7c0965205113","1255":"5e397b1233bc737317a4f42e872b7235c9d36d65","1256":"de3baa7d68f1a0b3301c4bf00b615f1fc0d06690","1257":"23a0b0a4d12f9b6231bcff19bc179582c63a8bca","1258":"c49ecde0a5fc208bf09e10e3a577b2550e64e377","1259":"e386e85ded4ab8eb559df2d35995bb3bf6986678","1260":"19375ac6b75feceb55cf93e8b9cb6e0b43457e5e","1261":"81b15e49d44426acd32f0adb5e15f25a15e39973","1262":"a80ee310c79572f9b84bd855950dd25b3beee3e4","1263":"fedadbfa8c7c6c58cc93e97ad7d1f37dcd98849c","1264":"27756e444665dceac31bccca1feed1a5a2d888c2","1265":"c3d6eb7261f440219228ddb62ad926004cdf09b9","1266":"cdf03c30aac97537926e0651dc70d5ac56f58163","1267":"65b3d01cdbe69afe4d7a84faff26509d5e866407","1268":"dd609f6355fa51f525f2804df8eaf7ddc2a57142","1269":"5f2d846f5473f5ddc93b99cf77341e49c7914bb0","1270":"787d4ec9217a7ec08ed219002fb750badab06b44","1271":"faca88d23ea0c626d0b354e43fe8ab154b43b4d0","1272":"09f1b39a2e92860acb5ad6506766ca863e751e8e","1273":"00522bccaae8d28c8f08356b00eda82704bdf476"},"externalIds":{"0":"{'DBLP': 'conf\/www\/MadanagopalC21', 'DOI': '10.1145\/3442442.3452353', 'CorpusId': 233225705}","1":"{'ArXiv': '2102.00287', 'DBLP': 'journals\/corr\/abs-2102-00287', 'ACL': '2021.eacl-main.188', 'DOI': '10.18653\/v1\/2021.eacl-main.188', 'CorpusId': 231740565}","2":"{'DBLP': 'journals\/ipm\/SpindeRMHGGD21', 'DOI': '10.1016\/j.ipm.2021.102505', 'CorpusId': 232045059}","3":"{'DBLP': 'journals\/corr\/abs-2007-06761', 'MAG': '3042795397', 'ArXiv': '2007.06761', 'CorpusId': 220514315}","4":"{'ArXiv': '2004.14601', 'DBLP': 'journals\/corr\/abs-2004-14601', 'MAG': '3023252952', 'CorpusId': 216867453}","5":"{'MAG': '2796989290', 'DOI': '10.1016\/J.LANGSCI.2018.06.006', 'CorpusId': 149552454}","6":"{'DBLP': 'conf\/naacl\/PryzantCJVS21', 'MAG': '3094245163', 'ACL': '2021.naacl-main.323', 'ArXiv': '2010.12919', 'DOI': '10.18653\/V1\/2021.NAACL-MAIN.323', 'CorpusId': 225067829}","7":"{'MAG': '3035267217', 'ACL': '2020.acl-main.465', 'DBLP': 'journals\/corr\/abs-2005-00955', 'ArXiv': '2005.00955', 'DOI': '10.18653\/v1\/2020.acl-main.465', 'CorpusId': 218487293}","8":"{'DBLP': 'conf\/acl\/AntoniakM20', 'ACL': '2021.acl-long.148', 'DOI': '10.18653\/v1\/2021.acl-long.148', 'CorpusId': 236460084}","9":"{'DBLP': 'conf\/acl\/LiG21', 'ACL': '2021.findings-acl.401', 'DOI': '10.18653\/v1\/2021.findings-acl.401', 'CorpusId': 236478070}","10":"{'DBLP': 'journals\/corr\/abs-2003-03014', 'ArXiv': '2003.03014', 'MAG': '3100718630', 'PubMedCentral': '7861242', 'DOI': '10.3389\/frai.2020.00055', 'CorpusId': 212628532, 'PubMed': '33733172'}","11":"{'MAG': '3043760925', 'DBLP': 'conf\/um\/DeshpandePF20', 'DOI': '10.1145\/3386392.3399569', 'CorpusId': 220040093}","12":"{'PubMedCentral': '7850083', 'DBLP': 'conf\/pkdd\/SpindeHG20', 'DOI': '10.1007\/978-3-030-65965-3_41', 'CorpusId': 231718248}","13":"{'ArXiv': '2004.08134', 'MAG': '3016899578', 'DBLP': 'journals\/corr\/abs-2004-08134', 'CorpusId': 211268325}","14":"{'MAG': '3034760557', 'ACL': '2020.acl-main.140', 'DBLP': 'conf\/acl\/AltGH20', 'DOI': '10.18653\/v1\/2020.acl-main.140', 'CorpusId': 220047815}","15":"{'DBLP': 'conf\/webi\/NozzaVF19', 'MAG': '2980350050', 'DOI': '10.1145\/3350546.3352512', 'CorpusId': 204754417}","16":"{'ACL': 'D19-1664', 'ArXiv': '1909.02670', 'DBLP': 'journals\/corr\/abs-1909-02670', 'MAG': '2971629656', 'DOI': '10.18653\/v1\/D19-1664', 'CorpusId': 202537179}","17":"{'DBLP': 'journals\/tkde\/YahavSS19', 'MAG': '2804344463', 'DOI': '10.1109\/TKDE.2018.2840127', 'CorpusId': 59620732}","18":"{'MAG': '3000226926', 'DOI': '10.1515\/lingty-2019-2031', 'CorpusId': 213768755}","19":"{'ACL': 'P19-1339', 'DBLP': 'conf\/acl\/GarimellaBHM19', 'MAG': '2952638532', 'DOI': '10.18653\/v1\/P19-1339', 'CorpusId': 196181460}","20":"{'ACL': '2022.acl-short.1', 'ArXiv': '2106.10199', 'DBLP': 'journals\/corr\/abs-2106-10199', 'CorpusId': 231672601}","21":"{'DBLP': 'conf\/acl\/SalazarLNK20', 'ACL': '2020.acl-main.240', 'MAG': '3024308166', 'DOI': '10.18653\/v1\/2020.acl-main.240', 'CorpusId': 218628872}","22":"{'DBLP': 'journals\/corr\/abs-1911-02969', 'MAG': '3099624838', 'ArXiv': '1911.02969', 'ACL': '2020.blackboxnlp-1.21', 'DOI': '10.18653\/v1\/2020.blackboxnlp-1.21', 'CorpusId': 207847960}","23":"{'ACL': '2021.naacl-main.78', 'DBLP': 'journals\/corr\/abs-2002-08911', 'ArXiv': '2002.08911', 'MAG': '3008019634', 'DOI': '10.18653\/V1\/2021.NAACL-MAIN.78', 'CorpusId': 211204926}","24":"{'DBLP': 'conf\/acl\/BalyKAKDAGN20', 'MAG': '3034442695', 'ACL': '2020.acl-main.308', 'ArXiv': '2005.04518', 'DOI': '10.18653\/v1\/2020.acl-main.308', 'CorpusId': 218581979}","25":"{'DBLP': 'journals\/corr\/abs-2004-05704', 'ACL': '2020.acl-main.727', 'ArXiv': '2004.05704', 'MAG': '3035561630', 'DOI': '10.18653\/v1\/2020.acl-main.727', 'CorpusId': 215745396}","26":"{'MAG': '2950080181', 'DBLP': 'journals\/topics\/FisherJS20', 'DOI': '10.1111\/TOPS.12447', 'CorpusId': 201018329, 'PubMed': '31419084'}","27":"{'ArXiv': '1903.06400', 'MAG': '2953258133', 'DBLP': 'conf\/naacl\/RavfogelGL19', 'ACL': 'N19-1356', 'DOI': '10.18653\/v1\/N19-1356', 'CorpusId': 80628431}","28":"{'ArXiv': '1906.08430', 'MAG': '2952111037', 'DBLP': 'journals\/corr\/abs-1906-08430', 'ACL': 'W19-1801', 'DOI': '10.18653\/v1\/W19-1801', 'CorpusId': 140080210}","29":"{'DBLP': 'conf\/emnlp\/YangHSCWWC19', 'ACL': 'D19-1309', 'MAG': '2971116243', 'DOI': '10.18653\/v1\/D19-1309', 'CorpusId': 202757910}","30":"{'DBLP': 'conf\/mm\/MakiuchiWUS19', 'MAG': '2981660166', 'DOI': '10.1145\/3347320.3357694', 'CorpusId': 204967216}","31":"{'MAG': '2991629320', 'PubMedCentral': '6867602', 'DOI': '10.1371\/journal.pone.0224425', 'CorpusId': 208217527, 'PubMed': '31747404'}","32":"{'MAG': '3034458735', 'DBLP': 'journals\/corr\/abs-2004-04498', 'ACL': '2020.acl-main.690', 'ArXiv': '2004.04498', 'DOI': '10.18653\/v1\/2020.acl-main.690', 'CorpusId': 215548916}","33":"{'MAG': '3095105395', 'DBLP': 'journals\/corr\/abs-2010-14534', 'ACL': '2020.gebnlp-1.1', 'ArXiv': '2010.14534', 'CorpusId': 225094152}","34":"{'DBLP': 'conf\/acl\/TanJKS20', 'ArXiv': '2005.04364', 'ACL': '2020.acl-main.263', 'MAG': '3099126561', 'DOI': '10.18653\/v1\/2020.acl-main.263', 'CorpusId': 218581359}","35":"{'DBLP': 'journals\/corr\/abs-2009-14715', 'ArXiv': '2009.14715', 'MAG': '3091164445', 'CorpusId': 222066972}","36":"{'MAG': '3098613713', 'ArXiv': '2010.05358', 'DBLP': 'journals\/corr\/abs-2010-05358', 'DOI': '10.18653\/v1\/2020.emnlp-main.16', 'CorpusId': 222290865}","37":"{'DBLP': 'journals\/corr\/abs-2008-06884', 'ArXiv': '2008.06884', 'MAG': '3049478012', 'DOI': '10.1145\/3394171.3413518', 'CorpusId': 221139303}","38":"{'MAG': '3104570641', 'ACL': '2020.emnlp-main.554', 'DBLP': 'conf\/emnlp\/PapadimitriouJ20', 'DOI': '10.18653\/v1\/2020.emnlp-main.554', 'CorpusId': 221891676}","39":"{'DBLP': 'journals\/corr\/abs-2010-10652', 'ArXiv': '2010.10652', 'MAG': '3093726604', 'ACL': '2020.nlpcss-1.16', 'DOI': '10.18653\/v1\/2020.nlpcss-1.16', 'CorpusId': 224814439}","40":"{'DBLP': 'journals\/corr\/abs-2006-16324', 'MAG': '3040224948', 'ArXiv': '2006.16324', 'CorpusId': 220265774}","41":"{'MAG': '2905440559', 'DBLP': 'journals\/ijis\/LiuL19a', 'DOI': '10.1002\/int.22071', 'CorpusId': 126084439}","42":"{'MAG': '2954482098', 'DBLP': 'conf\/icwsm\/AddawoodBLF19', 'CorpusId': 189818803}","43":"{'DBLP': 'journals\/ijis\/LiuL19b', 'MAG': '2947240092', 'DOI': '10.1002\/int.22114', 'CorpusId': 191156746}","44":"{'ArXiv': '1906.12068', 'MAG': '2955450582', 'ACL': 'W19-6622', 'DBLP': 'journals\/corr\/abs-1906-12068', 'CorpusId': 195750811}","45":"{'ArXiv': '2009.06367', 'DBLP': 'conf\/emnlp\/KrauseGMKJSR21', 'MAG': '3085190015', 'DOI': '10.18653\/v1\/2021.findings-emnlp.424', 'CorpusId': 221655075}","46":"{'DBLP': 'conf\/iclr\/LoveringJLP21', 'CorpusId': 235614282}","47":"{'DBLP': 'journals\/corr\/abs-2104-03869', 'ArXiv': '2104.03869', 'CorpusId': 233181741}","48":"{'DBLP': 'journals\/corr\/abs-2008-02754', 'MAG': '3047056223', 'ArXiv': '2008.02754', 'CorpusId': 221005761}","49":"{'MAG': '3011307745', 'DBLP': 'journals\/corr\/abs-2003-06576', 'ArXiv': '2003.06576', 'DOI': '10.1109\/cvpr42600.2020.01081', 'CorpusId': 212725353}","50":"{'ArXiv': '2007.08100', 'MAG': '3035591180', 'DBLP': 'journals\/corr\/abs-2007-08100', 'ACL': '2020.acl-main.488', 'DOI': '10.18653\/v1\/2020.acl-main.488', 'CorpusId': 207996257}","51":"{'DBLP': 'journals\/tse\/HuangXLM20', 'MAG': '2896373185', 'DOI': '10.1109\/TSE.2018.2876340', 'CorpusId': 53374575}","52":"{'MAG': '3033226103', 'DBLP': 'conf\/aaai\/ChopraSMS20', 'DOI': '10.1609\/aaai.v34i01.5374', 'CorpusId': 219327545}","53":"{'DBLP': 'conf\/acl\/AltHH19', 'ACL': 'P19-1134', 'MAG': '2949568611', 'ArXiv': '1906.08646', 'DOI': '10.18653\/v1\/P19-1134', 'CorpusId': 195218574}","54":"{'DBLP': 'journals\/corr\/abs-2005-00165', 'MAG': '3035121469', 'ArXiv': '2005.00165', 'ACL': '2020.acl-main.179', 'DOI': '10.18653\/v1\/2020.acl-main.179', 'CorpusId': 218470598}","55":"{'DBLP': 'conf\/emnlp\/BreitfellerAJT19', 'ACL': 'D19-1176', 'MAG': '2970395295', 'DOI': '10.18653\/v1\/D19-1176', 'CorpusId': 202778702}","56":"{'DBLP': 'journals\/corr\/abs-1910-04210', 'ArXiv': '1910.04210', 'MAG': '2972539067', 'ACL': 'D19-1578', 'DOI': '10.18653\/v1\/D19-1578', 'CorpusId': 203078302}","57":"{'DBLP': 'journals\/corr\/abs-1910-10408', 'ACL': '2019.iwslt-1.31', 'MAG': '2982026991', 'ArXiv': '1910.10408', 'DOI': '10.5281\/ZENODO.3524957', 'CorpusId': 204837859}","58":"{'MAG': '2969933719', 'DOI': '10.1038\/s41562-019-0663-x', 'CorpusId': 201064613, 'PubMed': '31427785'}","59":"{'ArXiv': '1905.12330', 'DBLP': 'conf\/acl\/ChaabouniKLDB19', 'MAG': '2947700923', 'ACL': 'P19-1509', 'DOI': '10.18653\/v1\/P19-1509', 'CorpusId': 168170188}","60":"{'DBLP': 'journals\/corr\/abs-1906-04177', 'ArXiv': '1906.04177', 'MAG': '2949531672', 'DOI': '10.24963\/ijcai.2019\/259', 'CorpusId': 184486848}","61":"{'DBLP': 'conf\/coling\/WachsmuthW20', 'ACL': '2020.coling-main.592', 'MAG': '3093239427', 'ArXiv': '2010.12473', 'DOI': '10.18653\/V1\/2020.COLING-MAIN.592', 'CorpusId': 225062549}","62":"{'MAG': '3162945253', 'DOI': '10.1109\/TDSC.2021.3079957', 'CorpusId': 236571732}","63":"{'ACL': '2021.findings-acl.302', 'DBLP': 'conf\/acl\/BanerjeeGYB21', 'ArXiv': '2012.02356', 'DOI': '10.18653\/v1\/2021.findings-acl.302', 'CorpusId': 235262536}","64":"{'MAG': '3164827908', 'DOI': '10.31234\/OSF.IO\/KCU27', 'CorpusId': 236590330}","65":"{'ACL': '2021.acl-long.247', 'DBLP': 'conf\/acl\/ZeinertID20', 'DOI': '10.18653\/v1\/2021.acl-long.247', 'CorpusId': 235803170}","66":"{'MAG': '3161223242', 'DOI': '10.31234\/OSF.IO\/YUBKZ', 'CorpusId': 236651192}","67":"{'DBLP': 'conf\/emnlp\/MunroM20', 'ACL': '2020.emnlp-main.157', 'MAG': '3100361495', 'DOI': '10.18653\/v1\/2020.emnlp-main.157', 'CorpusId': 226262223}","68":"{'MAG': '2768244601', 'DOI': '10.4324\/9781315782379-138', 'CorpusId': 5759479}","69":"{'DBLP': 'conf\/emnlp\/NiuB19', 'MAG': '2970418174', 'ACL': 'D19-1132', 'ArXiv': '1909.12868', 'DOI': '10.18653\/v1\/D19-1132', 'CorpusId': 202779778}","70":"{'DBLP': 'conf\/naacl\/PimentelRWCB21', 'ACL': '2021.naacl-main.349', 'ArXiv': '2104.06325', 'MAG': '3172754832', 'DOI': '10.18653\/V1\/2021.NAACL-MAIN.349', 'CorpusId': 233219935}","71":"{'ArXiv': '2104.05694', 'ACL': '2021.naacl-main.404', 'DBLP': 'conf\/naacl\/ZhangH21', 'MAG': '3169890186', 'DOI': '10.18653\/V1\/2021.NAACL-MAIN.404', 'CorpusId': 233209910}","72":"{'DBLP': 'conf\/acl\/WeiMC20', 'ArXiv': '2105.07144', 'ACL': '2021.acl-long.404', 'DOI': '10.18653\/v1\/2021.acl-long.404', 'CorpusId': 234741913}","73":"{'MAG': '2608225331', 'DBLP': 'journals\/zmp\/VaesLSA19', 'DOI': '10.1027\/1864-1105\/a000216', 'CorpusId': 152236350}","74":"{'ArXiv': '2110.01963', 'DBLP': 'journals\/corr\/abs-2110-01963', 'CorpusId': 238354158}","75":"{'DBLP': 'conf\/interspeech\/SarawgiZSM20', 'ArXiv': '2009.00700', 'MAG': '3082727480', 'DOI': '10.21437\/interspeech.2020-3137', 'CorpusId': 221447276}","76":"{'MAG': '3033691877', 'DBLP': 'conf\/aaai\/AgarwalLSS20', 'DOI': '10.1609\/aaai.v34i01.5369', 'CorpusId': 219331314}","77":"{'ACL': '2020.aacl-main.42', 'DBLP': 'conf\/ijcnlp\/JinS20', 'CorpusId': 227904565}","78":"{'ACL': 'P19-4001', 'MAG': '2966784200', 'DBLP': 'conf\/acl\/MartinsMNN19', 'DOI': '10.18653\/v1\/P19-4001', 'CorpusId': 199022672}","79":"{'ArXiv': '2010.05332', 'MAG': '3096713445', 'ACL': '2020.gebnlp-1.4', 'DBLP': 'journals\/corr\/abs-2010-05332', 'CorpusId': 222290588}","80":"{'MAG': '2971384067', 'DBLP': 'journals\/corr\/abs-1909-01543', 'ArXiv': '1909.01543', 'DOI': '10.1145\/1122445.3353763', 'CorpusId': 202539224}","81":"{'DBLP': 'journals\/corr\/abs-2109-08253', 'CorpusId': 237563021}","82":"{'ACL': 'W19-4823', 'DBLP': 'conf\/blackboxnlp\/MerrillKAHMF19', 'MAG': '2972733624', 'DOI': '10.18653\/v1\/W19-4823', 'CorpusId': 203166088}","83":"{'MAG': '2909510788', 'DOI': '10.1146\/ANNUREV-LINGUISTICS-011718-012329', 'CorpusId': 150268590}","84":"{'DBLP': 'journals\/lp\/CaoLW21', 'MAG': '3048519813', 'DOI': '10.1002\/leap.1322', 'CorpusId': 225370837}","85":"{'DBLP': 'journals\/scientometrics\/Ortega20', 'MAG': '2983943611', 'DOI': '10.1007\/s11192-019-03299-2', 'CorpusId': 208020313}","86":"{'DBLP': 'series\/cogtech\/Hedblom20', 'MAG': '3034789725', 'DOI': '10.1007\/978-3-030-47329-7', 'CorpusId': 219607936}","87":"{'DBLP': 'journals\/corr\/abs-1906-07414', 'ArXiv': '1906.07414', 'MAG': '2950224550', 'CorpusId': 189998963}","88":"{'ArXiv': '1910.08036', 'DBLP': 'journals\/corr\/abs-1910-08036', 'DOI': '10.26434\/chemrxiv.9992489', 'CorpusId': 204743676}","89":"{'DBLP': 'journals\/corr\/abs-2110-07871', 'ArXiv': '2110.07871', 'CorpusId': 239009591}","90":"{'MAG': '3016509184', 'DOI': '10.1075\/ijlcr.18012.bal', 'CorpusId': 218829671}","91":"{'MAG': '2955777885', 'DBLP': 'journals\/cogsci\/SchouwstraST19', 'DOI': '10.1111\/cogs.12732', 'CorpusId': 195785178, 'PubMed': '31310026'}","92":"{'DBLP': 'journals\/corr\/abs-1901-06595', 'MAG': '2914543347', 'CorpusId': 58981811}","93":"{'DBLP': 'journals\/corr\/abs-2002-08608', 'MAG': '3008254539', 'CorpusId': 211204984}","94":"{'DBLP': 'journals\/corr\/abs-2009-12979', 'MAG': '3088435213', 'ArXiv': '2009.12979', 'DOI': '10.1007\/978-3-030-60975-7_16', 'CorpusId': 221969973}","95":"{'DBLP': 'conf\/aaai\/PryzantMDKJY20', 'MAG': '3033129824', 'ArXiv': '1911.09709', 'DOI': '10.1609\/aaai.v34i01.5385', 'CorpusId': 208248333}","96":"{'DBLP': 'conf\/jcdl\/SpindeHDBG20', 'ArXiv': '2105.09640', 'MAG': '3046904879', 'DOI': '10.1145\/3383583.3398619', 'CorpusId': 219719916}","97":"{'DBLP': 'conf\/icer\/KafaiPL19', 'MAG': '2964862450', 'DOI': '10.1145\/3291279.3339400', 'CorpusId': 199022578}","98":"{'DBLP': 'journals\/pnas\/CinelliMGQS21', 'DOI': '10.1073\/pnas.2023301118', 'CorpusId': 232038574, 'PubMed': '33622786'}","99":"{'PubMedCentral': '6819366', 'MAG': '2981394430', 'DOI': '10.3389\/fmicb.2019.02407', 'CorpusId': 204831955, 'PubMed': '31708888'}","100":"{'ArXiv': '1911.03891', 'MAG': '2984662393', 'ACL': '2020.acl-main.486', 'DBLP': 'journals\/corr\/abs-1911-03891', 'DOI': '10.18653\/v1\/2020.acl-main.486', 'CorpusId': 207853290}","101":"{'DBLP': 'journals\/widm\/NtoutsiFGINVRTP20', 'MAG': '3004493409', 'DOI': '10.1002\/widm.1356', 'CorpusId': 211129042}","102":"{'PubMedCentral': '6392353', 'MAG': '2914254853', 'DOI': '10.1002\/ece3.4878', 'CorpusId': 71143323, 'PubMed': '30847112'}","103":"{'MAG': '2995849700', 'DBLP': 'journals\/corr\/abs-1910-04744', 'ArXiv': '1910.04744', 'CorpusId': 204009011}","104":"{'MAG': '2998304316', 'ArXiv': '1912.12910', 'DOI': '10.1364\/optica.386574', 'CorpusId': 209515304}","105":"{'MAG': '2908826212', 'DBLP': 'conf\/fat\/CelisKSV19', 'DOI': '10.1145\/3287560.3287601', 'CorpusId': 58006258}","106":"{'MAG': '3127254741', 'DOI': '10.5194\/GMD-2020-446', 'CorpusId': 233294635}","107":"{'DBLP': 'journals\/neuroimage\/GrattonDCALWKGF20', 'MAG': '2987227820', 'DOI': '10.1101\/837161', 'CorpusId': 209580141}","108":"{'ArXiv': '2006.08070', 'DBLP': 'journals\/corr\/abs-2006-08070', 'MAG': '3037838967', 'DOI': '10.1109\/TPAMI.2021.3100714', 'CorpusId': 219686942, 'PubMed': '34324423'}","109":"{'DBLP': 'journals\/corr\/abs-1909-11274', 'ArXiv': '1909.11274', 'MAG': '2995631573', 'CorpusId': 202750253}","110":"{'MAG': '2908235130', 'DBLP': 'conf\/wsdm\/ChenLX19', 'DOI': '10.1145\/3289600.3291000', 'CorpusId': 59528311}","111":"{'DBLP': 'conf\/fat\/KatellYDHGTBRK20', 'MAG': '3001754608', 'DOI': '10.1145\/3351095.3372874', 'CorpusId': 209421300}","112":"{'DBLP': 'journals\/corr\/abs-2003-07407', 'ArXiv': '2003.07407', 'MAG': '3011605433', 'DOI': '10.1109\/TSMC.2020.2980184', 'CorpusId': 212736860}","113":"{'MAG': '3148568192', 'ArXiv': '2001.01565', 'DBLP': 'journals\/ki\/SchillerDG21', 'DOI': '10.1007\/S13218-021-00714-W', 'CorpusId': 209862689}","114":"{'ArXiv': '2002.10770', 'MAG': '3035552210', 'DBLP': 'journals\/corr\/abs-2002-10770', 'DOI': '10.1109\/cvpr42600.2020.00802', 'CorpusId': 211296336}","115":"{'DBLP': 'journals\/corr\/abs-2109-08131', 'ArXiv': '2109.08131', 'CorpusId': 237532708}","116":"{'DBLP': 'journals\/frma\/Leefmann21', 'PubMedCentral': '8131867', 'DOI': '10.3389\/frma.2021.599909', 'CorpusId': 233732460, 'PubMed': '34027299'}","117":"{'MAG': '3184134349', 'DBLP': 'journals\/ethicsit\/Coeckelbergh21', 'DOI': '10.1007\/S10676-021-09604-Z', 'CorpusId': 237688476}","118":"{'DBLP': 'journals\/pacmhci\/MiceliPY22', 'DOI': '10.1145\/3492853', 'CorpusId': 245934049}","119":"{'DBLP': 'journals\/jdmdh\/Shadrova21', 'DOI': '10.46298\/jdmdh.7595', 'CorpusId': 243820823}","120":"{'DBLP': 'conf\/bias\/MakhortykhUU21', 'ArXiv': '2106.14072', 'DOI': '10.1007\/978-3-030-78818-6_5', 'CorpusId': 235659011}","121":"{'DBLP': 'conf\/bias\/0001B21', 'DOI': '10.1007\/978-3-030-78818-6_2', 'CorpusId': 235251586}","122":"{'DBLP': 'conf\/bias\/2021', 'DOI': '10.1007\/978-3-030-78818-6', 'CorpusId': 235614695}","123":"{'MAG': '2950437211', 'DBLP': 'journals\/corr\/abs-1906-07337', 'ArXiv': '1906.07337', 'ACL': 'W19-3823', 'DOI': '10.18653\/v1\/W19-3823', 'CorpusId': 190000105}","124":"{'DBLP': 'conf\/bias\/KirdemirKMHA21', 'DOI': '10.1007\/978-3-030-78818-6_10', 'CorpusId': 235700564}","125":"{'DBLP': 'conf\/bias\/LeavyMWG20', 'ArXiv': '2005.06898', 'MAG': '3025606488', 'DOI': '10.1007\/978-3-030-52485-2_2', 'CorpusId': 218628618}","126":"{'DBLP': 'conf\/bias\/HaakS21', 'DOI': '10.1007\/978-3-030-78818-6_12', 'CorpusId': 235700290}","127":"{'DBLP': 'conf\/bias\/KamishimaABK21', 'DOI': '10.1007\/978-3-030-78818-6_4', 'CorpusId': 235700160}","128":"{'DBLP': 'conf\/bias\/GuinezRS21', 'DOI': '10.1007\/978-3-030-78818-6_8', 'CorpusId': 235700266}","129":"{'MAG': '2909620036', 'ACL': 'W19-3821', 'DBLP': 'journals\/corr\/abs-1901-03116', 'ArXiv': '1901.03116', 'DOI': '10.18653\/v1\/W19-3821', 'CorpusId': 57761084}","130":"{'DBLP': 'conf\/bias\/2020', 'DOI': '10.1007\/978-3-030-52485-2', 'CorpusId': 220462340}","131":"{'DBLP': 'journals\/corr\/abs-1904-08783', 'ACL': 'W19-3805', 'ArXiv': '1904.08783', 'MAG': '2940406222', 'DOI': '10.18653\/v1\/W19-3805', 'CorpusId': 121125604}","132":"{'MAG': '3047936644', 'DBLP': 'conf\/bias\/KonstantakisPDP20', 'PubMedCentral': '7352118', 'DOI': '10.1007\/978-3-030-52485-2_7', 'CorpusId': 218500304}","133":"{'ACL': 'W19-3824', 'DBLP': 'journals\/corr\/abs-1905-11684', 'MAG': '2972866455', 'ArXiv': '1905.11684', 'DOI': '10.18653\/v1\/W19-3824', 'CorpusId': 167217680}","134":"{'ArXiv': '1908.02810', 'DBLP': 'journals\/corr\/abs-1908-02810', 'ACL': 'W19-3810', 'MAG': '2972663293', 'DOI': '10.18653\/v1\/W19-3810', 'CorpusId': 199501874}","135":"{'ACL': 'W19-3802', 'MAG': '2972535663', 'DOI': '10.18653\/v1\/W19-3802', 'CorpusId': 201685203}","136":"{'MAG': '2972697496', 'ACL': 'W19-3808', 'DOI': '10.18653\/v1\/W19-3808', 'CorpusId': 202588978}","137":"{'DBLP': 'conf\/cdmake\/AsherPR21', 'DOI': '10.1007\/978-3-030-84060-0_6', 'CorpusId': 237100805}","138":"{'DBLP': 'conf\/educon\/NantsouKT21a', 'DOI': '10.1109\/EDUCON46332.2021.9453876', 'CorpusId': 235476379}","139":"{'DBLP': 'conf\/bias\/NunzioFSS21', 'ArXiv': '2110.15683', 'DOI': '10.1007\/978-3-030-78818-6_7', 'CorpusId': 235078981}","140":"{'DBLP': 'journals\/corr\/abs-2106-13455', 'ArXiv': '2106.13455', 'CorpusId': 235651979}","141":"{'DBLP': 'conf\/bias\/HanSS21', 'MAG': '3174623079', 'ArXiv': '2105.02898', 'DOI': '10.1007\/978-3-030-78818-6_3', 'CorpusId': 234093861}","142":"{'DBLP': 'conf\/bias\/Misztal-Radecka21', 'DOI': '10.1007\/978-3-030-78818-6_9', 'CorpusId': 235700431}","143":"{'DBLP': 'journals\/corr\/abs-2001-07578', 'ArXiv': '2001.07578', 'MAG': '3001544787', 'DOI': '10.1007\/978-3-030-84060-0', 'CorpusId': 210839276}","144":"{'MAG': '3047275542', 'DBLP': 'journals\/corr\/abs-2008-01194', 'ArXiv': '2008.01194', 'DOI': '10.1007\/978-3-030-52485-2_1', 'CorpusId': 220527716}","145":"{'DBLP': 'conf\/bias\/GerritseV20', 'MAG': '3041549393', 'DOI': '10.1007\/978-3-030-52485-2_4', 'CorpusId': 220527543}","146":"{'DBLP': 'conf\/bias\/SilvaSBO20', 'MAG': '3041991003', 'DOI': '10.1007\/978-3-030-52485-2_6', 'CorpusId': 220527497}","147":"{'ArXiv': '1905.08868', 'MAG': '2973047719', 'ACL': 'W19-3814', 'DBLP': 'journals\/corr\/abs-1905-08868', 'DOI': '10.18653\/v1\/W19-3814', 'CorpusId': 162168850}","148":"{'ACL': 'W19-3812', 'MAG': '2972464357', 'DOI': '10.18653\/v1\/W19-3812', 'CorpusId': 201730645}","149":"{'MAG': '2948957015', 'DBLP': 'journals\/corr\/abs-1906-03695', 'ACL': 'W19-3819', 'ArXiv': '1906.03695', 'DOI': '10.18653\/v1\/w19-3819', 'CorpusId': 182952942}","150":"{'MAG': '2972677162', 'ACL': 'W19-3811', 'DOI': '10.18653\/v1\/W19-3811', 'CorpusId': 201627050}","151":"{'DBLP': 'conf\/bias\/KrafftHZ20', 'MAG': '3041042694', 'DOI': '10.1007\/978-3-030-52485-2_3', 'CorpusId': 220527663}","152":"{'DBLP': 'conf\/bias\/ParaschakisN20', 'MAG': '3041816753', 'DOI': '10.1007\/978-3-030-52485-2_5', 'CorpusId': 220527655}","153":"{'ACL': 'W19-3809', 'ArXiv': '1906.10256', 'MAG': '2956059299', 'DBLP': 'journals\/corr\/abs-1906-10256', 'DOI': '10.18653\/v1\/W19-3809', 'CorpusId': 195584301}","154":"{'MAG': '2969489748', 'DOI': '10.15760\/comminfolit.2019.13.1.8', 'CorpusId': 201888342}","155":"{'MAG': '3028225728', 'DOI': '10.23943\/princeton\/9780691196329.003.0005', 'CorpusId': 219896336}","156":"{'ACL': 'W19-3818', 'ArXiv': '1905.01780', 'DBLP': 'journals\/corr\/abs-1905-01780', 'MAG': '2973120304', 'DOI': '10.18653\/v1\/W19-3818', 'CorpusId': 146121114}","157":"{'DBLP': 'journals\/midm\/SoboczenskiTKBW19', 'MAG': '2902105843', 'PubMedCentral': '6505190', 'DOI': '10.1186\/s12911-019-0814-z', 'CorpusId': 81201005, 'PubMed': '31068178'}","158":"{'MAG': '3006299787', 'DOI': '10.1007\/s11019-020-09940-9', 'CorpusId': 211113359, 'PubMed': '32056071'}","159":"{'MAG': '3016630678', 'DOI': '10.31235\/osf.io\/hvcb5', 'CorpusId': 218798426}","160":"{'DBLP': 'conf\/teletraffic\/KlineACB20', 'DOI': '10.1109\/ITC3249928.2020.00009', 'CorpusId': 232062351}","161":"{'MAG': '3169200466', 'DOI': '10.16993\/BBK.B', 'CorpusId': 236256564}","162":"{'DBLP': 'journals\/corr\/abs-2102-04234', 'ArXiv': '2102.04234', 'CorpusId': 231847028}","163":"{'DBLP': 'journals\/corr\/abs-2201-10683', 'ArXiv': '2201.10683', 'CorpusId': 246285567}","164":"{'DBLP': 'conf\/cscl\/VogelJYHGAWWR0H19', 'CorpusId': 233416381}","165":"{'DBLP': 'conf\/iccS\/EnglertM20', 'PubMedCentral': '7303679', 'MAG': '3036984727', 'DOI': '10.1007\/978-3-030-50423-6_47', 'CorpusId': 219889691}","166":"{'DBLP': 'journals\/remotesensing\/ChenLFGWL21', 'DOI': '10.3390\/rs13132524', 'CorpusId': 236521298}","167":"{'ArXiv': '1901.09451', 'DBLP': 'journals\/corr\/abs-1901-09451', 'MAG': '2909212904', 'DOI': '10.1145\/3287560.3287572', 'CorpusId': 58006082}","168":"{'DBLP': 'conf\/cogsci\/OhmerKF20', 'CorpusId': 221133988}","169":"{'DBLP': 'journals\/corr\/abs-2009-13845', 'ArXiv': '2009.13845', 'MAG': '3091229675', 'CorpusId': 221995589}","170":"{'MAG': '3086725547', 'DBLP': 'journals\/tnn\/ZhangLLHSSL21', 'DOI': '10.1109\/tnnls.2020.3018790', 'CorpusId': 221626306, 'PubMed': '32903190'}","171":"{'ArXiv': '2103.17070', 'DBLP': 'journals\/corr\/abs-2103-17070', 'MAG': '3172288085', 'DOI': '10.1109\/CVPR46437.2021.01652', 'CorpusId': 232427835}","172":"{'ArXiv': '2107.11279', 'DBLP': 'journals\/corr\/abs-2107-11279', 'DOI': '10.1109\/iccv48922.2021.00685', 'CorpusId': 236318463}","173":"{'MAG': '3009976953', 'DBLP': 'conf\/wacv\/AzadFKAPD21', 'ArXiv': '2003.04052', 'DOI': '10.1109\/WACV48630.2021.00272', 'CorpusId': 212634001}","174":"{'MAG': '3088940539', 'DBLP': 'conf\/nips\/ZhangZT0S20', 'ArXiv': '2009.12547', 'CorpusId': 221970958}","175":"{'DBLP': 'conf\/aaai\/LiuJWXWV21', 'ArXiv': '2104.14795', 'CorpusId': 233476528}","176":"{'ArXiv': '2003.04614', 'DBLP': 'journals\/corr\/abs-2003-04614', 'MAG': '3010794128', 'DOI': '10.1007\/978-3-030-58583-9_29', 'CorpusId': 212644555}","177":"{'MAG': '3034359780', 'ArXiv': '2003.13261', 'DBLP': 'conf\/cvpr\/MinYXWZZ20', 'DOI': '10.1109\/cvpr42600.2020.01268', 'CorpusId': 214714502}","178":"{'DBLP': 'journals\/corr\/abs-2108-05720', 'ArXiv': '2108.05720', 'DOI': '10.1109\/iccv48922.2021.00897', 'CorpusId': 236986856}","179":"{'ACL': '2020.acl-main.260', 'MAG': '3035379020', 'DBLP': 'conf\/acl\/ZhaoMHCA20', 'ArXiv': '2005.00699', 'DOI': '10.18653\/v1\/2020.acl-main.260', 'CorpusId': 218487087}","180":"{'ACL': '2020.emnlp-main.23', 'MAG': '3104617516', 'DBLP': 'journals\/corr\/abs-2005-00614', 'ArXiv': '2005.00614', 'DOI': '10.18653\/v1\/2020.emnlp-main.23', 'CorpusId': 218487627}","181":"{'MAG': '3040296059', 'DBLP': 'conf\/eccv\/LiuWLCZY20', 'DOI': '10.1007\/978-3-030-58601-0_24', 'CorpusId': 220363383}","182":"{'ArXiv': '2002.08608', 'DBLP': 'journals\/peerj-cs\/KwakAJA21', 'PubMedCentral': '8323720', 'DOI': '10.7717\/peerj-cs.644', 'CorpusId': 236318586, 'PubMed': '34395864'}","183":"{'MAG': '3034847753', 'ACL': '2020.acl-main.484', 'DBLP': 'journals\/corr\/abs-2005-00965', 'ArXiv': '2005.00965', 'DOI': '10.18653\/v1\/2020.acl-main.484', 'CorpusId': 204770514}","184":"{'ACL': '2020.findings-emnlp.326', 'DBLP': 'conf\/emnlp\/VeysehNN20', 'MAG': '3102946850', 'ArXiv': '2010.13391', 'DOI': '10.18653\/v1\/2020.findings-emnlp.326', 'CorpusId': 225067984}","185":"{'DBLP': 'journals\/jbd\/HashemiH20', 'MAG': '2999546429', 'DOI': '10.1186\/s40537-019-0282-4', 'CorpusId': 209897114}","186":"{'MAG': '3034851464', 'DBLP': 'conf\/ijcai\/WangSZY020', 'DOI': '10.24963\/ijcai.2020\/119', 'CorpusId': 220484633}","187":"{'DBLP': 'conf\/emnlp\/OusidhoumSY20', 'ACL': '2020.emnlp-main.199', 'MAG': '3102141290', 'DOI': '10.18653\/v1\/2020.emnlp-main.199', 'CorpusId': 226262396}","188":"{'ArXiv': '2010.05495', 'DBLP': 'conf\/eccv\/KamannR20', 'MAG': '3108281323', 'DOI': '10.1007\/978-3-030-58607-2_22', 'CorpusId': 222290757}","189":"{'DBLP': 'journals\/corr\/abs-2007-00515', 'ArXiv': '2007.00515', 'MAG': '3086361745', 'DOI': '10.1109\/LSP.2020.3023340', 'CorpusId': 220280919}","190":"{'ArXiv': '1901.07656', 'MAG': '2913897682', 'DBLP': 'journals\/corr\/abs-1901-07656', 'CorpusId': 59158788}","191":"{'MAG': '3037165962', 'DBLP': 'conf\/acl\/Hamborg20', 'ACL': '2020.acl-srw.12', 'DOI': '10.18653\/v1\/2020.acl-srw.12', 'CorpusId': 220056948}","192":"{'MAG': '2917742317', 'DBLP': 'journals\/tip\/ShenZYYLS19', 'DOI': '10.1109\/TIP.2019.2899987', 'CorpusId': 73490126, 'PubMed': '30794175'}","193":"{'DBLP': 'conf\/emnlp\/ShinSJKJM20', 'ArXiv': '2004.03133', 'ACL': '2020.findings-emnlp.280', 'MAG': '3100881017', 'DOI': '10.18653\/v1\/2020.findings-emnlp.280', 'CorpusId': 215238794}","194":"{'DBLP': 'conf\/nips\/GondalWMLBVABSB19', 'ArXiv': '1906.03292', 'MAG': '2948215242', 'CorpusId': 182952649}","195":"{'DBLP': 'conf\/acl-deeplo\/SinghMSX19', 'ACL': 'D19-6106', 'MAG': '2985620815', 'DOI': '10.18653\/v1\/D19-6106', 'CorpusId': 207924237}","196":"{'MAG': '2979728922', 'DBLP': 'journals\/corr\/abs-1904-07659', 'ArXiv': '1904.07659', 'DOI': '10.1109\/CVPR.2019.00722', 'CorpusId': 119186616}","197":"{'DBLP': 'journals\/mta\/RezaeiYM20', 'MAG': '2911583416', 'DOI': '10.1007\/s11042-019-7305-1', 'CorpusId': 59606718}","198":"{'ArXiv': '1909.04165', 'ACL': 'D19-1391', 'DBLP': 'journals\/corr\/abs-1909-04165', 'MAG': '2970212756', 'DOI': '10.18653\/v1\/D19-1391', 'CorpusId': 202542899}","199":"{'DBLP': 'journals\/corr\/abs-1907-13054', 'MAG': '2964920648', 'ArXiv': '1907.13054', 'CorpusId': 198986162}","200":"{'DBLP': 'conf\/naacl\/AsaadiMK19', 'MAG': '2954604190', 'ACL': 'N19-1050', 'DOI': '10.18653\/v1\/N19-1050', 'CorpusId': 174799955}","201":"{'MAG': '2971733771', 'DBLP': 'conf\/emnlp\/LiLQW19', 'ArXiv': '1909.00141', 'ACL': 'D19-1623', 'DOI': '10.18653\/v1\/D19-1623', 'CorpusId': 202541388}","202":"{'DBLP': 'conf\/miccai\/YoonHG19', 'MAG': '2979553811', 'DOI': '10.1007\/978-3-030-32251-9_40', 'CorpusId': 201625607}","203":"{'MAG': '2970838167', 'DOI': '10.3758\/s13414-019-01849-7', 'CorpusId': 201659154, 'PubMed': '31456175'}","204":"{'DBLP': 'journals\/corr\/abs-1904-08577', 'MAG': '2935991147', 'ArXiv': '1904.08577', 'DOI': '10.1145\/3321707.3321776', 'CorpusId': 120358558}","205":"{'DBLP': 'conf\/iconference\/HamborgZG19', 'MAG': '2921663771', 'DOI': '10.1007\/978-3-030-15742-5_17', 'CorpusId': 77394379}","206":"{'DBLP': 'conf\/cogsci\/TomparyT19', 'MAG': '2977793219', 'DOI': '10.31234\/osf.io\/u754s', 'CorpusId': 203619769}","207":"{'MAG': '2981207735', 'ArXiv': '1910.07604', 'DBLP': 'journals\/corr\/abs-1910-07604', 'CorpusId': 204743639}","208":"{'DBLP': 'conf\/pricai\/AckermanGSS19', 'MAG': '2969472936', 'DOI': '10.1007\/978-3-030-29908-8_50', 'CorpusId': 201741922}","209":"{'DBLP': 'journals\/corr\/abs-2106-10270', 'ArXiv': '2106.10270', 'CorpusId': 235485156}","210":"{'DBLP': 'conf\/iclr\/WangLM0Y21', 'MAG': '3092063351', 'ArXiv': '2010.01809', 'CorpusId': 222134104}","211":"{'ACL': '2020.acl-main.676', 'MAG': '3035331128', 'ArXiv': '1904.09545', 'DBLP': 'journals\/corr\/abs-1904-09545', 'DOI': '10.18653\/v1\/2020.acl-main.676', 'CorpusId': 128000127}","212":"{'MAG': '3101004475', 'ACL': '2020.acl-main.468', 'DBLP': 'journals\/corr\/abs-1912-11078', 'ArXiv': '1912.11078', 'DOI': '10.18653\/v1\/2020.acl-main.468', 'CorpusId': 209461005}","213":"{'DBLP': 'journals\/corr\/abs-2007-03380', 'ArXiv': '2007.03380', 'MAG': '3039991645', 'DOI': '10.1109\/TPAMI.2021.3060412', 'CorpusId': 220380818, 'PubMed': '33600309'}","214":"{'DBLP': 'conf\/www\/WangZXLG19', 'MAG': '2913560138', 'ArXiv': '1904.12575', 'DOI': '10.1145\/3308558.3313417', 'CorpusId': 86631164}","215":"{'DBLP': 'conf\/iclr\/GuiziliniHLAG20', 'MAG': '3008064955', 'ArXiv': '2002.12319', 'CorpusId': 211532626}","216":"{'ArXiv': '2006.08545', 'DBLP': 'journals\/corr\/abs-2006-08545', 'MAG': '3101499628', 'CorpusId': 219687356}","217":"{'DBLP': 'conf\/cvpr\/HuynhE20', 'MAG': '3035655772', 'DOI': '10.1109\/cvpr42600.2020.00454', 'CorpusId': 216078798}","218":"{'DBLP': 'journals\/tmi\/LiuZSZOHCC21', 'MAG': '3085410595', 'DOI': '10.1109\/TMI.2020.3023466', 'CorpusId': 221637473, 'PubMed': '32915732'}","219":"{'DBLP': 'journals\/corr\/abs-2107-13807', 'ArXiv': '2107.13807', 'DOI': '10.1109\/iccv48922.2021.00019', 'CorpusId': 236493217}","220":"{'DBLP': 'conf\/mm\/LiYSC21', 'DOI': '10.1145\/3474085.3475540', 'CorpusId': 239012256}","221":"{'ACL': '2021.emnlp-main.411', 'DBLP': 'conf\/emnlp\/Dev0PS21', 'ArXiv': '2007.00049', 'MAG': '3039559565', 'DOI': '10.18653\/v1\/2021.emnlp-main.411', 'CorpusId': 220281039}","222":"{'DBLP': 'journals\/tnn\/ZhaoYZCYW21', 'MAG': '3022161521', 'DOI': '10.1109\/TNNLS.2020.2984810', 'CorpusId': 218469668, 'PubMed': '32356763'}","223":"{'DBLP': 'journals\/corr\/abs-2103-06413', 'ArXiv': '2103.06413', 'CorpusId': 232185104}","224":"{'MAG': '3000538487', 'DBLP': 'journals\/tip\/GaoHQCLZZS20', 'DOI': '10.1109\/TIP.2020.2964429', 'CorpusId': 210334032, 'PubMed': '31940538'}","225":"{'ArXiv': '2007.04873', 'DBLP': 'conf\/eccv\/ShenQHL0020', 'MAG': '3041404349', 'DOI': '10.1007\/978-3-030-58517-4_36', 'CorpusId': 220425382}","226":"{'DBLP': 'conf\/cvpr\/FanLJZFC20', 'MAG': '3034499925', 'DOI': '10.1109\/cvpr42600.2020.00299', 'CorpusId': 211858069}","227":"{'DBLP': 'conf\/midl\/BillotGLFID20', 'ArXiv': '2003.01995', 'MAG': '3009445070', 'CorpusId': 211989534}","228":"{'DBLP': 'journals\/corr\/abs-2012-02994', 'ArXiv': '2012.02994', 'MAG': '3099518117', 'DOI': '10.1007\/978-3-030-58589-1_39', 'CorpusId': 226308394}","229":"{'MAG': '2997326549', 'DBLP': 'conf\/aaai\/ZhuZZLZL20', 'DOI': '10.1609\/AAAI.V34I05.6525', 'CorpusId': 214273679}","230":"{'ArXiv': '1905.12866', 'DBLP': 'journals\/corr\/abs-1905-12866', 'MAG': '2947480709', 'ACL': 'P19-1360', 'DOI': '10.18653\/v1\/P19-1360', 'CorpusId': 170078653}","231":"{'DBLP': 'conf\/sigir\/ZhouDW20', 'MAG': '3034751553', 'DOI': '10.1145\/3397271.3401175', 'CorpusId': 220729675}","232":"{'DBLP': 'conf\/aaai\/MaH20', 'MAG': '2998124234', 'DOI': '10.1609\/AAAI.V34I07.6844', 'CorpusId': 213450595}","233":"{'DBLP': 'journals\/tacl\/KumarBKC20', 'MAG': '3083213769', 'ArXiv': '2006.01938', 'DOI': '10.1162\/tacl_a_00327', 'CorpusId': 219260204}","234":"{'DBLP': 'conf\/coling\/ConiaN20a', 'ACL': '2020.coling-main.291', 'MAG': '3115435759', 'DOI': '10.18653\/V1\/2020.COLING-MAIN.291', 'CorpusId': 227231460}","235":"{'DBLP': 'conf\/iccv\/FengKFY19', 'MAG': '3000029975', 'ArXiv': '1908.01925', 'DOI': '10.1109\/ICCV.2019.00808', 'CorpusId': 199452702}","236":"{'MAG': '3004532592', 'DOI': '10.1145\/3377713.3377792', 'CorpusId': 211104718}","237":"{'DBLP': 'journals\/corr\/abs-1909-08245', 'ArXiv': '1909.08245', 'MAG': '2974369872', 'CorpusId': 202661005}","238":"{'DBLP': 'journals\/bmcbi\/LiuT19', 'MAG': '2940574427', 'PubMedCentral': '6437941', 'DOI': '10.1186\/s12859-019-2752-2', 'CorpusId': 85528184, 'PubMed': '30917779'}","239":"{'ArXiv': '1908.04174', 'DBLP': 'journals\/corr\/abs-1908-04174', 'MAG': '2981648435', 'DOI': '10.1145\/3343031.3351092', 'CorpusId': 199543311}","240":"{'ACL': 'W19-4705', 'MAG': '2965988306', 'DOI': '10.18653\/v1\/W19-4705', 'CorpusId': 199532063}","241":"{'ACL': '2021.acl-long.75', 'MAG': '3093630174', 'ArXiv': '2010.12725', 'DBLP': 'conf\/acl\/ShawCPT20', 'DOI': '10.18653\/v1\/2021.acl-long.75', 'CorpusId': 225066984}","242":"{'DBLP': 'journals\/corr\/abs-2009-05021', 'MAG': '3084269450', 'ArXiv': '2009.05021', 'DOI': '10.1007\/S12559-021-09881-2', 'CorpusId': 221586314}","243":"{'DBLP': 'conf\/iccv\/BaekOH21', 'ArXiv': '2108.06536', 'DOI': '10.1109\/iccv48922.2021.00940', 'CorpusId': 237091069}","244":"{'MAG': '3034435444', 'DBLP': 'conf\/cvpr\/CermelliMB0C20', 'ArXiv': '2002.00718', 'DOI': '10.1109\/cvpr42600.2020.00925', 'CorpusId': 211011110}","245":"{'MAG': '3102977943', 'DBLP': 'conf\/eccv\/LiKLWY20', 'DOI': '10.1007\/978-3-030-58568-6_26', 'CorpusId': 226840200}","246":"{'ArXiv': '2009.02960', 'MAG': '3083755954', 'PubMedCentral': '8225802', 'DBLP': 'journals\/corr\/abs-2009-02960', 'DOI': '10.1038\/s41598-021-92337-2', 'CorpusId': 221516509, 'PubMed': '34168169'}","247":"{'MAG': '3038091703', 'DBLP': 'conf\/cibcb\/Jadon20', 'ArXiv': '2006.14822', 'DOI': '10.1109\/CIBCB48159.2020.9277638', 'CorpusId': 220128180}","248":"{'DBLP': 'journals\/corr\/abs-1911-03064', 'MAG': '2983486364', 'ACL': '2020.findings-emnlp.7', 'ArXiv': '1911.03064', 'DOI': '10.18653\/v1\/2020.findings-emnlp.7', 'CorpusId': 207847197}","249":"{'DBLP': 'journals\/ijsr\/SpatolaW21', 'MAG': '3092923622', 'DOI': '10.1007\/s12369-020-00701-5', 'CorpusId': 225107547}","250":"{'ArXiv': '2012.12545', 'DBLP': 'journals\/corr\/abs-2012-12545', 'CorpusId': 229363817}","251":"{'DBLP': 'journals\/corr\/abs-2001-08767', 'MAG': '3001655931', 'ArXiv': '2001.08767', 'DOI': '10.1145\/3351095.3372858', 'CorpusId': 210911504}","252":"{'DBLP': 'conf\/eccv\/HanZXC20', 'MAG': '3011098590', 'ArXiv': '2003.04676', 'DOI': '10.1007\/978-3-030-58545-7_15', 'CorpusId': 212644678}","253":"{'DBLP': 'conf\/jcdl\/SpindeKGHGG21', 'ArXiv': '2112.07392', 'DOI': '10.1109\/JCDL52503.2021.00018', 'CorpusId': 245130960}","254":"{'MAG': '3033221365', 'PubMedCentral': '7309110', 'DBLP': 'journals\/sensors\/KhanYAAM20', 'DOI': '10.3390\/s20113183', 'CorpusId': 219399160, 'PubMed': '32503330'}","255":"{'MAG': '3034984114', 'DBLP': 'conf\/ijcai\/ZhangTB20', 'ArXiv': '2005.03086', 'DOI': '10.24963\/ijcai.2020\/124', 'CorpusId': 213623552}","256":"{'MAG': '2981512393', 'DBLP': 'conf\/iccv\/0001XC19', 'ArXiv': '1909.13589', 'DOI': '10.1109\/ICCV.2019.00218', 'CorpusId': 203593505}","257":"{'DBLP': 'conf\/iccv\/NagelBBW19', 'MAG': '2950297794', 'ArXiv': '1906.04721', 'DOI': '10.1109\/ICCV.2019.00141', 'CorpusId': 184487878}","258":"{'DBLP': 'conf\/acl\/DubossarskyHTS19', 'MAG': '2948104589', 'ArXiv': '1906.01688', 'ACL': 'P19-1044', 'DOI': '10.18653\/v1\/P19-1044', 'CorpusId': 174799008}","259":"{'MAG': '3004292817', 'ArXiv': '2002.00176', 'DBLP': 'journals\/corr\/abs-2002-00176', 'CorpusId': 211011117}","260":"{'MAG': '2955015477', 'DOI': '10.1007\/s00259-019-04380-x', 'CorpusId': 195766482, 'PubMed': '31264170'}","261":"{'DBLP': 'journals\/remotesensing\/MalamboPKRZM19', 'MAG': '2994699036', 'DOI': '10.3390\/rs11242939', 'CorpusId': 210702616}","262":"{'DBLP': 'journals\/neuroimage\/ShahdlooCC20', 'MAG': '2947119568', 'DOI': '10.1101\/658096', 'CorpusId': 190881385}","263":"{'DBLP': 'journals\/corr\/abs-2012-09841', 'MAG': '3111551570', 'ArXiv': '2012.09841', 'DOI': '10.1109\/CVPR46437.2021.01268', 'CorpusId': 229297973}","264":"{'ArXiv': '2201.03545', 'CorpusId': 245837420}","265":"{'ArXiv': '2105.10497', 'DBLP': 'journals\/corr\/abs-2105-10497', 'CorpusId': 235125781}","266":"{'DBLP': 'journals\/corr\/abs-2010-00577', 'MAG': '3091534907', 'ArXiv': '2010.00577', 'CorpusId': 222090060}","267":"{'DBLP': 'journals\/corr\/abs-2002-11297', 'MAG': '3034230713', 'ArXiv': '2002.11297', 'DOI': '10.1109\/cvpr42600.2020.01096', 'CorpusId': 211506988}","268":"{'DBLP': 'journals\/corr\/abs-2108-04378', 'ArXiv': '2108.04378', 'ACL': '2022.acl-long.251', 'CorpusId': 236965823}","269":"{'DBLP': 'journals\/qss\/WangSHWDK20', 'MAG': '3002924435', 'DOI': '10.1162\/qss_a_00021', 'CorpusId': 210872675}","270":"{'ArXiv': '2101.11604', 'DBLP': 'journals\/corr\/abs-2101-11604', 'CorpusId': 231718721}","271":"{'DBLP': 'journals\/corr\/abs-2009-07526', 'ArXiv': '2009.07526', 'MAG': '3086903637', 'DOI': '10.24963\/ijcai.2021\/176', 'CorpusId': 221739238}","272":"{'DBLP': 'conf\/iclr\/HellendoornSSMB20', 'MAG': '2996086147', 'CorpusId': 213352113}","273":"{'DBLP': 'conf\/iclr\/0022WZ20', 'ArXiv': '1908.04942', 'MAG': '2967827612', 'CorpusId': 199577786}","274":"{'DBLP': 'conf\/iclr\/CasanovaPRP20', 'MAG': '2995306638', 'ArXiv': '2002.06583', 'CorpusId': 211133088}","275":"{'MAG': '3004153848', 'ArXiv': '2001.11314', 'DBLP': 'journals\/corr\/abs-2001-11314', 'DOI': '10.24963\/ijcai.2020\/549', 'CorpusId': 210966163}","276":"{'MAG': '2998463583', 'ArXiv': '1909.06092', 'DBLP': 'journals\/corr\/abs-1909-06092', 'DOI': '10.1609\/AAAI.V34I05.6325', 'CorpusId': 202572693}","277":"{'DBLP': 'journals\/corr\/abs-2005-02066', 'ArXiv': '2005.02066', 'MAG': '3034457289', 'DOI': '10.1109\/cvpr42600.2020.00430', 'CorpusId': 218502373}","278":"{'MAG': '3026289162', 'DBLP': 'conf\/uai\/DadanehBYZQ20', 'ArXiv': '2005.10477', 'CorpusId': 218763562}","279":"{'MAG': '3012187195', 'DBLP': 'journals\/gpem\/CavaM20', 'DOI': '10.1007\/s10710-020-09383-4', 'CorpusId': 212670167, 'PubMed': '33343224'}","280":"{'DBLP': 'journals\/tip\/ZhangYZJSC19', 'MAG': '2884326683', 'DOI': '10.1109\/TIP.2018.2855415', 'CorpusId': 51628379, 'PubMed': '30010565'}","281":"{'DBLP': 'journals\/tip\/XiaoZZGC20', 'MAG': '3016201367', 'DOI': '10.1109\/TIP.2020.2985868', 'CorpusId': 215771735, 'PubMed': '32286987'}","282":"{'ArXiv': '1909.07945', 'DBLP': 'journals\/corr\/abs-1909-07945', 'MAG': '2994785205', 'DOI': '10.1109\/ICCVW.2019.00166', 'CorpusId': 202583324}","283":"{'ArXiv': '1909.08975', 'MAG': '2973581025', 'DBLP': 'conf\/conll\/JumeletZH19', 'ACL': 'K19-1001', 'DOI': '10.18653\/v1\/K19-1001', 'CorpusId': 202676782}","284":"{'MAG': '2965280546', 'DBLP': 'conf\/aaai\/ParkHCCH0Y19', 'DOI': '10.1609\/aaai.v33i01.33016883', 'CorpusId': 198190002}","285":"{'DBLP': 'conf\/ijcnn\/DasL19', 'MAG': '2923124246', 'ArXiv': '1903.11701', 'DOI': '10.1109\/IJCNN.2019.8852315', 'CorpusId': 85543113}","286":"{'ArXiv': '1912.02973', 'MAG': '2994536035', 'DBLP': 'journals\/corr\/abs-1912-02973', 'CorpusId': 208857435}","287":"{'MAG': '2946202814', 'ACL': 'N19-1215', 'DBLP': 'conf\/naacl\/Oba0SAT19', 'DOI': '10.18653\/v1\/N19-1215', 'CorpusId': 174799874}","288":"{'DBLP': 'conf\/nips\/Purushwalkam020', 'MAG': '3105422445', 'ArXiv': '2007.13916', 'CorpusId': 220830871}","289":"{'MAG': '2950104027', 'DBLP': 'conf\/cvpr\/HudsonM19', 'DOI': '10.1109\/CVPR.2019.00686', 'CorpusId': 152282269}","290":"{'DBLP': 'conf\/nips\/MuA20', 'ArXiv': '2006.14032', 'MAG': '3037626499', 'CorpusId': 220055965}","291":"{'MAG': '2938082352', 'ArXiv': '1902.09506', 'DBLP': 'journals\/corr\/abs-1902-09506', 'CorpusId': 67855531}","292":"{'MAG': '2912371042', 'DBLP': 'journals\/corr\/abs-1901-06706', 'ArXiv': '1901.06706', 'CorpusId': 58981654}","293":"{'DBLP': 'journals\/corr\/abs-2010-08942', 'ArXiv': '2010.08942', 'MAG': '3092934936', 'DOI': '10.1109\/LSP.2021.3050712', 'CorpusId': 224704488}","294":"{'MAG': '2991321419', 'PubMedCentral': '6886168', 'DBLP': 'journals\/bmcbi\/ZengLWLP19', 'DOI': '10.1186\/s12859-019-3076-y', 'CorpusId': 208520564, 'PubMed': '31787076'}","295":"{'DBLP': 'journals\/staeors\/ChenWLXHD21', 'DOI': '10.1109\/JSTARS.2021.3053603', 'CorpusId': 231920423}","296":"{'ACL': '2021.emnlp-main.502', 'DBLP': 'journals\/corr\/abs-2012-14388', 'ArXiv': '2012.14388', 'DOI': '10.18653\/v1\/2021.emnlp-main.502', 'CorpusId': 229677944}","297":"{'MAG': '3109780340', 'DBLP': 'conf\/edm\/ArthursA20', 'CorpusId': 220934452}","298":"{'DBLP': 'journals\/corr\/abs-2006-08602', 'MAG': '3098467408', 'ArXiv': '2006.08602', 'CorpusId': 219708282}","299":"{'MAG': '3006396692', 'DBLP': 'journals\/tois\/QinZXZMCX20', 'DOI': '10.1145\/3376927', 'CorpusId': 212737484}","300":"{'DBLP': 'conf\/nips\/0004K19', 'MAG': '2983039579', 'ArXiv': '1911.00147', 'CorpusId': 202767955}","301":"{'ArXiv': '2010.10469', 'DBLP': 'journals\/corr\/abs-2010-10469', 'MAG': '3094064346', 'CorpusId': 224803983}","302":"{'ACL': '2020.emnlp-main.148', 'ArXiv': '2009.08552', 'DBLP': 'journals\/corr\/abs-2009-08552', 'MAG': '3101923488', 'DOI': '10.18653\/v1\/2020.emnlp-main.148', 'CorpusId': 221802508}","303":"{'DBLP': 'journals\/corr\/abs-1906-01440', 'ArXiv': '1906.01440', 'MAG': '2972953278', 'ACL': 'W19-4715', 'DOI': '10.18653\/v1\/W19-4715', 'CorpusId': 174797789}","304":"{'MAG': '2973804099', 'ArXiv': '1909.08859', 'DBLP': 'conf\/conll\/AmacYEE19', 'ACL': 'K19-1041', 'DOI': '10.18653\/v1\/K19-1041', 'CorpusId': 202676821}","305":"{'DBLP': 'journals\/corr\/abs-1905-09716', 'MAG': '2944855023', 'ArXiv': '1905.09716', 'DOI': '10.1201\/9780367815646-19', 'CorpusId': 162184317}","306":"{'DBLP': 'conf\/sigsoft\/YangA021', 'ArXiv': '2105.14874', 'DOI': '10.1145\/3468264.3473117', 'CorpusId': 235254427}","307":"{'MAG': '3034273940', 'DOI': '10.3390\/electronics9060997', 'CorpusId': 225692045}","308":"{'DBLP': 'journals\/corr\/abs-2104-02290', 'ArXiv': '2104.02290', 'CorpusId': 233033761}","309":"{'MAG': '2973802121', 'DOI': '10.1007\/s41809-019-00038-0', 'CorpusId': 203708988}","310":"{'MAG': '2996472110', 'DBLP': 'journals\/pacmpl\/AnSMS20', 'DOI': '10.1145\/3371124', 'CorpusId': 207992706}","311":"{'DBLP': 'journals\/fi\/SuJ20', 'MAG': '3006603615', 'DOI': '10.3390\/fi12020039', 'CorpusId': 214096038}","312":"{'DBLP': 'journals\/corr\/abs-2104-02768', 'ArXiv': '2104.02768', 'CorpusId': 233168673}","313":"{'DBLP': 'journals\/nca\/LiZYLDL21', 'MAG': '3084840705', 'DOI': '10.1007\/S00521-020-05322-7', 'CorpusId': 225038691}","314":"{'MAG': '3132560851', 'DOI': '10.1007\/S00521-021-05746-9', 'CorpusId': 233881378}","315":"{'DBLP': 'conf\/nips\/ZhangKYW21', 'ArXiv': '2106.02320', 'CorpusId': 235352909}","316":"{'MAG': '3009755915', 'DBLP': 'journals\/remotesensing\/SongC20', 'DOI': '10.3390\/rs12050799', 'CorpusId': 215414225}","317":"{'ACL': 'W19-3813', 'MAG': '2964843157', 'DBLP': 'journals\/corr\/abs-1908-00308', 'ArXiv': '1908.00308', 'DOI': '10.18653\/v1\/W19-3813', 'CorpusId': 199064406}","318":"{'DBLP': 'journals\/corr\/abs-2107-11443', 'ArXiv': '2107.11443', 'DOI': '10.1109\/iccv48922.2021.00711', 'CorpusId': 236428887}","319":"{'MAG': '2998773859', 'DBLP': 'journals\/jdi\/LindseyL20', 'DOI': '10.1007\/s10278-019-00197-0', 'CorpusId': 210826435, 'PubMed': '31939003'}","320":"{'DBLP': 'conf\/ccks\/LiCYBDZC21', 'ArXiv': '2009.06206', 'DOI': '10.1007\/978-981-16-6471-7_4', 'CorpusId': 237497400}","321":"{'DBLP': 'conf\/aaai\/ZhangW20a', 'MAG': '2997910357', 'DOI': '10.1609\/AAAI.V34I04.6169', 'CorpusId': 213132392}","322":"{'DBLP': 'journals\/sensors\/TeixeiraPBONCC21', 'PubMedCentral': '8587284', 'ArXiv': '2009.09780', 'MAG': '3087503966', 'DOI': '10.3390\/s21217116', 'CorpusId': 221819230, 'PubMed': '34770423'}","323":"{'DBLP': 'conf\/esem\/ZafarMW19', 'MAG': '2980731667', 'DOI': '10.1109\/ESEM.2019.8870174', 'CorpusId': 204817788}","324":"{'MAG': '3106169594', 'DBLP': 'journals\/ec\/VirgolinAWB21', 'DOI': '10.1162\/evco_a_00278', 'CorpusId': 195776100, 'PubMed': '32574084'}","325":"{'MAG': '3024226488', 'DOI': '10.1080\/01615440.2020.1760157', 'CorpusId': 219481638}","326":"{'MAG': '2996773210', 'DBLP': 'journals\/iotj\/HuWXW20', 'DOI': '10.1109\/JIOT.2019.2962630', 'CorpusId': 213177495}","327":"{'ArXiv': '2106.09645', 'DBLP': 'journals\/corr\/abs-2106-09645', 'CorpusId': 235457979}","328":"{'MAG': '2930153551', 'DBLP': 'journals\/jasis\/MachadoSS19', 'DOI': '10.1002\/asi.24111', 'CorpusId': 132452526}","329":"{'ArXiv': '2103.05841', 'DBLP': 'journals\/corr\/abs-2103-05841', 'DOI': '10.1145\/3524887', 'CorpusId': 232170385}","330":"{'DBLP': 'journals\/tcyb\/GongJLT19', 'MAG': '2805046565', 'DOI': '10.1109\/TCYB.2018.2834898', 'CorpusId': 51614376, 'PubMed': '29994343'}","331":"{'DBLP': 'journals\/corr\/abs-1912-05238', 'MAG': '2996314454', 'ArXiv': '1912.05238', 'CorpusId': 209202242}","332":"{'DBLP': 'journals\/corr\/abs-2006-06814', 'ArXiv': '2006.06814', 'MAG': '3034441005', 'CorpusId': 219636414}","333":"{'DBLP': 'journals\/corr\/abs-2012-02166', 'ArXiv': '2012.02166', 'MAG': '3109440167', 'CorpusId': 227254544}","334":"{'ArXiv': '2104.01832', 'DBLP': 'conf\/aaai\/WangCM0L21', 'CorpusId': 233024702}","335":"{'MAG': '2767800522', 'DBLP': 'journals\/synthese\/Dimmock19', 'DOI': '10.1007\/s11229-017-1603-9', 'CorpusId': 46961885}","336":"{'MAG': '3010899062', 'DBLP': 'journals\/corr\/abs-2003-08835', 'ArXiv': '2003.08835', 'PubMedCentral': '7924458', 'DOI': '10.7717\/peerj-cs.295', 'CorpusId': 213005207, 'PubMed': '33816946'}","337":"{'ArXiv': '2111.09888', 'DBLP': 'journals\/corr\/abs-2111-09888', 'CorpusId': 244346010}","338":"{'MAG': '3013660878', 'DBLP': 'journals\/corr\/abs-2003-11743', 'ArXiv': '2003.11743', 'CorpusId': 214667180}","339":"{'ArXiv': '2104.14674', 'ACL': '2021.naacl-main.443', 'MAG': '3167397433', 'DBLP': 'journals\/corr\/abs-2104-14674', 'DOI': '10.18653\/V1\/2021.NAACL-MAIN.443', 'CorpusId': 233476375}","340":"{'MAG': '2967369756', 'DBLP': 'journals\/corr\/abs-1908-04930', 'ArXiv': '1908.04930', 'DOI': '10.1109\/DICTA47822.2019.8945949', 'CorpusId': 199577523}","341":"{'DBLP': 'conf\/emnlp\/ZaremoodiH19', 'MAG': '2983490653', 'ACL': 'D19-5618', 'DOI': '10.18653\/v1\/D19-5618', 'CorpusId': 208165145}","342":"{'ArXiv': '1908.07026', 'MAG': '2969788869', 'DBLP': 'journals\/corr\/abs-1908-07026', 'CorpusId': 201103608}","343":"{'DBLP': 'conf\/acl\/DesaiA21', 'ACL': '2021.findings-acl.5', 'ArXiv': '2105.13496', 'DOI': '10.18653\/v1\/2021.findings-acl.5', 'CorpusId': 235247949}","344":"{'ArXiv': '2103.05271', 'DBLP': 'conf\/cvpr\/YangZ0WY21', 'DOI': '10.1109\/CVPR46437.2021.01234', 'CorpusId': 232168713}","345":"{'ArXiv': '2002.05322', 'DBLP': 'journals\/corr\/abs-2002-05322', 'MAG': '3006361452', 'CorpusId': 211096634}","346":"{'MAG': '2957896848', 'DBLP': 'conf\/bica\/IsmailovaKZW19', 'DOI': '10.1007\/978-3-030-25719-4_18', 'CorpusId': 199326897}","347":"{'DBLP': 'conf\/dsc\/GuanWWL20', 'MAG': '3080835043', 'DOI': '10.1109\/DSC50466.2020.00013', 'CorpusId': 221284355}","348":"{'MAG': '2943885184', 'DBLP': 'journals\/tmm\/XiaoWDXP19', 'DOI': '10.1109\/TMM.2019.2915033', 'CorpusId': 164350363}","349":"{'MAG': '3038023950', 'ArXiv': '2001.06944', 'DBLP': 'conf\/aistats\/ZhangCGWWC20', 'CorpusId': 210839491}","350":"{'MAG': '2980142079', 'DOI': '10.1075\/hcp.66', 'CorpusId': 214003313}","351":"{'DBLP': 'journals\/corr\/abs-2009-06206', 'MAG': '3085225979', 'CorpusId': 221655643}","352":"{'MAG': '2921050194', 'DBLP': 'conf\/wacv\/RezaeiYHM19', 'DOI': '10.1109\/WACV.2019.00200', 'CorpusId': 71150840}","353":"{'PubMedCentral': '7553929', 'MAG': '3092204459', 'DOI': '10.1038\/s41598-020-73978-1', 'CorpusId': 222344985, 'PubMed': '33051564'}","354":"{'DBLP': 'conf\/cvpr\/WuZZLZW20', 'MAG': '3035388827', 'DOI': '10.1109\/CVPR42600.2020.01278', 'CorpusId': 219979290}","355":"{'DBLP': 'journals\/corr\/abs-2008-11185', 'MAG': '3080429211', 'ArXiv': '2008.11185', 'CorpusId': 221293276}","356":"{'MAG': '3097927557', 'ACL': '2020.peoples-1.12', 'ArXiv': '2011.01599', 'DBLP': 'journals\/corr\/abs-2011-01599', 'CorpusId': 226237627}","357":"{'ArXiv': '1910.05177', 'DBLP': 'journals\/corr\/abs-1910-05177', 'MAG': '2980256670', 'CorpusId': 204401746}","358":"{'MAG': '2972388764', 'DBLP': 'conf\/interspeech\/TundikKS19', 'DOI': '10.21437\/interspeech.2019-2154', 'CorpusId': 202715851}","359":"{'MAG': '2983279852', 'ACL': 'D19-5015', 'DOI': '10.18653\/v1\/D19-5015', 'CorpusId': 207910876}","360":"{'PubMedCentral': '7212362', 'MAG': '3022023647', 'DOI': '10.3389\/fgene.2020.00384', 'CorpusId': 216554243, 'PubMed': '32425979'}","361":"{'MAG': '3008903937', 'DBLP': 'conf\/bigdataconf\/DareddyDY19', 'ArXiv': '1908.08227', 'DOI': '10.1109\/BigData47090.2019.9005670', 'CorpusId': 201304037}","362":"{'DBLP': 'journals\/pami\/YeZJZ21', 'MAG': '3025169037', 'DOI': '10.1109\/tpami.2020.2994749', 'CorpusId': 219489919, 'PubMed': '32750764'}","363":"{'DBLP': 'journals\/corr\/abs-2006-04648', 'MAG': '3033199763', 'CorpusId': 219531181}","364":"{'DBLP': 'journals\/corr\/abs-1812-00078', 'MAG': '2903305687', 'DOI': '10.1109\/ICSE-Companion.2019.00107', 'CorpusId': 54436862}","365":"{'DBLP': 'conf\/naacl\/SadhuCN21', 'MAG': '3168620925', 'ArXiv': '2104.03762', 'ACL': '2021.naacl-main.196', 'DOI': '10.18653\/V1\/2021.NAACL-MAIN.196', 'CorpusId': 233181708}","366":"{'DBLP': 'conf\/cogsci\/RussinJOB20', 'CorpusId': 231793410}","367":"{'MAG': '3080601402', 'DOI': '10.12720\/jait.11.3.109-118', 'CorpusId': 221693168}","368":"{'DBLP': 'conf\/miccai\/0001DHJM19', 'MAG': '2980081640', 'DOI': '10.1007\/978-3-030-32239-7_17', 'CorpusId': 204027007}","369":"{'DBLP': 'journals\/corr\/abs-2101-01686', 'ArXiv': '2101.01686', 'CorpusId': 230523794}","370":"{'DBLP': 'journals\/corr\/abs-2112-01683', 'ArXiv': '2112.01683', 'CorpusId': 244896547}","371":"{'MAG': '3127790566', 'DBLP': 'journals\/remotesensing\/TangZZT21', 'DOI': '10.3390\/rs13040612', 'CorpusId': 232314288}","372":"{'DBLP': 'conf\/emnlp\/KulshreshthaGC20', 'ArXiv': '2009.14304', 'MAG': '3089820221', 'ACL': '2020.findings-emnlp.83', 'DOI': '10.18653\/v1\/2020.findings-emnlp.83', 'CorpusId': 222067073}","373":"{'DBLP': 'journals\/corr\/abs-2111-14887', 'ArXiv': '2111.14887', 'CorpusId': 244729413}","374":"{'DBLP': 'journals\/corr\/abs-2006-00412', 'MAG': '3029035851', 'ArXiv': '2006.00412', 'DOI': '10.1109\/TMM.2021.3074252', 'CorpusId': 219176616}","375":"{'MAG': '3021013004', 'ArXiv': '2004.14003', 'DBLP': 'journals\/corr\/abs-2004-14003', 'DOI': '10.1148\/RYAI.2021200078', 'CorpusId': 216642238, 'PubMed': '34235438'}","376":"{'MAG': '2955504852', 'DOI': '10.3758\/s13414-019-01801-9', 'CorpusId': 195760136, 'PubMed': '31254261'}","377":"{'MAG': '3099632249', 'ArXiv': '2010.02467', 'DBLP': 'conf\/emnlp\/NiHGM20', 'ACL': '2020.findings-emnlp.176', 'DOI': '10.18653\/v1\/2020.findings-emnlp.176', 'CorpusId': 222140968}","378":"{'DBLP': 'conf\/ida\/DoorenmalenM20', 'MAG': '3018295854', 'DOI': '10.1007\/978-3-030-44584-3_12', 'CorpusId': 216072483}","379":"{'DBLP': 'conf\/acl\/NorouziTC20', 'ACL': '2021.acl-short.98', 'DOI': '10.18653\/v1\/2021.acl-short.98', 'CorpusId': 236459804}","380":"{'DBLP': 'conf\/bmvc\/WangSCA19', 'MAG': '2990071502', 'CorpusId': 204750334}","381":"{'DBLP': 'conf\/emnlp\/ZhaoZX021', 'DOI': '10.18653\/v1\/2021.findings-emnlp.209', 'CorpusId': 244119114}","382":"{'MAG': '2908532482', 'DBLP': 'journals\/access\/JiangGFWH19', 'DOI': '10.1109\/ACCESS.2019.2892973', 'CorpusId': 61808586}","383":"{'DBLP': 'journals\/corr\/abs-2103-00336', 'ArXiv': '2103.00336', 'CorpusId': 232075605}","384":"{'ArXiv': '2108.00968', 'CorpusId': 239050505}","385":"{'DBLP': 'journals\/corr\/abs-2006-03744', 'ArXiv': '2006.03744', 'MAG': '3033123705', 'CorpusId': 219530927}","386":"{'DBLP': 'journals\/corr\/abs-2106-05682', 'ArXiv': '2106.05682', 'CorpusId': 235390562}","387":"{'ACL': '2021.cl-2.14', 'DBLP': 'journals\/coling\/LoureiroRPC21', 'MAG': '3146681443', 'DOI': '10.1162\/coli_a_00405', 'CorpusId': 232278102}","388":"{'ArXiv': '2110.04541', 'DBLP': 'journals\/corr\/abs-2110-04541', 'CorpusId': 238583726}","389":"{'MAG': '3102914525', 'ACL': '2020.emnlp-main.602', 'DBLP': 'journals\/corr\/abs-2010-13816', 'ArXiv': '2010.13816', 'DOI': '10.18653\/v1\/2020.emnlp-main.602', 'CorpusId': 225075985}","390":"{'DBLP': 'journals\/csur\/MehrabiMSLG21', 'ArXiv': '1908.09635', 'MAG': '2969896603', 'DOI': '10.1145\/3457607', 'CorpusId': 201666566}","391":"{'MAG': '2970684805', 'DOI': '10.1136\/bmj.l4898', 'CorpusId': 201669438, 'PubMed': '31462531'}","392":"{'MAG': '2949678053', 'ACL': 'P19-1163', 'DBLP': 'conf\/acl\/SapCGCS19', 'DOI': '10.18653\/v1\/P19-1163', 'CorpusId': 196211238}","393":"{'MAG': '2788788682', 'DOI': '10.1007\/978-3-030-16920-6_12', 'CorpusId': 196128146}","394":"{'DBLP': 'conf\/hci\/KoivulaRS19', 'MAG': '2958804802', 'DOI': '10.1007\/978-3-030-22646-6_11', 'CorpusId': 195856958}","395":"{'MAG': '2997588435', 'DBLP': 'journals\/corr\/abs-1908-09369', 'ArXiv': '1908.09369', 'DOI': '10.1609\/AAAI.V34I05.6267', 'CorpusId': 201670701}","396":"{'MAG': '3209156192', 'DOI': '10.34179\/REVISEM.V6I3.14904', 'CorpusId': 244129123}","397":"{'MAG': '2907918833', 'DBLP': 'journals\/ijimai\/KumarHD19', 'DOI': '10.9781\/IJIMAI.2018.12.005', 'CorpusId': 59253424}","398":"{'ArXiv': '1906.05993', 'MAG': '2950742112', 'DBLP': 'journals\/corr\/abs-1906-05993', 'ACL': 'W19-3806', 'DOI': '10.18653\/v1\/W19-3806', 'CorpusId': 189898066}","399":"{'MAG': '3115557324', 'DOI': '10.1093\/oso\/9780190057657.003.0015', 'CorpusId': 234087087}","400":"{'MAG': '2973194547', 'ACL': 'W19-3820', 'DBLP': 'journals\/corr\/abs-1906-00839', 'ArXiv': '1906.00839', 'DOI': '10.18653\/v1\/W19-3820', 'CorpusId': 173990711}","401":"{'DBLP': 'journals\/corr\/abs-2010-10820', 'ArXiv': '2010.10820', 'MAG': '3094269534', 'CorpusId': 224814198}","402":"{'MAG': '3046851626', 'CorpusId': 226407202}","403":"{'DBLP': 'conf\/emnlp\/ZhouSZHCCC19', 'MAG': '2971904186', 'ArXiv': '1909.02224', 'ACL': 'D19-1531', 'DOI': '10.18653\/v1\/D19-1531', 'CorpusId': 202537733}","404":"{'MAG': '3100895823', 'ACL': '2020.emnlp-main.613', 'DBLP': 'journals\/corr\/abs-2009-12303', 'ArXiv': '2009.12303', 'DOI': '10.18653\/v1\/2020.emnlp-main.613', 'CorpusId': 221949175}","405":"{'DBLP': 'conf\/chi\/VorvoreanuZHHSB19', 'MAG': '2940473144', 'DOI': '10.1145\/3290605.3300283', 'CorpusId': 115140495}","406":"{'ACL': 'D19-1418', 'MAG': '2972051251', 'ArXiv': '1909.03683', 'DBLP': 'conf\/emnlp\/ClarkYZ19', 'DOI': '10.18653\/v1\/D19-1418', 'CorpusId': 202539031}","407":"{'MAG': '2918239264', 'DBLP': 'journals\/jcisd\/SiegFR19', 'DOI': '10.1021\/acs.jcim.8b00712', 'CorpusId': 73481875, 'PubMed': '30835112'}","408":"{'MAG': '3034072641', 'DBLP': 'journals\/corr\/abs-1907-09594', 'ArXiv': '1907.09594', 'CorpusId': 198179838}","409":"{'MAG': '3101295217', 'DBLP': 'journals\/corr\/abs-2010-05338', 'ArXiv': '2010.05338', 'ACL': '2020.emnlp-main.404', 'DOI': '10.18653\/v1\/2020.emnlp-main.404', 'CorpusId': 222290677}","410":"{'MAG': '2949918277', 'DBLP': 'conf\/naacl\/BalyKSGN19', 'ACL': 'N19-1216', 'ArXiv': '1904.00542', 'DOI': '10.18653\/v1\/N19-1216', 'CorpusId': 90262848}","411":"{'ArXiv': '2103.10979', 'PubMedCentral': '8371575', 'DOI': '10.2196\/29570', 'CorpusId': 236949098, 'PubMed': '34459833'}","412":"{'DBLP': 'journals\/corr\/abs-1906-12325', 'MAG': '2955488027', 'ArXiv': '1906.12325', 'DOI': '10.1103\/physrevlett.124.048301', 'CorpusId': 195750744, 'PubMed': '32058741'}","413":"{'MAG': '3137921573', 'DBLP': 'journals\/corr\/abs-2103-10979', 'CorpusId': 232307291}","414":"{'PubMedCentral': '6962360', 'MAG': '2999021003', 'DOI': '10.1038\/s41598-019-57272-3', 'CorpusId': 210195034, 'PubMed': '31941980'}","415":"{'DBLP': 'conf\/sigir\/GeZZPSOZ20', 'MAG': '3038744824', 'ArXiv': '2007.02474', 'DOI': '10.1145\/3397271.3401431', 'CorpusId': 220364075}","416":"{'DBLP': 'journals\/corr\/abs-2112-00626', 'ArXiv': '2112.00626', 'CorpusId': 244773073}","417":"{'MAG': '3177816149', 'DOI': '10.1109\/tcss.2021.3091168', 'CorpusId': 238011778}","418":"{'DBLP': 'journals\/corr\/abs-2106-05401', 'ArXiv': '2106.05401', 'CorpusId': 235390401}","419":"{'DBLP': 'journals\/corr\/abs-2112-05084', 'ArXiv': '2112.05084', 'CorpusId': 245006012}","420":"{'ArXiv': '2004.09603', 'DBLP': 'journals\/corr\/abs-2004-09603', 'MAG': '3017974519', 'CorpusId': 216036116}","421":"{'ArXiv': '2002.03915', 'DBLP': 'journals\/corr\/abs-2002-03915', 'MAG': '3005226152', 'DOI': '10.1103\/physrevx.10.041042', 'CorpusId': 211068675}","422":"{'DBLP': 'journals\/nms\/BoulianneKB20', 'MAG': '3014908418', 'DOI': '10.1177\/1461444819893983', 'CorpusId': 215801488}","423":"{'DBLP': 'journals\/misq\/KitchensJG20', 'MAG': '3111533018', 'DOI': '10.25300\/MISQ\/2020\/16371', 'CorpusId': 229294134}","424":"{'MAG': '3188013853', 'DOI': '10.2196\/32268', 'CorpusId': 238836631}","425":"{'DBLP': 'journals\/intr\/WangS20', 'MAG': '3037564251', 'DOI': '10.1108\/intr-11-2019-0491', 'CorpusId': 222069592}","426":"{'ArXiv': '2001.11461', 'DBLP': 'journals\/corr\/abs-2001-11461', 'MAG': '3004037623', 'CorpusId': 210966362}","427":"{'DBLP': 'journals\/corr\/abs-2010-13691', 'MAG': '3096737093', 'CorpusId': 225067744}","428":"{'MAG': '3102480025', 'DOI': '10.1109\/MLSD49919.2020.9247720', 'CorpusId': 226855627}","429":"{'MAG': '3136875571', 'ArXiv': '2010.01249', 'CorpusId': 222133375}","430":"{'MAG': '3094462252', 'DOI': '10.1101\/2020.10.17.20214312', 'CorpusId': 224803041}","431":"{'ArXiv': '2011.03890', 'MAG': '3097997002', 'DBLP': 'journals\/corr\/abs-2011-03890', 'CorpusId': 226281398}","432":"{'DBLP': 'journals\/corr\/abs-2011-12843', 'MAG': '3107549912', 'CorpusId': 227162643}","433":"{'DBLP': 'journals\/corr\/abs-2102-05477', 'PubMedCentral': '7854755', 'ArXiv': '2102.05477', 'DOI': '10.1038\/s41598-021-81531-x', 'CorpusId': 231789016, 'PubMed': '33531520'}","434":"{'MAG': '3081047394', 'DOI': '10.1007\/s42001-020-00084-7', 'CorpusId': 221297607}","435":"{'ArXiv': '1905.03919', 'DBLP': 'journals\/corr\/abs-1905-03919', 'MAG': '2944343747', 'CorpusId': 150374077}","436":"{'DBLP': 'conf\/lori\/PedersenSA19', 'MAG': '2980215826', 'DOI': '10.1007\/978-3-662-60292-8_14', 'CorpusId': 203980429}","437":"{'MAG': '2964241001', 'ACL': 'W19-2109', 'DOI': '10.18653\/v1\/W19-2109', 'CorpusId': 199556588}","438":"{'DBLP': 'conf\/ecis\/RisiusAH19', 'MAG': '2950584207', 'CorpusId': 174805022}","439":"{'ACL': 'D19-5548', 'DBLP': 'conf\/aclnut\/HanLLC19', 'MAG': '2986286738', 'DOI': '10.18653\/v1\/D19-5548', 'CorpusId': 207911937}","440":"{'DBLP': 'conf\/ecis\/MarkgrafS19', 'MAG': '2950225208', 'CorpusId': 174804995}","441":"{'ArXiv': '1903.11452', 'DBLP': 'journals\/corr\/abs-1903-11452', 'MAG': '2924043637', 'CorpusId': 85531515}","442":"{'DBLP': 'conf\/ecis\/NettoM19', 'MAG': '2949559665', 'CorpusId': 174804171}","443":"{'DBLP': 'conf\/cpsweek\/Niezink19', 'MAG': '2940438349', 'DOI': '10.1145\/3313294.3313381', 'CorpusId': 109938322}","444":"{'MAG': '2942988475', 'DOI': '10.3280\/SP2018-003004', 'CorpusId': 155519035}","445":"{'ArXiv': '2003.11906', 'MAG': '3012967881', 'DBLP': 'journals\/corr\/abs-2003-11906', 'CorpusId': 214667102}","446":"{'DBLP': 'conf\/www\/LoDXJK21', 'DOI': '10.1145\/3442442.3458613', 'CorpusId': 235324682}","447":"{'DBLP': 'journals\/pacmhci\/JeonKXLH21', 'DOI': '10.1145\/3479859', 'CorpusId': 237235763}","448":"{'DBLP': 'conf\/recsys\/Donkers021', 'DOI': '10.1145\/3460231.3474261', 'CorpusId': 237496336}","449":"{'DBLP': 'conf\/recsys\/TommaselRG21', 'DOI': '10.1145\/3460231.3474270', 'CorpusId': 237495110}","450":"{'MAG': '3168877225', 'DOI': '10.3390\/APP11125390', 'CorpusId': 236230784}","451":"{'PubMedCentral': '8379609', 'DBLP': 'journals\/snam\/VillaPV21', 'DOI': '10.1007\/s13278-021-00779-3', 'CorpusId': 237262584, 'PubMed': '34457082'}","452":"{'MAG': '3021560331', 'DBLP': 'journals\/corr\/abs-2005-01157', 'ACL': '2020.acl-main.633', 'ArXiv': '2005.01157', 'DOI': '10.18653\/v1\/2020.acl-main.633', 'CorpusId': 218487126}","453":"{'MAG': '2909429265', 'DBLP': 'journals\/epjds\/CotaFPS19', 'ArXiv': '1901.03688', 'DOI': '10.1140\/epjds\/s13688-019-0213-9', 'CorpusId': 57825711}","454":"{'DBLP': 'journals\/firstmonday\/NguyenV19', 'MAG': '2947894960', 'DOI': '10.5210\/FM.V24I6.9632', 'CorpusId': 184483947}","455":"{'ArXiv': '1906.09076', 'DBLP': 'journals\/corr\/abs-1906-09076', 'MAG': '2949660748', 'CorpusId': 195316688}","456":"{'ArXiv': '1910.06487', 'MAG': '2980538567', 'DBLP': 'journals\/corr\/abs-1910-06487', 'DOI': '10.1088\/2632-072X\/abe561', 'CorpusId': 204578272}","457":"{'MAG': '3132617560', 'DOI': '10.3386\/W28465', 'CorpusId': 221947142}","458":"{'DBLP': 'journals\/corr\/abs-2101-01391', 'ArXiv': '2101.01391', 'CorpusId': 230523767}","459":"{'DBLP': 'journals\/nca\/KaliyarGN21', 'PubMedCentral': '7776294', 'DOI': '10.1007\/s00521-020-05611-1', 'CorpusId': 230110183, 'PubMed': '33424132'}","460":"{'ArXiv': '2103.04653', 'PubMedCentral': '8389375', 'DBLP': 'journals\/corr\/abs-2103-04653', 'DOI': '10.1371\/journal.pone.0256705', 'CorpusId': 232146748, 'PubMed': '34437640'}","461":"{'MAG': '2996935963', 'DBLP': 'conf\/wsdm\/ChitraM20', 'DOI': '10.1145\/3336191.3371825', 'CorpusId': 210882624}","462":"{'MAG': '3106022469', 'PubMedCentral': '6987152', 'DBLP': 'journals\/corr\/abs-1905-03043', 'ArXiv': '1905.03043', 'DOI': '10.1038\/s41598-020-58166-5', 'CorpusId': 147703897, 'PubMed': '31992754'}","463":"{'DBLP': 'journals\/tjs\/KaliyarGN21', 'MAG': '3022024046', 'DOI': '10.1007\/s11227-020-03294-y', 'CorpusId': 218513655}","464":"{'DBLP': 'journals\/corr\/abs-2009-13674', 'ArXiv': '2009.13674', 'MAG': '3090252349', 'CorpusId': 221995658}","465":"{'DBLP': 'conf\/icwsm\/WuR21', 'ArXiv': '2104.05365', 'CorpusId': 233209808}","466":"{'PubMedCentral': '8179701', 'DBLP': 'journals\/aiethics\/Lauer21a', 'DOI': '10.1007\/s43681-021-00068-x', 'CorpusId': 235371695, 'PubMed': '34790950'}","467":"{'DBLP': 'journals\/corr\/abs-2102-08436', 'ArXiv': '2102.08436', 'MAG': '3130507581', 'DOI': '10.4324\/9781003024583-21', 'CorpusId': 231942592}","468":"{'DBLP': 'conf\/kdd\/KalimerisBKW21', 'DOI': '10.1145\/3447548.3467298', 'CorpusId': 236948810}","469":"{'DBLP': 'journals\/corr\/abs-2102-06516', 'ArXiv': '2102.06516', 'CorpusId': 231918759}","470":"{'DBLP': 'conf\/aies\/JiangCLGK19', 'MAG': '2917760808', 'ArXiv': '1902.10730', 'DOI': '10.1145\/3306618.3314288', 'CorpusId': 67855587}","471":"{'MAG': '3032654157', 'DOI': '10.1186\/s40649-019-0076-z', 'CorpusId': 210131507}","472":"{'MAG': '3095231503', 'PubMedCentral': '7682382', 'DOI': '10.1073\/pnas.2006089117', 'CorpusId': 226218378, 'PubMed': '33127755'}","473":"{'ArXiv': '2010.09801', 'DOI': '10.2478\/njms-2021-0006', 'CorpusId': 235747929}","474":"{'MAG': '3005903748', 'DBLP': 'conf\/chiir\/McKayMG0MPC20', 'DOI': '10.1145\/3343413.3377975', 'CorpusId': 212429556}","475":"{'DBLP': 'journals\/corr\/abs-2001-02878', 'MAG': '3086117012', 'ArXiv': '2001.02878', 'DOI': '10.1080\/0022250X.2020.1818078', 'CorpusId': 210116525}","476":"{'MAG': '2995754472', 'DBLP': 'journals\/corr\/abs-1908-05992', 'ArXiv': '1908.05992', 'DOI': '10.1088\/1367-2630\/ab623c', 'CorpusId': 201058562}","477":"{'DBLP': 'conf\/www\/LeMEHHS19', 'MAG': '2912265160', 'DOI': '10.1145\/3308558.3313682', 'CorpusId': 84832490}","478":"{'MAG': '3026151702', 'DBLP': 'journals\/corr\/abs-2005-10004', 'ArXiv': '2005.10004', 'DOI': '10.1007\/S41109-020-00286-Y', 'CorpusId': 218719211}","479":"{'MAG': '3004431915', 'DOI': '10.5117\/ccr2020.1.004.roch', 'CorpusId': 213940515}","480":"{'DBLP': 'conf\/icwsm\/AllisonB20', 'MAG': '3037728327', 'CorpusId': 219561168}","481":"{'MAG': '3024832649', 'DBLP': 'journals\/corr\/abs-2005-08141', 'CorpusId': 218674056}","482":"{'MAG': '3105699505', 'ArXiv': '1905.00867', 'DBLP': 'journals\/corr\/abs-1905-00867', 'DOI': '10.1088\/1742-5468\/ab6de3', 'CorpusId': 143423265}","483":"{'MAG': '3044754474', 'DBLP': 'journals\/access\/ShahinA20', 'DOI': '10.1109\/ACCESS.2020.3010326', 'CorpusId': 220888252}","484":"{'ArXiv': '2004.01967', 'DBLP': 'journals\/corr\/abs-2004-01967', 'MAG': '3014588274', 'CorpusId': 214802048}","485":"{'MAG': '3087804187', 'DOI': '10.1080\/02691728.2020.1815095', 'CorpusId': 224998988}","486":"{'MAG': '3011001705', 'DBLP': 'conf\/chiir\/FellGBH20', 'DOI': '10.1145\/3343413.3377981', 'CorpusId': 212676357}","487":"{'MAG': '2992016187', 'DBLP': 'journals\/tmi\/GhoriRJM20', 'DOI': '10.1109\/TMI.2019.2957290', 'CorpusId': 208768262, 'PubMed': '31804931'}","488":"{'DBLP': 'conf\/iui\/KangHC20', 'MAG': '3010852382', 'DOI': '10.1145\/3379336.3381486', 'CorpusId': 212676146}","489":"{'ArXiv': '2010.01462', 'DBLP': 'journals\/corr\/abs-2010-01462', 'MAG': '3090245990', 'CorpusId': 222133876}","490":"{'ArXiv': '1904.01534', 'MAG': '2950096578', 'DBLP': 'journals\/corr\/abs-1904-01534', 'CorpusId': 91184294}","491":"{'ArXiv': '1907.00181', 'MAG': '2954441166', 'DBLP': 'journals\/corr\/abs-1907-00181', 'CorpusId': 195767459}","492":"{'MAG': '2908227600', 'DBLP': 'journals\/ethicsit\/Reviglio19', 'DOI': '10.1007\/s10676-018-9496-y', 'CorpusId': 57426650}","493":"{'DBLP': 'journals\/corr\/abs-1902-02710', 'MAG': '2951912853', 'ArXiv': '1902.02710', 'DOI': '10.1109\/INFOCOM.2019.8737486', 'CorpusId': 59608833}","494":"{'MAG': '3101448662', 'PubMedCentral': '6894573', 'DOI': '10.1098\/rsos.190868', 'CorpusId': 207933514, 'PubMed': '31827834'}","495":"{'MAG': '2897794994', 'DOI': '10.1002\/9781118841570.IEJS0052', 'CorpusId': 169053514}","496":"{'MAG': '2972737762', 'DBLP': 'journals\/corr\/abs-1909-06474', 'CorpusId': 202577952}","497":"{'DBLP': 'journals\/tis\/Haussler19', 'MAG': '2952654806', 'DOI': '10.1080\/01972243.2019.1614707', 'CorpusId': 195804133}","498":"{'MAG': '2999364305', 'DBLP': 'conf\/asunam\/BagavathiBRPK19', 'ArXiv': '1906.04261', 'DOI': '10.1145\/3341161.3343695', 'CorpusId': 184487444}","499":"{'DBLP': 'journals\/ethicsit\/Elder20', 'MAG': '2972328174', 'DOI': '10.1007\/s10676-019-09511-4', 'CorpusId': 202159820}","500":"{'MAG': '2984827724', 'DBLP': 'journals\/corr\/abs-1911-02121', 'ArXiv': '1911.02121', 'CorpusId': 207880462}","501":"{'MAG': '3004464990', 'DOI': '10.3982\/te3273', 'CorpusId': 213638691}","502":"{'MAG': '2974132847', 'DOI': '10.1093\/oso\/9780198843498.003.0014', 'CorpusId': 204445282}","503":"{'DBLP': 'journals\/ijksr\/EngelL19', 'MAG': '2900936518', 'DOI': '10.4018\/IJSEUS.2019010104', 'CorpusId': 59414137}","504":"{'MAG': '2947475682', 'CorpusId': 212821515}","505":"{'MAG': '2965356693', 'DOI': '10.1139\/FACETS-2019-0002', 'CorpusId': 201145515}","506":"{'MAG': '2955245202', 'DBLP': 'conf\/um\/Sacharidis19', 'DOI': '10.1145\/3320435.3320479', 'CorpusId': 182951045}","507":"{'MAG': '2951994433', 'DBLP': 'conf\/um\/KampikN19', 'DOI': '10.1145\/3314183.3323451', 'CorpusId': 190006525}","508":"{'MAG': '2973980774', 'DBLP': 'journals\/ir\/BierigC19', 'DOI': '10.1007\/s10791-019-09365-w', 'CorpusId': 202641469}","509":"{'DBLP': 'conf\/websci\/WaltonR19', 'MAG': '2953754626', 'DOI': '10.1145\/3292522.3326049', 'CorpusId': 195776751}","510":"{'DBLP': 'journals\/corr\/abs-2102-12627', 'ArXiv': '2102.12627', 'CorpusId': 232046121}","511":"{'DBLP': 'journals\/pnas\/SantosLL21', 'DOI': '10.1073\/pnas.2102141118', 'CorpusId': 245072041, 'PubMed': '34876508'}","512":"{'ArXiv': '2105.07703', 'DBLP': 'journals\/corr\/abs-2105-07703', 'DOI': '10.1103\/PhysRevE.104.044312', 'CorpusId': 234742243, 'PubMed': '34781537'}","513":"{'DBLP': 'journals\/tccn\/ScataSCL21', 'MAG': '3089950634', 'DOI': '10.1109\/TCCN.2020.3027697', 'CorpusId': 225248304}","514":"{'MAG': '3012266030', 'ArXiv': '1903.00699', 'DBLP': 'journals\/corr\/abs-1903-00699', 'PubMedCentral': '7069632', 'DOI': '10.1371\/journal.pone.0229129', 'CorpusId': 67877093, 'PubMed': '32168347'}","515":"{'DBLP': 'journals\/firstmonday\/FerraraCCMP20', 'MAG': '3095610489', 'DOI': '10.5210\/fm.v25i11.11431', 'CorpusId': 228999033}","516":"{'MAG': '3098368877', 'ArXiv': '1904.09238', 'DBLP': 'journals\/corr\/abs-1904-09238', 'DOI': '10.1103\/PhysRevResearch.2.023041', 'CorpusId': 126180021}","517":"{'MAG': '2947741950', 'DBLP': 'journals\/misq\/GevaOS19', 'DOI': '10.25300\/MISQ\/2019\/14346', 'CorpusId': 167222077}","518":"{'MAG': '2945907425', 'DBLP': 'conf\/atal\/GaoSY19', 'CorpusId': 169031439}","519":"{'DBLP': 'journals\/cbsn\/LuzsaM19', 'MAG': '2945773567', 'DOI': '10.1089\/cyber.2018.0550', 'CorpusId': 157067891, 'PubMed': '31100022'}","520":"{'MAG': '2982705116', 'DBLP': 'conf\/nime\/HoCH19', 'CorpusId': 196054374}","521":"{'DBLP': 'conf\/ldk\/WaterschootBH21', 'MAG': '3198403105', 'DOI': '10.4230\/OASIcs.LDK.2021.39', 'CorpusId': 240521955}","522":"{'MAG': '3097563663', 'DOI': '10.1109\/CFIS49607.2020.9238753', 'CorpusId': 226230997}","523":"{'DBLP': 'journals\/corr\/abs-2201-05933', 'CorpusId': 246015727}","524":"{'DBLP': 'journals\/pnas\/HaghtalabJP21', 'DOI': '10.1073\/pnas.2010144118', 'CorpusId': 233721852, 'PubMed': '33941683'}","525":"{'DBLP': 'journals\/corr\/abs-2201-09161', 'ArXiv': '2201.09161', 'CorpusId': 246241080}","526":"{'MAG': '3014778583', 'CorpusId': 216610371}","527":"{'MAG': '3133666623', 'DOI': '10.1038\/D43978-021-00019-4', 'CorpusId': 233971278}","528":"{'DBLP': 'journals\/corr\/abs-2010-09801', 'MAG': '3094214863', 'CorpusId': 224803193}","529":"{'DBLP': 'conf\/icimth\/KindiHAS21', 'DOI': '10.3233\/shti210910', 'CorpusId': 246288296, 'PubMed': '35062143'}","530":"{'MAG': '3170132226', 'CorpusId': 236284128}","531":"{'DBLP': 'books\/sp\/19\/Stieglitz19', 'MAG': '2914007728', 'DOI': '10.1007\/978-3-030-06234-7_31', 'CorpusId': 77393095}","532":"{'ArXiv': '2010.13691', 'CorpusId': 239885999}","533":"{'DBLP': 'conf\/mc\/SchamsHSG19', 'MAG': '2972887567', 'DOI': '10.1145\/3340764.3344433', 'CorpusId': 202159010}","534":"{'ArXiv': '2106.08684', 'DBLP': 'journals\/corr\/abs-2106-08684', 'DOI': '10.2196\/preprints.32258', 'CorpusId': 235446425}","535":"{'DBLP': 'conf\/cogsci\/PerforsN19', 'MAG': '2977968798', 'CorpusId': 203620116}","536":"{'DBLP': 'conf\/scisisis\/AtiqiCD20', 'DOI': '10.1109\/SCISISIS50064.2020.9322696', 'CorpusId': 231714968}","537":"{'DBLP': 'conf\/medes\/TkachenkoG19', 'MAG': '2998760079', 'DOI': '10.1145\/3297662.3365819', 'CorpusId': 210722392}","538":"{'ArXiv': '2202.03961', 'DBLP': 'journals\/corr\/abs-2202-03961', 'CorpusId': 246652077}","539":"{'MAG': '2911129983', 'DOI': '10.1038\/s41593-018-0312-0', 'CorpusId': 58572343, 'PubMed': '30664771'}","540":"{'DBLP': 'conf\/visualization\/WallSE19', 'MAG': '2994650581', 'DOI': '10.1109\/VISUAL.2019.8933611', 'CorpusId': 199562511}","541":"{'MAG': '2894294331', 'DBLP': 'journals\/tvcg\/DimaraFPBD20', 'DOI': '10.1109\/TVCG.2018.2872577', 'CorpusId': 52917687, 'PubMed': '30281459'}","542":"{'MAG': '2941211423', 'DBLP': 'conf\/chi\/CarabanKGC19', 'DOI': '10.1145\/3290605.3300733', 'CorpusId': 140275762}","543":"{'MAG': '2792083042', 'DOI': '10.1007\/S10694-018-0708-0', 'CorpusId': 117150894}","544":"{'MAG': '2941349974', 'DBLP': 'conf\/chi\/DosonoS19', 'DOI': '10.1145\/3290605.3300372', 'CorpusId': 140224583}","545":"{'MAG': '2913846632', 'DBLP': 'journals\/tbe\/LiLSLLZHZYZ019', 'DOI': '10.1109\/TBME.2019.2897651', 'CorpusId': 73425227, 'PubMed': '30735981'}","546":"{'MAG': '2963213850', 'DBLP': 'journals\/sensors\/MiheljZKS19', 'PubMedCentral': '6695727', 'DOI': '10.3390\/s19153267', 'CorpusId': 198932849, 'PubMed': '31349546'}","547":"{'DBLP': 'journals\/jmis\/KimMD19', 'MAG': '2782032413', 'DOI': '10.2139\/SSRN.3090355', 'CorpusId': 149080476}","548":"{'DBLP': 'journals\/ejwcn\/Guaya-DelgadoPM19', 'MAG': '2937104025', 'DOI': '10.1186\/s13638-019-1375-7', 'CorpusId': 93002047}","549":"{'ArXiv': '2101.10291', 'DBLP': 'journals\/corr\/abs-2101-10291', 'DOI': '10.1109\/ICSE43902.2021.00098', 'CorpusId': 231699061}","550":"{'DBLP': 'journals\/access\/HussainZAAANKK20', 'MAG': '3006269462', 'DOI': '10.1109\/ACCESS.2020.2972968', 'CorpusId': 211243610}","551":"{'DBLP': 'journals\/isr\/KokkodisL20', 'MAG': '2996556610', 'DOI': '10.1287\/ISRE.2019.0895', 'CorpusId': 218951146}","552":"{'DBLP': 'journals\/access\/Reyes-MenendezS19', 'MAG': '2948013797', 'DOI': '10.1109\/ACCESS.2019.2919030', 'CorpusId': 174819933}","553":"{'DBLP': 'journals\/iotj\/CuiZZYL19', 'MAG': '2913613723', 'DOI': '10.1109\/JIOT.2019.2895136', 'CorpusId': 86852408}","554":"{'MAG': '2948913639', 'DBLP': 'journals\/games\/CartwrightC19', 'DOI': '10.3390\/G10020026', 'CorpusId': 195520175}","555":"{'MAG': '2770117644', 'DOI': '10.1109\/TLT.2017.2776273', 'CorpusId': 13620126}","556":"{'MAG': '2999786499', 'DBLP': 'conf\/kbse\/AmreenKM19', 'DOI': '10.1109\/ASE.2019.00107', 'CorpusId': 210696910}","557":"{'DBLP': 'conf\/icse\/AlamiCW19', 'MAG': '2955473245', 'DOI': '10.1109\/ICSE.2019.00111', 'CorpusId': 174800128}","558":"{'MAG': '2801389981', 'DOI': '10.1109\/TPWRS.2018.2834472', 'CorpusId': 115286169}","559":"{'DBLP': 'journals\/isr\/SunFT20', 'MAG': '2528724140', 'DOI': '10.1287\/ISRE.2019.0874', 'CorpusId': 216237464}","560":"{'DBLP': 'journals\/mansci\/BoltonKM19', 'MAG': '2947190306', 'DOI': '10.1287\/MNSC.2018.3191', 'CorpusId': 152503370}","561":"{'DBLP': 'journals\/sensors\/HirtanDG20', 'PubMedCentral': '7038681', 'MAG': '3003791501', 'DOI': '10.3390\/s20030791', 'CorpusId': 211046525, 'PubMed': '32023997'}","562":"{'DBLP': 'journals\/tetc\/SuQXGW20', 'MAG': '2589179198', 'DOI': '10.1109\/TETC.2017.2671843', 'CorpusId': 63200703}","563":"{'MAG': '2958684798', 'ArXiv': '1907.06331', 'DOI': '10.1063\/1.5115814', 'CorpusId': 196621655}","564":"{'MAG': '2891930034', 'DBLP': 'journals\/iotj\/SuWXFTZ19', 'DOI': '10.1109\/JIOT.2018.2869297', 'CorpusId': 67958924}","565":"{'MAG': '2991120549', 'DBLP': 'journals\/msom\/ChenYZ20', 'DOI': '10.1287\/msom.2019.0861', 'CorpusId': 216332459}","566":"{'DBLP': 'journals\/tnn\/Tao00YW19', 'MAG': '2807634467', 'DOI': '10.1109\/TNNLS.2018.2836969', 'CorpusId': 51612399, 'PubMed': '29994339'}","567":"{'MAG': '2972189363', 'DBLP': 'journals\/access\/UllahNJKLAM19', 'DOI': '10.1109\/ACCESS.2019.2937347', 'CorpusId': 202561859}","568":"{'MAG': '2939711250', 'DBLP': 'conf\/iccae\/RasoolBSA19', 'DOI': '10.1145\/3313991.3314008', 'CorpusId': 115153488}","569":"{'DBLP': 'conf\/kdd\/YeS19', 'MAG': '2920942353', 'ArXiv': '1903.07581', 'DOI': '10.1145\/3292500.3330709', 'CorpusId': 81981437}","570":"{'MAG': '3110237575', 'DBLP': 'journals\/access\/YahayaJJSKA20', 'DOI': '10.1109\/ACCESS.2020.3041931', 'CorpusId': 229376140}","571":"{'MAG': '3013200524', 'DBLP': 'conf\/aina\/ShahidSMIJJ20', 'DOI': '10.1007\/978-3-030-44041-1_2', 'CorpusId': 214730375}","572":"{'DBLP': 'conf\/wirtschaftsinformatik\/PrzybillaRWK19', 'MAG': '2921901671', 'CorpusId': 169562423}","573":"{'DBLP': 'journals\/access\/MahmoodGDS19', 'MAG': '2976817660', 'DOI': '10.1109\/ACCESS.2019.2943747', 'CorpusId': 204086116}","574":"{'DBLP': 'journals\/access\/KhanAOPM20a', 'MAG': '3039555386', 'DOI': '10.1109\/ACCESS.2020.3006043', 'CorpusId': 220669222}","575":"{'DBLP': 'conf\/bwcca\/JavaidZAKNJ19', 'MAG': '2980939756', 'DOI': '10.1007\/978-3-030-33506-9_16', 'CorpusId': 208112190}","576":"{'DBLP': 'conf\/comsnets\/CareemD20', 'MAG': '3011444390', 'DOI': '10.1109\/COMSNETS48256.2020.9027450', 'CorpusId': 210941547}","577":"{'MAG': '3111303119', 'DBLP': 'conf\/coling\/YuanMZHH20', 'ArXiv': '2012.04233', 'ACL': '2020.coling-main.475', 'DOI': '10.18653\/V1\/2020.COLING-MAIN.475', 'CorpusId': 227231112}","578":"{'DBLP': 'journals\/systems\/AlarconGWGRJBC20', 'MAG': '3048670931', 'DOI': '10.3390\/systems8030028', 'CorpusId': 222143061}","579":"{'DBLP': 'journals\/imds\/ShaoGLB20', 'MAG': '3037799145', 'DOI': '10.1108\/imds-12-2019-0651', 'CorpusId': 221355892}","580":"{'MAG': '2981041627', 'DOI': '10.1086\/716283', 'CorpusId': 238833486}","581":"{'MAG': '2981796806', 'DBLP': 'conf\/ifiptm\/CeolinP19', 'DOI': '10.1007\/978-3-030-33716-2_9', 'CorpusId': 202588834}","582":"{'MAG': '3083126649', 'DBLP': 'journals\/itp\/SoumelidouT20', 'DOI': '10.1108\/itp-08-2017-0241', 'CorpusId': 203092280}","583":"{'ACL': '2021.acl-short.45', 'DBLP': 'conf\/acl\/SunP20', 'ArXiv': '2106.01601', 'DOI': '10.18653\/v1\/2021.acl-short.45', 'CorpusId': 235313502}","584":"{'DBLP': 'conf\/recsys\/AbdollahpouriMB20', 'ArXiv': '2008.09273', 'MAG': '3080925373', 'DOI': '10.1145\/3383313.3418487', 'CorpusId': 221246043}","585":"{'MAG': '3010212693', 'DOI': '10.2139\/ssrn.3530090', 'CorpusId': 215891504}","586":"{'DBLP': 'conf\/jcdl\/HamborgZDG20', 'ArXiv': '2105.09672', 'MAG': '3046335513', 'DOI': '10.1145\/3383583.3398561', 'CorpusId': 220884820}","587":"{'DBLP': 'conf\/icml\/JessonMGS21', 'ArXiv': '2103.04850', 'CorpusId': 232147233}","588":"{'MAG': '3080555449', 'DOI': '10.1080\/1743727X.2020.1804541', 'CorpusId': 225273759}","589":"{'DBLP': 'journals\/corr\/abs-2104-10217', 'ArXiv': '2104.10217', 'DOI': '10.1109\/QoMEX51781.2021.9465384', 'CorpusId': 233324121}","590":"{'DBLP': 'conf\/ijcai\/GemalmazY21', 'DOI': '10.24963\/ijcai.2021\/238', 'CorpusId': 237100757}","591":"{'PubMedCentral': '6994430', 'MAG': '2944117629', 'DOI': '10.3758\/s13414-019-01744-1', 'CorpusId': 148568785, 'PubMed': '31069635'}","592":"{'DBLP': 'journals\/jwe\/MahmoodKR20', 'MAG': '3010627298', 'DOI': '10.13052\/jwe1540-9589.1911', 'CorpusId': 215941502}","593":"{'ArXiv': '1910.05755', 'MAG': '2979588656', 'DBLP': 'journals\/corr\/abs-1910-05755', 'CorpusId': 204509156}","594":"{'DBLP': 'journals\/tcas\/SantenAH19', 'MAG': '2921402340', 'DOI': '10.1109\/TCSI.2019.2898006', 'CorpusId': 117554998}","595":"{'MAG': '3033351949', 'DBLP': 'conf\/sigir\/FuXGZHGXGSZM20', 'ArXiv': '2006.02046', 'DOI': '10.1145\/3397271.3401051', 'CorpusId': 219260017}","596":"{'MAG': '3121950587', 'DOI': '10.1145\/3398730.3399194', 'CorpusId': 219525341}","597":"{'MAG': '3102243698', 'ArXiv': '1905.10713', 'DBLP': 'conf\/www\/PanATLLXH20', 'DOI': '10.1145\/3366423.3380154', 'CorpusId': 210921268}","598":"{'DBLP': 'journals\/corr\/abs-2011-00550', 'MAG': '3097843989', 'ArXiv': '2011.00550', 'DOI': '10.1145\/3340531.3412756', 'CorpusId': 224280759}","599":"{'DBLP': 'conf\/aaai\/HuMLWB21', 'CorpusId': 235306097}","600":"{'DBLP': 'journals\/jssc\/SatpathyMKSAKAH19', 'MAG': '2908207594', 'DOI': '10.1109\/JSSC.2018.2886350', 'CorpusId': 59567321}","601":"{'DBLP': 'conf\/emnlp\/GlushkovaZRM21', 'ArXiv': '2109.06352', 'DOI': '10.18653\/v1\/2021.findings-emnlp.330', 'CorpusId': 237503447}","602":"{'MAG': '2969249640', 'DBLP': 'conf\/cvpr\/CordelFSK19', 'DOI': '10.1109\/CVPR.2019.00415', 'CorpusId': 198118970}","603":"{'DBLP': 'conf\/bmvc\/GkanatsiosPM20', 'CorpusId': 221668220}","604":"{'MAG': '3008645523', 'DOI': '10.5194\/NHESS-20-2997-2020', 'CorpusId': 234739695}","605":"{'MAG': '2811352967', 'DBLP': 'journals\/tc\/KhdrAH19', 'DOI': '10.1109\/TC.2018.2848276', 'CorpusId': 56169292}","606":"{'ArXiv': '1910.14120', 'MAG': '2982403337', 'DBLP': 'journals\/corr\/abs-1910-14120', 'CorpusId': 207757666}","607":"{'MAG': '2940735040', 'DBLP': 'journals\/tcas\/PovoaLMCHG20', 'DOI': '10.1109\/TCSII.2019.2913083', 'CorpusId': 150005891}","608":"{'DBLP': 'journals\/tcad\/LeeKLHKP19', 'MAG': '2884564318', 'DOI': '10.1109\/TCAD.2018.2859240', 'CorpusId': 69208215}","609":"{'DBLP': 'conf\/aaai\/YanH20', 'MAG': '2998192266', 'DOI': '10.1609\/AAAI.V34I01.5458', 'CorpusId': 213224663}","610":"{'DBLP': 'conf\/www\/SunKNS19', 'MAG': '2945357717', 'DOI': '10.1145\/3308560.3317303', 'CorpusId': 153314780}","611":"{'MAG': '2931245396', 'DBLP': 'journals\/jsac\/GuZTGJZZ19', 'DOI': '10.1109\/JSAC.2019.2906746', 'CorpusId': 121362956}","612":"{'MAG': '3004620570', 'PubMedCentral': '7880146', 'DOI': '10.16910\/jemr.12.3.1', 'CorpusId': 211562425, 'PubMed': '33828736'}","613":"{'MAG': '2892123968', 'DBLP': 'journals\/tim\/RantanenRKM19', 'DOI': '10.1109\/TIM.2018.2863978', 'CorpusId': 77382927}","614":"{'DBLP': 'conf\/iwqos\/KouZSW21', 'DOI': '10.1109\/IWQOS52092.2021.9521312', 'CorpusId': 237332532}","615":"{'MAG': '2970253857', 'DBLP': 'journals\/jkm\/DabicK19', 'DOI': '10.1108\/jkm-03-2019-0129', 'CorpusId': 202787780}","616":"{'ArXiv': '2105.12660', 'DBLP': 'journals\/corr\/abs-2105-12660', 'DOI': '10.24963\/ijcai.2021\/99', 'CorpusId': 235195745}","617":"{'MAG': '2975792903', 'DBLP': 'journals\/tap\/Hadnett-HunterN19', 'DOI': '10.1145\/3352763', 'CorpusId': 202676020}","618":"{'MAG': '3024972070', 'DOI': '10.1101\/2020.05.13.20101121', 'CorpusId': 218657215}","619":"{'MAG': '2941135564', 'PubMedCentral': '6444552', 'DOI': '10.1186\/s40462-019-0154-8', 'CorpusId': 106399986, 'PubMed': '30984401'}","620":"{'DBLP': 'conf\/icc\/AbdelrahmanHA19', 'MAG': '2961767467', 'DOI': '10.1109\/ICC.2019.8761675', 'CorpusId': 198169220}","621":"{'ACL': '2021.eacl-main.220', 'DBLP': 'conf\/eacl\/BalachandranPLR21', 'DOI': '10.18653\/v1\/2021.eacl-main.220', 'CorpusId': 231934225}","622":"{'MAG': '3017100184', 'DBLP': 'conf\/msn\/CaiZ19', 'DOI': '10.1109\/MSN48538.2019.00016', 'CorpusId': 215815335}","623":"{'DBLP': 'journals\/sensors\/ThirlwellA20', 'MAG': '3030588146', 'PubMedCentral': '7308893', 'DOI': '10.3390\/s20113051', 'CorpusId': 219169289, 'PubMed': '32481523'}","624":"{'MAG': '2913906295', 'CorpusId': 86819342}","625":"{'MAG': '2980357811', 'DBLP': 'journals\/ijcomsys\/KhanZTUJK19', 'DOI': '10.1002\/dac.4144', 'CorpusId': 208121826}","626":"{'MAG': '3013568810', 'DBLP': 'journals\/games\/Kostelic20', 'DOI': '10.3390\/G11020017', 'CorpusId': 216286706}","627":"{'DBLP': 'conf\/um\/Schelenz21', 'DOI': '10.1145\/3450614.3463293', 'CorpusId': 235599441}","628":"{'DBLP': 'conf\/iot\/AlipourDJ20', 'MAG': '3091989034', 'DOI': '10.1145\/3423423.3423438', 'CorpusId': 222177483}","629":"{'DBLP': 'journals\/jib\/MonsuC21', 'DOI': '10.1515\/jib-2021-0032', 'CorpusId': 244119028, 'PubMed': '34783230'}","630":"{'ArXiv': '2009.01442', 'MAG': '3081517259', 'DBLP': 'journals\/corr\/abs-2009-01442', 'CorpusId': 221470290}","631":"{'MAG': '2941256520', 'DBLP': 'journals\/tcas\/Antunez-Calistro19', 'DOI': '10.1109\/TCSI.2019.2897090', 'CorpusId': 149679583}","632":"{'DBLP': 'journals\/twc\/YangWJL22', 'ArXiv': '2108.03609', 'MAG': '3195930807', 'DOI': '10.1109\/twc.2021.3104006', 'CorpusId': 236957024}","633":"{'MAG': '2920785527', 'DBLP': 'journals\/ejasp\/MenCWL19', 'DOI': '10.1186\/S13634-018-0600-6', 'CorpusId': 86638653}","634":"{'MAG': '2911589237', 'DOI': '10.1017\/S0140525X1900061X', 'CorpusId': 73441334, 'PubMed': '30714890'}","635":"{'DBLP': 'journals\/tcom\/MokhtarzadehTTG19', 'MAG': '2947605383', 'DOI': '10.1109\/TCOMM.2019.2919620', 'CorpusId': 191532269}","636":"{'MAG': '2971896702', 'DOI': '10.4018\/978-1-5225-9833-6.ch001', 'CorpusId': 202768522}","637":"{'MAG': '2981134958', 'DBLP': 'journals\/tii\/LiuZ20', 'DOI': '10.1109\/TII.2019.2947435', 'CorpusId': 208104135}","638":"{'DBLP': 'journals\/iotj\/LiuDH21', 'MAG': '3040117191', 'DOI': '10.1109\/jiot.2020.3007017', 'CorpusId': 226417040}","639":"{'DBLP': 'journals\/isem\/BrachtenBFRS20', 'MAG': '3036413616', 'DOI': '10.1007\/s10257-020-00471-7', 'CorpusId': 220511308}","640":"{'MAG': '2894383926', 'DBLP': 'journals\/iotj\/ZhangLPPMZ19', 'DOI': '10.1109\/JIOT.2018.2872013', 'CorpusId': 69595091}","641":"{'DBLP': 'journals\/access\/SongWLZ19', 'MAG': '2954193369', 'DOI': '10.1109\/ACCESS.2019.2926429', 'CorpusId': 198145071}","642":"{'DBLP': 'journals\/access\/XuQJ19', 'MAG': '2942622905', 'DOI': '10.1109\/ACCESS.2019.2914185', 'CorpusId': 155106477}","643":"{'DBLP': 'journals\/access\/LiuWMZML19', 'MAG': '2926475094', 'DOI': '10.1109\/ACCESS.2019.2909319', 'CorpusId': 116861702}","644":"{'DBLP': 'journals\/ett\/HalloushHAMS19', 'MAG': '2972606407', 'DOI': '10.1002\/ett.3602', 'CorpusId': 203178851}","645":"{'MAG': '2971300699', 'DOI': '10.1101\/746164', 'CorpusId': 202855858}","646":"{'MAG': '2926392003', 'DOI': '10.1109\/ICOMET.2019.8673503', 'CorpusId': 85502966}","647":"{'PubMedCentral': '6923388', 'MAG': '2996356400', 'DOI': '10.1038\/s41598-019-55948-4', 'CorpusId': 209410574, 'PubMed': '31857657'}","648":"{'MAG': '3162787663', 'DOI': '10.31234\/osf.io\/b4jm6', 'CorpusId': 236653643}","649":"{'DBLP': 'journals\/tetc\/DeneckeVA21', 'MAG': '3007384022', 'DOI': '10.1109\/tetc.2020.2974478', 'CorpusId': 213810982}","650":"{'MAG': '3044169398', 'DBLP': 'journals\/access\/DoNJJA20', 'DOI': '10.1109\/ACCESS.2020.3010842', 'CorpusId': 220887268}","651":"{'ArXiv': '2002.05769', 'MAG': '2998306677', 'DBLP': 'journals\/corr\/abs-2002-05769', 'CorpusId': 211126830}","652":"{'MAG': '2980031354', 'PubMedCentral': '6825178', 'DOI': '10.1038\/s41598-019-51996-y', 'CorpusId': 207808880, 'PubMed': '31676780'}","653":"{'DBLP': 'journals\/access\/SereshtMMLW20', 'MAG': '3000666967', 'DOI': '10.1109\/ACCESS.2020.2966760', 'CorpusId': 210995129}","654":"{'DBLP': 'journals\/wc\/WanSKYSX19', 'MAG': '2998711990', 'DOI': '10.1109\/MWC.001.1800582', 'CorpusId': 209456764}","655":"{'MAG': '2984889290', 'CorpusId': 208232167}","656":"{'MAG': '2895963365', 'DBLP': 'journals\/tccn\/Al-TahmeesschiL19', 'DOI': '10.1109\/TCCN.2018.2874456', 'CorpusId': 69548807}","657":"{'DBLP': 'journals\/tccn\/QinZZGLL20', 'MAG': '2982286025', 'ArXiv': '1909.11562', 'DOI': '10.1109\/TCCN.2019.2949279', 'CorpusId': 202750360}","658":"{'MAG': '3162125863', 'DOI': '10.31234\/osf.io\/jkhdf', 'CorpusId': 236809097}","659":"{'MAG': '3109191609', 'DOI': '10.1093\/oso\/9780198842286.003.0002', 'CorpusId': 229507239}","660":"{'MAG': '3087488456', 'PubMedCentral': '7530252', 'DOI': '10.3389\/fpsyt.2020.579934', 'CorpusId': 221765053, 'PubMed': '33061927'}","661":"{'MAG': '2966576392', 'DBLP': 'conf\/aiide\/FrazierR19', 'ArXiv': '1908.01007', 'CorpusId': 199442043}","662":"{'ArXiv': '2006.09471', 'MAG': '3036475981', 'DBLP': 'journals\/corr\/abs-2006-09471', 'CorpusId': 219720910}","663":"{'PubMedCentral': '7514179', 'DBLP': 'journals\/entropy\/HaidF19', 'MAG': '2909193544', 'DOI': '10.3390\/e21010070', 'CorpusId': 67770176, 'PubMed': '33266786'}","664":"{'DBLP': 'journals\/tccn\/TangCLYF20', 'MAG': '3016642727', 'DOI': '10.1109\/TCCN.2020.2988480', 'CorpusId': 218779331}","665":"{'MAG': '3033928195', 'DBLP': 'conf\/aaai\/GoswamiCD20', 'DOI': '10.1609\/aaai.v34i01.5378', 'CorpusId': 219327043}","666":"{'MAG': '2982145812', 'DOI': '10.1007\/978-3-030-28144-1_29', 'CorpusId': 208114507}","667":"{'MAG': '3011821633', 'DOI': '10.1017\/s0140525x19001614', 'CorpusId': 212666882, 'PubMed': '32159470'}","668":"{'DBLP': 'conf\/iui\/RobertsonKHKBUP21', 'DOI': '10.1145\/3397481.3450699', 'CorpusId': 233224122}","669":"{'DBLP': 'conf\/hworkload\/FrutosRZZCM19', 'MAG': '2979867514', 'DOI': '10.1007\/978-3-030-32423-0_6', 'CorpusId': 208113777}","670":"{'ArXiv': '1905.12630', 'MAG': '3101628471', 'DBLP': 'journals\/corr\/abs-1905-12630', 'DOI': '10.1007\/978-3-030-23367-9_8', 'CorpusId': 170078991}","671":"{'DBLP': 'conf\/cogsci\/NobandeganiCOS19', 'MAG': '2977654543', 'CorpusId': 203619994}","672":"{'PubMedCentral': '7443877', 'MAG': '3047433584', 'DOI': '10.1073\/pnas.2004929117', 'CorpusId': 221157858, 'PubMed': '32759219'}","673":"{'MAG': '2971258265', 'DBLP': 'conf\/services\/Romero19', 'ArXiv': '1906.00772', 'DOI': '10.1109\/SERVICES.2019.00118', 'CorpusId': 173990582}","674":"{'DBLP': 'conf\/acssc\/GaafarSAD19', 'MAG': '3013852972', 'DOI': '10.1109\/IEEECONF44664.2019.9048892', 'CorpusId': 214761227}","675":"{'MAG': '3011553529', 'ArXiv': '1904.11454', 'DBLP': 'conf\/cdc\/0005CBT19', 'DOI': '10.1109\/CDC40024.2019.9029476', 'CorpusId': 131774592}","676":"{'MAG': '3013568625', 'DBLP': 'journals\/snam\/PurohitCP20', 'DOI': '10.1007\/s13278-020-0633-3', 'CorpusId': 213187117}","677":"{'MAG': '3092308834', 'DOI': '10.1109\/ICOSEC49089.2020.9215360', 'CorpusId': 222223951}","678":"{'MAG': '3013593076', 'DOI': '10.1037\/xhp0000672', 'CorpusId': 195829450, 'PubMed': '31282694'}","679":"{'PubMedCentral': '7250191', 'MAG': '3026687585', 'DOI': '10.3389\/fncom.2020.00041', 'CorpusId': 218686036, 'PubMed': '32508611'}","680":"{'DBLP': 'journals\/ficn\/SmithSPF20', 'MAG': '3016041222', 'DOI': '10.1101\/633677', 'CorpusId': 216071812}","681":"{'DBLP': 'conf\/cogsci\/CorreaHCG20', 'MAG': '3045932054', 'ArXiv': '2007.13862', 'CorpusId': 220831113}","682":"{'MAG': '2979455883', 'DBLP': 'conf\/embc\/JaiswalCBC19', 'DOI': '10.1109\/EMBC.2019.8856458', 'CorpusId': 204231778, 'PubMed': '31946338'}","683":"{'DBLP': 'conf\/hpca\/ImaniZBRSKKR21', 'DOI': '10.1109\/HPCA51647.2021.00028', 'CorpusId': 233376633}","684":"{'DBLP': 'journals\/adb\/LiuWZL19', 'MAG': '2956017264', 'DOI': '10.1177\/1059712319858623', 'CorpusId': 198352470}","685":"{'DBLP': 'journals\/sensors\/WasilewskaB19', 'PubMedCentral': '6806316', 'MAG': '2979417858', 'DOI': '10.3390\/s19194348', 'CorpusId': 204032219, 'PubMed': '31597330'}","686":"{'MAG': '2989922948', 'DOI': '10.17605\/OSF.IO\/HQXTC', 'CorpusId': 213714371}","687":"{'DBLP': 'journals\/cogsci\/LloydSLL19', 'MAG': '2994753174', 'DOI': '10.1111\/cogs.12805', 'CorpusId': 209427152, 'PubMed': '31858632'}","688":"{'DBLP': 'journals\/corr\/abs-2004-04999', 'MAG': '3015278215', 'ArXiv': '2004.04999', 'CorpusId': 215737182}","689":"{'DBLP': 'journals\/bigdatama\/AgarwalSKK21', 'DOI': '10.26599\/BDMA.2020.9020014', 'CorpusId': 231966162}","690":"{'DBLP': 'journals\/tsmc\/LinWHJWMHZZ21', 'MAG': '2968404378', 'DOI': '10.1109\/TSMC.2019.2930908', 'CorpusId': 202135925}","691":"{'MAG': '3010910782', 'DOI': '10.1038\/s41596-019-0289-5', 'CorpusId': 213168502, 'PubMed': '32203486'}","692":"{'MAG': '3011558710', 'DBLP': 'journals\/access\/WangDxLJ20', 'DOI': '10.1109\/ACCESS.2020.2979898', 'CorpusId': 214596365}","693":"{'MAG': '2957598028', 'PubMedCentral': '7691698', 'DOI': '10.1136\/bmjebm-2019-111192', 'CorpusId': 195878826, 'PubMed': '31292208'}","694":"{'DBLP': 'journals\/frvir\/PimentelFDM21', 'DOI': '10.3389\/frvir.2021.627059', 'CorpusId': 231939510}","695":"{'DBLP': 'journals\/scientometrics\/GarciaRF20', 'MAG': '3002406643', 'DOI': '10.1007\/s11192-020-03357-0', 'CorpusId': 210913625}","696":"{'DBLP': 'journals\/corr\/abs-2006-05987', 'ArXiv': '2006.05987', 'MAG': '3034709122', 'CorpusId': 219558527}","697":"{'MAG': '2951618299', 'DOI': '10.1080\/00220973.2018.1520683', 'CorpusId': 197736648}","698":"{'MAG': '2963361005', 'DOI': '10.1177\/0731121419863785', 'CorpusId': 200072949}","699":"{'MAG': '3036578187', 'DOI': '10.5964\/meth.2805', 'CorpusId': 225724492}","700":"{'DBLP': 'journals\/remotesensing\/Fernandez-Carrillo20a', 'MAG': '3095164275', 'DOI': '10.3390\/rs12213634', 'CorpusId': 227033533}","701":"{'PubMedCentral': '6971266', 'MAG': '2999374125', 'DOI': '10.1038\/s41598-020-57739-8', 'CorpusId': 210716288, 'PubMed': '31959832'}","702":"{'ArXiv': '2012.02757', 'DBLP': 'journals\/corr\/abs-2012-02757', 'MAG': '3111265093', 'CorpusId': 227305541}","703":"{'MAG': '2946384169', 'DOI': '10.1080\/10286608.2019.1615474', 'CorpusId': 182858866}","704":"{'DBLP': 'journals\/remotesensing\/KrucekKCMK20', 'MAG': '3091817285', 'DOI': '10.3390\/rs12193260', 'CorpusId': 222413221}","705":"{'MAG': '2947448756', 'DBLP': 'journals\/tamd\/GrafTFL20', 'DOI': '10.1109\/TCDS.2019.2938924', 'CorpusId': 191527759}","706":"{'DBLP': 'journals\/corr\/abs-2110-03443', 'ArXiv': '2110.03443', 'CorpusId': 238419128}","707":"{'DBLP': 'journals\/corr\/abs-2010-01069', 'ArXiv': '2010.01069', 'MAG': '3089963978', 'DOI': '10.5555\/3535850.3536016', 'CorpusId': 222124902}","708":"{'MAG': '3162850844', 'DOI': '10.1155\/2021\/6668822', 'CorpusId': 236563008}","709":"{'MAG': '2978183748', 'ACL': 'W19-6714', 'DBLP': 'conf\/mtsummit\/QianLLP19', 'CorpusId': 202670693}","710":"{'DBLP': 'journals\/jdiq\/CummingsL21', 'DOI': '10.1145\/3418034', 'CorpusId': 221188459}","711":"{'DBLP': 'journals\/remotesensing\/ZhangBGWLLXL20', 'MAG': '3111435944', 'DOI': '10.3390\/rs12244137', 'CorpusId': 230528876}","712":"{'MAG': '2950443673', 'DOI': '10.1002\/hbm.24692', 'CorpusId': 186204308, 'PubMed': '31187917'}","713":"{'MAG': '2763353875', 'DOI': '10.2139\/SSRN.3044553', 'CorpusId': 219085573}","714":"{'MAG': '2984529943', 'DBLP': 'conf\/igarss\/JoO19', 'DOI': '10.1109\/IGARSS.2019.8898562', 'CorpusId': 208034370}","715":"{'DBLP': 'journals\/pacmhci\/ZytkoD19', 'MAG': '2991926983', 'DOI': '10.1145\/3361117', 'CorpusId': 209168165}","716":"{'MAG': '3025806812', 'DOI': '10.23668\/PSYCHARCHIVES.2905', 'CorpusId': 219468395}","717":"{'MAG': '3107803094', 'ArXiv': '2012.02015', 'DBLP': 'conf\/coling\/BergM20', 'ACL': '2020.coling-main.556', 'DOI': '10.18653\/V1\/2020.COLING-MAIN.556', 'CorpusId': 227231061}","718":"{'DBLP': 'conf\/naacl\/ZhaoWYCOC19', 'MAG': '2926555354', 'ArXiv': '1904.03310', 'ACL': 'N19-1064', 'DOI': '10.18653\/v1\/N19-1064', 'CorpusId': 102352962}","719":"{'MAG': '2964420626', 'DBLP': 'journals\/corr\/abs-1907-13625', 'ArXiv': '1907.13625', 'CorpusId': 199000713}","720":"{'ArXiv': '1910.06222', 'MAG': '2980313216', 'DBLP': 'journals\/corr\/abs-1910-06222', 'CorpusId': 204509033}","721":"{'DBLP': 'conf\/icml\/PooleOOAT19', 'MAG': '2946006146', 'ArXiv': '1905.06922', 'CorpusId': 155100374}","722":"{'ACL': 'W19-3621', 'ArXiv': '1903.03862', 'DBLP': 'journals\/corr\/abs-1903-03862', 'MAG': '2963381846', 'DOI': '10.18653\/V1\/N19-1061', 'CorpusId': 73729169}","723":"{'PubMedCentral': '6693809', 'MAG': '2922315794', 'DOI': '10.1093\/ije\/dyz032', 'CorpusId': 81981544, 'PubMed': '30879056'}","724":"{'MAG': '2955124656', 'DBLP': 'conf\/nips\/CadeneDBCP19', 'ArXiv': '1906.10169', 'CorpusId': 195584122}","725":"{'MAG': '3104142662', 'DBLP': 'conf\/nips\/VigGBQNSS20', 'CorpusId': 227275068}","726":"{'MAG': '3004636243', 'DOI': '10.1097\/SIH.0000000000000411', 'CorpusId': 211048788, 'PubMed': '32028447'}","727":"{'DBLP': 'journals\/corr\/abs-2105-04760', 'ArXiv': '2105.04760', 'DOI': '10.1145\/3461702.3462608', 'CorpusId': 234358073}","728":"{'MAG': '3032388710', 'ACL': '2020.acl-main.485', 'ArXiv': '2005.14050', 'DBLP': 'journals\/corr\/abs-2005-14050', 'DOI': '10.18653\/v1\/2020.acl-main.485', 'CorpusId': 218971825}","729":"{'ArXiv': '2105.11910', 'DBLP': 'journals\/corr\/abs-2105-11910', 'CorpusId': 231773931}","730":"{'DBLP': 'journals\/corr\/abs-2103-01592', 'ArXiv': '2103.01592', 'DOI': '10.1109\/tts.2021.3111823', 'CorpusId': 232092494}","731":"{'DBLP': 'conf\/kdd\/KricheneR20', 'MAG': '3081170586', 'DOI': '10.1145\/3394486.3403226', 'CorpusId': 221191136}","732":"{'ArXiv': '2002.09284', 'DBLP': 'conf\/ecai\/DarwicheH20', 'MAG': '3090471081', 'DOI': '10.3233\/FAIA200158', 'CorpusId': 211252504}","733":"{'MAG': '3024423892', 'ArXiv': '2005.06915', 'DBLP': 'journals\/corr\/abs-2005-06915', 'DOI': '10.1145\/3397271.3401112', 'CorpusId': 218629963}","734":"{'MAG': '3035658430', 'DBLP': 'conf\/acl\/DayanikP20', 'ACL': '2020.acl-main.404', 'DOI': '10.18653\/v1\/2020.acl-main.404', 'CorpusId': 220047861}","735":"{'DBLP': 'journals\/corr\/abs-1901-10002', 'MAG': '2912457762', 'CorpusId': 59336269}","736":"{'DBLP': 'journals\/corr\/abs-2006-07356', 'ArXiv': '2006.07356', 'MAG': '3035184894', 'CorpusId': 219636017}","737":"{'PubMedCentral': '6891052', 'MAG': '2977979921', 'DOI': '10.1523\/JNEUROSCI.0925-19.2019', 'CorpusId': 204968244, 'PubMed': '31662425'}","738":"{'MAG': '3088965320', 'DBLP': 'conf\/emnlp\/ChenK0W20', 'ACL': '2020.findings-emnlp.383', 'ArXiv': '2010.10649', 'DOI': '10.18653\/v1\/2020.findings-emnlp.383', 'CorpusId': 224818447}","739":"{'MAG': '2936510927', 'DOI': '10.1007\/s11368-019-02322-6', 'CorpusId': 145949264}","740":"{'MAG': '3033936902', 'DOI': '10.36548\/jei.2020.2.004', 'CorpusId': 219902356}","741":"{'MAG': '2963585549', 'ArXiv': '1901.04645', 'DOI': '10.1007\/JHEP06(2019)030', 'CorpusId': 119341946}","742":"{'ArXiv': '2104.08728', 'DBLP': 'journals\/corr\/abs-2104-08728', 'CorpusId': 233296615}","743":"{'MAG': '2952116081', 'DOI': '10.1523\/JNEUROSCI.1714-18.2019', 'CorpusId': 189815590, 'PubMed': '31196934'}","744":"{'ArXiv': '1905.13350', 'MAG': '2947652146', 'DBLP': 'journals\/corr\/abs-1905-13350', 'CorpusId': 173188140}","745":"{'MAG': '2912578021', 'CorpusId': 88517600}","746":"{'ACL': '2021.emnlp-main.598', 'DBLP': 'conf\/emnlp\/ZhouKLLHPR21', 'ArXiv': '2005.00782', 'MAG': '3087922520', 'DOI': '10.18653\/v1\/2021.emnlp-main.598', 'CorpusId': 221865854}","747":"{'MAG': '3028407866', 'ArXiv': '2005.11009', 'DBLP': 'journals\/corr\/abs-2005-11009', 'CorpusId': 218863028}","748":"{'DBLP': 'journals\/nle\/SarmaSG22', 'MAG': '3171205933', 'DOI': '10.1017\/S1351324921000115', 'CorpusId': 236246098}","749":"{'DBLP': 'conf\/sac\/ChoC22', 'DOI': '10.1145\/3477314.3507071', 'CorpusId': 248545979}","750":"{'MAG': '2955061976', 'DBLP': 'conf\/naacl\/AnanyaPS19', 'ACL': 'N19-1303', 'DOI': '10.18653\/v1\/N19-1303', 'CorpusId': 174800820}","751":"{'DBLP': 'journals\/corr\/abs-2205-03784', 'ArXiv': '2205.03784', 'DOI': '10.48550\/arXiv.2205.03784', 'CorpusId': 248571945}","752":"{'MAG': '2980569537', 'DOI': '10.1088\/1757-899x\/646\/1\/012026', 'CorpusId': 208098512}","753":"{'PubMedCentral': '7217446', 'MAG': '3024368629', 'DOI': '10.1371\/journal.pone.0232840', 'CorpusId': 218619818, 'PubMed': '32396579'}","754":"{'MAG': '2955635700', 'ArXiv': '1904.03035', 'DBLP': 'journals\/corr\/abs-1904-03035', 'ACL': 'N19-3002', 'DOI': '10.18653\/v1\/N19-3002', 'CorpusId': 102352788}","755":"{'ACL': 'P19-2031', 'MAG': '2963524349', 'DBLP': 'conf\/acl\/QianMZH19', 'ArXiv': '1905.12801', 'DOI': '10.18653\/v1\/P19-2031', 'CorpusId': 170078973}","756":"{'ACL': '2020.emnlp-main.44', 'DBLP': 'conf\/emnlp\/FieldT20', 'MAG': '3104260136', 'ArXiv': '2004.08361', 'DOI': '10.18653\/v1\/2020.emnlp-main.44', 'CorpusId': 215814487}","757":"{'ArXiv': '1901.02860', 'DBLP': 'conf\/acl\/DaiYYCLS19', 'ACL': 'P19-1285', 'MAG': '2950160217', 'DOI': '10.18653\/v1\/P19-1285', 'CorpusId': 57759363}","758":"{'ArXiv': '2105.03654', 'ACL': '2021.acl-long.142', 'DBLP': 'journals\/corr\/abs-2105-03654', 'DOI': '10.18653\/v1\/2021.acl-long.142', 'CorpusId': 234337605}","759":"{'ArXiv': '2205.01243', 'DBLP': 'journals\/corr\/abs-2205-01243', 'DOI': '10.48550\/arXiv.2205.01243', 'CorpusId': 248506011}","760":"{'MAG': '3096845365', 'DOI': '10.1111\/evj.13358', 'CorpusId': 226232245, 'PubMed': '33135243'}","761":"{'ACL': '2020.socialnlp-1.1', 'MAG': '3045592540', 'DBLP': 'conf\/acl-socialnlp\/KameswariSM20', 'DOI': '10.18653\/v1\/2020.socialnlp-1.1', 'CorpusId': 220444934}","762":"{'MAG': '2971377618', 'DBLP': 'conf\/emnlp\/ZhangYESXLSXSR19', 'ArXiv': '1909.00786', 'ACL': 'D19-1537', 'DOI': '10.18653\/v1\/D19-1537', 'CorpusId': 202540793}","763":"{'DBLP': 'conf\/cvpr\/BitenGRK19', 'MAG': '2928602793', 'ArXiv': '1904.01475', 'DOI': '10.1109\/CVPR.2019.01275', 'CorpusId': 91184120}","764":"{'ACL': 'N19-2024', 'MAG': '2945656493', 'DBLP': 'conf\/naacl\/MansfieldSLGH19', 'DOI': '10.18653\/v1\/N19-2024', 'CorpusId': 172132261}","765":"{'DBLP': 'conf\/context\/DibitsoOO19', 'MAG': '2989361680', 'DOI': '10.1007\/978-3-030-34974-5_6', 'CorpusId': 207957201}","766":"{'MAG': '3038130333', 'DBLP': 'conf\/eais\/MaioFGLV20', 'DOI': '10.1109\/EAIS48028.2020.9122701', 'CorpusId': 220079348}","767":"{'DBLP': 'journals\/csedu\/XuRTU19', 'MAG': '2909604546', 'DOI': '10.1080\/08993408.2019.1565233', 'CorpusId': 67914194}","768":"{'DBLP': 'conf\/fat\/DhamalaSKKPCG21', 'ArXiv': '2101.11718', 'DOI': '10.1145\/3442188.3445924', 'CorpusId': 231719337}","769":"{'MAG': '3159574466', 'DOI': '10.1086\/715162', 'CorpusId': 109936713}","770":"{'DBLP': 'journals\/corr\/abs-2106-12672', 'ArXiv': '2106.12672', 'CorpusId': 235624202}","771":"{'ACL': '2021.findings-acl.397', 'DBLP': 'conf\/acl\/GarimellaAKYNCS21', 'DOI': '10.18653\/v1\/2021.findings-acl.397', 'CorpusId': 236477795}","772":"{'DBLP': 'journals\/it\/RachWYUAM21', 'DOI': '10.1515\/itit-2020-0050', 'CorpusId': 233015870}","773":"{'ACL': 'D19-1472', 'DBLP': 'journals\/corr\/abs-2001-07209', 'ArXiv': '2001.07209', 'MAG': '3002007568', 'DOI': '10.18653\/v1\/D19-1472', 'CorpusId': 201630114}","774":"{'DBLP': 'journals\/corr\/abs-2003-02356', 'MAG': '3010341014', 'ArXiv': '2003.02356', 'CorpusId': 212414676}","775":"{'DBLP': 'conf\/acl\/YuJYX20', 'MAG': '3035448883', 'ACL': '2020.acl-main.306', 'DOI': '10.18653\/v1\/2020.acl-main.306', 'CorpusId': 220045906}","776":"{'ArXiv': '2006.03955', 'DBLP': 'journals\/corr\/abs-2006-03955', 'MAG': '3034115845', 'DOI': '10.1145\/3461702.3462536', 'CorpusId': 219530686}","777":"{'DBLP': 'journals\/corr\/abs-2110-15439', 'ArXiv': '2110.15439', 'DOI': '10.18653\/v1\/2021.findings-emnlp.19', 'CorpusId': 240288895}","778":"{'DBLP': 'journals\/tcss\/WuDFTYMH22', 'MAG': '3198214341', 'DOI': '10.1109\/tcss.2021.3106003', 'CorpusId': 239647104}","779":"{'ArXiv': '1903.10561', 'DBLP': 'conf\/naacl\/MayWBBR19', 'MAG': '2963078909', 'ACL': 'N19-1063', 'DOI': '10.18653\/v1\/N19-1063', 'CorpusId': 85518027}","780":"{'MAG': '2946558277', 'ACL': 'N19-1078', 'DBLP': 'conf\/naacl\/AkbikBV19', 'DOI': '10.18653\/v1\/N19-1078', 'CorpusId': 174799702}","781":"{'ArXiv': '2104.07496', 'DBLP': 'journals\/corr\/abs-2104-07496', 'CorpusId': 233241161}","782":"{'DBLP': 'journals\/bmcbi\/ChakrabortyMB21', 'PubMedCentral': '7879691', 'DOI': '10.1186\/s12859-020-03918-3', 'CorpusId': 231886486, 'PubMed': '33573603'}","783":"{'ArXiv': '1911.01485', 'MAG': '2987750715', 'DBLP': 'journals\/corr\/abs-1911-01485', 'CorpusId': 202781363}","784":"{'ArXiv': '1907.05339', 'MAG': '2962896208', 'DBLP': 'conf\/acl\/ZhangLPGC19', 'ACL': 'P19-1362', 'DOI': '10.18653\/v1\/P19-1362', 'CorpusId': 195886246}","785":"{'DBLP': 'journals\/corr\/abs-2205-01576', 'ArXiv': '2205.01576', 'DOI': '10.48550\/arXiv.2205.01576', 'CorpusId': 248506148}","786":"{'DBLP': 'conf\/acl\/YuanFCTPT20', 'MAG': '2970010237', 'ArXiv': '1908.10449', 'ACL': '2020.acl-main.211', 'DOI': '10.18653\/v1\/2020.acl-main.211', 'CorpusId': 201657804}","787":"{'DBLP': 'journals\/corr\/abs-1911-11931', 'ArXiv': '1911.11931', 'MAG': '2997283613', 'DOI': '10.1609\/AAAI.V34I05.6523', 'CorpusId': 208310123}","788":"{'MAG': '2937402758', 'DBLP': 'conf\/icassp\/BruguierPPS19', 'DOI': '10.1109\/ICASSP.2019.8682441', 'CorpusId': 145913147}","789":"{'MAG': '2972020530', 'DBLP': 'conf\/emnlp\/ShengCNP19', 'ArXiv': '1909.01326', 'ACL': 'D19-1339', 'DOI': '10.18653\/v1\/D19-1339', 'CorpusId': 202537041}","790":"{'PubMedCentral': '7861227', 'MAG': '3026218336', 'DBLP': 'journals\/frai\/SchramowskiTJRK20', 'DOI': '10.3389\/frai.2020.00036', 'CorpusId': 218685997, 'PubMed': '33733154'}","791":"{'DBLP': 'journals\/corr\/abs-2101-01169', 'ArXiv': '2101.01169', 'DOI': '10.1145\/3505244', 'CorpusId': 230435805}","792":"{'MAG': '3010132389', 'ArXiv': '2003.03983', 'DBLP': 'journals\/corr\/abs-2003-03983', 'DOI': '10.1109\/FG47880.2020.00010', 'CorpusId': 212634242}","793":"{'DBLP': 'conf\/www\/AroyoDTRR19', 'MAG': '2944944282', 'DOI': '10.1145\/3308560.3317083', 'CorpusId': 153314098}","794":"{'DBLP': 'journals\/corr\/abs-2010-04924', 'MAG': '3102138045', 'ACL': '2020.findings-emnlp.276', 'ArXiv': '2010.04924', 'DOI': '10.18653\/v1\/2020.findings-emnlp.276', 'CorpusId': 222290834}","795":"{'DBLP': 'journals\/imwut\/KunzlerMKKFK19', 'DOI': '10.1145\/3369805', 'CorpusId': 209376111}","796":"{'DBLP': 'journals\/datamine\/ShaalanZCS21', 'DOI': '10.1007\/s10618-020-00725-5', 'CorpusId': 230110710}","797":"{'ArXiv': '2103.11790', 'DOI': '10.1038\/s42256-022-00458-8', 'CorpusId': 246824056}","798":"{'MAG': '2953510135', 'DOI': '10.4000\/JTEI.1777', 'CorpusId': 198315236}","799":"{'PubMedCentral': '8522832', 'DBLP': 'journals\/jamia\/VeerRCPTBAHWOP21', 'DOI': '10.1093\/jamia\/ocab127', 'CorpusId': 236775161, 'PubMed': '34333646'}","800":"{'ACL': '2020.emnlp-main.710', 'ArXiv': '1911.03631', 'MAG': '2989536007', 'DBLP': 'journals\/corr\/abs-1911-03631', 'DOI': '10.18653\/v1\/2020.emnlp-main.710', 'CorpusId': 207853300}","801":"{'DBLP': 'conf\/nips\/ZellersHRBFRC19', 'ArXiv': '1905.12616', 'MAG': '2947813521', 'CorpusId': 168169824}","802":"{'MAG': '3006066545', 'DOI': '10.4000\/jtei.2800', 'CorpusId': 212614483}","803":"{'MAG': '3026998801', 'DOI': '10.1002\/jee.20326', 'CorpusId': 219438149}","804":"{'MAG': '2990769611', 'DOI': '10.1007\/s13369-019-04241-7', 'CorpusId': 214117697}","805":"{'MAG': '3091047907', 'DBLP': 'conf\/ijcnn\/HoTK20', 'DOI': '10.1109\/IJCNN48605.2020.9206616', 'CorpusId': 221659113}","806":"{'MAG': '2988462106', 'DBLP': 'journals\/pacmhci\/SantosLSH19', 'DOI': '10.1145\/3359242', 'CorpusId': 207940086}","807":"{'MAG': '3036624831', 'DBLP': 'books\/sp\/Gomez-PerezDG20', 'DOI': '10.1007\/978-3-030-44830-1', 'CorpusId': 219691982}","808":"{'MAG': '3087957006', 'DBLP': 'conf\/compsac\/SenDG20', 'DOI': '10.1109\/COMPSAC48688.2020.00-95', 'CorpusId': 221915175}","809":"{'DBLP': 'journals\/talip\/HuangXMJLH22', 'DOI': '10.1145\/3481298', 'CorpusId': 243483821}","810":"{'DBLP': 'journals\/kais\/ZhangYYW19', 'MAG': '2787274798', 'DOI': '10.1007\/s10115-018-1165-2', 'CorpusId': 20218585}","811":"{'MAG': '2950342274', 'PubMedCentral': '6956794', 'DBLP': 'journals\/bioinformatics\/JungeJ20', 'DOI': '10.1093\/bioinformatics\/btz490', 'CorpusId': 189815241, 'PubMed': '31199464'}","812":"{'DBLP': 'journals\/corr\/abs-2103-11790', 'CorpusId': 232307728}","813":"{'DBLP': 'conf\/icassp\/ZhaoZCW20', 'MAG': '3015302980', 'DOI': '10.1109\/ICASSP40776.2020.9053767', 'CorpusId': 216517786}","814":"{'DBLP': 'journals\/corr\/abs-2011-04864', 'ArXiv': '2011.04864', 'MAG': '3101855539', 'CorpusId': 226289632}","815":"{'MAG': '2934798344', 'DBLP': 'journals\/access\/HeWLFW19', 'DOI': '10.1109\/ACCESS.2019.2907992', 'CorpusId': 106411499}","816":"{'DBLP': 'journals\/corr\/abs-2003-11530', 'MAG': '3014018559', 'ArXiv': '2003.11530', 'DOI': '10.1609\/AAAI.V34I05.6490', 'CorpusId': 214311867}","817":"{'DBLP': 'journals\/access\/LiuXYXS19', 'MAG': '2981916718', 'DOI': '10.1109\/ACCESS.2019.2949175', 'CorpusId': 207833242}","818":"{'DBLP': 'journals\/tcas\/NieZSLXM20', 'MAG': '3012438093', 'DOI': '10.1109\/TCSI.2020.2979321', 'CorpusId': 216488503}","819":"{'DBLP': 'conf\/icip\/ZhuWH019', 'MAG': '2971325593', 'DOI': '10.1109\/ICIP.2019.8803203', 'CorpusId': 202772570}","820":"{'ArXiv': '2201.10376', 'DBLP': 'journals\/corr\/abs-2201-10376', 'CorpusId': 246275962}","821":"{'MAG': '2910177331', 'DOI': '10.1007\/s10669-019-09717-3', 'CorpusId': 68150016}","822":"{'DBLP': 'journals\/fdata\/HuAHDKDXHTJKD22', 'PubMedCentral': '8905631', 'DOI': '10.3389\/fdata.2022.805713', 'CorpusId': 246631401, 'PubMed': '35284822'}","823":"{'DBLP': 'journals\/corr\/abs-2101-09901', 'ArXiv': '2101.09901', 'CorpusId': 231698775}","824":"{'DBLP': 'journals\/tcas\/LuDKLH19', 'MAG': '2901606664', 'DOI': '10.1109\/TCSII.2018.2881389', 'CorpusId': 115375540}","825":"{'MAG': '3172055360', 'DBLP': 'journals\/jssc\/FassioLRLCA21', 'DOI': '10.1109\/JSSC.2021.3081440', 'CorpusId': 236414808}","826":"{'DBLP': 'journals\/tgrs\/El-AlemCLERR19', 'MAG': '2951861274', 'DOI': '10.1109\/TGRS.2019.2917636', 'CorpusId': 197490710}","827":"{'MAG': '2964135309', 'DBLP': 'journals\/scientometrics\/BajwaK19', 'DOI': '10.1007\/s11192-019-03180-2', 'CorpusId': 198190924}","828":"{'DBLP': 'journals\/scientometrics\/KinneA20', 'MAG': '3092664763', 'DOI': '10.1007\/s11192-020-03726-9', 'CorpusId': 225125295}","829":"{'ArXiv': '2107.00414', 'DBLP': 'journals\/corr\/abs-2107-00414', 'CorpusId': 235694582}","830":"{'DBLP': 'journals\/corr\/abs-2011-04084', 'ArXiv': '2011.04084', 'MAG': '3101459742', 'DOI': '10.1109\/SLT48900.2021.9383466', 'CorpusId': 226281481}","831":"{'DBLP': 'conf\/kbse\/Wang19', 'MAG': '3000489089', 'DOI': '10.1109\/ASE.2019.00031', 'CorpusId': 210697407}","832":"{'MAG': '2959406073', 'DOI': '10.1007\/978-3-030-21373-2_14', 'CorpusId': 199014166}","833":"{'ACL': '2021.inlg-1.25', 'DBLP': 'conf\/inlg\/KasnerMD21', 'CorpusId': 237558712}","834":"{'DBLP': 'conf\/dicta\/HuangWGHC21', 'DOI': '10.1109\/DICTA52665.2021.9647413', 'CorpusId': 245462122}","835":"{'DBLP': 'journals\/access\/XuMZYWZ19', 'MAG': '2974174128', 'DOI': '10.1109\/ACCESS.2019.2941653', 'CorpusId': 203606271}","836":"{'DBLP': 'journals\/corr\/abs-2002-12612', 'MAG': '3007000238', 'ArXiv': '2002.12612', 'CorpusId': 211572468}","837":"{'DBLP': 'conf\/cvpr\/LiuZZW20', 'MAG': '3035062169', 'DOI': '10.1109\/CVPRW50498.2020.00283', 'CorpusId': 220889617}","838":"{'ACL': '2021.trustnlp-1.7', 'MAG': '3167454113', 'DOI': '10.18653\/V1\/2021.TRUSTNLP-1.7', 'CorpusId': 235097209}","839":"{'ArXiv': '2106.15144', 'DBLP': 'conf\/interspeech\/BaeBJC21', 'DOI': '10.21437\/interspeech.2021-471', 'CorpusId': 235670211}","840":"{'ArXiv': '2008.11608', 'DBLP': 'journals\/corr\/abs-2008-11608', 'MAG': '3081304984', 'CorpusId': 221319787}","841":"{'ACL': '2021.acl-long.305', 'DBLP': 'conf\/acl\/Zhang0Z20', 'DOI': '10.18653\/v1\/2021.acl-long.305', 'CorpusId': 236459897}","842":"{'DBLP': 'conf\/mm\/WuHTLL21', 'ArXiv': '2107.12059', 'DOI': '10.1145\/3474085.3475515', 'CorpusId': 236428159}","843":"{'DBLP': 'journals\/cogsci\/FayWKP21', 'DOI': '10.1111\/cogs.13033', 'CorpusId': 237435655, 'PubMed': '34490917'}","844":"{'PubMedCentral': '7344967', 'MAG': '3036561850', 'DOI': '10.3390\/ijerph17124509', 'CorpusId': 220078516, 'PubMed': '32585932'}","845":"{'MAG': '3008594746', 'DOI': '10.22478\/ufpb.2179-7137.2019v8n7.49948', 'CorpusId': 214059754}","846":"{'MAG': '2981547993', 'DBLP': 'journals\/taslp\/ShinL20', 'DOI': '10.1109\/TASLP.2019.2948773', 'CorpusId': 208096706}","847":"{'MAG': '2953303002', 'DOI': '10.1186\/s13750-019-0165-3', 'CorpusId': 195583687}","848":"{'DBLP': 'journals\/jitt\/MaAR20', 'MAG': '3040760541', 'DOI': '10.1007\/s40558-020-00184-0', 'CorpusId': 220511460}","849":"{'MAG': '3127642875', 'DOI': '10.1080\/00220973.2021.1873088', 'CorpusId': 233894088}","850":"{'MAG': '3035765524', 'DOI': '10.1007\/978-981-15-3647-2_35', 'CorpusId': 226606152}","851":"{'DBLP': 'conf\/ecai\/WangR20', 'MAG': '3091467130', 'DOI': '10.3233\/FAIA200345', 'CorpusId': 221714336}","852":"{'DBLP': 'journals\/wicomm\/PangLZHMPP21', 'DOI': '10.1155\/2021\/5534615', 'CorpusId': 237101075}","853":"{'DBLP': 'conf\/icassp\/PanWYWXM21', 'DOI': '10.1109\/ICASSP39728.2021.9415078', 'CorpusId': 235780340}","854":"{'DBLP': 'journals\/tse\/SalmanRTTG22', 'MAG': '3082269804', 'DOI': '10.1109\/tse.2020.3019892', 'CorpusId': 225197789}","855":"{'ACL': '2021.gebnlp-1.11', 'DBLP': 'journals\/corr\/abs-2107-05987', 'ArXiv': '2107.05987', 'DOI': '10.18653\/v1\/2021.gebnlp-1.11', 'CorpusId': 235829093}","856":"{'MAG': '3168188043', 'DBLP': 'journals\/lht\/ZouLBL21', 'DOI': '10.1108\/LHT-01-2021-0041', 'CorpusId': 236227127}","857":"{'MAG': '3210319804', 'DOI': '10.11575\/CPAI.V3I1.68399', 'CorpusId': 244985363}","858":"{'DBLP': 'journals\/corr\/abs-2202-09950', 'ArXiv': '2202.09950', 'CorpusId': 247011922}","859":"{'DBLP': 'conf\/aaai\/KilitciogluK21', 'CorpusId': 235363673}","860":"{'DBLP': 'conf\/acl\/GuoSWLFLYL20', 'ACL': '2021.acl-long.180', 'DOI': '10.18653\/v1\/2021.acl-long.180', 'CorpusId': 236460087}","861":"{'ACL': '2021.acl-long.126', 'DBLP': 'conf\/acl\/BarrowJLDMMORW20', 'DOI': '10.18653\/v1\/2021.acl-long.126', 'CorpusId': 236459789}","862":"{'MAG': '3171005645', 'DOI': '10.25394\/PGS.14515176.V1', 'CorpusId': 236588269}","863":"{'ArXiv': '2106.00169', 'DBLP': 'journals\/corr\/abs-2106-00169', 'ACL': '2021.acl-short.15', 'DOI': '10.18653\/v1\/2021.acl-short.15', 'CorpusId': 235266085}","864":"{'DBLP': 'journals\/corr\/abs-2108-12601', 'ACL': '2021.wnut-1.21', 'ArXiv': '2108.12601', 'DOI': '10.18653\/v1\/2021.wnut-1.21', 'CorpusId': 237353165}","865":"{'MAG': '3006260012', 'ArXiv': '2002.06644', 'DBLP': 'conf\/www\/PantDM20', 'DOI': '10.1145\/3366424.3382704', 'CorpusId': 211133000}","866":"{'DBLP': 'conf\/lrec\/LiuZCS20', 'ArXiv': '2003.02756', 'MAG': '3031416356', 'ACL': '2020.lrec-1.846', 'CorpusId': 212414966}","867":"{'DBLP': 'journals\/ijdsa\/YangYYTW21', 'MAG': '3048774754', 'DOI': '10.1007\/s41060-020-00231-3', 'CorpusId': 221110019}","868":"{'MAG': '3174301198', 'DOI': '10.4324\/9781410603494-33', 'CorpusId': 53365166}","869":"{'DBLP': 'conf\/cogsci\/GuHMU20', 'CorpusId': 231792530}","870":"{'MAG': '2945505538', 'DBLP': 'conf\/www\/LimaFFA19', 'DOI': '10.1145\/3308560.3317597', 'CorpusId': 153314109}","871":"{'MAG': '2935469169', 'DBLP': 'conf\/pakdd\/JiSZY19', 'DOI': '10.1007\/978-3-030-16148-4_13', 'CorpusId': 92998063}","872":"{'MAG': '3137171007', 'DBLP': 'journals\/informatics\/KrommydaRBA21', 'DOI': '10.3390\/informatics8010019', 'CorpusId': 233487031}","873":"{'DBLP': 'journals\/corr\/abs-2109-13137', 'ArXiv': '2109.13137', 'DOI': '10.1145\/3465416.3483299', 'CorpusId': 237940142}","874":"{'ACL': '2020.osact-1.5', 'MAG': '3088728183', 'CorpusId': 219301519}","875":"{'DBLP': 'conf\/acl\/Gupta0020', 'ArXiv': '2107.05833', 'ACL': '2021.acl-short.22', 'DOI': '10.18653\/v1\/2021.acl-short.22', 'CorpusId': 235829779}","876":"{'DBLP': 'journals\/corr\/abs-2202-09003', 'ArXiv': '2202.09003', 'CorpusId': 246996829}","877":"{'DBLP': 'journals\/corr\/abs-2201-12806', 'ArXiv': '2201.12806', 'DOI': '10.1109\/icassp43922.2022.9747101', 'CorpusId': 246431261}","878":"{'ACL': '2021.alvr-1.4', 'MAG': '3170939930', 'DOI': '10.18653\/V1\/2021.ALVR-1.4', 'CorpusId': 235097548}","879":"{'DBLP': 'journals\/corr\/abs-1904-00560', 'ArXiv': '1904.00560', 'MAG': '2928594414', 'DOI': '10.1109\/CVPR.2019.00207', 'CorpusId': 90259087}","880":"{'DBLP': 'conf\/fat\/MustafarajLD20', 'MAG': '3013549950', 'DOI': '10.1145\/3351095.3372835', 'CorpusId': 211041485}","881":"{'MAG': '2963483681', 'DOI': '10.1111\/2041-210X.13268', 'CorpusId': 219264595}","882":"{'MAG': '2946948418', 'DOI': '10.1080\/23273798.2019.1622750', 'CorpusId': 191541486, 'PubMed': '32953924'}","883":"{'MAG': '2973723395', 'ArXiv': '1909.09428', 'DBLP': 'journals\/corr\/abs-1909-09428', 'CorpusId': 202712733}","884":"{'ACL': 'N19-1080', 'MAG': '2945058366', 'DBLP': 'conf\/naacl\/LiuLZYZ19', 'DOI': '10.18653\/v1\/N19-1080', 'CorpusId': 174800619}","885":"{'MAG': '2981646065', 'DBLP': 'journals\/corr\/abs-1910-12180', 'ArXiv': '1910.12180', 'DOI': '10.1109\/TKDE.2020.2982148', 'CorpusId': 204907004}","886":"{'MAG': '3166817489', 'DOI': '10.1108\/IJCHM-08-2020-0861', 'CorpusId': 236281810}","887":"{'ArXiv': '2108.07790', 'DBLP': 'journals\/corr\/abs-2108-07790', 'CorpusId': 237142520}","888":"{'DBLP': 'journals\/corr\/abs-2107-07751', 'ArXiv': '2107.07751', 'MAG': '3184858581', 'PubMedCentral': '8233377', 'DOI': '10.1038\/s41598-021-92719-6', 'CorpusId': 235648154, 'PubMed': '34172813'}","889":"{'DBLP': 'conf\/nips\/ParkALDR21', 'CorpusId': 244906179}","890":"{'DBLP': 'journals\/corr\/abs-2102-11479', 'ArXiv': '2102.11479', 'DOI': '10.1145\/3442381.3450114', 'CorpusId': 232013829}","891":"{'ACL': '2022.acl-long.267', 'DBLP': 'journals\/corr\/abs-2203-08979', 'ArXiv': '2203.08979', 'DOI': '10.48550\/arXiv.2203.08979', 'CorpusId': 247518578}","892":"{'DBLP': 'journals\/icae\/ZhangW21', 'ArXiv': '2005.02158', 'MAG': '3022622191', 'DOI': '10.3233\/ica-200626', 'CorpusId': 218502581}","893":"{'ArXiv': '2106.02569', 'DBLP': 'journals\/corr\/abs-2106-02569', 'ACL': '2021.acl-long.531', 'DOI': '10.18653\/v1\/2021.acl-long.531', 'CorpusId': 235352798}","894":"{'DBLP': 'conf\/sigir\/SarwarMJA21', 'DOI': '10.1145\/3404835.3463121', 'CorpusId': 235792282}","895":"{'ACL': '2021.emnlp-main.215', 'DBLP': 'journals\/corr\/abs-2110-09749', 'ArXiv': '2110.09749', 'DOI': '10.18653\/v1\/2021.emnlp-main.215', 'CorpusId': 239024441}","896":"{'DBLP': 'conf\/www\/ChenS0HP20', 'ArXiv': '2002.10782', 'MAG': '3007812914', 'DOI': '10.1145\/3366423.3380206', 'CorpusId': 211296408}","897":"{'DBLP': 'conf\/interspeech\/ZhaoSRRBLP19', 'MAG': '2972625221', 'DOI': '10.21437\/interspeech.2019-1209', 'CorpusId': 202716857}","898":"{'MAG': '3090776688', 'DOI': '10.5334\/GJGL.1085', 'CorpusId': 224919429}","899":"{'DBLP': 'conf\/uss\/CidonGBKST19', 'MAG': '2965877922', 'CorpusId': 199556814}","900":"{'MAG': '2797520548', 'DOI': '10.4324\/9781410603494-27', 'CorpusId': 53969193}","901":"{'MAG': '3042065032', 'DOI': '10.6018\/ijes.403481', 'CorpusId': 225655898}","902":"{'MAG': '3086884967', 'DBLP': 'conf\/icbk\/ZuXL20', 'DOI': '10.1109\/ICBK50248.2020.00020', 'CorpusId': 221715751}","903":"{'DBLP': 'journals\/corr\/abs-2007-16013', 'ArXiv': '2007.16013', 'MAG': '3046828968', 'CorpusId': 220920068}","904":"{'MAG': '3049242154', 'DOI': '10.3844\/jcssp.2020.1128.1138', 'CorpusId': 221675349}","905":"{'MAG': '3014349462', 'DOI': '10.1353\/LAN.0.0245', 'CorpusId': 234737965}","906":"{'MAG': '2946263956', 'DOI': '10.1177\/0023830919847691', 'CorpusId': 159040127, 'PubMed': '31106699'}","907":"{'DBLP': 'conf\/fruct\/SolovyevSGMI19', 'MAG': '2945562585', 'DOI': '10.23919\/FRUCT.2019.8711900', 'CorpusId': 155106873}","908":"{'ArXiv': '1910.11119', 'MAG': '2981449480', 'DBLP': 'journals\/corr\/abs-1910-11119', 'CorpusId': 204852039}","909":"{'MAG': '3122960574', 'DOI': '10.2139\/ssrn.3345716', 'CorpusId': 208097835}","910":"{'MAG': '2912461302', 'DOI': '10.1007\/978-3-030-01563-3_4', 'CorpusId': 126499705}","911":"{'MAG': '1502299551', 'DOI': '10.4324\/9781315789354', 'CorpusId': 60647345}","912":"{'DBLP': 'conf\/ease\/AlatawiXX20', 'MAG': '3020951519', 'DOI': '10.1145\/3383219.3383221', 'CorpusId': 218522367}","913":"{'MAG': '3010561098', 'DOI': '10.1080\/23273798.2020.1734639', 'CorpusId': 215906353}","914":"{'DBLP': 'journals\/corr\/abs-2202-08926', 'ArXiv': '2202.08926', 'CorpusId': 246996797}","915":"{'DBLP': 'journals\/corr\/abs-2203-00888', 'ArXiv': '2203.00888', 'DOI': '10.48550\/arXiv.2203.00888', 'CorpusId': 247218649}","916":"{'DBLP': 'journals\/corr\/abs-1906-01161', 'MAG': '2949044118', 'ArXiv': '1906.01161', 'ACL': 'W19-3817', 'DOI': '10.18653\/v1\/W19-3817', 'CorpusId': 174798404}","917":"{'MAG': '3204783485', 'DOI': '10.1080\/23273798.2021.1980595', 'CorpusId': 244245264}","918":"{'DBLP': 'conf\/iva\/BickmorePKO21', 'DOI': '10.1145\/3472306.3478365', 'CorpusId': 237456968}","919":"{'DBLP': 'journals\/cogsci\/HuangO22', 'DOI': '10.1111\/cogs.13076', 'CorpusId': 246361213, 'PubMed': '35088446'}","920":"{'DBLP': 'journals\/iacr\/WuAS21', 'CorpusId': 235657205}","921":"{'ACL': '2022.acl-long.481', 'DBLP': 'journals\/corr\/abs-2203-12918', 'ArXiv': '2203.12918', 'DOI': '10.48550\/arXiv.2203.12918', 'CorpusId': 247627717}","922":"{'DBLP': 'conf\/fie\/McSkimmingMD21', 'DOI': '10.1109\/FIE49875.2021.9637198', 'CorpusId': 245388304}","923":"{'ArXiv': '1909.00556', 'MAG': '2971989450', 'DBLP': 'journals\/corr\/abs-1909-00556', 'CorpusId': 202541426}","924":"{'DBLP': 'conf\/ihiet\/Al-Saggaf20a', 'MAG': '3014880171', 'DOI': '10.1007\/978-3-030-44267-5_79', 'CorpusId': 216201146}","925":"{'ArXiv': '2104.06893', 'ACL': '2021.emnlp-main.568', 'DBLP': 'journals\/corr\/abs-2104-06893', 'DOI': '10.18653\/v1\/2021.emnlp-main.568', 'CorpusId': 233231501}","926":"{'DBLP': 'journals\/corr\/abs-2203-13901', 'ArXiv': '2203.13901', 'DOI': '10.48550\/arXiv.2203.13901', 'CorpusId': 247762168}","927":"{'DBLP': 'journals\/corr\/abs-2203-10338', 'ArXiv': '2203.10338', 'DOI': '10.48550\/arXiv.2203.10338', 'CorpusId': 247594315}","928":"{'DBLP': 'conf\/aclnut\/BertschB21', 'ACL': '2021.wnut-1.36', 'DOI': '10.18653\/v1\/2021.wnut-1.36', 'CorpusId': 241583532}","929":"{'ArXiv': '1912.00239', 'MAG': '2991429427', 'DBLP': 'journals\/corr\/abs-1912-00239', 'CorpusId': 208526908}","930":"{'DBLP': 'journals\/corr\/abs-2106-04636', 'ArXiv': '2106.04636', 'CorpusId': 235376750}","931":"{'DBLP': 'conf\/conll\/ZhaoNHB21', 'ACL': '2021.conll-1.6', 'DOI': '10.18653\/v1\/2021.conll-1.6', 'CorpusId': 241583291}","932":"{'DBLP': 'journals\/corr\/abs-2003-13841', 'ArXiv': '2003.13841', 'MAG': '3014359195', 'CorpusId': 214727914}","933":"{'DBLP': 'journals\/ese\/PereraATJTKW22', 'DOI': '10.1007\/s10664-022-10116-7', 'CorpusId': 247885648}","934":"{'ArXiv': '2203.05243', 'DBLP': 'journals\/corr\/abs-2203-05243', 'DOI': '10.48550\/arXiv.2203.05243', 'CorpusId': 247362957}","935":"{'DBLP': 'journals\/corr\/abs-2106-03297', 'ACL': '2021.findings-acl.422', 'ArXiv': '2106.03297', 'DOI': '10.18653\/v1\/2021.findings-acl.422', 'CorpusId': 235358300}","936":"{'DBLP': 'conf\/nips\/BaiMWX21', 'ArXiv': '2106.05515', 'CorpusId': 235390419}","937":"{'MAG': '3037026856', 'PubMedCentral': '7324401', 'DOI': '10.1038\/s41467-020-16958-3', 'CorpusId': 220150838, 'PubMed': '32601272'}","938":"{'DBLP': 'journals\/corr\/abs-1901-09236', 'MAG': '2912985732', 'ArXiv': '1901.09236', 'DOI': '10.1109\/TWC.2019.2957222', 'CorpusId': 59316741}","939":"{'DBLP': 'journals\/corr\/abs-1901-07555', 'MAG': '2950090357', 'ArXiv': '1901.07555', 'CorpusId': 59158829}","940":"{'DBLP': 'journals\/corr\/abs-1907-13286', 'MAG': '2977371568', 'ArXiv': '1907.13286', 'CorpusId': 199000958}","941":"{'DBLP': 'conf\/ecir\/BorattoFM19', 'MAG': '2926898503', 'DOI': '10.1007\/978-3-030-15712-8_30', 'CorpusId': 104292869}","942":"{'DBLP': 'conf\/jcdl\/HamborgZG19', 'MAG': '2968536016', 'DOI': '10.1109\/JCDL.2019.00036', 'CorpusId': 197626884}","943":"{'MAG': '2918405503', 'DOI': '10.1101\/566554', 'CorpusId': 92747267}","944":"{'PubMedCentral': '7228100', 'ArXiv': '1902.04200', 'MAG': '3014714397', 'DOI': '10.1289\/EHP5838', 'CorpusId': 215407481, 'PubMed': '32255670'}","945":"{'MAG': '3004404638', 'ArXiv': '2108.02836', 'DOI': '10.1214\/19-BA1195', 'CorpusId': 212929492}","946":"{'DBLP': 'conf\/naacl\/WangHLSL19', 'MAG': '2946760275', 'ACL': 'N19-1105', 'DOI': '10.18653\/v1\/N19-1105', 'CorpusId': 174799895}","947":"{'DBLP': 'journals\/tgrs\/Bauer-Marschallinger19', 'MAG': '2907323557', 'DOI': '10.1109\/TGRS.2018.2858004', 'CorpusId': 57190654}","948":"{'MAG': '3029886712', 'DOI': '10.1111\/gcb.14904', 'CorpusId': 209518256, 'PubMed': '31891233'}","949":"{'DBLP': 'conf\/eccv\/YuLZMDF20', 'ArXiv': '2004.03355', 'MAG': '3015281547', 'DOI': '10.1007\/978-3-030-58542-6_23', 'CorpusId': 215238930}","950":"{'DBLP': 'conf\/sigsoft\/Harel-CanadaWGG20', 'MAG': '2994987245', 'DOI': '10.1145\/3368089.3409754', 'CorpusId': 210146632}","951":"{'MAG': '2905053357', 'DBLP': 'journals\/twc\/LiuZZYT19', 'DOI': '10.1109\/TWC.2018.2882434', 'CorpusId': 57763931}","952":"{'MAG': '3107527779', 'PubMedCentral': '7779004', 'DBLP': 'journals\/nar\/SzklarczykGNLKP21', 'DOI': '10.1093\/nar\/gkaa1074', 'CorpusId': 227166175, 'PubMed': '33237311'}","953":"{'DBLP': 'conf\/iclr\/0002CI20', 'MAG': '2959108703', 'ArXiv': '1907.07171', 'CorpusId': 196831582}","954":"{'MAG': '2946160190', 'DOI': '10.1029\/2018JD029522', 'CorpusId': 198426810}","955":"{'MAG': '2970161131', 'DBLP': 'conf\/emnlp\/DavisonFR19', 'ACL': 'D19-1109', 'ArXiv': '1909.00505', 'DOI': '10.18653\/v1\/D19-1109', 'CorpusId': 202541043}","956":"{'MAG': '2907627192', 'DOI': '10.1146\/annurev-biophys-052118-115333', 'CorpusId': 58591964, 'PubMed': '30601678'}","957":"{'PubMedCentral': '7426948', 'MAG': '3048908832', 'DOI': '10.1038\/s41467-020-17755-8', 'CorpusId': 221111942, 'PubMed': '32792486'}","958":"{'ArXiv': '2011.07194', 'DBLP': 'journals\/corr\/abs-2011-07194', 'MAG': '3101729298', 'DOI': '10.1145\/3442188.3445881', 'CorpusId': 226965061}","959":"{'MAG': '2978570193', 'DOI': '10.1111\/ddi.12985', 'CorpusId': 208583968}","960":"{'MAG': '3031292160', 'DBLP': 'conf\/sigmod\/JinXSAJ20', 'DOI': '10.1145\/3318464.3384689', 'CorpusId': 218982528}","961":"{'MAG': '3082499364', 'DBLP': 'journals\/pvldb\/LinGAJ20', 'DOI': '10.14778\/3407790.3407821', 'CorpusId': 221114373}","962":"{'DBLP': 'conf\/aaai\/LiuYDLCY20', 'ArXiv': '1909.13459', 'MAG': '2975357497', 'DOI': '10.1609\/AAAI.V34I01.5344', 'CorpusId': 203593196}","963":"{'MAG': '3005040148', 'DBLP': 'conf\/aies\/SharmaZABMV20', 'DOI': '10.1145\/3375627.3375865', 'CorpusId': 211041896}","964":"{'MAG': '2299619150', 'DBLP': 'journals\/mansci\/DaGLW21', 'DOI': '10.1287\/MNSC.2019.3452', 'CorpusId': 213403138}","965":"{'MAG': '2969576731', 'DOI': '10.1109\/TRANSDUCERS.2019.8808264', 'CorpusId': 201622948}","966":"{'DBLP': 'conf\/visualization\/WallAGJ19', 'MAG': '2996667268', 'DOI': '10.1109\/VISUAL.2019.8933779', 'CorpusId': 199560635}","967":"{'DBLP': 'journals\/ijgi\/Zhang20a', 'MAG': '3092450323', 'DOI': '10.3390\/ijgi9100597', 'CorpusId': 225133419}","968":"{'DBLP': 'journals\/corr\/abs-2009-10273', 'MAG': '3088375704', 'ArXiv': '2009.10273', 'DOI': '10.1109\/ICDM50108.2020.00031', 'CorpusId': 221836653}","969":"{'DBLP': 'journals\/corr\/abs-1906-03114', 'ArXiv': '1906.03114', 'MAG': '3015328199', 'DOI': '10.1109\/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00222', 'CorpusId': 174801060}","970":"{'MAG': '2963543279', 'DBLP': 'journals\/corr\/abs-1803-02111', 'CorpusId': 195346671}","971":"{'MAG': '3092852967', 'DOI': '10.1007\/s42064-020-0084-7', 'CorpusId': 225124655}","972":"{'MAG': '2939700077', 'DOI': '10.1152\/jn.00168.2019', 'CorpusId': 108293277, 'PubMed': '30969894'}","973":"{'MAG': '2970813212', 'DBLP': 'journals\/mansci\/ChungKP21', 'DOI': '10.1287\/MNSC.2020.3853', 'CorpusId': 201027407}","974":"{'DBLP': 'journals\/tcad\/ChoiSS19', 'MAG': '2795908090', 'DOI': '10.1109\/TCAD.2018.2824255', 'CorpusId': 131776864}","975":"{'ArXiv': '2001.11358', 'MAG': '3004018054', 'DBLP': 'conf\/www\/OvaisiAZVZ20', 'DOI': '10.1145\/3366423.3380255', 'CorpusId': 210966320}","976":"{'DBLP': 'journals\/corr\/abs-2010-01243', 'ArXiv': '2010.01243', 'MAG': '3089426191', 'CorpusId': 222134052}","977":"{'DBLP': 'conf\/recsys\/ZhaoHWCNAKSYC19', 'MAG': '2973172293', 'DOI': '10.1145\/3298689.3346997', 'CorpusId': 202640022}","978":"{'MAG': '2941960673', 'DOI': '10.1101\/612903', 'CorpusId': 149932494}","979":"{'MAG': '3011743134', 'DOI': '10.1002\/cl2.1080', 'CorpusId': 216467975}","980":"{'MAG': '2995858837', 'DBLP': 'conf\/icse\/TianZOKR20a', 'ArXiv': '1905.07831', 'DOI': '10.1145\/3377811.3380400', 'CorpusId': 209444764}","981":"{'MAG': '3093937844', 'DBLP': 'conf\/cikm\/0001BJL20', 'DOI': '10.1145\/3340531.3412876', 'CorpusId': 221339851}","982":"{'DBLP': 'journals\/corr\/abs-2103-12506', 'ArXiv': '2103.12506', 'CorpusId': 232320269}","983":"{'DBLP': 'conf\/sigir\/ZhuYGZ021', 'DOI': '10.1145\/3404835.3462846', 'CorpusId': 235792429}","984":"{'DBLP': 'conf\/www\/DaconL21', 'DOI': '10.1145\/3442442.3452325', 'CorpusId': 235324884}","985":"{'DBLP': 'journals\/corr\/abs-2104-07360', 'ArXiv': '2104.07360', 'CorpusId': 233240858}","986":"{'DBLP': 'conf\/jcdl\/SpindeHG20', 'MAG': '3046684368', 'DOI': '10.1145\/3383583.3398585', 'CorpusId': 220885734}","987":"{'DBLP': 'journals\/corr\/abs-1904-01531', 'MAG': '2931330384', 'ArXiv': '1904.01531', 'CorpusId': 91184553}","988":"{'DBLP': 'conf\/blackboxnlp\/GangulaDM19', 'ACL': 'W19-4809', 'MAG': '2951700705', 'DOI': '10.18653\/v1\/W19-4809', 'CorpusId': 196185219}","989":"{'DBLP': 'journals\/corr\/abs-1912-11602', 'ArXiv': '1912.11602', 'MAG': '2998501909', 'CorpusId': 209500822}","990":"{'MAG': '3105035347', 'DBLP': 'conf\/sigir\/MorikSHJ20', 'ArXiv': '2005.14713', 'DOI': '10.1145\/3397271.3401100', 'CorpusId': 219124041}","991":"{'ArXiv': '2005.08141', 'PubMedCentral': '8458339', 'DOI': '10.1038\/s41467-021-25738-6', 'CorpusId': 235755530, 'PubMed': '34552073'}","992":"{'ArXiv': '1907.08922', 'MAG': '2971028401', 'ACL': 'W19-4712', 'DBLP': 'journals\/corr\/abs-1907-08922', 'DOI': '10.18653\/v1\/W19-4712', 'CorpusId': 198147587}","993":"{'DBLP': 'journals\/corr\/abs-2006-16742', 'ArXiv': '2006.16742', 'MAG': '3038896787', 'CorpusId': 220266008}","994":"{'PubMedCentral': '7931917', 'DBLP': 'journals\/fdata\/ThornhillMPB19', 'MAG': '2969970552', 'DOI': '10.3389\/fdata.2019.00011', 'CorpusId': 174798754, 'PubMed': '33693334'}","995":"{'DBLP': 'conf\/iconference\/SpindeRHG21', 'ArXiv': '2112.07384', 'DOI': '10.1007\/978-3-030-71305-8_17', 'CorpusId': 231686498}","996":"{'DBLP': 'journals\/corr\/abs-2104-12259', 'ArXiv': '2104.12259', 'DOI': '10.1145\/3404835.3462990', 'CorpusId': 233393714}","997":"{'DBLP': 'conf\/acl-socialnlp\/MoonCL20', 'MAG': '3032521127', 'ArXiv': '2005.12503', 'ACL': '2020.socialnlp-1.4', 'DOI': '10.18653\/v1\/2020.socialnlp-1.4', 'CorpusId': 218889729}","998":"{'MAG': '3029492690', 'DBLP': 'conf\/lrec\/LimJFY20', 'ACL': '2020.lrec-1.184', 'CorpusId': 218627041}","999":"{'ArXiv': '2102.04567', 'DBLP': 'conf\/icwsm\/NorregaardHA19', 'MAG': '3012283937', 'DOI': '10.48550\/arXiv.2203.05659', 'CorpusId': 91184550}","1000":"{'DBLP': 'journals\/misq\/KimD19', 'MAG': '2915312768', 'DOI': '10.2139\/SSRN.2987866', 'CorpusId': 150700693}","1001":"{'DBLP': 'journals\/misq\/MoravecMD19', 'MAG': '2980765523', 'DOI': '10.2139\/ssrn.3269541', 'CorpusId': 207910520}","1002":"{'DBLP': 'conf\/icwsm\/BozarthB20', 'MAG': '3038050353', 'CorpusId': 219561107}","1003":"{'MAG': '3011271423', 'DOI': '10.1080\/10584609.2020.1713267', 'CorpusId': 216349246}","1004":"{'DBLP': 'conf\/incos\/IbrishimovaL19', 'MAG': '2967393046', 'DOI': '10.1007\/978-3-030-29035-1_22', 'CorpusId': 201109397}","1005":"{'DBLP': 'journals\/scn\/LagoPB19', 'MAG': '2938045713', 'DOI': '10.1155\/2019\/9236910', 'CorpusId': 133608632}","1006":"{'MAG': '2965248888', 'DBLP': 'conf\/uai\/GoindaniN19', 'CorpusId': 197661927}","1007":"{'ArXiv': '1911.11641', 'MAG': '2989588035', 'DBLP': 'journals\/corr\/abs-1911-11641', 'DOI': '10.1609\/AAAI.V34I05.6239', 'CorpusId': 208290939}","1008":"{'DBLP': 'journals\/corr\/abs-2005-00649', 'ArXiv': '2005.00649', 'ACL': '2020.acl-main.474', 'MAG': '3023719900', 'DOI': '10.18653\/v1\/2020.acl-main.474', 'CorpusId': 218487374}","1009":"{'MAG': '3105786751', 'DOI': '10.3386\/w28075', 'CorpusId': 221652527}","1010":"{'ACL': 'D19-1327', 'MAG': '2970611986', 'DBLP': 'conf\/emnlp\/JungKMH19', 'ArXiv': '1908.11723', 'DOI': '10.18653\/v1\/D19-1327', 'CorpusId': 201698380}","1011":"{'MAG': '2972901607', 'DBLP': 'journals\/corr\/abs-1910-08948', 'ArXiv': '1910.08948', 'DOI': '10.21437\/interspeech.2019-2965', 'CorpusId': 203171703}","1012":"{'ACL': '2021.acl-long.424', 'ArXiv': '2106.01300', 'DBLP': 'conf\/acl\/QiWWH20', 'DOI': '10.18653\/v1\/2021.acl-long.424', 'CorpusId': 235294032}","1013":"{'MAG': '2920852800', 'DOI': '10.1177\/2372732218814855', 'CorpusId': 150504901}","1014":"{'MAG': '2971982774', 'DOI': '10.1633\/JISTAP.2019.7.2.4', 'CorpusId': 202779877}","1015":"{'DBLP': 'conf\/wsdm\/DuanJ19', 'MAG': '2907695709', 'DOI': '10.1145\/3289600.3291008', 'CorpusId': 59528441}","1016":"{'MAG': '2970127261', 'DBLP': 'conf\/emnlp\/MaZYS19', 'ACL': 'D19-1490', 'DOI': '10.18653\/v1\/D19-1490', 'CorpusId': 202773093}","1017":"{'DBLP': 'conf\/bigdataconf\/RazaD19', 'MAG': '3008291289', 'DOI': '10.1109\/BigData47090.2019.9005459', 'CorpusId': 211298727}","1018":"{'MAG': '3042179685', 'ArXiv': '1908.01623', 'DBLP': 'journals\/corr\/abs-1908-01623', 'DOI': '10.1109\/TNNLS.2020.3004626', 'CorpusId': 199442520, 'PubMed': '32649280'}","1019":"{'DBLP': 'journals\/misqe\/Martin19', 'MAG': '2946999569', 'DOI': '10.17705\/2MSQE.00012', 'CorpusId': 191189156}","1020":"{'MAG': '2886635168', 'DOI': '10.2139\/SSRN.3188065', 'CorpusId': 126122244}","1021":"{'DBLP': 'journals\/corr\/abs-2011-01575', 'ArXiv': '2011.01575', 'MAG': '3097701710', 'ACL': '2020.wanlp-1.17', 'CorpusId': 226237614}","1022":"{'MAG': '2981783889', 'DOI': '10.1145\/3358528.3358567', 'CorpusId': 204837726}","1023":"{'DBLP': 'journals\/corr\/abs-2102-08537', 'ArXiv': '2102.08537', 'CorpusId': 231942492}","1024":"{'MAG': '3169823389', 'DOI': '10.3390\/ELECTRONICS10111348', 'CorpusId': 235484013}","1025":"{'MAG': '2985671795', 'DBLP': 'conf\/cikm\/ChenAJC19', 'DOI': '10.1145\/3357384.3358131', 'CorpusId': 207757560}","1026":"{'ArXiv': '1909.04028', 'DBLP': 'journals\/corr\/abs-1909-04028', 'ACL': 'D19-1620', 'MAG': '2972462987', 'DOI': '10.18653\/v1\/D19-1620', 'CorpusId': 202542690}","1027":"{'DBLP': 'conf\/vl\/BehrooziPB19', 'MAG': '2973760291', 'DOI': '10.1109\/VLHCC.2019.8818836', 'CorpusId': 203697937}","1028":"{'DBLP': 'conf\/sp\/RedmilesKM19', 'MAG': '2931556662', 'DOI': '10.1109\/SP.2019.00014', 'CorpusId': 49255782}","1029":"{'DBLP': 'conf\/emnlp\/YangZGZ0D20', 'ArXiv': '2001.00725', 'MAG': '3105245805', 'ACL': '2020.findings-emnlp.168', 'DOI': '10.18653\/v1\/2020.findings-emnlp.168', 'CorpusId': 209832298}","1030":"{'DBLP': 'conf\/asunam\/ShresthaS19', 'MAG': '2953370557', 'DOI': '10.1145\/3341161.3343536', 'CorpusId': 197708977}","1031":"{'MAG': '3012209663', 'DBLP': 'journals\/cacm\/ChaGL20', 'DOI': '10.1145\/3378422', 'CorpusId': 213193811}","1032":"{'DBLP': 'conf\/www\/StoicaHC20', 'MAG': '3012895300', 'DOI': '10.1145\/3366423.3380275', 'CorpusId': 211194341}","1033":"{'MAG': '3107921991', 'DBLP': 'journals\/corr\/abs-1907-07759', 'ArXiv': '1907.07759', 'DOI': '10.1007\/s11704-020-9256-0', 'CorpusId': 197545086}","1034":"{'DBLP': 'conf\/ht\/MeloMV19', 'MAG': '2974127902', 'DOI': '10.1145\/3345645.3351107', 'CorpusId': 202640417}","1035":"{'ArXiv': '1912.05474', 'DBLP': 'journals\/jasis\/SinghCIF20', 'MAG': '2994826132', 'DOI': '10.1002\/asi.24335', 'CorpusId': 209202780}","1036":"{'DBLP': 'journals\/nms\/MeerH21', 'MAG': '3046904096', 'DOI': '10.1177\/1461444820946455', 'CorpusId': 225352604}","1037":"{'MAG': '2953590462', 'DBLP': 'conf\/icwsm\/VolkovaAAHH19', 'CorpusId': 189818875}","1038":"{'MAG': '2966295280', 'DBLP': 'conf\/sigir\/StanojevicADO19', 'CorpusId': 198189778}","1039":"{'DBLP': 'journals\/corr\/abs-1904-03513', 'ArXiv': '1904.03513', 'ACL': 'S19-2182', 'MAG': '2953647525', 'DOI': '10.18653\/v1\/S19-2182', 'CorpusId': 102351875}","1040":"{'ACL': 'D19-5016', 'MAG': '2982953871', 'DOI': '10.18653\/v1\/D19-5016', 'CorpusId': 207810883}","1041":"{'ArXiv': '2007.14071', 'DBLP': 'journals\/tcyb\/WangKSLZ21', 'MAG': '3024507639', 'DOI': '10.1109\/TCYB.2020.2987064', 'CorpusId': 218659500, 'PubMed': '32413938'}","1042":"{'MAG': '3036910473', 'DOI': '10.1109\/ICICCS48265.2020.9120902', 'CorpusId': 219989591}","1043":"{'ArXiv': '2007.12986', 'MAG': '3104589861', 'DBLP': 'conf\/kdd\/McInerneyBCMC20', 'DOI': '10.1145\/3394486.3403229', 'CorpusId': 220793974}","1044":"{'DBLP': 'conf\/emnlp\/SpindePKRGA21', 'DOI': '10.18653\/v1\/2021.findings-emnlp.101', 'CorpusId': 244119684}","1045":"{'MAG': '2941039078', 'DBLP': 'journals\/corr\/abs-1904-07325', 'ArXiv': '1904.07325', 'DOI': '10.1109\/CVPRW.2019.00281', 'CorpusId': 118717910}","1046":"{'DBLP': 'journals\/sigmetrics\/HargreavesAMNRA18', 'MAG': '2914945108', 'DOI': '10.1145\/3308897.3308928', 'CorpusId': 59337637}","1047":"{'DBLP': 'conf\/icwsm\/GangulyKAK20', 'MAG': '3037713666', 'CorpusId': 219560974}","1048":"{'DBLP': 'conf\/hci\/SpillaneLW20', 'MAG': '3040791640', 'DOI': '10.1007\/978-3-030-49059-1_50', 'CorpusId': 220490794}","1049":"{'DBLP': 'journals\/corr\/abs-2108-07865', 'ACL': '2021.case-1.1', 'ArXiv': '2108.07865', 'DOI': '10.18653\/v1\/2021.case-1.1', 'CorpusId': 236486088}","1050":"{'MAG': '3093284009', 'CorpusId': 224801419}","1051":"{'MAG': '3105217530', 'DBLP': 'conf\/jcdl\/GebhardH20', 'ArXiv': '2005.14024', 'DOI': '10.1145\/3383583.3398567', 'CorpusId': 218971797}","1052":"{'DBLP': 'conf\/edbt\/PitouraKS20', 'MAG': '3013171878', 'DOI': '10.5441\/002\/edbt.2020.86', 'CorpusId': 214613323}","1053":"{'DBLP': 'conf\/acl\/PapalampidiKFL20', 'ACL': '2020.acl-main.174', 'MAG': '3020656123', 'ArXiv': '2004.12727', 'DOI': '10.18653\/v1\/2020.acl-main.174', 'CorpusId': 216553636}","1054":"{'MAG': '3093591015', 'PubMedCentral': '7901026', 'DBLP': 'conf\/misdoom\/NygrenFLG20', 'DOI': '10.1007\/978-3-030-61841-4_5', 'CorpusId': 225043283}","1055":"{'MAG': '3133139416', 'DOI': '10.1007\/S40747-021-00294-0', 'CorpusId': 233977898}","1056":"{'ArXiv': '2109.00024', 'DBLP': 'journals\/corr\/abs-2109-00024', 'CorpusId': 237372232}","1057":"{'DBLP': 'journals\/corr\/abs-2008-06460', 'MAG': '3049565363', 'ArXiv': '2008.06460', 'PubMedCentral': '7451563', 'DOI': '10.1371\/journal.pone.0237861', 'CorpusId': 221136077, 'PubMed': '32853205'}","1058":"{'DBLP': 'journals\/osnm\/Papakyriakopoulos20', 'MAG': '2997149517', 'DOI': '10.1016\/j.osnem.2019.100058', 'CorpusId': 211830167}","1059":"{'DBLP': 'journals\/corr\/abs-2003-02488', 'ArXiv': '2003.02488', 'MAG': '3009247505', 'DOI': '10.1109\/TTS.2020.2992344', 'CorpusId': 212415067}","1060":"{'ACL': 'W19-3504', 'DBLP': 'journals\/corr\/abs-1905-12516', 'MAG': '2972735048', 'ArXiv': '1905.12516', 'DOI': '10.18653\/v1\/W19-3504', 'CorpusId': 168170119}","1061":"{'MAG': '3013854004', 'DBLP': 'conf\/fat\/Papakyriakopoulos20', 'DOI': '10.1145\/3351095.3372843', 'CorpusId': 211040995}","1062":"{'DBLP': 'journals\/corr\/abs-2001-05495', 'MAG': '3098310665', 'ArXiv': '2001.05495', 'DOI': '10.1145\/3308558.3313504', 'CorpusId': 86446136}","1063":"{'ACL': '2020.acl-main.50', 'MAG': '3035238981', 'DBLP': 'conf\/acl\/StefanovDAN20', 'DOI': '10.18653\/v1\/2020.acl-main.50', 'CorpusId': 220047716}","1064":"{'MAG': '2919411440', 'DOI': '10.1177\/0894439319831643', 'CorpusId': 86853868}","1065":"{'MAG': '2984184072', 'DOI': '10.1177\/0022243719881113', 'CorpusId': 211736212}","1066":"{'DBLP': 'conf\/www\/WangHAGHFJ19', 'MAG': '2911735741', 'ArXiv': '1905.05961', 'DOI': '10.1145\/3308558.3313684', 'CorpusId': 86439163}","1067":"{'DBLP': 'conf\/chi\/ErnalaBCRSKC19', 'MAG': '2940817972', 'DOI': '10.1145\/3290605.3300364', 'CorpusId': 106402356}","1068":"{'DBLP': 'conf\/aaai\/MathewSYBG021', 'ArXiv': '2012.10289', 'CorpusId': 229332119}","1069":"{'MAG': '2920647919', 'DBLP': 'journals\/nms\/GodlerRM20', 'DOI': '10.1177\/1461444819856922', 'CorpusId': 151078947}","1070":"{'DBLP': 'conf\/fat\/ChancellorBCSC19', 'MAG': '2908543495', 'DOI': '10.1145\/3287560.3287587', 'CorpusId': 58006083}","1071":"{'MAG': '3021994662', 'PubMedCentral': '7327724', 'DOI': '10.12688\/wellcomeopenres.15889.2', 'CorpusId': 220453567, 'PubMed': '32656368'}","1072":"{'MAG': '3091139943', 'DOI': '10.1177\/2050157920959106', 'CorpusId': 225018533}","1073":"{'DBLP': 'journals\/nms\/GerrardT20', 'MAG': '3041336306', 'DOI': '10.1177\/1461444820912540', 'CorpusId': 220725208}","1074":"{'DBLP': 'journals\/iacr\/Vaudenay20a', 'MAG': '3030358118', 'CorpusId': 218626039}","1075":"{'DBLP': 'conf\/chi\/SahaBCCCDDGGJMM19', 'MAG': '2942539385', 'DOI': '10.1145\/3290607.3299065', 'CorpusId': 88507504}","1076":"{'MAG': '3087065520', 'DBLP': 'conf\/ecai\/HellstromDB20', 'CorpusId': 221716464}","1077":"{'MAG': '2996625981', 'DBLP': 'journals\/nms\/Jaramillo-DentP21', 'DOI': '10.1177\/1461444819894241', 'CorpusId': 212426645}","1078":"{'ArXiv': '2005.05921', 'MAG': '3024844811', 'DBLP': 'journals\/corr\/abs-2005-05921', 'CorpusId': 218595698}","1079":"{'ACL': '2020.semeval-1.186', 'DBLP': 'journals\/corr\/abs-2009-02696', 'ArXiv': '2009.02696', 'MAG': '3083091152', 'DOI': '10.18653\/v1\/2020.semeval-1.186', 'CorpusId': 221517069}","1080":"{'ArXiv': '1908.09951', 'DBLP': 'journals\/corr\/abs-1908-09951', 'MAG': '2970554290', 'DOI': '10.1145\/3381750', 'CorpusId': 201646068}","1081":"{'MAG': '3035389441', 'DBLP': 'conf\/acl\/DuT20', 'ACL': '2020.acl-main.307', 'DOI': '10.18653\/v1\/2020.acl-main.307', 'CorpusId': 220046498}","1082":"{'DBLP': 'conf\/acl\/ChoubeyLHW20', 'MAG': '3035185704', 'ACL': '2020.acl-main.478', 'DOI': '10.18653\/v1\/2020.acl-main.478', 'CorpusId': 218515665}","1083":"{'DBLP': 'journals\/elektrik\/OnanT20', 'MAG': '3014870144', 'DOI': '10.3906\/elk-1907-11', 'CorpusId': 209168508}","1084":"{'MAG': '2969545244', 'PubMedCentral': '6705863', 'DOI': '10.1371\/journal.pone.0220976', 'CorpusId': 201619008, 'PubMed': '31437181'}","1085":"{'MAG': '2939100138', 'DBLP': 'conf\/www\/RudnikEFTTT19', 'ArXiv': '1904.05557', 'DOI': '10.1145\/3308560.3316761', 'CorpusId': 119184738}","1086":"{'DBLP': 'journals\/tcss\/ChakrabortyBDC19', 'MAG': '2963783457', 'DOI': '10.1109\/TCSS.2019.2926144', 'CorpusId': 199510157}","1087":"{'ArXiv': '1909.02766', 'DBLP': 'conf\/recsys\/HamborgBG19', 'MAG': '2971585879', 'CorpusId': 202537206}","1088":"{'MAG': '2964938584', 'DOI': '10.14569\/IJACSA.2019.0100742', 'CorpusId': 199529782}","1089":"{'MAG': '2935044269', 'DOI': '10.1109\/ICOMET.2019.8673428', 'CorpusId': 85500757}","1090":"{'MAG': '2921394995', 'DBLP': 'conf\/semco\/TraylorSGS19', 'DOI': '10.1109\/ICOSC.2019.8665593', 'CorpusId': 77391630}","1091":"{'MAG': '3007968087', 'DOI': '10.1080\/15205436.2020.1733613', 'CorpusId': 213691231}","1092":"{'DBLP': 'journals\/corr\/abs-2011-03327', 'ArXiv': '2011.03327', 'MAG': '3098106685', 'DOI': '10.1007\/978-3-030-73696-5_3', 'CorpusId': 226278226}","1093":"{'ACL': 'P19-1479', 'DBLP': 'conf\/acl\/LiXHYWS19', 'ArXiv': '1906.01231', 'MAG': '2948542853', 'DOI': '10.18653\/v1\/P19-1479', 'CorpusId': 174798138}","1094":"{'DBLP': 'conf\/sigir\/WuWQ021', 'ArXiv': '2104.07413', 'DOI': '10.1145\/3404835.3463069', 'CorpusId': 233241208}","1095":"{'ACL': '2020.acl-main.331', 'MAG': '3034503922', 'DBLP': 'conf\/acl\/WuQCWQLLXGWZ20', 'DOI': '10.18653\/v1\/2020.acl-main.331', 'CorpusId': 220046458}","1096":"{'DBLP': 'conf\/eacl\/GhanemPRR21', 'ACL': '2021.eacl-main.56', 'ArXiv': '2101.09810', 'DOI': '10.18653\/v1\/2021.eacl-main.56', 'CorpusId': 231698956}","1097":"{'DBLP': 'journals\/jasis\/SinghGS21', 'MAG': '3023208170', 'DOI': '10.1002\/asi.24359', 'CorpusId': 218922449}","1098":"{'DBLP': 'journals\/corr\/abs-2006-11343', 'ArXiv': '2006.11343', 'DOI': '10.36190\/2020.14', 'CorpusId': 219965603}","1099":"{'MAG': '3098835531', 'DBLP': 'journals\/corr\/abs-2006-05557', 'ArXiv': '2006.05557', 'DOI': '10.1145\/3340531.3412880', 'CorpusId': 219558530}","1100":"{'DBLP': 'conf\/pakdd\/ZhouWZ20', 'ArXiv': '2003.04981', 'MAG': '3012090365', 'DOI': '10.1007\/978-3-030-47436-2_27', 'CorpusId': 212657536}","1101":"{'MAG': '2950641664', 'ArXiv': '1906.01749', 'DBLP': 'conf\/acl\/FabbriLSLR19', 'ACL': 'P19-1102', 'DOI': '10.18653\/v1\/P19-1102', 'CorpusId': 174799390}","1102":"{'DBLP': 'journals\/corr\/abs-1912-12520', 'ArXiv': '1912.12520', 'MAG': '3034027410', 'DOI': '10.1609\/aaai.v34i01.5389', 'CorpusId': 209391868}","1103":"{'MAG': '2970487286', 'ACL': 'D19-1565', 'DBLP': 'journals\/corr\/abs-1910-02517', 'ArXiv': '1910.02517', 'DOI': '10.18653\/v1\/D19-1565', 'CorpusId': 202788575}","1104":"{'MAG': '3101260801', 'DBLP': 'journals\/corr\/abs-1908-04212', 'ArXiv': '1908.04212', 'DOI': '10.1007\/s10579-019-09471-7', 'CorpusId': 199543943}","1105":"{'DBLP': 'conf\/recsys\/LiuLWQCS020', 'MAG': '3034449195', 'DOI': '10.1145\/3383313.3412237', 'CorpusId': 221662308}","1106":"{'MAG': '2912305564', 'DBLP': 'conf\/www\/KhattarG0V19', 'DOI': '10.1145\/3308558.3313552', 'CorpusId': 86785940}","1107":"{'DBLP': 'conf\/semeval\/KieselMSVACSP19', 'ACL': 'S19-2145', 'MAG': '2955041501', 'DOI': '10.18653\/v1\/S19-2145', 'CorpusId': 120224153}","1108":"{'MAG': '3091926346', 'ACL': '2020.findings-emnlp.128', 'DBLP': 'conf\/emnlp\/QiWWH020', 'DOI': '10.18653\/v1\/2020.findings-emnlp.128', 'CorpusId': 222225275}","1109":"{'DBLP': 'conf\/aaai\/SinghalKSS0K20', 'MAG': '3037666784', 'DOI': '10.1609\/aaai.v34i10.7230', 'CorpusId': 219182395}","1110":"{'DBLP': 'conf\/kdd\/WuWAHHX19', 'ArXiv': '1907.05559', 'MAG': '2963502609', 'DOI': '10.1145\/3292500.3330665', 'CorpusId': 196181724}","1111":"{'MAG': '3092546490', 'DBLP': 'conf\/emnlp\/VoL20', 'ACL': '2020.emnlp-main.621', 'ArXiv': '2010.03159', 'DOI': '10.18653\/v1\/2020.emnlp-main.621', 'CorpusId': 222177140}","1112":"{'MAG': '3036049456', 'PubMedCentral': '7298180', 'DBLP': 'conf\/nldb\/GiachanouRGCR20', 'DOI': '10.1007\/978-3-030-51310-8_17', 'CorpusId': 219721895}","1113":"{'DBLP': 'conf\/recsys\/SheuL20', 'MAG': '3088971166', 'DOI': '10.1145\/3383313.3418477', 'CorpusId': 221785083}","1114":"{'DBLP': 'conf\/www\/GuM0L00FYZZ20', 'ArXiv': '2001.09386', 'MAG': '3012910066', 'DOI': '10.1145\/3366423.3380247', 'CorpusId': 210919915}","1115":"{'MAG': '3036963250', 'DBLP': 'conf\/ht\/Gangireddy0L020', 'DOI': '10.1145\/3372923.3404783', 'CorpusId': 220433969}","1116":"{'DBLP': 'conf\/websci\/ZannettouEBNS20', 'MAG': '3038114639', 'ArXiv': '2005.07926', 'DOI': '10.1145\/3394231.3397902', 'CorpusId': 218673824}","1117":"{'MAG': '2738927550', 'DOI': '10.1177\/1464884917716699', 'CorpusId': 148775880}","1118":"{'ArXiv': '1903.07389', 'DBLP': 'conf\/naacl\/KarimiT19', 'MAG': '2964243798', 'ACL': 'N19-1347', 'DOI': '10.18653\/v1\/N19-1347', 'CorpusId': 81977022}","1119":"{'MAG': '2945267390', 'DOI': '10.1177\/2053951719843310', 'CorpusId': 181689055}","1120":"{'MAG': '2977178908', 'DBLP': 'conf\/bigdataservice\/MohanMSVA19', 'DOI': '10.1109\/BigDataService.2019.00035', 'CorpusId': 203566840}","1121":"{'MAG': '2955567097', 'DBLP': 'conf\/icwsm\/SalemFEJF19', 'CorpusId': 189818729}","1122":"{'DBLP': 'journals\/corr\/abs-1912-06810', 'MAG': '2966487074', 'ArXiv': '1912.06810', 'DOI': '10.1609\/aaai.v33i01.33019847', 'CorpusId': 198189779}","1123":"{'DBLP': 'conf\/www\/DhojuRKH19', 'MAG': '2946125616', 'DOI': '10.1145\/3308560.3316741', 'CorpusId': 153313896}","1124":"{'MAG': '3106300911', 'DBLP': 'journals\/corr\/abs-1905-00957', 'ArXiv': '1905.00957', 'DOI': '10.1145\/3308560.3316739', 'CorpusId': 145048301}","1125":"{'MAG': '2912723748', 'DOI': '10.1007\/S42001-019-00035-X', 'CorpusId': 86577387}","1126":"{'DBLP': 'conf\/asunam\/BenamiraDLRSM19', 'MAG': '2982591719', 'DOI': '10.1145\/3341161.3342958', 'CorpusId': 208113391}","1127":"{'DBLP': 'conf\/www\/JosephJ19', 'MAG': '2946340210', 'ArXiv': '1905.13132', 'DOI': '10.1145\/3308560.3317703', 'CorpusId': 153314061}","1128":"{'ACL': 'P19-2050', 'DBLP': 'conf\/acl\/PathakS19', 'MAG': '2949661904', 'DOI': '10.18653\/v1\/P19-2050', 'CorpusId': 196214317}","1129":"{'ArXiv': '1911.12237', 'ACL': 'D19-5409', 'DBLP': 'journals\/corr\/abs-1911-12237', 'MAG': '2989743967', 'DOI': '10.18653\/v1\/D19-5409', 'CorpusId': 208010268}","1130":"{'DBLP': 'conf\/emnlp\/YilmazYZL19', 'MAG': '2971209824', 'ACL': 'D19-1352', 'DOI': '10.18653\/v1\/D19-1352', 'CorpusId': 202635721}","1131":"{'DBLP': 'conf\/kdd\/AhmadianE0M19', 'MAG': '2964134703', 'ArXiv': '1905.12753', 'DOI': '10.1145\/3292500.3330987', 'CorpusId': 170078576}","1132":"{'MAG': '2964992537', 'DOI': '10.1109\/ICACTM.2019.8776800', 'CorpusId': 199058192}","1133":"{'MAG': '3001654774', 'DBLP': 'journals\/access\/FengKRA20', 'DOI': '10.1109\/ACCESS.2020.2967792', 'CorpusId': 210993948}","1134":"{'DBLP': 'journals\/corr\/abs-2009-01325', 'ArXiv': '2009.01325', 'MAG': '3098985263', 'CorpusId': 221665105}","1135":"{'ACL': 'P19-1630', 'MAG': '2952586322', 'DBLP': 'conf\/acl\/FrermannK19', 'DOI': '10.18653\/v1\/P19-1630', 'CorpusId': 196184038}","1136":"{'MAG': '3029801143', 'PubMedCentral': '7281826', 'DBLP': 'journals\/cin\/ManoharanS20', 'DOI': '10.1155\/2020\/3791541', 'CorpusId': 219699439, 'PubMed': '32565771'}","1137":"{'MAG': '3013330736', 'DOI': '10.1177\/1536867X20909688', 'CorpusId': 216352732}","1138":"{'ArXiv': '2002.05780', 'DBLP': 'conf\/aaai\/YePWCZXL20', 'MAG': '2998034590', 'DOI': '10.1609\/AAAI.V34I01.5462', 'CorpusId': 211126763}","1139":"{'DBLP': 'journals\/corr\/abs-1912-10806', 'ArXiv': '1912.10806', 'MAG': '2995421442', 'CorpusId': 209445032}","1140":"{'DBLP': 'journals\/corr\/abs-2004-10400', 'ArXiv': '2004.10400', 'MAG': '3029581652', 'DOI': '10.1162\/qss_a_00066', 'CorpusId': 216056157}","1141":"{'ACL': 'N19-1141', 'MAG': '2945264558', 'DBLP': 'conf\/naacl\/NguyenDCD19', 'DOI': '10.18653\/v1\/N19-1141', 'CorpusId': 174799917}","1142":"{'MAG': '2979276526', 'DBLP': 'conf\/cikm\/LiuBLZSWX19', 'CorpusId': 204777685}","1143":"{'MAG': '2974015196', 'DBLP': 'conf\/ic3\/BhutaniRSP19', 'DOI': '10.1109\/IC3.2019.8844880', 'CorpusId': 202699969}","1144":"{'PubMedCentral': '6968875', 'ArXiv': '1907.08170', 'MAG': '2956224423', 'DBLP': 'journals\/corr\/abs-1907-08170', 'DOI': '10.1371\/journal.pone.0227821', 'CorpusId': 197545175, 'PubMed': '31951628'}","1145":"{'MAG': '2979653555', 'DOI': '10.1109\/COMITCon.2019.8862265', 'CorpusId': 204230531}","1146":"{'MAG': '3097642862', 'DOI': '10.1007\/s40031-020-00501-5', 'CorpusId': 228890387}","1147":"{'DBLP': 'conf\/icwsm\/Brena0CGPR19', 'MAG': '2955986275', 'CorpusId': 189818763}","1148":"{'DBLP': 'journals\/corr\/abs-1903-05538', 'MAG': '2911641603', 'ArXiv': '1903.05538', 'DOI': '10.1145\/3308558.3313657', 'CorpusId': 76663904}","1149":"{'MAG': '2791869820', 'DBLP': 'journals\/ijhci\/KimL19', 'DOI': '10.1080\/10447318.2018.1437864', 'CorpusId': 59540906}","1150":"{'MAG': '2992999841', 'DOI': '10.1109\/ICTCS.2019.8923073', 'CorpusId': 208880995}","1151":"{'MAG': '3091471597', 'DBLP': 'journals\/corr\/abs-2010-00502', 'ArXiv': '2010.00502', 'CorpusId': 222090618}","1152":"{'MAG': '2885955761', 'DOI': '10.1093\/RAPSTU\/RAZ007', 'CorpusId': 203271365}","1153":"{'MAG': '3011244125', 'DOI': '10.1109\/ISCON47742.2019.9036221', 'CorpusId': 213177074}","1154":"{'MAG': '2955502916', 'DOI': '10.5121\/IJNLC.2019.8302', 'CorpusId': 197634561}","1155":"{'DBLP': 'journals\/mansci\/Papanastasiou20', 'MAG': '2755869366', 'DOI': '10.1287\/MNSC.2019.3295', 'CorpusId': 213013081}","1156":"{'MAG': '2949530332', 'ACL': 'P19-1210', 'DBLP': 'conf\/acl\/LiZJR19', 'DOI': '10.18653\/v1\/P19-1210', 'CorpusId': 196199831}","1157":"{'DBLP': 'conf\/lrec\/CruzTC20', 'MAG': '3031068414', 'ACL': '2020.lrec-1.316', 'ArXiv': '1910.09295', 'DOI': '10.13140\/RG.2.2.23028.40322', 'CorpusId': 204800316}","1158":"{'DBLP': 'journals\/corr\/abs-2202-07269', 'ArXiv': '2202.07269', 'DOI': '10.2139\/ssrn.3712218', 'CorpusId': 226317730}","1159":"{'DBLP': 'conf\/chi\/MoslehMER21', 'DOI': '10.1145\/3411764.3445642', 'CorpusId': 233987905}","1160":"{'MAG': '3118993169', 'DOI': '10.1177\/0022243720987147', 'CorpusId': 234171237}","1161":"{'DBLP': 'conf\/ic3k\/BradshawOC20', 'DOI': '10.5220\/0010144202770281', 'CorpusId': 227129961}","1162":"{'DBLP': 'journals\/corr\/abs-1912-11211', 'MAG': '2997626578', 'ArXiv': '1912.11211', 'DOI': '10.5210\/fm.v25i3.10419', 'CorpusId': 209460683}","1163":"{'DBLP': 'conf\/asunam\/SharmaKSS20', 'DOI': '10.1109\/ASONAM49781.2020.9381344', 'CorpusId': 230125494}","1164":"{'DBLP': 'journals\/corr\/abs-2110-09151', 'ArXiv': '2110.09151', 'CorpusId': 239016699}","1165":"{'ArXiv': '2110.09158', 'DBLP': 'journals\/corr\/abs-2110-09158', 'DOI': '10.1109\/JCDL52503.2021.00025', 'CorpusId': 239016686}","1166":"{'DBLP': 'journals\/sigact\/Hemaspaandra21c', 'DOI': '10.1145\/3510382.3510391', 'CorpusId': 245652469}","1167":"{'DBLP': 'journals\/sigact\/HohneSS21', 'DOI': '10.1145\/3510382.3510396', 'CorpusId': 245652466}","1168":"{'DBLP': 'journals\/sigact\/Hemaspaandra21', 'DOI': '10.1145\/3457588.3457597', 'CorpusId': 232245707}","1169":"{'DBLP': 'journals\/sigact\/Hemaspaandra21b', 'DOI': '10.1145\/3494656.3494665', 'CorpusId': 243765532}","1170":"{'DBLP': 'journals\/sigact\/Hemaspaandra21a', 'DOI': '10.1145\/3471469.3471478', 'CorpusId': 235463195}","1171":"{'DBLP': 'conf\/iconference\/SpindeKRMGAG22', 'DOI': '10.1007\/978-3-030-96957-8_20', 'CorpusId': 247075509}","1172":"{'MAG': '2981530776', 'DBLP': 'conf\/mm\/GuptaY19', 'DOI': '10.1145\/3343031.3351048', 'CorpusId': 204837066}","1173":"{'DBLP': 'journals\/sigact\/HohneSS20', 'DOI': '10.1145\/3444815.3444830', 'CorpusId': 231606976}","1174":"{'DBLP': 'journals\/sigact\/Hemaspaandra20', 'MAG': '3012513177', 'DOI': '10.1145\/3388392.3388400', 'CorpusId': 212676447}","1175":"{'DBLP': 'journals\/sigact\/Hemaspaandra20b', 'MAG': '3089472057', 'DOI': '10.1145\/3427361.3427371', 'CorpusId': 222001517}","1176":"{'MAG': '3036348639', 'DBLP': 'journals\/sigact\/Hemaspaandra20a', 'DOI': '10.1145\/3406678.3406687', 'CorpusId': 219709739}","1177":"{'MAG': '3118240568', 'DBLP': 'journals\/sigact\/Hemaspaandra20c', 'DOI': '10.1145\/3444815.3444824', 'CorpusId': 231606975}","1178":"{'MAG': '2940201152', 'DOI': '10.1177\/1931243119829430', 'CorpusId': 145957197}","1179":"{'MAG': '2985431777', 'DOI': '10.1177\/1931243119883839', 'CorpusId': 209080497}","1180":"{'MAG': '2943017960', 'CorpusId': 155599006}","1181":"{'DBLP': 'journals\/sigact\/Hemaspaandra19b', 'MAG': '2975427411', 'DOI': '10.1145\/3364626.3364636', 'CorpusId': 203621217}","1182":"{'ArXiv': '2105.06603', 'ACL': '2021.naacl-main.379', 'MAG': '3169849687', 'DBLP': 'conf\/naacl\/AllawaySM21', 'DOI': '10.18653\/V1\/2021.NAACL-MAIN.379', 'CorpusId': 234679287}","1183":"{'MAG': '3212918693', 'DOI': '10.17645\/mac.v9i4.4164', 'CorpusId': 244460846}","1184":"{'MAG': '2946643424', 'DOI': '10.1080\/08940886.2019.1608121', 'CorpusId': 182782656}","1185":"{'MAG': '2971603890', 'DOI': '10.1108\/lhtn-06-2019-0040', 'CorpusId': 202787784}","1186":"{'DBLP': 'conf\/kdd\/ShuCW0L19', 'MAG': '2951307134', 'DOI': '10.1145\/3292500.3330935', 'CorpusId': 160015036}","1187":"{'DBLP': 'journals\/corr\/abs-1902-06673', 'MAG': '2911710347', 'ArXiv': '1902.06673', 'CorpusId': 62841478}","1188":"{'MAG': '2944575651', 'DBLP': 'journals\/expert\/ReisCMVBC19', 'DOI': '10.1109\/MIS.2019.2899143', 'CorpusId': 85548285}","1189":"{'MAG': '2903981179', 'DBLP': 'conf\/aaai\/YangSWG0019', 'DOI': '10.1609\/AAAI.V33I01.33015644', 'CorpusId': 54049995}","1190":"{'MAG': '2970793364', 'ACL': 'D19-1671', 'DBLP': 'conf\/emnlp\/WuWGQHX19', 'DOI': '10.18653\/v1\/D19-1671', 'CorpusId': 202774468}","1191":"{'MAG': '3041406295', 'DBLP': 'journals\/csur\/ZhouZ20', 'DOI': '10.1145\/3395046', 'CorpusId': 218517373}","1192":"{'DBLP': 'conf\/wsdm\/ZhouZSL19', 'MAG': '2912642460', 'DOI': '10.1145\/3289600.3291382', 'CorpusId': 53664813}","1193":"{'DBLP': 'journals\/corr\/abs-1907-05576', 'MAG': '2964536660', 'ArXiv': '1907.05576', 'DOI': '10.24963\/ijcai.2019\/536', 'CorpusId': 196471084}","1194":"{'MAG': '3033168164', 'DOI': '10.5392\/JKCA.2020.20.05.457', 'CorpusId': 222185741}","1195":"{'MAG': '2991370774', 'DOI': '10.3390\/electronics8121377', 'CorpusId': 213972852}","1196":"{'ArXiv': '2004.02566', 'MAG': '3015170206', 'DBLP': 'journals\/corr\/abs-2004-02566', 'CorpusId': 214803021}","1197":"{'DBLP': 'conf\/icalp2\/AlkhairMSO19', 'MAG': '2977485612', 'DOI': '10.1007\/978-3-030-32959-4_21', 'CorpusId': 203848652}","1198":"{'DBLP': 'journals\/corr\/abs-1903-09196', 'ArXiv': '1903.09196', 'MAG': '3037987827', 'CorpusId': 85459756}","1199":"{'MAG': '3028860567', 'DOI': '10.1007\/s41133-020-00032-0', 'CorpusId': 219756231}","1200":"{'MAG': '2753241397', 'DOI': '10.1177\/0894439317734157', 'CorpusId': 59516834}","1201":"{'ArXiv': '1904.13355', 'DBLP': 'conf\/asunam\/ShuZWZL19', 'MAG': '2943105737', 'DOI': '10.1145\/3341161.3342927', 'CorpusId': 140226077}","1202":"{'DBLP': 'journals\/corr\/abs-1907-07757', 'MAG': '2960841035', 'ArXiv': '1907.07757', 'DOI': '10.1145\/3308558.3314119', 'CorpusId': 85548567}","1203":"{'ArXiv': '1901.09657', 'MAG': '3099803414', 'DBLP': 'conf\/icaart\/ZhouGBH19', 'DOI': '10.5220\/0007566307940800', 'CorpusId': 59317019}","1204":"{'DBLP': 'journals\/corr\/abs-2004-03705', 'MAG': '3156333129', 'ArXiv': '2004.03705', 'DOI': '10.1145\/3439726', 'CorpusId': 215416034}","1205":"{'DBLP': 'journals\/oir\/AhmedL19', 'MAG': '2898374174', 'DOI': '10.1108\/OIR-03-2018-0093', 'CorpusId': 69555240}","1206":"{'MAG': '3087330443', 'DOI': '10.1007\/S00779-020-01461-9', 'CorpusId': 225020039}","1207":"{'DBLP': 'conf\/snams\/SchroederPL19', 'MAG': '2996740338', 'DOI': '10.1109\/SNAMS.2019.8931870', 'CorpusId': 209383051}","1208":"{'MAG': '3080295236', 'DBLP': 'journals\/access\/UmerIUMCO20', 'DOI': '10.1109\/ACCESS.2020.3019735', 'CorpusId': 221567744}","1209":"{'MAG': '2945089338', 'DBLP': 'conf\/www\/Budak19', 'DOI': '10.1145\/3308558.3313721', 'CorpusId': 153314609}","1210":"{'MAG': '3088833022', 'DOI': '10.2352\/ISSN.2470-1173.2020.16.AVM-148', 'CorpusId': 226142141}","1211":"{'DBLP': 'journals\/access\/SadiqRNUH20', 'DOI': '10.1109\/access.2020.3044346', 'CorpusId': 230716916}","1212":"{'MAG': '2979665083', 'DOI': '10.1007\/978-3-030-24737-9_3', 'CorpusId': 208123465}","1213":"{'MAG': '2979734645', 'DOI': '10.1007\/978-3-030-24737-9_27', 'CorpusId': 209072078}","1214":"{'DBLP': 'journals\/tgrs\/ZhangZDHWZ22', 'MAG': '3160128245', 'DOI': '10.1109\/TGRS.2021.3077083', 'CorpusId': 236585653}","1215":"{'DBLP': 'journals\/staeors\/TompkinL21', 'DOI': '10.1109\/JSTARS.2021.3074418', 'CorpusId': 234499789}","1216":"{'MAG': '3095818528', 'DBLP': 'conf\/rfid\/Parthiban20', 'DOI': '10.1109\/RFID49298.2020.9244878', 'CorpusId': 226265439}","1217":"{'MAG': '3093740735', 'DOI': '10.1117\/12.2575993', 'CorpusId': 222210463}","1218":"{'MAG': '2965500191', 'DBLP': 'journals\/remotesensing\/WilganSSGF19', 'DOI': '10.3390\/RS11151789', 'CorpusId': 201308672}","1219":"{'MAG': '2967937824', 'DOI': '10.1049\/JOE.2019.0326', 'CorpusId': 201892198}","1220":"{'MAG': '3009634428', 'DOI': '10.1109\/IMITEC45504.2019.9015837', 'CorpusId': 211685210}","1221":"{'MAG': '2984872576', 'DBLP': 'conf\/igarss\/DongXZ0L19', 'DOI': '10.1109\/IGARSS.2019.8899316', 'CorpusId': 208036913}","1222":"{'MAG': '2998828306', 'DOI': '10.36968\/jpdc.0301.04', 'CorpusId': 213073486}","1223":"{'DBLP': 'journals\/access\/LvZSTE22', 'DOI': '10.1109\/access.2022.3159791', 'CorpusId': 247504264}","1224":"{'DBLP': 'journals\/remotesensing\/BrenotRKMSTRBMC20', 'MAG': '2997401331', 'DOI': '10.3390\/rs12010030', 'CorpusId': 210843364}","1225":"{'ArXiv': '1901.00511', 'MAG': '2907758373', 'DBLP': 'journals\/corr\/abs-1901-00511', 'DOI': '10.1109\/JCN.2019.000005', 'CorpusId': 57375770}","1226":"{'ArXiv': '1912.03184', 'ACL': '2020.lrec-1.194', 'MAG': '3030815165', 'DBLP': 'conf\/lrec\/BostanKK20', 'CorpusId': 208857380}","1227":"{'DBLP': 'conf\/wirtschaftsinformatik\/0001HKS19', 'MAG': '2943976830', 'CorpusId': 164787124}","1228":"{'DBLP': 'conf\/chi\/GraceH19', 'MAG': '2942584965', 'DOI': '10.1145\/3290607.3299046', 'CorpusId': 144208006}","1229":"{'MAG': '2900993107', 'DBLP': 'journals\/jmui\/OchsMMPSLFB19', 'DOI': '10.1007\/s12193-018-0289-8', 'CorpusId': 57426067}","1230":"{'MAG': '2982370645', 'DOI': '10.1109\/ISEMANTIC.2019.8884291', 'CorpusId': 204939282}","1231":"{'DBLP': 'journals\/ejis\/LaatoIIW20', 'MAG': '3033580827', 'DOI': '10.1080\/0960085X.2020.1770632', 'CorpusId': 219931799}","1232":"{'DBLP': 'journals\/corr\/abs-2004-09600', 'MAG': '3104394795', 'ArXiv': '2004.09600', 'DOI': '10.1080\/0960085X.2020.1770632', 'CorpusId': 216036346}","1233":"{'MAG': '2964778068', 'DBLP': 'journals\/nms\/ScaccoM20', 'DOI': '10.1177\/1461444819863408', 'CorpusId': 201426558}","1234":"{'PubMedCentral': '6762082', 'MAG': '2975067599', 'DOI': '10.1371\/journal.pone.0222713', 'CorpusId': 203567679, 'PubMed': '31557213'}","1235":"{'MAG': '2940265767', 'DOI': '10.1177\/1729881419839596', 'CorpusId': 146005566}","1236":"{'DBLP': 'conf\/aies\/ChuanTC19', 'MAG': '2961130995', 'DOI': '10.1145\/3306618.3314285', 'CorpusId': 195877435}","1237":"{'DBLP': 'journals\/ett\/KumarAUUA20', 'MAG': '2984545517', 'DOI': '10.1002\/ett.3767', 'CorpusId': 209055420}","1238":"{'MAG': '3030263457', 'DBLP': 'conf\/chi\/LuJLNW20', 'DOI': '10.1145\/3313831.3376612', 'CorpusId': 210843764}","1239":"{'DBLP': 'conf\/dev\/Al-AmeenTNACA20', 'MAG': '3039982061', 'DOI': '10.1145\/3378393.3402244', 'CorpusId': 220281569}","1240":"{'DBLP': 'journals\/fi\/ManiouV20', 'MAG': '3038288326', 'DOI': '10.3390\/fi12070109', 'CorpusId': 221356164}","1241":"{'MAG': '2980145593', 'DOI': '10.1353\/pla.2019.0040', 'CorpusId': 208109806}","1242":"{'DBLP': 'conf\/hci\/LoosN20', 'MAG': '3041056725', 'DOI': '10.1007\/978-3-030-50232-4_6', 'CorpusId': 220527639}","1243":"{'DBLP': 'journals\/corr\/abs-2101-05509', 'ArXiv': '2101.05509', 'MAG': '3158073235', 'DOI': '10.1007\/978-3-030-73696-5_9', 'CorpusId': 231602959}","1244":"{'DBLP': 'journals\/nms\/Jones-JangKK21', 'MAG': '3045245306', 'DOI': '10.1177\/1461444820943878', 'CorpusId': 225547458}","1245":"{'MAG': '3127078949', 'DOI': '10.4018\/JGIM.2021030105', 'CorpusId': 233856875}","1246":"{'MAG': '2978258033', 'DBLP': 'conf\/webist\/ChunHDWBG19', 'DOI': '10.5220\/0008350303340342', 'CorpusId': 204754730}","1247":"{'MAG': '3036253866', 'DBLP': 'conf\/aaai\/0008RW20', 'DOI': '10.1609\/aaai.v34i09.7117', 'CorpusId': 219182214}","1248":"{'ArXiv': '2004.12162', 'MAG': '2896239072', 'DOI': '10.2139\/ssrn.3583596', 'CorpusId': 69569604}","1249":"{'MAG': '3000509134', 'DOI': '10.1017\/pan.2019.42', 'CorpusId': 213569902}","1250":"{'DBLP': 'conf\/icwsm\/JiangRW19', 'MAG': '2953559754', 'CorpusId': 189818773}","1251":"{'MAG': '3042970922', 'DOI': '10.1017\/pan.2020.14', 'CorpusId': 225565010}","1252":"{'MAG': '3129141465', 'DOI': '10.1017\/ipo.2021.1', 'CorpusId': 233957814}","1253":"{'DBLP': 'conf\/acl-alw\/WichBG20', 'MAG': '3105090453', 'ACL': '2020.alw-1.7', 'DOI': '10.18653\/v1\/2020.alw-1.7', 'CorpusId': 226284001}","1254":"{'MAG': '3011130393', 'DOI': '10.1017\/pan.2020.3', 'CorpusId': 53516831}","1255":"{'MAG': '3115465103', 'DOI': '10.1017\/pan.2020.41', 'CorpusId': 234461147}","1256":"{'MAG': '3181158838', 'DOI': '10.1017\/pan.2021.22', 'CorpusId': 237825402}","1257":"{'MAG': '2972275627', 'DBLP': 'journals\/nature\/StewartMDARP19', 'DOI': '10.1038\/s41586-019-1507-6', 'CorpusId': 201834218, 'PubMed': '31485058'}","1258":"{'DBLP': 'journals\/corr\/abs-1902-00043', 'ArXiv': '1902.00043', 'MAG': '2952224515', 'DOI': '10.1145\/3308560.3316486', 'CorpusId': 59553576}","1259":"{'DBLP': 'journals\/see\/Grundy21', 'DOI': '10.1007\/s11948-021-00315-8', 'CorpusId': 235360182, 'PubMed': '34097141'}","1260":"{'MAG': '3092629077', 'DOI': '10.1111\/rssa.12608', 'CorpusId': 225143259}","1261":"{'DBLP': 'conf\/ht\/KnochePLS19', 'MAG': '2974834756', 'DOI': '10.1145\/3342220.3343658', 'CorpusId': 202640737}","1262":"{'ArXiv': '2004.07225', 'DBLP': 'conf\/icwsm\/FatemiZ20', 'MAG': '3037970860', 'CorpusId': 214733330}","1263":"{'DBLP': 'conf\/www\/LiZJW22', 'ArXiv': '2104.12222', 'MAG': '3165262575', 'DOI': '10.1145\/3485447.3512063', 'CorpusId': 233394231}","1264":"{'MAG': '2947160886', 'DOI': '10.1007\/S13347-019-00355-W', 'CorpusId': 189989313}","1265":"{'DBLP': 'conf\/www\/UmarovaM19', 'MAG': '2945924652', 'DOI': '10.1145\/3308560.3316760', 'CorpusId': 153314690}","1266":"{'DBLP': 'journals\/mansci\/FreemanRS21', 'MAG': '3092094523', 'DOI': '10.1287\/mnsc.2020.3711', 'CorpusId': 225114024}","1267":"{'DBLP': 'journals\/jasis\/PotnisT21', 'MAG': '3138824093', 'DOI': '10.1002\/asi.24467', 'CorpusId': 233659061}","1268":"{'MAG': '3012299745', 'DOI': '10.1080\/21670811.2020.1736946', 'CorpusId': 215841603}","1269":"{'DBLP': 'conf\/icwsm\/BandyD20', 'ArXiv': '1908.00456', 'MAG': '3037169037', 'CorpusId': 199064693}","1270":"{'MAG': '2943188882', 'DOI': '10.1093\/CT\/QTZ008', 'CorpusId': 155291992}","1271":"{'DBLP': 'journals\/pnas\/Gonzalez-Bailon21', 'PubMedCentral': '7980437', 'DOI': '10.1073\/pnas.2013443118', 'CorpusId': 232245604, 'PubMed': '33836572'}","1272":"{'PubMedCentral': '7415331', 'MAG': '3048335295', 'DBLP': 'journals\/ais\/Schiff21', 'DOI': '10.1007\/s00146-020-01033-8', 'CorpusId': 221084245, 'PubMed': '32836908'}","1273":"{'MAG': '2735097881', 'DBLP': 'journals\/ais\/Al-Rawi19', 'DOI': '10.1007\/s00146-017-0742-3', 'CorpusId': 23518628}"},"url":{"0":"https:\/\/www.semanticscholar.org\/paper\/c0d2579463db52df8d3b303392729e77358aa9b9","1":"https:\/\/www.semanticscholar.org\/paper\/f28208f6847012f986c4ce63b34236284e65407c","2":"https:\/\/www.semanticscholar.org\/paper\/861a1e8f281809d5d6c26d6d8a18b648cbd50c69","3":"https:\/\/www.semanticscholar.org\/paper\/0e012c2bd18236445cfbc6e3e409eb02df4691fe","4":"https:\/\/www.semanticscholar.org\/paper\/2297c559ac3509b3ab456229f7032b2a0fbf23c1","5":"https:\/\/www.semanticscholar.org\/paper\/4ad766d33c9e63539f2394585419c992056ffc06","6":"https:\/\/www.semanticscholar.org\/paper\/1ce96d8dbf69199ebd043de6cfa25d7e48b8ab03","7":"https:\/\/www.semanticscholar.org\/paper\/d0cda85c030711aaa5383c80d5928a4d22f8d3bf","8":"https:\/\/www.semanticscholar.org\/paper\/3ca7a604e0d351e512bfda045d2837caeb9831df","9":"https:\/\/www.semanticscholar.org\/paper\/56441f4f3beb3276350d811c67307e28d5f61b43","10":"https:\/\/www.semanticscholar.org\/paper\/26f5da9bfffd101fb86f6ab16b1b7ff8ce6046c3","11":"https:\/\/www.semanticscholar.org\/paper\/e960beaf0e84bc20cbcfd67fb7aefe37db15e1a1","12":"https:\/\/www.semanticscholar.org\/paper\/7779b04aae43f65ff5cf4419c8042761fa37578c","13":"https:\/\/www.semanticscholar.org\/paper\/74b4612444691865b9bff96585bbdf176dbac45f","14":"https:\/\/www.semanticscholar.org\/paper\/98a25ab6f929583138e526f8dccea4b343865c0d","15":"https:\/\/www.semanticscholar.org\/paper\/a413a801b470955dbe5862984910a0431949921f","16":"https:\/\/www.semanticscholar.org\/paper\/8592983238261838603caf503def12d3396de710","17":"https:\/\/www.semanticscholar.org\/paper\/2ffa22885c2df0f14bb059a1234f3a9b2b0c3e5d","18":"https:\/\/www.semanticscholar.org\/paper\/306a70c6f9a8e5863efca4931f9481d9af270b15","19":"https:\/\/www.semanticscholar.org\/paper\/e85a50b523915b5fba3e3f1fdb743650f7d21bed","20":"https:\/\/www.semanticscholar.org\/paper\/339b2b711fb5b228d097b03ebc3e62a521779235","21":"https:\/\/www.semanticscholar.org\/paper\/4099c4d272c12081b562392606e6d567e4ae7031","22":"https:\/\/www.semanticscholar.org\/paper\/48689c4bb52a45c0bc97d1421d72d11bab6c346b","23":"https:\/\/www.semanticscholar.org\/paper\/59bb7f41e72bae283f8aa2222b346956ee197a7a","24":"https:\/\/www.semanticscholar.org\/paper\/e7a00d7bdc5f9e2d4aaa17a3d44ee1239f33fc30","25":"https:\/\/www.semanticscholar.org\/paper\/2f4a012aa325cdee5a5c779fe2133e146616a5d5","26":"https:\/\/www.semanticscholar.org\/paper\/0aa199ecfacdc0fb087c9fd8d602c402a74b4e31","27":"https:\/\/www.semanticscholar.org\/paper\/32948ae25dbd35f2d94a59c27f6bee935bd602b8","28":"https:\/\/www.semanticscholar.org\/paper\/a25800880aa6905f9cf2fb4e6aef54164f999cbd","29":"https:\/\/www.semanticscholar.org\/paper\/56d41f91193994eb80884ec83c1c1e74b7cc3058","30":"https:\/\/www.semanticscholar.org\/paper\/56a77b2810dfa3fedf22bdfda0eb33b5b2ca882f","31":"https:\/\/www.semanticscholar.org\/paper\/8371efc92fc65a883ae3eb19c8ca1eb2b30be09e","32":"https:\/\/www.semanticscholar.org\/paper\/00059087c954c1af6ece33115315e3e0ecc2f2c2","33":"https:\/\/www.semanticscholar.org\/paper\/0712334d1109248e52706f13aeff5281834727f8","34":"https:\/\/www.semanticscholar.org\/paper\/af0b84d24764fc5751af75a8f68fe535ef10d08b","35":"https:\/\/www.semanticscholar.org\/paper\/9c49a2178134517701befea536400c01a1cdefe7","36":"https:\/\/www.semanticscholar.org\/paper\/055fac05cd424e7b1bdcd359ff7980ca8d938ef3","37":"https:\/\/www.semanticscholar.org\/paper\/080ee4e93438f8b8cbdd894eef15af71f0c30097","38":"https:\/\/www.semanticscholar.org\/paper\/0ebb1d1fbf488fba8c18a5a6057a6ccd9e87510f","39":"https:\/\/www.semanticscholar.org\/paper\/0110df900ebf9cb6e77c0f4a326e5431c849359d","40":"https:\/\/www.semanticscholar.org\/paper\/cfc9a178c413d4960840379a12f552dc5cea6c6d","41":"https:\/\/www.semanticscholar.org\/paper\/19f288c459aa8e74170c8f8430f7c87760950fe4","42":"https:\/\/www.semanticscholar.org\/paper\/7a6aab74d2feeadaa9b13edbcd36b595ed38e4df","43":"https:\/\/www.semanticscholar.org\/paper\/d626fe7c303e9baa175649aaff0f365b158ebbbe","44":"https:\/\/www.semanticscholar.org\/paper\/278f7495e50db8b3d01112ba36223e8976f73b60","45":"https:\/\/www.semanticscholar.org\/paper\/07bcda1dff9bb696ea9cbc69303eee8bd3d85bd6","46":"https:\/\/www.semanticscholar.org\/paper\/a33b4a2002161a18bc7eb929566d77fd5178c2e9","47":"https:\/\/www.semanticscholar.org\/paper\/4072a2333682941d23755e9b7e1e3a6d899683c6","48":"https:\/\/www.semanticscholar.org\/paper\/43b184a9912ecb6de0454892c68c82200f77f234","49":"https:\/\/www.semanticscholar.org\/paper\/dc08d90005b12f66a12798fd79959a8f7f8c4885","50":"https:\/\/www.semanticscholar.org\/paper\/0d965ed237a3b4592ecefdb618c29f63adedff76","51":"https:\/\/www.semanticscholar.org\/paper\/f87fd4e849775c8b1b1caa8432ca80f09c383923","52":"https:\/\/www.semanticscholar.org\/paper\/e44b31118bcf73e0bf0065a74aab780ddeca1683","53":"https:\/\/www.semanticscholar.org\/paper\/68e686817f2c33cd09ba3805fa082348f18affd9","54":"https:\/\/www.semanticscholar.org\/paper\/7a6385947507c8187043ced97c87480134543a44","55":"https:\/\/www.semanticscholar.org\/paper\/afc79b2d49fcd87bf87916002566136f5490f821","56":"https:\/\/www.semanticscholar.org\/paper\/e3d3571533e43f42218bceaa8cfda9fdaedb89d0","57":"https:\/\/www.semanticscholar.org\/paper\/046c8a31b33412a3c48758078055661235aff50a","58":"https:\/\/www.semanticscholar.org\/paper\/d0e7b2150915c2f778873155a9b12ed74ab87834","59":"https:\/\/www.semanticscholar.org\/paper\/e24e44515b15e1326dd25ab092a152a067c63fc1","60":"https:\/\/www.semanticscholar.org\/paper\/daa19a47b5de20c7009c8be0b0f31ee1e32e2b38","61":"https:\/\/www.semanticscholar.org\/paper\/a875218fff0e8f00daa39ecdecc1ab52b9335a12","62":"https:\/\/www.semanticscholar.org\/paper\/dbcd4eb004b5dbdf2a22aafb225e9b3b62a4f7f9","63":"https:\/\/www.semanticscholar.org\/paper\/1a575075ba357723009a9a8905d5dccf9115ae6c","64":"https:\/\/www.semanticscholar.org\/paper\/d46cc155e033b09c530061afecebebc77542a0a2","65":"https:\/\/www.semanticscholar.org\/paper\/bbe109dbc96dab47a3fd049065b82115922d7a52","66":"https:\/\/www.semanticscholar.org\/paper\/b4793bc9c098e0f0705523efc06830a85c0c4a43","67":"https:\/\/www.semanticscholar.org\/paper\/055c04900d65bdcacdd0cc98a782e34f9bd7a544","68":"https:\/\/www.semanticscholar.org\/paper\/d68827abb1b848ca39978d04e44ff9bedf04061c","69":"https:\/\/www.semanticscholar.org\/paper\/5cfd70f5cfd8e4742cf8937c2e0cfb7f12f3acfe","70":"https:\/\/www.semanticscholar.org\/paper\/886d79423b7e5a5e20c4d13b0aa3a45851fd9487","71":"https:\/\/www.semanticscholar.org\/paper\/5f11dfa7cd146b456dceed19923f5ed6214fcc44","72":"https:\/\/www.semanticscholar.org\/paper\/06994c2810c2720b302153fc73f8c4459f05fda7","73":"https:\/\/www.semanticscholar.org\/paper\/0a2e38c925f29f8b02a36dbcb3aa6700f7d97852","74":"https:\/\/www.semanticscholar.org\/paper\/267f1de5ff863ab03f8c48c7ac3df1d422de7c3b","75":"https:\/\/www.semanticscholar.org\/paper\/7c4224f253709a0797a956383c884770b65cd5f1","76":"https:\/\/www.semanticscholar.org\/paper\/3e975d1ebc2f5acb4b980c8df8886889e3b7e0da","77":"https:\/\/www.semanticscholar.org\/paper\/a13a180aa995ce2a03d17ea1550813ef4336964b","78":"https:\/\/www.semanticscholar.org\/paper\/a8abe785f46ebdeec6768ab741162830ba66b4ec","79":"https:\/\/www.semanticscholar.org\/paper\/5b489e91cc8ab5735d914895b3df5d54284e91b9","80":"https:\/\/www.semanticscholar.org\/paper\/9b535d6350135af99398b057406d5f0840f4f04c","81":"https:\/\/www.semanticscholar.org\/paper\/02687a71c3b95b4fdb7b1f257b3c3c8346a38eeb","82":"https:\/\/www.semanticscholar.org\/paper\/1fc14493677e2f496c8c871f1542f3271184c6ae","83":"https:\/\/www.semanticscholar.org\/paper\/736bda6fee547a7a95e5127a746e897947e09185","84":"https:\/\/www.semanticscholar.org\/paper\/55db065bfc3394521eefbd3a8502314b7eda8a36","85":"https:\/\/www.semanticscholar.org\/paper\/b8ec7086dbdd6104d06076be7f5a0bba3562a48f","86":"https:\/\/www.semanticscholar.org\/paper\/2a88be4c0aec67911910e921ccfd8e7d783bd6ea","87":"https:\/\/www.semanticscholar.org\/paper\/3334415629c52e57f927fd8d80c4043c647afc78","88":"https:\/\/www.semanticscholar.org\/paper\/b1d383ad8e602391af5b9f6c1c937d9c799469bb","89":"https:\/\/www.semanticscholar.org\/paper\/20e1ddc105f0f145ea7647a9ea4b9c94a8aeab62","90":"https:\/\/www.semanticscholar.org\/paper\/9c14c9288772135f560d274a07723e26189e49bc","91":"https:\/\/www.semanticscholar.org\/paper\/aee6b8c768c3d060bad1c4bb3f1487c8daeda5f9","92":"https:\/\/www.semanticscholar.org\/paper\/fc8df4ad35282ccf19261e02de87d8e35c956537","93":"https:\/\/www.semanticscholar.org\/paper\/245bcbdfff19721c226059a5d5b1ae71b67e0572","94":"https:\/\/www.semanticscholar.org\/paper\/de196985c8284d54ef9db4cbfbbe830d3a028cc2","95":"https:\/\/www.semanticscholar.org\/paper\/16981cc4ddefd3ea7655754fd83a2a8ff2203a8b","96":"https:\/\/www.semanticscholar.org\/paper\/053dacc5d11fca880a550ddd98fdbfb149c129d1","97":"https:\/\/www.semanticscholar.org\/paper\/1be7d9cd613f51c53c3c3b5509e82358a8242677","98":"https:\/\/www.semanticscholar.org\/paper\/67820785cf3c849fce6ba1e401ab3e1c231c7e73","99":"https:\/\/www.semanticscholar.org\/paper\/877be06c2690b8cf9c5f2015cb38a19f5ca39544","100":"https:\/\/www.semanticscholar.org\/paper\/2ea64b7c7617f6cc1768373124ca0243d772a90f","101":"https:\/\/www.semanticscholar.org\/paper\/17f423a5e542a4bd4de0243548e127038dea6ab5","102":"https:\/\/www.semanticscholar.org\/paper\/c3114fe08b35c1f3d7f1eb04dc4803720aba8504","103":"https:\/\/www.semanticscholar.org\/paper\/f696ea202d5f2af57c66b6f9f2783f124399e0dd","104":"https:\/\/www.semanticscholar.org\/paper\/ee51e97d96a2a82e4504a78f57f56462e81e6b3d","105":"https:\/\/www.semanticscholar.org\/paper\/0a414eb148ba7b60fca26eccfd42e3f6913cfbb3","106":"https:\/\/www.semanticscholar.org\/paper\/f1e14322be0a7f32612f42e4e6b13f7de6c5d213","107":"https:\/\/www.semanticscholar.org\/paper\/dd89cb9f9be07459b0e2fb66dcde9a615db103b9","108":"https:\/\/www.semanticscholar.org\/paper\/47c416de8a8ee7082fae08c1d539bce14e576cd5","109":"https:\/\/www.semanticscholar.org\/paper\/822055e65da2dd1ff729f851e1266403745d55ac","110":"https:\/\/www.semanticscholar.org\/paper\/1cf28fa7d015d8dc08a643531d1932b6a063a7eb","111":"https:\/\/www.semanticscholar.org\/paper\/384859a38bb8112ad3d3ef7ccdf21469a869cebf","112":"https:\/\/www.semanticscholar.org\/paper\/62e2a439b5a519a4c50c98077b75a427ea4966dd","113":"https:\/\/www.semanticscholar.org\/paper\/6f26402680b489d3b231c051d1e927aed264f20d","114":"https:\/\/www.semanticscholar.org\/paper\/c842b46f715dae530c368ce97e5419e521f1769f","115":"https:\/\/www.semanticscholar.org\/paper\/434d211269bf82cd743b4f3dbbd3c377d763aa27","116":"https:\/\/www.semanticscholar.org\/paper\/137829c2f0547aab19d6f810d3478f8006ef4696","117":"https:\/\/www.semanticscholar.org\/paper\/e0b2972f6794a0d5959cdd367c51ff755e02d09e","118":"https:\/\/www.semanticscholar.org\/paper\/000064b18bd46acd77adf24ab4482fda6417c2ab","119":"https:\/\/www.semanticscholar.org\/paper\/e981ea39be14db75265251fe4dcbcc698dc534a3","120":"https:\/\/www.semanticscholar.org\/paper\/43b016cd8f426bd8e47838e4918670f72318ec90","121":"https:\/\/www.semanticscholar.org\/paper\/5b825f4260fc2b54f3879f1375c048830b1f164f","122":"https:\/\/www.semanticscholar.org\/paper\/521273a2719eeaca3fa3e58cc37f7769dd0ee120","123":"https:\/\/www.semanticscholar.org\/paper\/a2ce1fb96c0b78bee18bb2cb2c3d55dc48d54cbd","124":"https:\/\/www.semanticscholar.org\/paper\/4418af0d31e5ee653076ce684d68d0d91b345c52","125":"https:\/\/www.semanticscholar.org\/paper\/7074519c8a2d975509345b1301d14e4b8b36fcf0","126":"https:\/\/www.semanticscholar.org\/paper\/d04b8150fcc17015f6d52b8eabdb477b9652865a","127":"https:\/\/www.semanticscholar.org\/paper\/23cc8e927da962f5acc4c0bc5f5e3df42835976e","128":"https:\/\/www.semanticscholar.org\/paper\/1f4adafb2c55ed1029c05dccb68cfaaba8abe629","129":"https:\/\/www.semanticscholar.org\/paper\/50154080ccbaec1a3b4ba401bebd94b80225d21a","130":"https:\/\/www.semanticscholar.org\/paper\/c9762ba3ceeadf067a6c1da233b90a75faa187d5","131":"https:\/\/www.semanticscholar.org\/paper\/69accd35f2ae56aa71ceaa5abeb814fcedc8a58e","132":"https:\/\/www.semanticscholar.org\/paper\/540fe88124ea978dd5344d263d3c03accdd218cd","133":"https:\/\/www.semanticscholar.org\/paper\/004fbcb0f3248afcbc158d97d3b02f0ea42e137a","134":"https:\/\/www.semanticscholar.org\/paper\/f397df630e0708d411e76309b85f56440b853b86","135":"https:\/\/www.semanticscholar.org\/paper\/f05b9b663f1461ef2e20be5d2e8d2116a5a44f94","136":"https:\/\/www.semanticscholar.org\/paper\/dd20fc43fa2a3d32eb85d4520d3c34c7ce4e41b9","137":"https:\/\/www.semanticscholar.org\/paper\/847c38b08c9d596c2fbe15a95b7f5e608a0b9dc1","138":"https:\/\/www.semanticscholar.org\/paper\/9b4988a9ea035e5e67c227ef603d1bb53f8f69ab","139":"https:\/\/www.semanticscholar.org\/paper\/fa2a6af315a319f1ef5a95e8a0152ff88500dba1","140":"https:\/\/www.semanticscholar.org\/paper\/6e4f435f4106956e205e00582fee8cd80b80f626","141":"https:\/\/www.semanticscholar.org\/paper\/51adbb95234875a7021eacd4105b1fd07aaa6242","142":"https:\/\/www.semanticscholar.org\/paper\/b59b9289c5942ca224135a7d8064cd1a320a7400","143":"https:\/\/www.semanticscholar.org\/paper\/ad60516f670b13bf196a5ebf05c529eb78ddd3ca","144":"https:\/\/www.semanticscholar.org\/paper\/220e1a3ec7ed17c8ab8ade6e0d31c3db59aa896e","145":"https:\/\/www.semanticscholar.org\/paper\/d35d1ca234f7775eebf4d063511afcee7b798aae","146":"https:\/\/www.semanticscholar.org\/paper\/b9344e6a12a8e8ffed25bfaea3fd1f20b58ba153","147":"https:\/\/www.semanticscholar.org\/paper\/a6f8fd15058e3386aa02c95f88da7ad9ba7481d1","148":"https:\/\/www.semanticscholar.org\/paper\/3f8781992c33a4d45c1e4cd0b830fab4ae9d083b","149":"https:\/\/www.semanticscholar.org\/paper\/a52ad4f73f690c350c054a2463db9bc5f94e9360","150":"https:\/\/www.semanticscholar.org\/paper\/1465ac9b14117a2a5db5b08d451fd14895890a03","151":"https:\/\/www.semanticscholar.org\/paper\/5bec18a65a5b0d33952897ccb2b7d0a71f558b6d","152":"https:\/\/www.semanticscholar.org\/paper\/090379adc989ce81f5528f30779ccf346315175e","153":"https:\/\/www.semanticscholar.org\/paper\/9246a72d4267a6887f8225e73b9b58a0435d3c4e","154":"https:\/\/www.semanticscholar.org\/paper\/423a23c9f5188a66e630e64f06c6c6dfa3e9d4b9","155":"https:\/\/www.semanticscholar.org\/paper\/61a95df08985d9272ca23d337c3833328e7fa66d","156":"https:\/\/www.semanticscholar.org\/paper\/67565d01e1d517addd49c063a01eb14b9b0dffca","157":"https:\/\/www.semanticscholar.org\/paper\/b4c124ba7638c3effaaf7e61f07689aae1265af9","158":"https:\/\/www.semanticscholar.org\/paper\/ea87e61426b6072b622b11403ac2c18d35b5c0d7","159":"https:\/\/www.semanticscholar.org\/paper\/3dc3c7b4835830a3a372286bc496dded70fba6c1","160":"https:\/\/www.semanticscholar.org\/paper\/50ccfcc9cb9fd5315ffc6a5f0c6516f4f9fc5676","161":"https:\/\/www.semanticscholar.org\/paper\/6bf2e55b403b93f3786463dcf2d726a9a94be080","162":"https:\/\/www.semanticscholar.org\/paper\/ce719054d0a141dca6d1a60376c87e9042e443ec","163":"https:\/\/www.semanticscholar.org\/paper\/edbf580400b3db00f082fdb567bd9d7cf0efefeb","164":"https:\/\/www.semanticscholar.org\/paper\/99f6da372954b1de701cd0e836eac445107088c6","165":"https:\/\/www.semanticscholar.org\/paper\/7dfe02fffefee9d0fdf207054af6f39317bcaabf","166":"https:\/\/www.semanticscholar.org\/paper\/e5a599cf801b97952d5043eafb7d22bebd679e7c","167":"https:\/\/www.semanticscholar.org\/paper\/c4afa2b3eda95a1194313394901e0e96e24cefaa","168":"https:\/\/www.semanticscholar.org\/paper\/c4c96642359f1f96517b5aae8c13b42c0e25b996","169":"https:\/\/www.semanticscholar.org\/paper\/8b2cbb2f101b025c16e12d0d7628f65e5378e10d","170":"https:\/\/www.semanticscholar.org\/paper\/ebd5b2d28a6ec478d0f0eb2de194f694ff1c5232","171":"https:\/\/www.semanticscholar.org\/paper\/634cc3a29b4818ace36c955b3995ce8c13dffb85","172":"https:\/\/www.semanticscholar.org\/paper\/29ed5ab47631800c922f42ef1ff5165a1df56fc8","173":"https:\/\/www.semanticscholar.org\/paper\/3feacdc2cc1fd01fe533a150211dd4423433b133","174":"https:\/\/www.semanticscholar.org\/paper\/cff4d87fcd98c65b352e9dabe1e6f444d99e6aad","175":"https:\/\/www.semanticscholar.org\/paper\/60f016adc29f6f2e9b29031c9c2e8cbea00774d6","176":"https:\/\/www.semanticscholar.org\/paper\/4c4718539d1696954520aa3c43fdcd597558e815","177":"https:\/\/www.semanticscholar.org\/paper\/825eeae79a97825b69a4516a05e5a8975422609a","178":"https:\/\/www.semanticscholar.org\/paper\/c7222838952ec619b17952a7b061f77fdb8d486c","179":"https:\/\/www.semanticscholar.org\/paper\/e3e9d2bdcc3fefab7c294196c8b2e149727376ed","180":"https:\/\/www.semanticscholar.org\/paper\/ad9d93406f3cf3ffe5a640cb4d742f202339a511","181":"https:\/\/www.semanticscholar.org\/paper\/0ebf5a0208ec2d930673e5e852cab44f9e1c8811","182":"https:\/\/www.semanticscholar.org\/paper\/ae7d31774c81d955c8185402dd400a9594973f65","183":"https:\/\/www.semanticscholar.org\/paper\/b58abb51a5dae7fb753be4535e468a6f1f07f873","184":"https:\/\/www.semanticscholar.org\/paper\/73623dbc70ea2713e8e70c2b85f90ce48164a5ba","185":"https:\/\/www.semanticscholar.org\/paper\/337d7199c4edc4c8558043a51ef0712beaa3e137","186":"https:\/\/www.semanticscholar.org\/paper\/7ebe65c7ff53bfd1d1911259c988a6a615fb51d1","187":"https:\/\/www.semanticscholar.org\/paper\/ad9d1b39adee847a8be67aa1eed9a52e0242a34b","188":"https:\/\/www.semanticscholar.org\/paper\/426a5caf4b676db6e077fe79ec433efee45a0a60","189":"https:\/\/www.semanticscholar.org\/paper\/365bc3a263ea6447c6d041a324912c3420ca235b","190":"https:\/\/www.semanticscholar.org\/paper\/b16314c914d7b52262100c58e03a93eb724bf671","191":"https:\/\/www.semanticscholar.org\/paper\/c1d21cd3a58a8ee74fde2d4da35133c9e5f9035d","192":"https:\/\/www.semanticscholar.org\/paper\/d402bfeeee71b68a24d651f88b88d10cb8b7aaae","193":"https:\/\/www.semanticscholar.org\/paper\/10414a2f2f00028f2c725c3461b00c3a2ec98951","194":"https:\/\/www.semanticscholar.org\/paper\/a3da5fa82d316513ade2dc355ee058af58487751","195":"https:\/\/www.semanticscholar.org\/paper\/9eb4cd1a4b4717c97c47e3dc4563a75779ae9390","196":"https:\/\/www.semanticscholar.org\/paper\/fe976fcc6c6d6b47ce3c1f53f03f1a9318235f0b","197":"https:\/\/www.semanticscholar.org\/paper\/081bd8662cd8f7b3d67fbe4bea49b3da31edbfc7","198":"https:\/\/www.semanticscholar.org\/paper\/a6af5e3766e510fb67fc4632b34bb9ef702ebdb1","199":"https:\/\/www.semanticscholar.org\/paper\/13b48b0f190cde85e55341e49d8a40edacf41b87","200":"https:\/\/www.semanticscholar.org\/paper\/9817392064d6a340531d56b9e512fae993052bf0","201":"https:\/\/www.semanticscholar.org\/paper\/d2803635b4ab094f230481c74e7d680f333e1d14","202":"https:\/\/www.semanticscholar.org\/paper\/cd3d457c594bd52f6824b8f41fa62ce2f8aba2dc","203":"https:\/\/www.semanticscholar.org\/paper\/9b92723cf1b6ed2d096208ef3751ded0e9433a85","204":"https:\/\/www.semanticscholar.org\/paper\/e44616baa06dd24388d629ede70b06b2e79d3906","205":"https:\/\/www.semanticscholar.org\/paper\/82fd1d147e7d524d65196ea0ec2c041f5cc41927","206":"https:\/\/www.semanticscholar.org\/paper\/379132b019b02841acfaab31eb17c64b7b8ae6ea","207":"https:\/\/www.semanticscholar.org\/paper\/f0891d9af5c17237321e79930fd7256185a0b0c9","208":"https:\/\/www.semanticscholar.org\/paper\/de2bc64c653cef1a41675ddae38ce173e0871a50","209":"https:\/\/www.semanticscholar.org\/paper\/7b589eb32d2cc857f85c413f4039ca9a5b834707","210":"https:\/\/www.semanticscholar.org\/paper\/d618752d2e666d7b25f1bd6c7c3bd7c056e19d96","211":"https:\/\/www.semanticscholar.org\/paper\/d4ae9dff186553d98eef4a275762b4cb15e1e41d","212":"https:\/\/www.semanticscholar.org\/paper\/eef4df3a5232c7ce70123aaebb326ff9169a3c8c","213":"https:\/\/www.semanticscholar.org\/paper\/1d0612edb7e52c01611e0f7c898655bdb1262966","214":"https:\/\/www.semanticscholar.org\/paper\/371c799bde8b162e7f8fa2b2a0a8cfb29765f89f","215":"https:\/\/www.semanticscholar.org\/paper\/86be6c7ba5ca77a668e5d6ab342445b72ca24208","216":"https:\/\/www.semanticscholar.org\/paper\/c2eff53cc9db9eaca8d9ffe06f2d618b0e360c9d","217":"https:\/\/www.semanticscholar.org\/paper\/ed0e117152196693a42fd845740ca08ae1d5ef8a","218":"https:\/\/www.semanticscholar.org\/paper\/90b115737efb108a39e6134035b33b26941cc85f","219":"https:\/\/www.semanticscholar.org\/paper\/b72ccdf9072dd3358c44550ed0c52bd8eeed6ef0","220":"https:\/\/www.semanticscholar.org\/paper\/a0c0af7c0e1f14aa39b72a52d98dc058ea80df6a","221":"https:\/\/www.semanticscholar.org\/paper\/09fba948316e04f0e1641926948b67b0799c8e0d","222":"https:\/\/www.semanticscholar.org\/paper\/2b43db82f61a80f375a24564205814c7fc8fb368","223":"https:\/\/www.semanticscholar.org\/paper\/df157cb42b574c3f46b269504c18375bfa5bc5b1","224":"https:\/\/www.semanticscholar.org\/paper\/0fc05ff99b3de969261f4294e17fcd6ccffa19f4","225":"https:\/\/www.semanticscholar.org\/paper\/513892f6232f56b6ab35688b8aa59534cc81a928","226":"https:\/\/www.semanticscholar.org\/paper\/4e258110246003b6d47015c8de12a754eda31c3b","227":"https:\/\/www.semanticscholar.org\/paper\/14d35b1cc3db2304b795a7dd33e464aa6bb87581","228":"https:\/\/www.semanticscholar.org\/paper\/85ae9dbe1be0ef86d5f1985607c1e9de0547afc2","229":"https:\/\/www.semanticscholar.org\/paper\/d82038498cae2dbe60017544d4cfd326a1abcfe6","230":"https:\/\/www.semanticscholar.org\/paper\/4d7df81767737c81890411c7f1685bb232921cb7","231":"https:\/\/www.semanticscholar.org\/paper\/9b090ead7797e67c7cc79cf1144a1113a579bf9d","232":"https:\/\/www.semanticscholar.org\/paper\/92ba9c2588f2e9d9e1379a187c9b0adfcfe025a6","233":"https:\/\/www.semanticscholar.org\/paper\/c2ecc9073672a8d8bf21fe442dbf3f76356858ee","234":"https:\/\/www.semanticscholar.org\/paper\/6e358392f48bf4bd7c43e2bbe45832fcb684640b","235":"https:\/\/www.semanticscholar.org\/paper\/5daad753c9e154d4f328220437f8d7ebf9e2c1b9","236":"https:\/\/www.semanticscholar.org\/paper\/9fc8ededf4f46f19874b36a6aed48e8e54cfcfed","237":"https:\/\/www.semanticscholar.org\/paper\/4bf40263e1c7e3766d9b3ed334edee2fcfb0b14c","238":"https:\/\/www.semanticscholar.org\/paper\/01a75a8aa2a5c0df3a996affb03f3b8ff336c6df","239":"https:\/\/www.semanticscholar.org\/paper\/72ff295b03e0e223b59697eef967e6ce0d1f7618","240":"https:\/\/www.semanticscholar.org\/paper\/3e3eb188860292fc8d700236cdb076a4b2fe878a","241":"https:\/\/www.semanticscholar.org\/paper\/acf8a1040034820bf99379a3422815f4e0859ec9","242":"https:\/\/www.semanticscholar.org\/paper\/36d7998ec3e462e3907c6d3c1d13984234f7e8cc","243":"https:\/\/www.semanticscholar.org\/paper\/f7f36acdc79bd57fffe337c2baccb6e39b5be9f2","244":"https:\/\/www.semanticscholar.org\/paper\/25936b2fc79ca12aa35a759cbe866f13ab1e2a20","245":"https:\/\/www.semanticscholar.org\/paper\/4543a8564c58550a5e6ab4b6d89045c800a44aa0","246":"https:\/\/www.semanticscholar.org\/paper\/8eb6b7e4ddf3dd5f7cefd44350c58be696ecb6f5","247":"https:\/\/www.semanticscholar.org\/paper\/b8601c86905b0184b9387b042400609febb93d10","248":"https:\/\/www.semanticscholar.org\/paper\/5d22b241836e30d5b0d852b463951ab7e3245ea4","249":"https:\/\/www.semanticscholar.org\/paper\/f341da48986fd5d253bc6bee559e31f25c136c03","250":"https:\/\/www.semanticscholar.org\/paper\/11de73205f632acb422de5cadae7ed4571595bf5","251":"https:\/\/www.semanticscholar.org\/paper\/a17e342264d7531f23116cc5cb300f0480a1c816","252":"https:\/\/www.semanticscholar.org\/paper\/035a7a7cc24d1aee1865bb07eae0ba6520f65a66","253":"https:\/\/www.semanticscholar.org\/paper\/380c35590e2c112e620863689f481122d19e5f19","254":"https:\/\/www.semanticscholar.org\/paper\/060985340191174d6b041f59bed18104b3d66018","255":"https:\/\/www.semanticscholar.org\/paper\/dd2d81e91b051dba756df2fafb79dcb4aac7d057","256":"https:\/\/www.semanticscholar.org\/paper\/af4082b90c5d71bb1f27b6ae2d197feca4d4778a","257":"https:\/\/www.semanticscholar.org\/paper\/d77123b54dcc8014949584ab624e97298617bcad","258":"https:\/\/www.semanticscholar.org\/paper\/8948d2e7ef2cfd5cd9995eca4aaece7da67b31b4","259":"https:\/\/www.semanticscholar.org\/paper\/b4127311564e121dd991be80881641142c35a944","260":"https:\/\/www.semanticscholar.org\/paper\/0eeaf72692be70cb1afea945dcd43340b99772a3","261":"https:\/\/www.semanticscholar.org\/paper\/3447feb86edcb747e6ecd8cc2d8dd639c2fcc9e4","262":"https:\/\/www.semanticscholar.org\/paper\/4949b9f93789bd480f4c7099f409860c99cdacb5","263":"https:\/\/www.semanticscholar.org\/paper\/47f7ec3d0a5e6e83b6768ece35206a94dc81919c","264":"https:\/\/www.semanticscholar.org\/paper\/177e957f5cd93229c9794ea652c646d2557b4a69","265":"https:\/\/www.semanticscholar.org\/paper\/03db529f0bfae6d0b64b0feef565196327fe8d50","266":"https:\/\/www.semanticscholar.org\/paper\/6bae464ccb62a3bbbc972e036ddade42d1fd7a60","267":"https:\/\/www.semanticscholar.org\/paper\/ae9bf201f128cabaa4350b54ff6607525c736cd5","268":"https:\/\/www.semanticscholar.org\/paper\/49e65b12d8d11f2ccb5ddd7be72a8f746b2d1bc2","269":"https:\/\/www.semanticscholar.org\/paper\/ea9a516d5cb0b298f0df50e82b3e0400b72fcdff","270":"https:\/\/www.semanticscholar.org\/paper\/fa3d0599f8a082add349b5b09a208136489dae34","271":"https:\/\/www.semanticscholar.org\/paper\/32502aa3d32e7c495e39409e8f1565b5968f245c","272":"https:\/\/www.semanticscholar.org\/paper\/08066c80919620397e8e4e5372ff84caf401e675","273":"https:\/\/www.semanticscholar.org\/paper\/e47e6c814d2742527fdd352db13a5fd95b7ce24b","274":"https:\/\/www.semanticscholar.org\/paper\/bc69db360d720ebefdbb66dc02409142505e5212","275":"https:\/\/www.semanticscholar.org\/paper\/6191a5122d67dfbab421bc89540d264822dd8173","276":"https:\/\/www.semanticscholar.org\/paper\/d5513ae4aee1f0b27dc260585ec05211f1dce274","277":"https:\/\/www.semanticscholar.org\/paper\/974ffaf2775a8c32e405c551436a111714a5dc3c","278":"https:\/\/www.semanticscholar.org\/paper\/289fdb45f5076457e5739db57ab7d2004d7cbfa4","279":"https:\/\/www.semanticscholar.org\/paper\/9b9ac0169a8d7c4325fbdf0a1660d1b2ad17a80e","280":"https:\/\/www.semanticscholar.org\/paper\/16a2a1bf612f9f9719a7945485f7e73324d18783","281":"https:\/\/www.semanticscholar.org\/paper\/dd93a358c7e441855ba7fd46872099da6dc23b5a","282":"https:\/\/www.semanticscholar.org\/paper\/130373cc752e2c51a6cf14c6d1b2e5f7d9006987","283":"https:\/\/www.semanticscholar.org\/paper\/b5fcd192bb6a714433eab1b56bf968fae0f98979","284":"https:\/\/www.semanticscholar.org\/paper\/f5c25a0f61005bf18953249cd3e08094b69a5d98","285":"https:\/\/www.semanticscholar.org\/paper\/4f416b19d6c6d9fe42b6ced7af34627894627757","286":"https:\/\/www.semanticscholar.org\/paper\/36ec104c405b17b41ad6d9998572d3d757a5d331","287":"https:\/\/www.semanticscholar.org\/paper\/331a5bbc64d624fe45f85d5d0113cb0af00ec429","288":"https:\/\/www.semanticscholar.org\/paper\/10569a326b860e87f6ebb7bf569af9ea59cc252a","289":"https:\/\/www.semanticscholar.org\/paper\/1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1","290":"https:\/\/www.semanticscholar.org\/paper\/56d1003fd02346e93354ab55cd204485c268512a","291":"https:\/\/www.semanticscholar.org\/paper\/c122fa378a774ba202d418cf71c5c356cf2f902f","292":"https:\/\/www.semanticscholar.org\/paper\/3c54b796cc10cb530f77caa4d18e1c80ac863822","293":"https:\/\/www.semanticscholar.org\/paper\/754cb424e0f9cdcbe4be2e683d503a7e82130f75","294":"https:\/\/www.semanticscholar.org\/paper\/22ec1b3a190deef662a822ade2dc2f273b3ac208","295":"https:\/\/www.semanticscholar.org\/paper\/734647b1582bd01501cfb35b49aae1c1bb268932","296":"https:\/\/www.semanticscholar.org\/paper\/a15421b034d3c75043190bbe4de28540f403f99c","297":"https:\/\/www.semanticscholar.org\/paper\/53d0569d1aeba0701e2cf5e831bac151c82317e6","298":"https:\/\/www.semanticscholar.org\/paper\/12a562148ce22687c6544b054ae292434f9d50ee","299":"https:\/\/www.semanticscholar.org\/paper\/6c17c2cd03dcea90ff33418e9d2a80ddad600922","300":"https:\/\/www.semanticscholar.org\/paper\/c8922345e2aaf4e4a88cf2c2e91b8545ef54c6d2","301":"https:\/\/www.semanticscholar.org\/paper\/37864082f80fa5879d947cd294cec63e866ed581","302":"https:\/\/www.semanticscholar.org\/paper\/40e9deebb5f73a9bf907f0ca72d4524e952be854","303":"https:\/\/www.semanticscholar.org\/paper\/a6a08b716dd4decfb103435b44e76927fb73205a","304":"https:\/\/www.semanticscholar.org\/paper\/dfb92b8424c5e0f912f240b3bb9c746fe19e891e","305":"https:\/\/www.semanticscholar.org\/paper\/2f01034cf72fd91a5fa7a791100e273df89b7259","306":"https:\/\/www.semanticscholar.org\/paper\/1986be3bd1c14748fa7390ec87142d91ce4a6b05","307":"https:\/\/www.semanticscholar.org\/paper\/c722eb5cb5029dec57c471cfd9677e62d12c28b1","308":"https:\/\/www.semanticscholar.org\/paper\/732f76b0a2aa5d255d60cb6e29257d9fb292a6f4","309":"https:\/\/www.semanticscholar.org\/paper\/6dc68719e77f70e2e42fbbf35e9ca003dc939b42","310":"https:\/\/www.semanticscholar.org\/paper\/3b1ff258503d522807a63d390d5438314db04e8c","311":"https:\/\/www.semanticscholar.org\/paper\/9d33cc86a2059569ce990e8f715a7bf6b15c6dbf","312":"https:\/\/www.semanticscholar.org\/paper\/52de3b694153c980c8ae26e5132425ed0e1b41cf","313":"https:\/\/www.semanticscholar.org\/paper\/03936b36d2c8874fa56e70907d2df1fd85b038fa","314":"https:\/\/www.semanticscholar.org\/paper\/4b23d64e4964367ac9eec982f12035bf8baa85b8","315":"https:\/\/www.semanticscholar.org\/paper\/d7f2a424056b43718b25aa9dc1074923bd258be6","316":"https:\/\/www.semanticscholar.org\/paper\/2330f83d7521a92aacd70d448494dcfcf93f05bc","317":"https:\/\/www.semanticscholar.org\/paper\/4e92152bf0ad51e6b5e8754403f956aa2ba3e219","318":"https:\/\/www.semanticscholar.org\/paper\/e165faf18da54e5e1d6ded5665448ed91f792743","319":"https:\/\/www.semanticscholar.org\/paper\/1e8576a640352c9f3b1976a648b2c668eae7d3de","320":"https:\/\/www.semanticscholar.org\/paper\/4075ee946fbc9730e679e6c949b9de441f3c38e1","321":"https:\/\/www.semanticscholar.org\/paper\/2b71dc2cd458aa61f90d3a9f592db05a04d4b8ba","322":"https:\/\/www.semanticscholar.org\/paper\/1b8de5b0a1c9b3dc4c5a4e09b5b3f86283b4a375","323":"https:\/\/www.semanticscholar.org\/paper\/9f54586a6664e541c6b980e1ac8565b504a729bf","324":"https:\/\/www.semanticscholar.org\/paper\/22c742aad1210ad8f298f81de7edf41dc9814fca","325":"https:\/\/www.semanticscholar.org\/paper\/f43fa2e1f2bb4822160fa9c90be8902f359faa9c","326":"https:\/\/www.semanticscholar.org\/paper\/17be21b89ea8ac02273212badac6654f5b7ccf79","327":"https:\/\/www.semanticscholar.org\/paper\/33d77b39a6046526595b39dd372dac1db03de661","328":"https:\/\/www.semanticscholar.org\/paper\/b56f05ecdba31fa3a70c36c74a7e397fa573ef1b","329":"https:\/\/www.semanticscholar.org\/paper\/8994bce4b85a8b4087584661c49f8776f868f7dd","330":"https:\/\/www.semanticscholar.org\/paper\/d410c1507a86054a017154ad4d81cf8233ca9cd4","331":"https:\/\/www.semanticscholar.org\/paper\/8755c15fe073c6af03664b2a74aafef1fed5f198","332":"https:\/\/www.semanticscholar.org\/paper\/4fd961ec9a6af0c0d15e0a85471d0ff596342ac5","333":"https:\/\/www.semanticscholar.org\/paper\/c92ccde8efe40d1696dc7acdadaddc923c9d945d","334":"https:\/\/www.semanticscholar.org\/paper\/08db45d0e427cdde77cc16307a4d13bcb1cd3d55","335":"https:\/\/www.semanticscholar.org\/paper\/2adadfdff4d38484df7624e17a93c814864264fa","336":"https:\/\/www.semanticscholar.org\/paper\/458533b6fcf1944b6dcebb904a03215795db2ba8","337":"https:\/\/www.semanticscholar.org\/paper\/826383e18568c9c37b5fc5dd7e2913352db22b47","338":"https:\/\/www.semanticscholar.org\/paper\/b430a5384c82beb6102106fbea0a134425a08c23","339":"https:\/\/www.semanticscholar.org\/paper\/44e02e57b186dfef713b24beb44727d4b1048fe8","340":"https:\/\/www.semanticscholar.org\/paper\/7c81bd211b5df56094ee3bbf2929bb7feade753e","341":"https:\/\/www.semanticscholar.org\/paper\/6c8c9dc8da6a91531821a8687ada84ac3f1781bf","342":"https:\/\/www.semanticscholar.org\/paper\/9b3f7cf0550833208ee4dffaf45549b19dcfa867","343":"https:\/\/www.semanticscholar.org\/paper\/73395837a22eb00ce4106be3653460377bed7725","344":"https:\/\/www.semanticscholar.org\/paper\/a6721a2fd36f1d6432024a15385a26309379b078","345":"https:\/\/www.semanticscholar.org\/paper\/e3c4c9ac216a3bd8dfcee6e3f780975cb2fdf36b","346":"https:\/\/www.semanticscholar.org\/paper\/9007daf4171590d09672b563212f4bfacd785c7e","347":"https:\/\/www.semanticscholar.org\/paper\/bbe6639f3b89ab5b72d77ca268fb709a98410b44","348":"https:\/\/www.semanticscholar.org\/paper\/bbb9f5378eac3eb8245cbd0f998a95cef2954508","349":"https:\/\/www.semanticscholar.org\/paper\/86724befacdd9fd8748607f5b025aa59fb7ef010","350":"https:\/\/www.semanticscholar.org\/paper\/4d2af4f30df721caf857d66b8db521482f8c0606","351":"https:\/\/www.semanticscholar.org\/paper\/d4aa625b2ea90b3b884886cc80f995b8e766d1ee","352":"https:\/\/www.semanticscholar.org\/paper\/36e0edff4c7972853d12e4c20436e077397a8551","353":"https:\/\/www.semanticscholar.org\/paper\/874b18b8d8554ae5890f44d728315fcebc6faf02","354":"https:\/\/www.semanticscholar.org\/paper\/1e0eeb8cb3a0dca331e40f21c74eb619cde66183","355":"https:\/\/www.semanticscholar.org\/paper\/3e53f94215998a91b1f8124914cb6cd15f2a03c9","356":"https:\/\/www.semanticscholar.org\/paper\/c1dfb3db7a952a9cf7454967319bac3bf7b4bb5c","357":"https:\/\/www.semanticscholar.org\/paper\/cb66cbcab02f08a2492e0f53983cdd3ec06618f3","358":"https:\/\/www.semanticscholar.org\/paper\/a14bb8f09fac4c0e8e5acc53e43b5986cdf6998d","359":"https:\/\/www.semanticscholar.org\/paper\/5661835ded4431433206af57d80d13c567e3e555","360":"https:\/\/www.semanticscholar.org\/paper\/0c6caa6d9643dbeb39ed3bdd4b67153d51292e81","361":"https:\/\/www.semanticscholar.org\/paper\/589490604f143ee347b628a6d496eceb092bc5fa","362":"https:\/\/www.semanticscholar.org\/paper\/6a1d361136da6983b5335ad74274d0e2d0b6fa67","363":"https:\/\/www.semanticscholar.org\/paper\/8d1a392200066bc7ef2ac1c78ecea6d2d5ac630d","364":"https:\/\/www.semanticscholar.org\/paper\/7ab9d8246c2abac232e7904e98db6e6c95402851","365":"https:\/\/www.semanticscholar.org\/paper\/1161e9556092cf9bf2923e0b15d03b01be1ce929","366":"https:\/\/www.semanticscholar.org\/paper\/389b9d9f88c262fa65800318cf029aca1b37eb1f","367":"https:\/\/www.semanticscholar.org\/paper\/46b2e31094041d6f76fa9dd78121fb66a7e6b222","368":"https:\/\/www.semanticscholar.org\/paper\/33d2f8efd905eef4c76f6f72fec6f7e2a14be7d5","369":"https:\/\/www.semanticscholar.org\/paper\/d64192da0b6d43c91c902105c089b18b76f9fe77","370":"https:\/\/www.semanticscholar.org\/paper\/e54cb48aac19d8c7714fdc1af4c328dca49bb7f3","371":"https:\/\/www.semanticscholar.org\/paper\/18b5ce6a05295de48df6138fc412f27cc2cd78cf","372":"https:\/\/www.semanticscholar.org\/paper\/bbeed471a946eac19aeced258067f1534e1f1783","373":"https:\/\/www.semanticscholar.org\/paper\/f6282d4bbd942f7f08ceb549cb4ee647a22aaa50","374":"https:\/\/www.semanticscholar.org\/paper\/bec0e7ee888b9abaf8653777d71c9ad78f4c3027","375":"https:\/\/www.semanticscholar.org\/paper\/73c9d413f275a1520aedf4649be817e1a228cedd","376":"https:\/\/www.semanticscholar.org\/paper\/547311799835f6e5eaed4e07b39fb344c2542e66","377":"https:\/\/www.semanticscholar.org\/paper\/bf7757a4c88109c18265f53dc21786fa29178b27","378":"https:\/\/www.semanticscholar.org\/paper\/18bca3a5f684ad0f7a31b9845757e395bcad4052","379":"https:\/\/www.semanticscholar.org\/paper\/b029346bfa85fa2fc7a12498ae5f018922ce55f9","380":"https:\/\/www.semanticscholar.org\/paper\/0be8b1a085abbd83d49960437634104ff7d3d209","381":"https:\/\/www.semanticscholar.org\/paper\/f1acf5b35888c4dd90f1c949dfd103e3a7a342a7","382":"https:\/\/www.semanticscholar.org\/paper\/ccb2a2f0f63f59f4092e161cbfb62bf73e30c296","383":"https:\/\/www.semanticscholar.org\/paper\/a194297f3703bae8040ddfd0c08a60cdcaea2aeb","384":"https:\/\/www.semanticscholar.org\/paper\/422ff5da34fa241269ef7b3b56254030daa0b45a","385":"https:\/\/www.semanticscholar.org\/paper\/461420c80d3bdc156e5db7af13264a955a6a2010","386":"https:\/\/www.semanticscholar.org\/paper\/d8530a37603e0dbcbfdf49d2726fd8dbfe7c47e8","387":"https:\/\/www.semanticscholar.org\/paper\/2d22b0b3339b302d25f5d683950459d2fdfc34bd","388":"https:\/\/www.semanticscholar.org\/paper\/a2412fdebd53bd25476f834ae2b8aa8cb44cb1e1","389":"https:\/\/www.semanticscholar.org\/paper\/e02c114d6269f4781b0fa92f4e2c9376e7462906","390":"https:\/\/www.semanticscholar.org\/paper\/0090023afc66cd2741568599057f4e82b566137c","391":"https:\/\/www.semanticscholar.org\/paper\/4e20cb972bbb43bc7bcabb2f2c9fdf980a9445d2","392":"https:\/\/www.semanticscholar.org\/paper\/8963317176fa81e185fd7a8f8cd001d7e11a4868","393":"https:\/\/www.semanticscholar.org\/paper\/0e3384f5f301e5fb9a2eedd366763f076c41acff","394":"https:\/\/www.semanticscholar.org\/paper\/76733a6699ff63aab75ff87db7bef5665fa9ca1c","395":"https:\/\/www.semanticscholar.org\/paper\/825a609040ed9eb66a79c3efb51e2efbaa03fd78","396":"https:\/\/www.semanticscholar.org\/paper\/bf73676a952052453075f9db6034dd81a9c63561","397":"https:\/\/www.semanticscholar.org\/paper\/7f4db0ba14319eab5ccda83c331ef6e491b4e38f","398":"https:\/\/www.semanticscholar.org\/paper\/dcfbdcf6bd3e6bb4101cc3f8eb1ca122db1eab61","399":"https:\/\/www.semanticscholar.org\/paper\/7049da930167f40ab631187707de705feb8b1b93","400":"https:\/\/www.semanticscholar.org\/paper\/0a0019691463eea92a54df9631754efe2839319f","401":"https:\/\/www.semanticscholar.org\/paper\/02326a950eb469b9eb3cad70df05efd87ba6b07f","402":"https:\/\/www.semanticscholar.org\/paper\/4aab9b7a3486e73fd05bcac83d63a98e5243377b","403":"https:\/\/www.semanticscholar.org\/paper\/4e520a1cc111870c5b0bf0a3580bee2051b16062","404":"https:\/\/www.semanticscholar.org\/paper\/6a3cc30d5d6342d912851deb4362b8c47fa5ede3","405":"https:\/\/www.semanticscholar.org\/paper\/bb96dc3ce7c2196446c72e6d8c151abe578ee216","406":"https:\/\/www.semanticscholar.org\/paper\/ba783d92d0eaf6a7bff6ced7660150ce38016bbc","407":"https:\/\/www.semanticscholar.org\/paper\/3f9e4c99346d231ada37ada243bdbcb58c47387d","408":"https:\/\/www.semanticscholar.org\/paper\/581ba155f617dc99d27d3043400994bcf0640c78","409":"https:\/\/www.semanticscholar.org\/paper\/ce6945d32780c599d829c1995dfc1555ab33bdd1","410":"https:\/\/www.semanticscholar.org\/paper\/e5b60f6dc59073cc52523876f69a48adf480fd54","411":"https:\/\/www.semanticscholar.org\/paper\/b1d344488c54887fef5b590ad6e9928f9322d175","412":"https:\/\/www.semanticscholar.org\/paper\/7e59497190df5504852b90596b6ffa757e8a09c7","413":"https:\/\/www.semanticscholar.org\/paper\/b6148e42f1ab386bf3607e8fa291c398bf1f5204","414":"https:\/\/www.semanticscholar.org\/paper\/2500516ea6909f42e56a2520c7568c5f97b850fa","415":"https:\/\/www.semanticscholar.org\/paper\/3a3f07b74f556df8ec6cd1118043c30057a4e710","416":"https:\/\/www.semanticscholar.org\/paper\/322b44b346f921158e3ec64199e32f61adc4ea14","417":"https:\/\/www.semanticscholar.org\/paper\/ad774ebe0ad25baeab8bc47f3ab7a7abcc779898","418":"https:\/\/www.semanticscholar.org\/paper\/00569f007647ca81326750d191b2be1f4c7c946f","419":"https:\/\/www.semanticscholar.org\/paper\/7bcc043ad0a388c023fdb3227c71b6a672efc108","420":"https:\/\/www.semanticscholar.org\/paper\/6ae13ff2b6ea986dae80a0db3e3d6a284eb8b050","421":"https:\/\/www.semanticscholar.org\/paper\/8ae88a7131c61f65d4eb62787455b2b66a2247f6","422":"https:\/\/www.semanticscholar.org\/paper\/203381852858d7d8939e9da6e0e55a65fc96b0e4","423":"https:\/\/www.semanticscholar.org\/paper\/9bd0259da1e65a0d16561672277a2524b9a481e1","424":"https:\/\/www.semanticscholar.org\/paper\/1673c92875480c20951523df9731c90fc8319ad6","425":"https:\/\/www.semanticscholar.org\/paper\/1fefecf4d5174910b46d9497a7dae3cc70e4ba69","426":"https:\/\/www.semanticscholar.org\/paper\/0e0371817a2988ec1a4535934bb6251c5936dfd4","427":"https:\/\/www.semanticscholar.org\/paper\/0171661833b7d245582e1db7045c18d34c363421","428":"https:\/\/www.semanticscholar.org\/paper\/d636444a03000b93795d4a3e25fd1b1d37e17692","429":"https:\/\/www.semanticscholar.org\/paper\/25ba294cc30534579ae06aaab5f27bc6f83d5b42","430":"https:\/\/www.semanticscholar.org\/paper\/2b9a2888c9b20c3097c0b64c99254d4dae02514f","431":"https:\/\/www.semanticscholar.org\/paper\/425b1d26148558a36046d0d2cbe39e497520cd80","432":"https:\/\/www.semanticscholar.org\/paper\/93b0383c0906e54e9da706c8fc9aadb728a12f7a","433":"https:\/\/www.semanticscholar.org\/paper\/81af8dfaa3ecd2c970f5642ce547d6fd57c702d2","434":"https:\/\/www.semanticscholar.org\/paper\/bbd7a55c6e88ab71dd5c15ce952bfd2c46ca6c1f","435":"https:\/\/www.semanticscholar.org\/paper\/c548083e0764ddf04c35c8e4064da5171206428b","436":"https:\/\/www.semanticscholar.org\/paper\/98c562deff4a45afccbeb6081d7ad0a2c9a46c09","437":"https:\/\/www.semanticscholar.org\/paper\/090d2219fcc9137eb707f6380cfda8d425980d5b","438":"https:\/\/www.semanticscholar.org\/paper\/fb65e9d96e9f008a95994e688921cc91a4ea2d30","439":"https:\/\/www.semanticscholar.org\/paper\/0e37360430939764c009ec738439a1e5b4d8ad07","440":"https:\/\/www.semanticscholar.org\/paper\/155284d48fcac8243346b1698e6da17fa02532fa","441":"https:\/\/www.semanticscholar.org\/paper\/cc72ff48242b1b06fb52e17e2009144adbd3e992","442":"https:\/\/www.semanticscholar.org\/paper\/ba2bf60cee6aa0fec354803d073ed4cbfa4ee997","443":"https:\/\/www.semanticscholar.org\/paper\/2e1602c17383959d1b3d5aa65dbf6c5a7ff18ec8","444":"https:\/\/www.semanticscholar.org\/paper\/da31394e39bcdec42c02287702fbce0c00d94d6e","445":"https:\/\/www.semanticscholar.org\/paper\/4f628abdb2c2c32db950d5a16f74aed1779b5d9d","446":"https:\/\/www.semanticscholar.org\/paper\/70d208b0a52f32a7c0bb7715f717e0b19ef57085","447":"https:\/\/www.semanticscholar.org\/paper\/ed6cc6ebcb6646ef173951b4e6cb6d2a13996396","448":"https:\/\/www.semanticscholar.org\/paper\/a08599dcd02e6afc8c05e2310416d675ccd33597","449":"https:\/\/www.semanticscholar.org\/paper\/00956e6fe5700cda5bc930c1ef8b982d42ca26cf","450":"https:\/\/www.semanticscholar.org\/paper\/d274812705171203f1e8d0a767bec330d212a8f2","451":"https:\/\/www.semanticscholar.org\/paper\/65b18bc693536f124282e1585f28700ef3fd3295","452":"https:\/\/www.semanticscholar.org\/paper\/6fe6221c5aa6cdcf1613ee4d41ac20d7676357e9","453":"https:\/\/www.semanticscholar.org\/paper\/6580afff031fa614b8374b15d0585215dbec1e62","454":"https:\/\/www.semanticscholar.org\/paper\/9cd06ab2c446f4c23ed37cebef78bd534184acdd","455":"https:\/\/www.semanticscholar.org\/paper\/d6a69512cd242e32872b8c76dacb0af4a9b8b2d1","456":"https:\/\/www.semanticscholar.org\/paper\/1d513ee94daa2569b517d664b9333aa8b07b8a51","457":"https:\/\/www.semanticscholar.org\/paper\/2645244644c65d85931451ab12f2eb5564de2291","458":"https:\/\/www.semanticscholar.org\/paper\/2029444fa98d7d1a7f621dfe81330e9a7c5d2726","459":"https:\/\/www.semanticscholar.org\/paper\/84729df1775316bc38c66f423e53a63a3b81fe5d","460":"https:\/\/www.semanticscholar.org\/paper\/1442f135814c31f413128277a55762c6822eb546","461":"https:\/\/www.semanticscholar.org\/paper\/3e5a0b24e2066017ef6069a62ddce7fde8c85c52","462":"https:\/\/www.semanticscholar.org\/paper\/8d0f3d211e6c5a96ceedd6db3f23797eb657603a","463":"https:\/\/www.semanticscholar.org\/paper\/0a03bd6fa5dfc31d11700c0bfcd47305ec744a6b","464":"https:\/\/www.semanticscholar.org\/paper\/8bf80f049dc48982540597b3594d0445cc2a44c8","465":"https:\/\/www.semanticscholar.org\/paper\/942aab4a46ac63b993948dd2248d5d8416d06b69","466":"https:\/\/www.semanticscholar.org\/paper\/71d814f3c0fab9e2ea3223fee16c10c582a8268b","467":"https:\/\/www.semanticscholar.org\/paper\/11fa7b93618fed59f3fb2734449b53086ab1c0d7","468":"https:\/\/www.semanticscholar.org\/paper\/336609fcc8bd79faa6f8c0eb8a4432d89302a640","469":"https:\/\/www.semanticscholar.org\/paper\/98991c366c9fc5ecdcbe98d23061db6bbe608861","470":"https:\/\/www.semanticscholar.org\/paper\/92b55d1b93b80eaac3612ef8fca2677bd7d8740b","471":"https:\/\/www.semanticscholar.org\/paper\/84061ba075e2585108ed5c27963f237d6a90c9c7","472":"https:\/\/www.semanticscholar.org\/paper\/cb19373a5dec73f541e126ecfc787893ddb32e6f","473":"https:\/\/www.semanticscholar.org\/paper\/e8531c9735812e1e9ef2d0a73ec5c13f6e84ae3f","474":"https:\/\/www.semanticscholar.org\/paper\/0d2a9330e84d3bb82a5dcde88ff45443ac4e06b7","475":"https:\/\/www.semanticscholar.org\/paper\/86f7db76c94f48573c3e8f396934a48240b5326b","476":"https:\/\/www.semanticscholar.org\/paper\/9b7fdfb8782e42f224f6a7013cc3cda5dc04408d","477":"https:\/\/www.semanticscholar.org\/paper\/5670751022cf23f973028c9252b68afe7cbdb796","478":"https:\/\/www.semanticscholar.org\/paper\/1c671f5d9d7a4d784459885895c7ceb3bfda1e52","479":"https:\/\/www.semanticscholar.org\/paper\/9b32d19e46af00ec53d775f06e9c630b0d862084","480":"https:\/\/www.semanticscholar.org\/paper\/c0c969a54a6010ec902095bd1867b2c401ca5459","481":"https:\/\/www.semanticscholar.org\/paper\/47820ff88ec0ec723b586a04dbfce8e0b282277f","482":"https:\/\/www.semanticscholar.org\/paper\/c4492597c02d34c0cd64fb0096b9d0658dfaf88c","483":"https:\/\/www.semanticscholar.org\/paper\/24a699120f3247c88b097d62aec8e83ce7083ede","484":"https:\/\/www.semanticscholar.org\/paper\/c5cb74472783c13ac8181ed6ede0e392d526d9bd","485":"https:\/\/www.semanticscholar.org\/paper\/228a82bcad250b40b08c8e6b5c43dbf517cbd377","486":"https:\/\/www.semanticscholar.org\/paper\/aefcf7d4f3d966c58030c956449a13c308ce266f","487":"https:\/\/www.semanticscholar.org\/paper\/8056ee573f31749f63ba12a314c32faebba9d03e","488":"https:\/\/www.semanticscholar.org\/paper\/63c5d75af5e45be05c54e46bab07ed9d879d0894","489":"https:\/\/www.semanticscholar.org\/paper\/9c3633142561e8a40a67e6d110a88cda1ad32bb7","490":"https:\/\/www.semanticscholar.org\/paper\/ce72866ac641804785fa78085b0b06c117c012a4","491":"https:\/\/www.semanticscholar.org\/paper\/d50cc51b1b3d57a95bfd1b426d3c4619815e8d18","492":"https:\/\/www.semanticscholar.org\/paper\/f103c95e12291eef23f912877dcd534104bf0cfa","493":"https:\/\/www.semanticscholar.org\/paper\/29027dfe031bd1d685cf4b6c18e0e725e80da107","494":"https:\/\/www.semanticscholar.org\/paper\/305b869a7152fafb43270f448a117613f5acb32d","495":"https:\/\/www.semanticscholar.org\/paper\/3ea234b92cda5bf637fa4656f7f3c338b9c02366","496":"https:\/\/www.semanticscholar.org\/paper\/ea27e84e60cae4599335e59814d5521422c659a3","497":"https:\/\/www.semanticscholar.org\/paper\/322e3b6ef060a6bd6a041ea27c13701979b6fe8b","498":"https:\/\/www.semanticscholar.org\/paper\/163352c28deb856cbc1676a85f717c651c2d0b22","499":"https:\/\/www.semanticscholar.org\/paper\/da1e1290df1a9206b7af912a0268563fde3dc715","500":"https:\/\/www.semanticscholar.org\/paper\/0ce2db95b183f99c945394ff6e773c54beebb477","501":"https:\/\/www.semanticscholar.org\/paper\/783ebee9e8d09eb67166c8c21d11ad7bec676cd3","502":"https:\/\/www.semanticscholar.org\/paper\/7b881332aa2a236dc9be3f38610e00f4b42d8a33","503":"https:\/\/www.semanticscholar.org\/paper\/5bf1cb1c804afb81296f56becf9bb4ecee2cd090","504":"https:\/\/www.semanticscholar.org\/paper\/45b0a263930038e397394dea5abd9243bd30caf0","505":"https:\/\/www.semanticscholar.org\/paper\/7ad4d6821e4cd4a7519e82e46c55402c91f43355","506":"https:\/\/www.semanticscholar.org\/paper\/50f0e2fdbdc09495549424053c1bfb6b315610c2","507":"https:\/\/www.semanticscholar.org\/paper\/659ad17a0c2c40deaa784f4c44570ddfca422613","508":"https:\/\/www.semanticscholar.org\/paper\/0e92cb24b271b61980ef766dbcca489af1cc896a","509":"https:\/\/www.semanticscholar.org\/paper\/0ad792ca539bb62e9e29c35e459787b2c6d2e0d2","510":"https:\/\/www.semanticscholar.org\/paper\/5cee90b85b88e4de1d51b2963613a48b68916ac7","511":"https:\/\/www.semanticscholar.org\/paper\/c85eac363a2780e74fe638a4ef260d79cdf7dfd6","512":"https:\/\/www.semanticscholar.org\/paper\/0e45939bd8eae2e4897bdfccff859cd86ba32964","513":"https:\/\/www.semanticscholar.org\/paper\/8e8a312aeea66265b556b6d47295c82e6a0d33e1","514":"https:\/\/www.semanticscholar.org\/paper\/25821bd1b451053e1da2434dd6d9fa116af5404c","515":"https:\/\/www.semanticscholar.org\/paper\/2573edf113cb0f8191495bbcf0821fb76cd011e7","516":"https:\/\/www.semanticscholar.org\/paper\/cef6e6636daad076a3e8add2725d7ac76f4ef9cb","517":"https:\/\/www.semanticscholar.org\/paper\/dfa0e01dd7a92a295c3fc7a0e8d579fc1687a038","518":"https:\/\/www.semanticscholar.org\/paper\/d9bf8d9c73fc2b40db8ed17fb685f6d040050057","519":"https:\/\/www.semanticscholar.org\/paper\/477dcae2f6d5df0fd63c8bc37c1a4bbfdc9d9aca","520":"https:\/\/www.semanticscholar.org\/paper\/0082bff56884fa4dcf2c8439f1ff8e7c47f5c350","521":"https:\/\/www.semanticscholar.org\/paper\/c4da501c7183716dc4de01a9128c0b0b5609d7c5","522":"https:\/\/www.semanticscholar.org\/paper\/e164a302ab6d8ea8e16ff7cc324e16573f7f52c8","523":"https:\/\/www.semanticscholar.org\/paper\/9ae39b1b2a029bd0134c4e115136a7acd91d0fd3","524":"https:\/\/www.semanticscholar.org\/paper\/fbf95a25b8e350b18561c65e9c7e0c894aed164a","525":"https:\/\/www.semanticscholar.org\/paper\/2f8c88fafcb8417e64555f5a7c1b6c2d1d354cbf","526":"https:\/\/www.semanticscholar.org\/paper\/c128086627e3f04c8ce0c46ba72f81a3a8d9f4f6","527":"https:\/\/www.semanticscholar.org\/paper\/d918d0072fb677d35e0f2abf8afac6900442b3d4","528":"https:\/\/www.semanticscholar.org\/paper\/142087d3fda4b83272dc8ccf0c44f167717b5075","529":"https:\/\/www.semanticscholar.org\/paper\/aa7407a50c013b970171c95e598735b8e44c935b","530":"https:\/\/www.semanticscholar.org\/paper\/ca99973a761f961cb508cfabbae411c846604c7c","531":"https:\/\/www.semanticscholar.org\/paper\/b93a7da6fa6267d2a2a204717a83e832dd44e108","532":"https:\/\/www.semanticscholar.org\/paper\/895ac6ec9a12822e6b8ecb58f9737aed2ee35acb","533":"https:\/\/www.semanticscholar.org\/paper\/a7550d64f6d746681852aeba6d5536febfd5f0d3","534":"https:\/\/www.semanticscholar.org\/paper\/8fd2eca5fe7473d1c848c27346cefdb9bacb1301","535":"https:\/\/www.semanticscholar.org\/paper\/8fba8c41288ea0b2058c41d82f34992a52b34ba2","536":"https:\/\/www.semanticscholar.org\/paper\/c72779898ee3001c1cd72a3472611d593f90cef7","537":"https:\/\/www.semanticscholar.org\/paper\/d3ada3b13f0bccbc3bc7cffad3f030838bfbc6d0","538":"https:\/\/www.semanticscholar.org\/paper\/a5007d2e180385e67fe4c06eecf27d581dc7db0f","539":"https:\/\/www.semanticscholar.org\/paper\/a15a83214124ac3e55d8a1ef03c028a0e61564fb","540":"https:\/\/www.semanticscholar.org\/paper\/2732ca837cd54d765410656caf389ee969f32621","541":"https:\/\/www.semanticscholar.org\/paper\/0cf35b501d9e51fd21dfb4f72fc5765cfa891008","542":"https:\/\/www.semanticscholar.org\/paper\/4cadb4a6d1c728dd1c6a1df1fcd7a99a4e530deb","543":"https:\/\/www.semanticscholar.org\/paper\/4f1c897a05957932db2d0172d6ae5acef8115d4e","544":"https:\/\/www.semanticscholar.org\/paper\/ecc1a304e529528b656f90cfd5c4693da6aed031","545":"https:\/\/www.semanticscholar.org\/paper\/5ebef85aa9c97c0cbf60e095e82fcd15ba00a81d","546":"https:\/\/www.semanticscholar.org\/paper\/f29818f8c1790818ad871de01eff75ced3ccc68b","547":"https:\/\/www.semanticscholar.org\/paper\/a35a6d60f1853d52db3eb99fbb08c70e95a912ad","548":"https:\/\/www.semanticscholar.org\/paper\/303e604aa6e447a0e140ff110c1eec59966baceb","549":"https:\/\/www.semanticscholar.org\/paper\/ac6ef3da52f4ddb574446b6a96fa4701790be05d","550":"https:\/\/www.semanticscholar.org\/paper\/f5ccd96e87a117b73b5eef9d8c2f478a80b4f646","551":"https:\/\/www.semanticscholar.org\/paper\/5d94786428a83e3b4fa2f094458223f79398604e","552":"https:\/\/www.semanticscholar.org\/paper\/1faad55fe36893bbbdc8566151425e1b3caab0a3","553":"https:\/\/www.semanticscholar.org\/paper\/b8bd4ea53c1f5c47ca9e988b766c96905446cc28","554":"https:\/\/www.semanticscholar.org\/paper\/264cec8654087c131b483922b12edb9c416a97dd","555":"https:\/\/www.semanticscholar.org\/paper\/6887af19dc49c4f7c98c2f2130793da9d99aa585","556":"https:\/\/www.semanticscholar.org\/paper\/078b7993b74ad3ed6d3dc6cf7d416b88e8e75026","557":"https:\/\/www.semanticscholar.org\/paper\/8194def1ac2313190a53487a5f246c587796d857","558":"https:\/\/www.semanticscholar.org\/paper\/7747a7e83a7b44df463f5e8f81f68ecc0c038571","559":"https:\/\/www.semanticscholar.org\/paper\/a9ec36df50f789390692c8c520538c2ccc9d1028","560":"https:\/\/www.semanticscholar.org\/paper\/91d3100850e4cae3b8c52b27a3f9b9125654611b","561":"https:\/\/www.semanticscholar.org\/paper\/ecdf4e17862d162604e3cf8e532a6212ef4fa50d","562":"https:\/\/www.semanticscholar.org\/paper\/3f526fd08e84d725709317fa569da0504cfc7344","563":"https:\/\/www.semanticscholar.org\/paper\/f06c7fcd8575903259dd4ab398e167f0d1511dac","564":"https:\/\/www.semanticscholar.org\/paper\/eeafc2434bbd5f63995c206eb3eedc1a01550145","565":"https:\/\/www.semanticscholar.org\/paper\/93f205a9a655745dd866899cb4fc679cd60c9252","566":"https:\/\/www.semanticscholar.org\/paper\/c2097879a07ca4aca883311a60293af99887291c","567":"https:\/\/www.semanticscholar.org\/paper\/311caedb65fff281470100585d90f2c672a9f97f","568":"https:\/\/www.semanticscholar.org\/paper\/bfdf939c1b640c32bd9c9b0a075fa9e41b32a767","569":"https:\/\/www.semanticscholar.org\/paper\/b73a1d52f743e93087b6cb3254c7c57bc6069e30","570":"https:\/\/www.semanticscholar.org\/paper\/2c896f04663eb92f2e28f54fe939d22542a52a2a","571":"https:\/\/www.semanticscholar.org\/paper\/9a9d268cfbc2f0b973d5f64021326c4f4ca03491","572":"https:\/\/www.semanticscholar.org\/paper\/bbff27d942550cdecb5583ff206fa07b8bac1e1a","573":"https:\/\/www.semanticscholar.org\/paper\/7f12a305000d1b54d7fb65a30b0681b0cbc0bcaa","574":"https:\/\/www.semanticscholar.org\/paper\/9421641b3699e5682d6352c8e129e656177bceff","575":"https:\/\/www.semanticscholar.org\/paper\/bdfd9dbc612de159e42efe1688b3694c0a8e2365","576":"https:\/\/www.semanticscholar.org\/paper\/d64e886cf8d1c681284d3226b828b2ef661f2e22","577":"https:\/\/www.semanticscholar.org\/paper\/fdfd718572385f913da89bb1758db6dc9fbb0ee1","578":"https:\/\/www.semanticscholar.org\/paper\/381523408be14614d06753f172f01a268fac97d8","579":"https:\/\/www.semanticscholar.org\/paper\/2c4bde86a59e38e35305ed18b714a4dd21c6d4fc","580":"https:\/\/www.semanticscholar.org\/paper\/aef528766110ed9e0b4355b2f93ead16c68f4196","581":"https:\/\/www.semanticscholar.org\/paper\/ee6f891c5fe8f9ae0ce8346579bb1cee2b4a55f3","582":"https:\/\/www.semanticscholar.org\/paper\/4e2a346d596793741fa341179440a2d3e5b7f997","583":"https:\/\/www.semanticscholar.org\/paper\/35511226f4e0e8aa39ebbfd22844fbfbd0070799","584":"https:\/\/www.semanticscholar.org\/paper\/1511697652b846369874fc95721a6531446571d4","585":"https:\/\/www.semanticscholar.org\/paper\/98447518a6a2e6f2fc7043c090ac8eaab4dbd873","586":"https:\/\/www.semanticscholar.org\/paper\/162366bcdb4cc7a797efb78c07c3e9e7bb91066b","587":"https:\/\/www.semanticscholar.org\/paper\/80f6c9099cea17e9b21ac17b23fd37e78b2ffdda","588":"https:\/\/www.semanticscholar.org\/paper\/fed4fa066b8c56114ef62bc6b83dc25e5f5e78cd","589":"https:\/\/www.semanticscholar.org\/paper\/4ff28fd5025fb60bc6003cf1ca04a629ff634c2d","590":"https:\/\/www.semanticscholar.org\/paper\/f277c1ca350cae36975fc98be4730f67685f7dc6","591":"https:\/\/www.semanticscholar.org\/paper\/23a3e0a7e4bf1027844185a2ba6c8cf77c5eb0d0","592":"https:\/\/www.semanticscholar.org\/paper\/87954115b2a3e90387d7d299420afa7d6a5e2845","593":"https:\/\/www.semanticscholar.org\/paper\/66596207f5e6a5d8a456380a90048a9024cd18b4","594":"https:\/\/www.semanticscholar.org\/paper\/130dbac765282bd85c053dc9e5753aee75375a5c","595":"https:\/\/www.semanticscholar.org\/paper\/302263cee909b4dad7f4137bd6f0c117f8708bd3","596":"https:\/\/www.semanticscholar.org\/paper\/4179d8e2324ff8a3b3b94ae64f83268cf3fc9f49","597":"https:\/\/www.semanticscholar.org\/paper\/5d099e4edb6a5a4ce1a9388796de469393541785","598":"https:\/\/www.semanticscholar.org\/paper\/30e19cfa8ab5b4b1a116240de100e44288ab7db2","599":"https:\/\/www.semanticscholar.org\/paper\/461b4e2458517d8ffa52ffc63742a35158a383b6","600":"https:\/\/www.semanticscholar.org\/paper\/88192249582f78a48d4e581cc03f2f96261ca9a7","601":"https:\/\/www.semanticscholar.org\/paper\/2a8ec34500e2f90c5070fa34317b50939ac8f6f9","602":"https:\/\/www.semanticscholar.org\/paper\/d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3","603":"https:\/\/www.semanticscholar.org\/paper\/bca6b4dca4dbf282a7d4b0141d15d485f5ea274e","604":"https:\/\/www.semanticscholar.org\/paper\/8b80aef602b6b65d1fcef40423cd39cb6516d1b6","605":"https:\/\/www.semanticscholar.org\/paper\/696d9e4ad06e97527eaa3c95c78e8131a173e198","606":"https:\/\/www.semanticscholar.org\/paper\/3d2b0f22f8d2479102b77c9f0df1dbf1bd9f851e","607":"https:\/\/www.semanticscholar.org\/paper\/b3d2e8638b22a2ffebab9faa5268713e6ec1f2c1","608":"https:\/\/www.semanticscholar.org\/paper\/8e472406ad4ec2811a78296d5acfc7151edf1bff","609":"https:\/\/www.semanticscholar.org\/paper\/7a60f9516e9dee313855937d854a1931b42086fc","610":"https:\/\/www.semanticscholar.org\/paper\/48765ab4fefc240decbf0f81dd033439ab95096b","611":"https:\/\/www.semanticscholar.org\/paper\/c720dc32b9487fbe05ca04c387f8dd1726746f1c","612":"https:\/\/www.semanticscholar.org\/paper\/0b809bb69855b5bee3fdc96521c34d7a95d56913","613":"https:\/\/www.semanticscholar.org\/paper\/ab81213f73b7d8054b3f66d2a0bc4728d119d5fa","614":"https:\/\/www.semanticscholar.org\/paper\/069cb34a2f63797e7bf7e4f88f3d921e584e74f5","615":"https:\/\/www.semanticscholar.org\/paper\/eec2311b64672dc796c146ac39f24f26d311348a","616":"https:\/\/www.semanticscholar.org\/paper\/4cb1979846e6701f9b7a7f1bfed447ca3aaaae69","617":"https:\/\/www.semanticscholar.org\/paper\/b7aa030471b33ac682c4fecd9dba414b74e13504","618":"https:\/\/www.semanticscholar.org\/paper\/1a053536691a58ad65428f24bfe4362eef9fc6dc","619":"https:\/\/www.semanticscholar.org\/paper\/7bb9e11618932e0ef2d62f9cc0babf6a2878e067","620":"https:\/\/www.semanticscholar.org\/paper\/594d2c0fb1dc9fc0eefc5c50c9bc5ebc4dee110f","621":"https:\/\/www.semanticscholar.org\/paper\/8c5ba1c914eab16b705da03352fe69d5bcfc72ea","622":"https:\/\/www.semanticscholar.org\/paper\/18e56f63f1ef0bee7f7125fcfa1d46c931559ce2","623":"https:\/\/www.semanticscholar.org\/paper\/7a11eb364a56167e1fee9a52c5260f0ca9e32808","624":"https:\/\/www.semanticscholar.org\/paper\/742d581cba9c8716f30e7f8b1d45052e334a8a87","625":"https:\/\/www.semanticscholar.org\/paper\/62597cc93aa6604ee531ec9b7ab281b46633adbb","626":"https:\/\/www.semanticscholar.org\/paper\/06ac91f367b0c7af125e3a67417bfb52c62d14c2","627":"https:\/\/www.semanticscholar.org\/paper\/a167f78d44f5c496a51149a353bc01eec8965336","628":"https:\/\/www.semanticscholar.org\/paper\/7e95632e12fefef6ac58f671d90466b49a3c4bf1","629":"https:\/\/www.semanticscholar.org\/paper\/f6669bf41524a385a498cfde04a31019a5a4bf18","630":"https:\/\/www.semanticscholar.org\/paper\/172c881f7aa9e5bfd453dc9ee2bb2e2687103638","631":"https:\/\/www.semanticscholar.org\/paper\/f112ad62655e0d2cb8f6e795cad77cc375bb208a","632":"https:\/\/www.semanticscholar.org\/paper\/c6053887119a560818f1f3cd32df0c59737ee1d9","633":"https:\/\/www.semanticscholar.org\/paper\/186084b5df9eb0576aabddb7424833f716da4452","634":"https:\/\/www.semanticscholar.org\/paper\/6969b9811ed0c8c94e984ad4d0a4c0558cd94878","635":"https:\/\/www.semanticscholar.org\/paper\/1003e7dc2b77ac7676046bac71854bf6dd9a54ca","636":"https:\/\/www.semanticscholar.org\/paper\/6267e717e7e70a282e27cbb95ac6b3cb93403fae","637":"https:\/\/www.semanticscholar.org\/paper\/f8dffc53abb574eeeebdbf8dbb10052be70fd5d0","638":"https:\/\/www.semanticscholar.org\/paper\/adcaa8b63e7e3f10959e37ca0ff8cd71fdd6b74f","639":"https:\/\/www.semanticscholar.org\/paper\/64fd8f10fd15aeb511973f2a85374c34c694ffcf","640":"https:\/\/www.semanticscholar.org\/paper\/b7ff5bb5fe6ddf108280eecee662646c1e930440","641":"https:\/\/www.semanticscholar.org\/paper\/f2f7c987f262bd0aeb3d45d62fc419d8a2102b97","642":"https:\/\/www.semanticscholar.org\/paper\/5924f1b2dcebebee06b5e510a3a2962354b99809","643":"https:\/\/www.semanticscholar.org\/paper\/93aa2bdaec8ac048994bae6fb2fbe852dcdb28a0","644":"https:\/\/www.semanticscholar.org\/paper\/16962bb2d718e3bfdb7e4ead48193a8adb5f9e59","645":"https:\/\/www.semanticscholar.org\/paper\/622d7cf8f8609f6da854a3bbddbd4c19e7a4f266","646":"https:\/\/www.semanticscholar.org\/paper\/b455a956e845269c05089b8cb1bacee609412b8d","647":"https:\/\/www.semanticscholar.org\/paper\/0579777cd0b132a6454fcb1bd609eafef73876e1","648":"https:\/\/www.semanticscholar.org\/paper\/16aef42d9b453dad02a7aba750825bcb6e049bc1","649":"https:\/\/www.semanticscholar.org\/paper\/51a07653ed8ef7a0145be505bb257d317e2c6451","650":"https:\/\/www.semanticscholar.org\/paper\/ab42ab145f02ab3da5f01bd18fbb2111e611469e","651":"https:\/\/www.semanticscholar.org\/paper\/3aa6c163ad9e657eae11323a98e65449b7001b66","652":"https:\/\/www.semanticscholar.org\/paper\/08e6d7936377f381afad027291f6cb72531a9f62","653":"https:\/\/www.semanticscholar.org\/paper\/a136ad1eab71821964207ba89ef5d07696d54033","654":"https:\/\/www.semanticscholar.org\/paper\/85611149ed39ecba065ab89cc0fafc18929245b6","655":"https:\/\/www.semanticscholar.org\/paper\/02846c0c089d931fdfae92f0df4b1c979fe120a2","656":"https:\/\/www.semanticscholar.org\/paper\/5499b7ac2e023ffb124ee5e9dc1c434911d1a4d3","657":"https:\/\/www.semanticscholar.org\/paper\/3d5889713c530cd2559d9edd19fd9625ac0718d6","658":"https:\/\/www.semanticscholar.org\/paper\/c0e97f6fa973d226bbfa680aefea9ffcce3a08b3","659":"https:\/\/www.semanticscholar.org\/paper\/fb6fba73e1952b8f658761a350f02fb2d1d28c35","660":"https:\/\/www.semanticscholar.org\/paper\/93029e4f8a123e8bbd1eff27cc636dabf82dc0f0","661":"https:\/\/www.semanticscholar.org\/paper\/08835d8cd7396bb941697d2e68c285ba17757d0b","662":"https:\/\/www.semanticscholar.org\/paper\/5c3f78e2355b64c4ded503af766da9279380b748","663":"https:\/\/www.semanticscholar.org\/paper\/d2e5d458acce815f2ad5deaec21293467d9e9c22","664":"https:\/\/www.semanticscholar.org\/paper\/a19b9f68e6731b9457a3268b2e6d28c3964954c8","665":"https:\/\/www.semanticscholar.org\/paper\/a5a01357ecc2ac930f7263ea5c2796b377a97bb3","666":"https:\/\/www.semanticscholar.org\/paper\/d532d5c513325eddfdaa6d73060d1e9f7e7d63e0","667":"https:\/\/www.semanticscholar.org\/paper\/9dbec5d91ea20c0e3ecaf10bc4ff8d62402d803c","668":"https:\/\/www.semanticscholar.org\/paper\/b0e5a1ca466e5b4cef42da2bb500e8bda7f96e41","669":"https:\/\/www.semanticscholar.org\/paper\/6a5092a1cdf98022b1bcf5fbb8b7d36c1e440416","670":"https:\/\/www.semanticscholar.org\/paper\/be6a8364c591fefb3584cd712ac31f9f028ba69c","671":"https:\/\/www.semanticscholar.org\/paper\/d07975da0f6382d16d312ee409d88f0c35f15afe","672":"https:\/\/www.semanticscholar.org\/paper\/f57e2e7941398124ae85f337b3c396b892ce7560","673":"https:\/\/www.semanticscholar.org\/paper\/934e01d4c79de7b0414c60d442832e4ba96f5c32","674":"https:\/\/www.semanticscholar.org\/paper\/ef5913ac3d588f0de4b28a57f81a79cfecdbe4a4","675":"https:\/\/www.semanticscholar.org\/paper\/3726a87ba838eda5febf731457b0180d3d4a4f64","676":"https:\/\/www.semanticscholar.org\/paper\/25356a288cfd036271d13c16c534c9e6c160cf82","677":"https:\/\/www.semanticscholar.org\/paper\/ca4bc509c4cb7e66d4c77e1076f00a4b249d9ed2","678":"https:\/\/www.semanticscholar.org\/paper\/c88b564f6567841d9a57c6922b3fd9e01dc4fea6","679":"https:\/\/www.semanticscholar.org\/paper\/b5bac83950808b7cab76c884404b019277faba95","680":"https:\/\/www.semanticscholar.org\/paper\/6c76bedc6dbb4fc5715060bd54b3de668a032411","681":"https:\/\/www.semanticscholar.org\/paper\/9e825f22eaf5c9e8f3a11c4735939b0be2aa7178","682":"https:\/\/www.semanticscholar.org\/paper\/4043b9f526074db22024687c101c2dedc3fd9e45","683":"https:\/\/www.semanticscholar.org\/paper\/59a5d097baa8b31ea886f623869aa2c1f8f27f36","684":"https:\/\/www.semanticscholar.org\/paper\/cc3dc528115ca2687e42a829358d3c30b001fd9a","685":"https:\/\/www.semanticscholar.org\/paper\/4f2d6de514b2f67fcf3c3a8db6053dac51966a52","686":"https:\/\/www.semanticscholar.org\/paper\/1604795f2f2a39005971c38dd14846830a2b04ee","687":"https:\/\/www.semanticscholar.org\/paper\/c6ed86d93c136365d3f61bd237c75fe8421258f1","688":"https:\/\/www.semanticscholar.org\/paper\/bf13c1dc27a462136106efe81c95766198953815","689":"https:\/\/www.semanticscholar.org\/paper\/371eb0818fbc91a02d3ea51993691d80cef165b0","690":"https:\/\/www.semanticscholar.org\/paper\/1d96551197ec48eda05c1ce795b8c0a2d7c9f195","691":"https:\/\/www.semanticscholar.org\/paper\/475f29ad0e537ee7776b10b9326bbbbb435bd273","692":"https:\/\/www.semanticscholar.org\/paper\/1f06863f61beb5b0b7f32b4faa36b840d7444d1f","693":"https:\/\/www.semanticscholar.org\/paper\/44252c984de4c92c11bd661b8b0f0266bf906416","694":"https:\/\/www.semanticscholar.org\/paper\/48e5a6dd1303820fd56df7fb44c14c70608e7100","695":"https:\/\/www.semanticscholar.org\/paper\/52fb8bfd553abc2f8f488dbcfd559c787fd7baac","696":"https:\/\/www.semanticscholar.org\/paper\/056935031bc5cf0aeeaa0946320de26e14a1817e","697":"https:\/\/www.semanticscholar.org\/paper\/0458311cb0ec92112c964abb086990c362a40013","698":"https:\/\/www.semanticscholar.org\/paper\/1a9974e623287867c6debb2c794df207305715ff","699":"https:\/\/www.semanticscholar.org\/paper\/a1363625abac6360da491adb6c0e134d960ae294","700":"https:\/\/www.semanticscholar.org\/paper\/3915e31eb09cb1fbe5bf7c6f89495e9059af540e","701":"https:\/\/www.semanticscholar.org\/paper\/d568cd7d015462e7ebc795980e0b413650defff9","702":"https:\/\/www.semanticscholar.org\/paper\/ee3b952ea6e7ef2b2ed9e0ea705db30c8ed0b365","703":"https:\/\/www.semanticscholar.org\/paper\/116c57babe0ccd928048faac17d83c4b142e938c","704":"https:\/\/www.semanticscholar.org\/paper\/126853f3b04ce0a79a71ff6749c509bc3b810aa0","705":"https:\/\/www.semanticscholar.org\/paper\/9a8e2e39ee1cafd891b9b4afb4e58e441dcfdc0a","706":"https:\/\/www.semanticscholar.org\/paper\/bcbaf9d2eee6a266b2d2fbad48c2a089c1c36244","707":"https:\/\/www.semanticscholar.org\/paper\/6c7389c3c1edb1253cb3b2a51f8997e77f0f992f","708":"https:\/\/www.semanticscholar.org\/paper\/e5fc40dd94d6fa94aceec7c356bf953c493117e0","709":"https:\/\/www.semanticscholar.org\/paper\/f080e7f62cc50b8f1e922102414ca21a01647076","710":"https:\/\/www.semanticscholar.org\/paper\/0f1b97d8b7197a48b3ce22d139dbed8c5170ad59","711":"https:\/\/www.semanticscholar.org\/paper\/d8f6a7dfda0d4cbc358e86426de7f2817b1bb573","712":"https:\/\/www.semanticscholar.org\/paper\/8dd220d119a35af83567e0679bf2e8252a86be39","713":"https:\/\/www.semanticscholar.org\/paper\/47a49468ad06e9ea2e0f6bd0006a1f72c00ea590","714":"https:\/\/www.semanticscholar.org\/paper\/30303f35417a054f8b4fa70b7150f6fd3f7ff746","715":"https:\/\/www.semanticscholar.org\/paper\/e86bb957c089316fba5a9c43735bfa6d9ea42f4b","716":"https:\/\/www.semanticscholar.org\/paper\/bbf70ccfdc5e386bfcd62fb7b8d01aa3f84473e2","717":"https:\/\/www.semanticscholar.org\/paper\/8a07e79cbaeed972b2d392d4267aa611b81f88be","718":"https:\/\/www.semanticscholar.org\/paper\/e235ad7dcf6e97cd372f09724dc947c5b1efac79","719":"https:\/\/www.semanticscholar.org\/paper\/41fcef711faca9013fd0980a9f6ec1d23c9c76c8","720":"https:\/\/www.semanticscholar.org\/paper\/7a70764c4e1173ceab983a759ac3c665a88f2195","721":"https:\/\/www.semanticscholar.org\/paper\/4aea3547974399a32d7aa7c007b10bd665e93fab","722":"https:\/\/www.semanticscholar.org\/paper\/94cf3f2c4410fcb06a90abebd99f7113c69e1ed9","723":"https:\/\/www.semanticscholar.org\/paper\/8bf831e3398ce79badb8e2f2d4ef70638b054228","724":"https:\/\/www.semanticscholar.org\/paper\/ab9cc2c6a8d35d7a145cf608ff9dd7af87213253","725":"https:\/\/www.semanticscholar.org\/paper\/78d08b8ab4132defffe98ec7f80a51452203f70d","726":"https:\/\/www.semanticscholar.org\/paper\/4168df2c88c0f942b955ca4cc817f5aaf05d8fc5","727":"https:\/\/www.semanticscholar.org\/paper\/17f357f3c6fdd86f7e8a141d1e3b9acb2e59a89a","728":"https:\/\/www.semanticscholar.org\/paper\/d47a682723f710395454687319bb55635e653105","729":"https:\/\/www.semanticscholar.org\/paper\/bb55ce957aefacf775422bbff406f21d83be0545","730":"https:\/\/www.semanticscholar.org\/paper\/47f1fc1fd5c0be10e5446d1e65a2726cb243a30b","731":"https:\/\/www.semanticscholar.org\/paper\/41f9fd1c997473d8c50a4f7f61eb317ac7a6f25c","732":"https:\/\/www.semanticscholar.org\/paper\/83c64a66a0fff925e49a4395ae52d7dc450df5e7","733":"https:\/\/www.semanticscholar.org\/paper\/2760dd9cd9c0ca5df8bd9369a9bd9a43a05f5204","734":"https:\/\/www.semanticscholar.org\/paper\/756e84448d2b21e0aee58840dc2872fd359a5c7d","735":"https:\/\/www.semanticscholar.org\/paper\/61c425bdda0e053074e96c3e6761ff1d7e0dd469","736":"https:\/\/www.semanticscholar.org\/paper\/c9c6e84d5510f0eb34ec40ce74c954d4fbe2464e","737":"https:\/\/www.semanticscholar.org\/paper\/bd3f087d8f7003e9776078f8f52f4c728a734839","738":"https:\/\/www.semanticscholar.org\/paper\/a68e53c34f7c0c6a6d806e5dab0bba8e92c85f6a","739":"https:\/\/www.semanticscholar.org\/paper\/3dcf5d3776bdd19576a4b2841d561f35514f3349","740":"https:\/\/www.semanticscholar.org\/paper\/1ff029d6b207c1bd5d3eaaef9ba41fa81a1a1913","741":"https:\/\/www.semanticscholar.org\/paper\/330c88e277f24ac0dbb0e72f1dd8a60ce14948ce","742":"https:\/\/www.semanticscholar.org\/paper\/34be38f7f18f3fb4a58256ddf96365f2934551dd","743":"https:\/\/www.semanticscholar.org\/paper\/21f93750f737f1de1177a0e831c7e273851352c7","744":"https:\/\/www.semanticscholar.org\/paper\/febcbbf070f0da26ed51454d08b6383aab541663","745":"https:\/\/www.semanticscholar.org\/paper\/35f78de3f4f78f186ebfb83a495e7b16b8680e9c","746":"https:\/\/www.semanticscholar.org\/paper\/011869f932f89d047ce2bd36d73a95cc04888193","747":"https:\/\/www.semanticscholar.org\/paper\/45cdcd93de82c1c5cf23ab5dc6c9e4d87c9c7993","748":"https:\/\/www.semanticscholar.org\/paper\/e985f056638f5433c541f40f45810300e2210b6e","749":"https:\/\/www.semanticscholar.org\/paper\/8597f2fd702744315bfc6315cf315278f9a0b258","750":"https:\/\/www.semanticscholar.org\/paper\/6c5e40f3c6a1b057b36a73d9aaeb79bc937d4959","751":"https:\/\/www.semanticscholar.org\/paper\/39e8c02fbce5fcfaf9c2cb49bd21f697ce54f679","752":"https:\/\/www.semanticscholar.org\/paper\/f81d64a772d49bcc2eff837290742a955ea8e93b","753":"https:\/\/www.semanticscholar.org\/paper\/0903826c840078e12fd381e104bb598d70e6ed75","754":"https:\/\/www.semanticscholar.org\/paper\/a4e67bcbf912e13cebbb1241d05d1ca0a1df9df8","755":"https:\/\/www.semanticscholar.org\/paper\/623b1c61aa36048a38485a44551cb3fdcbcc827b","756":"https:\/\/www.semanticscholar.org\/paper\/213e3b93d0c911c56d4c90a4063e6bf2201c0150","757":"https:\/\/www.semanticscholar.org\/paper\/c4744a7c2bb298e4a52289a1e085c71cc3d37bc6","758":"https:\/\/www.semanticscholar.org\/paper\/e6fc6a23c057ce90c950adff480afceb07979386","759":"https:\/\/www.semanticscholar.org\/paper\/8500b01cbdb3c92b83cba6c4a4f6bc5eb46419b4","760":"https:\/\/www.semanticscholar.org\/paper\/6008c949b32267f53a51eb60cc8d00c57a3b82c1","761":"https:\/\/www.semanticscholar.org\/paper\/e9d87b6ffdcc812707ab1721a677fd6ce4c7d9c2","762":"https:\/\/www.semanticscholar.org\/paper\/bc5c077cc0437e5529aabad7880427fe9a8223ca","763":"https:\/\/www.semanticscholar.org\/paper\/908c6b1577a1f5309ae183daf2e24363039f22a8","764":"https:\/\/www.semanticscholar.org\/paper\/fbafd188d94d958c5f1b6f62e897ce02211cbc23","765":"https:\/\/www.semanticscholar.org\/paper\/1fbd1a1b5cadd4e83a516898ae47a222fd448be0","766":"https:\/\/www.semanticscholar.org\/paper\/b1b9b770acb5f42ecba3270732a0b8f6f4ac3ff5","767":"https:\/\/www.semanticscholar.org\/paper\/19a939c3ec496de2882f4c019a007a6331187e8d","768":"https:\/\/www.semanticscholar.org\/paper\/ce3b364b7e6358940ce97d8d5887a65e5024ca21","769":"https:\/\/www.semanticscholar.org\/paper\/4d5247af0cc487ad70813893ef945d46b2a34c11","770":"https:\/\/www.semanticscholar.org\/paper\/e79d1206292bc5e67ba19737d87d4b2ea4a37105","771":"https:\/\/www.semanticscholar.org\/paper\/ea667d3f5df2954c7365b8d1218889e2fc514829","772":"https:\/\/www.semanticscholar.org\/paper\/97ede42d86fabe465528893561dec04da6947bbb","773":"https:\/\/www.semanticscholar.org\/paper\/d48c92e3e34e64c26f0bee4c4dec3e5d809dd1d7","774":"https:\/\/www.semanticscholar.org\/paper\/e2d2f64b3bb200c2c3db5ddc367b06311c369341","775":"https:\/\/www.semanticscholar.org\/paper\/1b4a45b3d2f7573451048d695fbf81cfcee9253e","776":"https:\/\/www.semanticscholar.org\/paper\/7ea0e91c5d5dc73f2133bc46d7ebb6cb83034dae","777":"https:\/\/www.semanticscholar.org\/paper\/a729503f528d5f0be0f897aa1841e1ff8ffcb313","778":"https:\/\/www.semanticscholar.org\/paper\/e4a9c8f91acdc0620e25adce9d67f49c14e990b9","779":"https:\/\/www.semanticscholar.org\/paper\/5e9c85235210b59a16bdd84b444a904ae271f7e7","780":"https:\/\/www.semanticscholar.org\/paper\/edfe9dd16316618e694cd087d0d418dac91eb48c","781":"https:\/\/www.semanticscholar.org\/paper\/437727b6c00a5eb4944600091f66f41626d1002d","782":"https:\/\/www.semanticscholar.org\/paper\/43df433e74d45bf5a37e457298211d5d35264109","783":"https:\/\/www.semanticscholar.org\/paper\/039b1c1210c437f3b3ce6e0275ee2137bf5b951c","784":"https:\/\/www.semanticscholar.org\/paper\/67262b3ae544f51f7480650b064a740816e194c9","785":"https:\/\/www.semanticscholar.org\/paper\/e19b56cdce8eba05f82ca60e2152f9023c2bda58","786":"https:\/\/www.semanticscholar.org\/paper\/c0dd6f4ad8210f959a5fc50049a2da960165f741","787":"https:\/\/www.semanticscholar.org\/paper\/01f2b214962997260020279bd1fd1f8f372249d4","788":"https:\/\/www.semanticscholar.org\/paper\/80d26b206ee5621169e4175f2f1a6bfff464efbe","789":"https:\/\/www.semanticscholar.org\/paper\/5019dbe8d1da5f128f4f373d6849095cf18fd519","790":"https:\/\/www.semanticscholar.org\/paper\/a0278907a87ad05555297a678481f906da98bf73","791":"https:\/\/www.semanticscholar.org\/paper\/3a906b77fa218adc171fecb28bb81c24c14dcc7b","792":"https:\/\/www.semanticscholar.org\/paper\/0872f4a6e14c6da98424e6daefe4d9b626ba4d3d","793":"https:\/\/www.semanticscholar.org\/paper\/76c4f474db9f4b559af7a93fc3d5a56e8389e393","794":"https:\/\/www.semanticscholar.org\/paper\/3fd45fc420a882ab2fba3166ef08f376cc758ad0","795":"https:\/\/www.semanticscholar.org\/paper\/67d354cd3c40d263a8d9347a34562b03c756570f","796":"https:\/\/www.semanticscholar.org\/paper\/a27415b81a7989e0049bfd18714fb5d4f8f4e94b","797":"https:\/\/www.semanticscholar.org\/paper\/f5d1dbdaa6c8a44f388f3f7fe538403baefc1252","798":"https:\/\/www.semanticscholar.org\/paper\/d479b283c979e0da3ce6b12ff813f2200465f3a3","799":"https:\/\/www.semanticscholar.org\/paper\/cb332b26162ee33f73e03fa3fdfd94a0a3fa82cb","800":"https:\/\/www.semanticscholar.org\/paper\/2c88d7486f9871cb741ba3c7076b8adbb7fd5b68","801":"https:\/\/www.semanticscholar.org\/paper\/ad7129af0644dbcafa9aa2f111cb76526ea444a1","802":"https:\/\/www.semanticscholar.org\/paper\/3da9ea9cab33c9e52632e70e85e184c46d31d590","803":"https:\/\/www.semanticscholar.org\/paper\/ae5a42cd7624365fceae9283c0ed32198f5c2860","804":"https:\/\/www.semanticscholar.org\/paper\/6ff64171a2a6f4c9b74784796d4c8cf07668f39b","805":"https:\/\/www.semanticscholar.org\/paper\/c2f85cb1a4887ab078a58b0b4ae6d20b6ae0efb9","806":"https:\/\/www.semanticscholar.org\/paper\/3e8d5d777e2d4b329513a114bca0dee12d6e14d3","807":"https:\/\/www.semanticscholar.org\/paper\/1dd19753c01476612db6f668967ded7b859deb83","808":"https:\/\/www.semanticscholar.org\/paper\/ade992f2b154dadfa4c370f457da85eae08a18aa","809":"https:\/\/www.semanticscholar.org\/paper\/0a702c3d66a614e797093c43794c1cb1906c5057","810":"https:\/\/www.semanticscholar.org\/paper\/52722be14cf55c8599459cc32b40e3635cc4c368","811":"https:\/\/www.semanticscholar.org\/paper\/2475ba09351c957bc60f90774aaafe8d81aa5b8a","812":"https:\/\/www.semanticscholar.org\/paper\/1bbbe12b060f54a97a4e81fd23cbb7932ff9de53","813":"https:\/\/www.semanticscholar.org\/paper\/cae979ad6218066249a7f9e134a31b47bdb1f4b9","814":"https:\/\/www.semanticscholar.org\/paper\/ffbfce72f12aa0be619be5e49698c2657853409f","815":"https:\/\/www.semanticscholar.org\/paper\/db9b452f34e5dd6522acaad64e1d0d11868aa5d3","816":"https:\/\/www.semanticscholar.org\/paper\/034697983626566addc2c2832d9a176e66fe1bec","817":"https:\/\/www.semanticscholar.org\/paper\/3a8ca1d96345fc7b8291650149b183e3b569559e","818":"https:\/\/www.semanticscholar.org\/paper\/2468c0ccff91f48eb2111ad3e8d4080fec2f7ce7","819":"https:\/\/www.semanticscholar.org\/paper\/45af13e3e9d8ce9f368b8c7b13e231b581ea0443","820":"https:\/\/www.semanticscholar.org\/paper\/8bb24b335845441564e2f23d2656102b27d6dfca","821":"https:\/\/www.semanticscholar.org\/paper\/3b00f5cbdcf854992e43b5d31d7d17dd6d317aaa","822":"https:\/\/www.semanticscholar.org\/paper\/db27f121753a4517882da37f5366219fd36576da","823":"https:\/\/www.semanticscholar.org\/paper\/2e84295dbe37cdf9183e45ceef9962754002a9ca","824":"https:\/\/www.semanticscholar.org\/paper\/92443e393dc076df1382771a43707ad54ac4b313","825":"https:\/\/www.semanticscholar.org\/paper\/d879f0ede5587241ece22dddef408efc6dc62dcf","826":"https:\/\/www.semanticscholar.org\/paper\/50e7b940a3bf3b75cd4611eb8c7c6efbb61f2fdb","827":"https:\/\/www.semanticscholar.org\/paper\/61fb1ac7d49258b63882c4b7722a3716a169d745","828":"https:\/\/www.semanticscholar.org\/paper\/8ffc8ebfe66eb9fd60906998e8c7c1bf6b333622","829":"https:\/\/www.semanticscholar.org\/paper\/e853ef5d79b5584f4476e82c7a6b736c53a18bfc","830":"https:\/\/www.semanticscholar.org\/paper\/913ad51defbde43f6147d8b79244a5dc4d0a2071","831":"https:\/\/www.semanticscholar.org\/paper\/c815ac9e6f15fa5fe34c2d52d94b68113576e7e4","832":"https:\/\/www.semanticscholar.org\/paper\/35e082eabdbb35aa8890ea2d15e967ab0e48e8eb","833":"https:\/\/www.semanticscholar.org\/paper\/857b9342d773ac4e8a645857c7ea2ded93f430eb","834":"https:\/\/www.semanticscholar.org\/paper\/a63c2a4062e1d9ab75b36585bcdaa3446cf833eb","835":"https:\/\/www.semanticscholar.org\/paper\/2f42a79e76b6b4f8b8050c99d30f32aa9f906f89","836":"https:\/\/www.semanticscholar.org\/paper\/159d42b6ec043a3409b773ba2cb2c73e72fa1056","837":"https:\/\/www.semanticscholar.org\/paper\/0603f0f4017ef28473e1467ecf5a84893230e9c6","838":"https:\/\/www.semanticscholar.org\/paper\/0274b1ac36f9eb933c13faf8cb7e862ea219eb25","839":"https:\/\/www.semanticscholar.org\/paper\/499533050ea59697e5be630eb0b954717a3bff40","840":"https:\/\/www.semanticscholar.org\/paper\/a7cb7c67a181c35f2e2dd2767e21defc0af9c14a","841":"https:\/\/www.semanticscholar.org\/paper\/75ca384b69494c16ad7e814d069745be854082bb","842":"https:\/\/www.semanticscholar.org\/paper\/cfd2884eeb5031e3dfccd0292cdf3cabf7b901eb","843":"https:\/\/www.semanticscholar.org\/paper\/959f09931596459b6022aad4d253461ab0e75e33","844":"https:\/\/www.semanticscholar.org\/paper\/56c51fea80589e5dd75a3efe5bac023329b81a5b","845":"https:\/\/www.semanticscholar.org\/paper\/6a3fc1599bf6faa2d15006f8303b772e92c8c3bc","846":"https:\/\/www.semanticscholar.org\/paper\/e2eb9b0c04df959ff26ab0b9034bb24ff878f187","847":"https:\/\/www.semanticscholar.org\/paper\/c587f1a415b9b724fee5954d23d9ee2a16dd149e","848":"https:\/\/www.semanticscholar.org\/paper\/a3d652dd58c60c10582bb9d6b409dcf927bfd561","849":"https:\/\/www.semanticscholar.org\/paper\/f5780dec0e7532caaf520d943f6553293a4c9dec","850":"https:\/\/www.semanticscholar.org\/paper\/84174325955f55b3cc2878d1b15b430fecc856e7","851":"https:\/\/www.semanticscholar.org\/paper\/e74b55ce5957ee3df5c63e260e2f22696ffb6b54","852":"https:\/\/www.semanticscholar.org\/paper\/ad6a97b9a9019229f15174d98354e4ec87e4248f","853":"https:\/\/www.semanticscholar.org\/paper\/96dd86c4fe31d137fea73a3886ef849a84712408","854":"https:\/\/www.semanticscholar.org\/paper\/6018537da402776cc08c12a56f0064d0e41f992e","855":"https:\/\/www.semanticscholar.org\/paper\/2dfd336a2beb6af1f7facb5ad9ad0444467ae5fe","856":"https:\/\/www.semanticscholar.org\/paper\/e3f9dab374b133f46215fa77070a2229f5d39a9c","857":"https:\/\/www.semanticscholar.org\/paper\/744389b9a207724f68b966f0254915ae6577705d","858":"https:\/\/www.semanticscholar.org\/paper\/76ffc62996b7add5ac3255c105c32a62dcbed3f2","859":"https:\/\/www.semanticscholar.org\/paper\/88d073c4b9a148a32932368efd853bb45899fde8","860":"https:\/\/www.semanticscholar.org\/paper\/d4d26ccbf1e64e725b5bffc08ab28a72e271facb","861":"https:\/\/www.semanticscholar.org\/paper\/6e0bde6ebe84eeb745c42c5901332cdf307bfaab","862":"https:\/\/www.semanticscholar.org\/paper\/ee38fbbb9a7b38d707c6e98afe72be237fd33d16","863":"https:\/\/www.semanticscholar.org\/paper\/63052e581f1b272eefdbf109a230c7ec87e1f79a","864":"https:\/\/www.semanticscholar.org\/paper\/95f29543d5ee6f35219121ca5cb87018d2b52815","865":"https:\/\/www.semanticscholar.org\/paper\/b4befcf6681670eb01385d931c24ed3cf44d692a","866":"https:\/\/www.semanticscholar.org\/paper\/1d8dcf5e99557c7d6b7015a280e4043439ecd1a5","867":"https:\/\/www.semanticscholar.org\/paper\/944e44cf94dcddeb8727d70f58a86ae06c62e529","868":"https:\/\/www.semanticscholar.org\/paper\/75e94f79cd94636611e0421d63b9908e9a814597","869":"https:\/\/www.semanticscholar.org\/paper\/982e260e1ced1063f7b9227210601a34a7df21aa","870":"https:\/\/www.semanticscholar.org\/paper\/de06fe87e4d9f989a7509ca977623bd5aa163167","871":"https:\/\/www.semanticscholar.org\/paper\/328e3c9745911d84f6b075e6ca62d1ca00d856f6","872":"https:\/\/www.semanticscholar.org\/paper\/34fdd362440fdc1fe1509ba9d83cb0fcf4282db0","873":"https:\/\/www.semanticscholar.org\/paper\/e632d3f4c160704a7d2506a71ad9ec0481478dc3","874":"https:\/\/www.semanticscholar.org\/paper\/acc88786e83acc3a7fc0280bbe592706a8034c8f","875":"https:\/\/www.semanticscholar.org\/paper\/447a36764df662076e0be38e2ed14aed7f5bace6","876":"https:\/\/www.semanticscholar.org\/paper\/d33cef96c8d74161346e09a3275cfeaeb412d31b","877":"https:\/\/www.semanticscholar.org\/paper\/6d5bd04cd1c8d27a095bf41fdc71d8812ec75dd3","878":"https:\/\/www.semanticscholar.org\/paper\/35b67abd153fc7743a7c635313273b5577e8ee00","879":"https:\/\/www.semanticscholar.org\/paper\/740db108d536a8b6f53111407898f4ecaecf80ea","880":"https:\/\/www.semanticscholar.org\/paper\/2cc6faba2872e83cfd28434cd9d84e7eebf96f33","881":"https:\/\/www.semanticscholar.org\/paper\/2d829c524dd90d674b64a3b4efc3eb3292009702","882":"https:\/\/www.semanticscholar.org\/paper\/719ea70b55fbcd1dc5736d2edde796a04b10cbf2","883":"https:\/\/www.semanticscholar.org\/paper\/7150472d17a6353aa2e0af513be91cf9406729e1","884":"https:\/\/www.semanticscholar.org\/paper\/5aefdda20616a65ada0ba5dc360e5d4981633bbf","885":"https:\/\/www.semanticscholar.org\/paper\/206704d164acb4eb54e2f9258477b02e4a452b50","886":"https:\/\/www.semanticscholar.org\/paper\/4d9824620d4cd0a8cf032bbe495d7982dc1a7ac8","887":"https:\/\/www.semanticscholar.org\/paper\/1a21ed83b4c06d96db34e35df8b2db24fbdc4c26","888":"https:\/\/www.semanticscholar.org\/paper\/c874421f460d0ae1cbf740264866294d0dce757a","889":"https:\/\/www.semanticscholar.org\/paper\/87d76615c649357d76c6adb5d317ced97851a0fc","890":"https:\/\/www.semanticscholar.org\/paper\/a223becf074a6d9ff6f1bada0e0f6eb15fd69341","891":"https:\/\/www.semanticscholar.org\/paper\/2957bdd2bce3124f84935277231c2867a9a4ef4e","892":"https:\/\/www.semanticscholar.org\/paper\/bf86aa7492eaed91872191d51fed7cc9ac385442","893":"https:\/\/www.semanticscholar.org\/paper\/c552c158776ad85814ef4fbca5b040d443573dda","894":"https:\/\/www.semanticscholar.org\/paper\/03442d7517f345ace9640b44a1e056d7267f1a8b","895":"https:\/\/www.semanticscholar.org\/paper\/51819d708e00c0fe7ca3e8befc4f8665ac12ad0e","896":"https:\/\/www.semanticscholar.org\/paper\/40fe3388043ce73a93a14b33dafd533ac0baec55","897":"https:\/\/www.semanticscholar.org\/paper\/d6c70a2ce72ccc11461860c3a738a1f7ca8d7309","898":"https:\/\/www.semanticscholar.org\/paper\/47b44ee5c47d4fb569d4e997f71bb01fe5bdb373","899":"https:\/\/www.semanticscholar.org\/paper\/057e59cef6deef4220740c05ec058165344391b1","900":"https:\/\/www.semanticscholar.org\/paper\/f3be8fb277646ee961974111c04579e157b341fd","901":"https:\/\/www.semanticscholar.org\/paper\/80f92649dfdde7c4e1c0d46831412c3490b77fca","902":"https:\/\/www.semanticscholar.org\/paper\/5298ac1e6643a39912e0ef2a231ae2d3b6d47a0e","903":"https:\/\/www.semanticscholar.org\/paper\/13bda78db02c8be8ee01dcdb954385d0cf039050","904":"https:\/\/www.semanticscholar.org\/paper\/109c3c35e56365f245e5c2a85d5339706b3e34fc","905":"https:\/\/www.semanticscholar.org\/paper\/abb6fed2839d4aa79c93e133989a209d00b8862f","906":"https:\/\/www.semanticscholar.org\/paper\/6981c7de04c5481c36bfcbfdb3c3ea3776a22ed5","907":"https:\/\/www.semanticscholar.org\/paper\/d1c2702bbe0594665bde6fe81ef0e129182c9f98","908":"https:\/\/www.semanticscholar.org\/paper\/0b88eec9400ef4e0c5a204d26d9b6b467f0d3c3a","909":"https:\/\/www.semanticscholar.org\/paper\/e85b31bab22be578872fc08dcabb460caf7aed71","910":"https:\/\/www.semanticscholar.org\/paper\/c1c65e5a0f54b34296fbf824b86a3df4b50c4775","911":"https:\/\/www.semanticscholar.org\/paper\/8b8274529958ab3176a79291a36da1b80545791d","912":"https:\/\/www.semanticscholar.org\/paper\/ebea5f14666efb2ab1dbba1597cf177355109e66","913":"https:\/\/www.semanticscholar.org\/paper\/3852971e04b08a41c3856f19aaae3f318cd5e359","914":"https:\/\/www.semanticscholar.org\/paper\/657ec6e3d6332e41a2daa2352ecf2bda0bdb8038","915":"https:\/\/www.semanticscholar.org\/paper\/739be8b7a88921bc23eb6bb597fc8ce2b86b5cb3","916":"https:\/\/www.semanticscholar.org\/paper\/2d1e289a6b4d41341f24c4d72cfae660891397be","917":"https:\/\/www.semanticscholar.org\/paper\/85ef684e8f761e31cc8da9fcd6fe37c553d093f3","918":"https:\/\/www.semanticscholar.org\/paper\/378b834ab661464c6d3a518bf5f112579eacc3a5","919":"https:\/\/www.semanticscholar.org\/paper\/310feecccdd26690612788622c887bf1823a4dce","920":"https:\/\/www.semanticscholar.org\/paper\/1c650aeb2862c1e44a7bc21a2b856a0ea364dad6","921":"https:\/\/www.semanticscholar.org\/paper\/5f8943a8eb911e2c6976861422a35425b9de4c78","922":"https:\/\/www.semanticscholar.org\/paper\/33def44beac530f5a5e16e08e81d134d230ed632","923":"https:\/\/www.semanticscholar.org\/paper\/c2cad3c319f2e2bcd00d32a8903d0d595395efec","924":"https:\/\/www.semanticscholar.org\/paper\/50ca60adef5f4adf4f1ce18a8c0ab37c9232810b","925":"https:\/\/www.semanticscholar.org\/paper\/8aea804f26e2ed8321bb57e76fb3b0b0a0964506","926":"https:\/\/www.semanticscholar.org\/paper\/9b534639bcadc9ad232b338e760c523a4d74c8de","927":"https:\/\/www.semanticscholar.org\/paper\/f5bcabc298499a4b576a2883cfe641ed095896d9","928":"https:\/\/www.semanticscholar.org\/paper\/839c850367f7e7835fcaef588ae3309adf976c36","929":"https:\/\/www.semanticscholar.org\/paper\/ac382e3f9886570046eb1775697a4352a345cc85","930":"https:\/\/www.semanticscholar.org\/paper\/d72e2373c24b74f63a2c0d2a3f2fc494c82ba1a5","931":"https:\/\/www.semanticscholar.org\/paper\/38a91371928f8ec3ad0f0d3f71af06e1efc0ef9d","932":"https:\/\/www.semanticscholar.org\/paper\/6624ce2d2ec3b3119aad5664f66d72ca38679f35","933":"https:\/\/www.semanticscholar.org\/paper\/e5e851351cfb5ef6ab4b00e30545283dfa1959e4","934":"https:\/\/www.semanticscholar.org\/paper\/9c9c5596f8a7a41fc31e5376a4ce1de9b93671ae","935":"https:\/\/www.semanticscholar.org\/paper\/0f192e9c7a1e3fdc6e051fc502f74b04c53bb3a3","936":"https:\/\/www.semanticscholar.org\/paper\/66462bfd498cd8b1ea0883674114db2e528f02b8","937":"https:\/\/www.semanticscholar.org\/paper\/bbbc9b092f9a8921f5c6c0c68acb47c50acdf215","938":"https:\/\/www.semanticscholar.org\/paper\/3ec89e12fe08eb0c6a5e805be8e0bfc5926f6ad5","939":"https:\/\/www.semanticscholar.org\/paper\/6d77d7467f993780d02f3d8ea563959643d48f89","940":"https:\/\/www.semanticscholar.org\/paper\/c81ace13799f82e53a8c4cc8ccfb30ec2c0ccbf4","941":"https:\/\/www.semanticscholar.org\/paper\/8ab812155692852fa0791ee19a852493c633d4d2","942":"https:\/\/www.semanticscholar.org\/paper\/24797b500be4a205199a8cf108d096f79e7a4eb8","943":"https:\/\/www.semanticscholar.org\/paper\/b9b639522465cc606df878eee62e7f9c4bf19e62","944":"https:\/\/www.semanticscholar.org\/paper\/131315a2795054d85cdbc31fd31e2439b7b0a1bc","945":"https:\/\/www.semanticscholar.org\/paper\/18342afa1404e66a16fd04e53dcfd8337587fc20","946":"https:\/\/www.semanticscholar.org\/paper\/569829ab76a311b1f7f5b33d37ffff6a3fae6490","947":"https:\/\/www.semanticscholar.org\/paper\/ef2f72db7a4d97da8108ae85751eb13c4cc64c92","948":"https:\/\/www.semanticscholar.org\/paper\/f326e698768373b2dfdba9608f75841d55a9c6e5","949":"https:\/\/www.semanticscholar.org\/paper\/9649ce5d8b1546992304cba084de2ed6fa4a32ab","950":"https:\/\/www.semanticscholar.org\/paper\/abb90e08b106623961a2cbed107d2a7ec861b6f5","951":"https:\/\/www.semanticscholar.org\/paper\/637305a303d00dc57d9ce3435797b1f2282d81fb","952":"https:\/\/www.semanticscholar.org\/paper\/a3e6744f39b2fa2f133099832d84be8bb633c6cf","953":"https:\/\/www.semanticscholar.org\/paper\/9fac2ad81a561398506ce566d897f7169583b4f8","954":"https:\/\/www.semanticscholar.org\/paper\/3245c96d239994d5f2ab25b41196861977cbcee6","955":"https:\/\/www.semanticscholar.org\/paper\/f98e135986414cccf29aec593d547c0656e4d82c","956":"https:\/\/www.semanticscholar.org\/paper\/a609c93d72afa0721f9a7d03823e431e57233914","957":"https:\/\/www.semanticscholar.org\/paper\/3fb29d252cd7ef25936994d455c32e9d15e95c63","958":"https:\/\/www.semanticscholar.org\/paper\/3de0e65b87d59a21b35ea4d8b6173aab94b093b3","959":"https:\/\/www.semanticscholar.org\/paper\/59dc8b35813f2cb0a7d6663a0b7165495f41d6e7","960":"https:\/\/www.semanticscholar.org\/paper\/e697c495d35513c864e0123d5177210d56bf21a5","961":"https:\/\/www.semanticscholar.org\/paper\/4214ea56f7f145900e646556e125cba8dd5eb713","962":"https:\/\/www.semanticscholar.org\/paper\/0ef0b6d81b7304d475907098099fa1fd169c33c4","963":"https:\/\/www.semanticscholar.org\/paper\/515fd971491e165a30805f10079f2a18306cc57a","964":"https:\/\/www.semanticscholar.org\/paper\/da1a9266ef25c988b4cc30ab8adc0799b775b140","965":"https:\/\/www.semanticscholar.org\/paper\/330eb6a85a974e132f738353f85824f360a92f2c","966":"https:\/\/www.semanticscholar.org\/paper\/b0d1b2812c2499dbe635f0f33f0948ce9ad4cf89","967":"https:\/\/www.semanticscholar.org\/paper\/2aaae14aad0dc7612a1af5053207b3f3c6340772","968":"https:\/\/www.semanticscholar.org\/paper\/7244122d7a8039c7d35f431b581b1894725dc79c","969":"https:\/\/www.semanticscholar.org\/paper\/cb37918708c3cc8f1c5c06fd035bb60b4a55c2bd","970":"https:\/\/www.semanticscholar.org\/paper\/fabd293157b9c579fe4f166980d69cd792632763","971":"https:\/\/www.semanticscholar.org\/paper\/f3bc763fbf924ce363d06833c52f22ea9ab83c10","972":"https:\/\/www.semanticscholar.org\/paper\/141eb2166b7ce3f4bfcd1bcdfae068da0b25cba7","973":"https:\/\/www.semanticscholar.org\/paper\/67be8e7047ffb8a0d76bc6148a865cafd2b24199","974":"https:\/\/www.semanticscholar.org\/paper\/1639113de8f6deb89c458b1a5c68280b8c4c764b","975":"https:\/\/www.semanticscholar.org\/paper\/9ee68ae6997914df4e122729c4735e24e6840aee","976":"https:\/\/www.semanticscholar.org\/paper\/e245f15bdddac514454fecf32f2a3ecb069f6dec","977":"https:\/\/www.semanticscholar.org\/paper\/e85f83d76b443795a9aee58e51c6cd76834c59f9","978":"https:\/\/www.semanticscholar.org\/paper\/8f953e700223309674a2329a8fbe41f9f58f2f5b","979":"https:\/\/www.semanticscholar.org\/paper\/02fdee1a6130ac2af220b1331c738e95c89e19e9","980":"https:\/\/www.semanticscholar.org\/paper\/3ce573e678778ead8db852780d00075967962d83","981":"https:\/\/www.semanticscholar.org\/paper\/562dc3493879c6605d1981b173ec2020e4d6e903","982":"https:\/\/www.semanticscholar.org\/paper\/60c1f0796e68b594e3e3d726632c27ce54b8eb0b","983":"https:\/\/www.semanticscholar.org\/paper\/7e579e3d1b4f27da51625b985439433b9fa77280","984":"https:\/\/www.semanticscholar.org\/paper\/d6246cc6ace146bc8c1f4b004370386878b634fe","985":"https:\/\/www.semanticscholar.org\/paper\/fff6bb9e7e9cbbe951f6a5b823be4b05896696e5","986":"https:\/\/www.semanticscholar.org\/paper\/0399b9211e6ddb6a74a8a0bf54aca7ab5c8de296","987":"https:\/\/www.semanticscholar.org\/paper\/e9de3570a34c05df980ffa9b4e8eb1913ec2643d","988":"https:\/\/www.semanticscholar.org\/paper\/ce4876ed845d8e041111d674dbcfdd4b2957a8e6","989":"https:\/\/www.semanticscholar.org\/paper\/958c7ca303e1ce8f04bf7abdf106bf9044560afc","990":"https:\/\/www.semanticscholar.org\/paper\/1be329a8b514e9be985f6df42d2091ade2c42d85","991":"https:\/\/www.semanticscholar.org\/paper\/d6c7bf822a75d07ce318b4795e9aa1517d507e98","992":"https:\/\/www.semanticscholar.org\/paper\/cf9afb34557de5a524a3cebc6130da9bcf343b0f","993":"https:\/\/www.semanticscholar.org\/paper\/a61854cb81538a2edd667d84b6127d6b8b4501b2","994":"https:\/\/www.semanticscholar.org\/paper\/cc57fb7167266c37e52b5092fb01a4a736e5d2f7","995":"https:\/\/www.semanticscholar.org\/paper\/851a2d0f6295c294804095cf6735b8ccd204602b","996":"https:\/\/www.semanticscholar.org\/paper\/081a386a2a314b5bc2da6fd20ed3e7cafbcad76e","997":"https:\/\/www.semanticscholar.org\/paper\/edcb7cf5a4671041038fdcce918759477e376159","998":"https:\/\/www.semanticscholar.org\/paper\/22421f2dbe66d1981c695986450b943c849865a2","999":"https:\/\/www.semanticscholar.org\/paper\/44ced4b9c1536c1ec620d48d68aec7f8e982c12f","1000":"https:\/\/www.semanticscholar.org\/paper\/b8fe3db4399019577ad4e6aa8ab668ab40a93cf0","1001":"https:\/\/www.semanticscholar.org\/paper\/c167c000a53365c4456681c8246ebf5bb600ffc1","1002":"https:\/\/www.semanticscholar.org\/paper\/b7d01b084ae45eab1485cdcef0f229631ed9dbf4","1003":"https:\/\/www.semanticscholar.org\/paper\/5173e66b5ce4250878d57dcc45d9c51249660ca4","1004":"https:\/\/www.semanticscholar.org\/paper\/ae6f8134a17bf0e60116f740264dfc50e1417ed5","1005":"https:\/\/www.semanticscholar.org\/paper\/7d0a0d7f2a085b41981361f6e385c168258ffd5e","1006":"https:\/\/www.semanticscholar.org\/paper\/e0afc89232082d4c5002832ef939bc642ba51fe5","1007":"https:\/\/www.semanticscholar.org\/paper\/04f4e55e14150b7c48b0287ba77c7443df76ed45","1008":"https:\/\/www.semanticscholar.org\/paper\/79c5a02c387c90202e66d7a36942a94e0dba8c70","1009":"https:\/\/www.semanticscholar.org\/paper\/29f98ae6090278ae98a9b1c87d8a6b77384be317","1010":"https:\/\/www.semanticscholar.org\/paper\/7cf3d3a4a027be71d840717843a5934b164ab76d","1011":"https:\/\/www.semanticscholar.org\/paper\/afa0f48dab3884c0a6e309699bf67efa2f8d5b61","1012":"https:\/\/www.semanticscholar.org\/paper\/c7923f0e978310d7b7e38d7a1ba798b8bc50690a","1013":"https:\/\/www.semanticscholar.org\/paper\/c1614112a4f2846e7855cd07a4d5364cc7408007","1014":"https:\/\/www.semanticscholar.org\/paper\/eab593108645e7e8ff23b4eec38196b628acc178","1015":"https:\/\/www.semanticscholar.org\/paper\/807dd08fa07aa796e9a74e058f19b605adf908e1","1016":"https:\/\/www.semanticscholar.org\/paper\/e5d17d6ec61c72471002e74a0b219f3cddd41059","1017":"https:\/\/www.semanticscholar.org\/paper\/174d95f8a81b12e8301cf60ccfde65dd5361a205","1018":"https:\/\/www.semanticscholar.org\/paper\/4bbb23119c815e643e453b72f2ef10f46da58eb4","1019":"https:\/\/www.semanticscholar.org\/paper\/26602f1e36bb08e8cb87ac5751eeade227725e6a","1020":"https:\/\/www.semanticscholar.org\/paper\/6493cf6e3a393772f878457864a51edb8da875f6","1021":"https:\/\/www.semanticscholar.org\/paper\/abd834ca7c3bb61e9a5724ebb190458d95481f72","1022":"https:\/\/www.semanticscholar.org\/paper\/466659a2016dae35337d1e78aba54a7766ba9e63","1023":"https:\/\/www.semanticscholar.org\/paper\/769fec9ee0a3402746692b8794d48c75b31987bb","1024":"https:\/\/www.semanticscholar.org\/paper\/6c106e060e84509c91928de2c8baeb7c4a86af03","1025":"https:\/\/www.semanticscholar.org\/paper\/9386c51d138311a1eba74c7f6d337dfc22010641","1026":"https:\/\/www.semanticscholar.org\/paper\/36b1ce08de25a44c056ffe4605772e8a2167d9a9","1027":"https:\/\/www.semanticscholar.org\/paper\/358fd1d7cc7fc9076f0bcfcc73f8526d13401532","1028":"https:\/\/www.semanticscholar.org\/paper\/62e86916443a40f799424458e49b3490f5a6b64b","1029":"https:\/\/www.semanticscholar.org\/paper\/0c194f2f36f0a6407f0c140fa795af353f1517e6","1030":"https:\/\/www.semanticscholar.org\/paper\/474dc11c51ec1f9821feb46622d3b1d76d4843ee","1031":"https:\/\/www.semanticscholar.org\/paper\/3f4a9554ca87fe2e065bb6f1f4bc40199ef6652c","1032":"https:\/\/www.semanticscholar.org\/paper\/be1038136200672519c7681e00621228faaa9e2f","1033":"https:\/\/www.semanticscholar.org\/paper\/12145bc1223441a7e83b96bfa750f4efc4facfb1","1034":"https:\/\/www.semanticscholar.org\/paper\/9cbc11bc8654e4c09237892dc4f5985e0b35d0a5","1035":"https:\/\/www.semanticscholar.org\/paper\/20d712bfba1c252b0aaea51e9b291549ef1e6c85","1036":"https:\/\/www.semanticscholar.org\/paper\/467047589b16ae15270b7aaa641ff33c9446fe80","1037":"https:\/\/www.semanticscholar.org\/paper\/0f0221f460fd4539a61d002dc38c2d8794dbeaa6","1038":"https:\/\/www.semanticscholar.org\/paper\/ee6c929b5829c735170e3ef07038f60a9de12d1d","1039":"https:\/\/www.semanticscholar.org\/paper\/bfc1c20084484edad6e71f968955c6e982f81d82","1040":"https:\/\/www.semanticscholar.org\/paper\/bf41b3470eccf12eed5edea4cf41d526b613b229","1041":"https:\/\/www.semanticscholar.org\/paper\/628246d1682c1256f773c79f8647f0bce85defbd","1042":"https:\/\/www.semanticscholar.org\/paper\/4defc309ccc5c5c4d92a08a9c61295a6326d1813","1043":"https:\/\/www.semanticscholar.org\/paper\/58316f7eb6221fc6f42daaedbc0a7a633e75ff69","1044":"https:\/\/www.semanticscholar.org\/paper\/e36caccdeb4d85842e46363b0938ef0235a8db6c","1045":"https:\/\/www.semanticscholar.org\/paper\/581b496cb9f561e5e27d57b41866f64ad35de98d","1046":"https:\/\/www.semanticscholar.org\/paper\/96eb52eef56cd0579582edbe8494bd7b3c9fdd93","1047":"https:\/\/www.semanticscholar.org\/paper\/2879f6eb47af06a01727afd4c6f14a0ad63d0dd4","1048":"https:\/\/www.semanticscholar.org\/paper\/7d7afee3d2397d5e03934b5b362e34875e27ffe5","1049":"https:\/\/www.semanticscholar.org\/paper\/8a9fd5b7f37af3f36941e527b1d0761816fd1bef","1050":"https:\/\/www.semanticscholar.org\/paper\/62b1ce65ca6fa2e5ccf85f457c25eba6e0ec3356","1051":"https:\/\/www.semanticscholar.org\/paper\/17b70d213bea6d39ecfa1c14d8fc8319b0fe18dd","1052":"https:\/\/www.semanticscholar.org\/paper\/fc7f723cc1e4a390dbf286a38d642b8b07bdb22f","1053":"https:\/\/www.semanticscholar.org\/paper\/979a4428bde364415d21c6231609eb4564df84a8","1054":"https:\/\/www.semanticscholar.org\/paper\/dc1b3af105dd4621578f770981f6596f9b9eeaf1","1055":"https:\/\/www.semanticscholar.org\/paper\/9236a1560acc4b41335e19f2885d70f8518125c2","1056":"https:\/\/www.semanticscholar.org\/paper\/a2ba499d29f7285f98a9dae97db22e24f0fcee0e","1057":"https:\/\/www.semanticscholar.org\/paper\/6d954bd1cba2d59f79d18bb15d5f5e464df2a665","1058":"https:\/\/www.semanticscholar.org\/paper\/e9af86233f9c1f444c3c33465f505428411b97c1","1059":"https:\/\/www.semanticscholar.org\/paper\/1432d44f04d4beb2f6cc34af0a5ea44d005c61c0","1060":"https:\/\/www.semanticscholar.org\/paper\/5af1e8b2f546ab8dbac7a35e89e5a2b2af7968d7","1061":"https:\/\/www.semanticscholar.org\/paper\/99fe63245121726cbab65847718ec10d5ab9355e","1062":"https:\/\/www.semanticscholar.org\/paper\/6ef21d5bf92ca5bab0ba304a12454e6d48b6527a","1063":"https:\/\/www.semanticscholar.org\/paper\/ecb00a6e83b35e7e05cb8ae341a2fa88d2e6016a","1064":"https:\/\/www.semanticscholar.org\/paper\/4b72e2345e11bc766e008acf7f3ce60e1a2f0411","1065":"https:\/\/www.semanticscholar.org\/paper\/ae456fa5af4e277c2125c094059451efc4dae346","1066":"https:\/\/www.semanticscholar.org\/paper\/6fe83fde68c05d19b64149f8f49d579d2dc15e35","1067":"https:\/\/www.semanticscholar.org\/paper\/4bc99bf60b1683ddff1c36a4987c1ea550649884","1068":"https:\/\/www.semanticscholar.org\/paper\/3728ab7974f5a2f3392ea0ded15c5104400004fb","1069":"https:\/\/www.semanticscholar.org\/paper\/6f5d58f834d2d357742947dc215092fe2bbd0aa3","1070":"https:\/\/www.semanticscholar.org\/paper\/e624fe8bc5a4d93e0e921d31b7005e0807d762f5","1071":"https:\/\/www.semanticscholar.org\/paper\/799133257e92d81b70ae97fe3b5038c93ffadedf","1072":"https:\/\/www.semanticscholar.org\/paper\/fb83c9a38055079f97f9e9f0d771ab13f98adc83","1073":"https:\/\/www.semanticscholar.org\/paper\/19f008fdc597014e18d2ae56be95aa509df1b3ea","1074":"https:\/\/www.semanticscholar.org\/paper\/9bc916203b8c039eca8acd16a7d2bb0aefc1f50b","1075":"https:\/\/www.semanticscholar.org\/paper\/b1cc1e2d2f3576d38d176dfa190504e58f5ff096","1076":"https:\/\/www.semanticscholar.org\/paper\/5d4f9dee7237634ab172814b5b5457c78ba13c71","1077":"https:\/\/www.semanticscholar.org\/paper\/d82343c9eb0d8e8e9c47e9652350411abb6058b0","1078":"https:\/\/www.semanticscholar.org\/paper\/30beb9509665db59679f07728483181ec1c3925a","1079":"https:\/\/www.semanticscholar.org\/paper\/237a2b25e1ced676b0ebe8ccaa0cd4b7c5adac6b","1080":"https:\/\/www.semanticscholar.org\/paper\/2078f6d5a27aa724d9803a613c3f3ed6359eed76","1081":"https:\/\/www.semanticscholar.org\/paper\/465b79c0e2ce7d25bdf456ac5ea393fef33f1862","1082":"https:\/\/www.semanticscholar.org\/paper\/2941b843d309576971106d520fd4b848a113504f","1083":"https:\/\/www.semanticscholar.org\/paper\/c6f44fcc7c8ed53c49179a00d3279a78fd3f618c","1084":"https:\/\/www.semanticscholar.org\/paper\/03d57f7c0628deb1f1d09fc2061226b2fb5791e2","1085":"https:\/\/www.semanticscholar.org\/paper\/c00850a19bf0f3676f9deb5baaa9dceda3528db4","1086":"https:\/\/www.semanticscholar.org\/paper\/0135a2788939b55f3676dac35821d2f4ff113c9e","1087":"https:\/\/www.semanticscholar.org\/paper\/050fd52f62f84eb71bde9de27a7a56e1a55c9c4a","1088":"https:\/\/www.semanticscholar.org\/paper\/caf5b10072c03fc78b4d4a5c007c8e9e1feaa0d4","1089":"https:\/\/www.semanticscholar.org\/paper\/050666368e3f6b3e7736495d5c2033a7ccec3245","1090":"https:\/\/www.semanticscholar.org\/paper\/46b120147cf66325ea4c5dc23cf62c72b07d2f9f","1091":"https:\/\/www.semanticscholar.org\/paper\/69c2ed18eca8c132be2f96147ee4e10d27d509f9","1092":"https:\/\/www.semanticscholar.org\/paper\/5e2a6e5430cb77bcf01d75a383f867faaa2c7c4b","1093":"https:\/\/www.semanticscholar.org\/paper\/b2125d912941244c243a33e31b01e34467cea457","1094":"https:\/\/www.semanticscholar.org\/paper\/f665c28c6d5acb171774b85f85970a0428000eb8","1095":"https:\/\/www.semanticscholar.org\/paper\/dbdfd22ec8b71d48ff100819235eff56a4a374a3","1096":"https:\/\/www.semanticscholar.org\/paper\/28625648fae0a1ba915c5d2a19c312841afc1b1c","1097":"https:\/\/www.semanticscholar.org\/paper\/406bf6b19f3aa936f51d3c878cd6ea0e658d986c","1098":"https:\/\/www.semanticscholar.org\/paper\/7895137ad9283d3e62141c15502765f5d739035e","1099":"https:\/\/www.semanticscholar.org\/paper\/06fb506703d8015b67d8f0ecdf01d7b23cd99f22","1100":"https:\/\/www.semanticscholar.org\/paper\/1ed82cc306245ef20bc9415aa32b703e80d63a7c","1101":"https:\/\/www.semanticscholar.org\/paper\/cc27ec53160d88c25fc5096c0df65536eb780de4","1102":"https:\/\/www.semanticscholar.org\/paper\/c1243acc6a98733f872617f9aec3208dddac3a20","1103":"https:\/\/www.semanticscholar.org\/paper\/a12d22ff91ce159a0d3558ed5aaed115115beabd","1104":"https:\/\/www.semanticscholar.org\/paper\/a179b6fdbaf2fbad5d7fe3dc0cc34351bc586439","1105":"https:\/\/www.semanticscholar.org\/paper\/cebc111b8c2668094058d92871a24f27a12f68de","1106":"https:\/\/www.semanticscholar.org\/paper\/2f42ec0d6fe1172122333b36337f09ff5d3d400b","1107":"https:\/\/www.semanticscholar.org\/paper\/fc089a09074c84979d1f34e89341318a5bc26d3d","1108":"https:\/\/www.semanticscholar.org\/paper\/2107fae2a198ec3c9f9592cf1f189a724575c70b","1109":"https:\/\/www.semanticscholar.org\/paper\/49b290f26bbe9b9d88c16558f5863f7621ea3831","1110":"https:\/\/www.semanticscholar.org\/paper\/57eb5a5d584844e140ac51f17d5c3f5a24802daf","1111":"https:\/\/www.semanticscholar.org\/paper\/baecf8a1e649162482879a28f795976b7230a31e","1112":"https:\/\/www.semanticscholar.org\/paper\/21c391666b2c50270649338b73448d72d8d52bd0","1113":"https:\/\/www.semanticscholar.org\/paper\/3202064ed8beacef7ddf26908d80fff2c0bdbf2f","1114":"https:\/\/www.semanticscholar.org\/paper\/ef57ad148ec2eeef5eb3467f3e37e30042b2c7bd","1115":"https:\/\/www.semanticscholar.org\/paper\/d482a85b80b48a3a3d70e024905f1d84e6b704c4","1116":"https:\/\/www.semanticscholar.org\/paper\/ccd16db1499fe683d449dc1981a223ef652d0547","1117":"https:\/\/www.semanticscholar.org\/paper\/fb2ab2c0203bfc85f233e0d37ef27cdddb75fb48","1118":"https:\/\/www.semanticscholar.org\/paper\/1d260eb591a05369d622c3de3eee654c4cfa5d0b","1119":"https:\/\/www.semanticscholar.org\/paper\/b2239452680e97c503a90f62ccdc8137a893b1e9","1120":"https:\/\/www.semanticscholar.org\/paper\/b3ef7b901d530a043a2846c717525bd8cbae0ecd","1121":"https:\/\/www.semanticscholar.org\/paper\/6426093d36d870c03349ecfdcc77d4877ffd69cf","1122":"https:\/\/www.semanticscholar.org\/paper\/524d9597f08dc62de4226ed8ed3580568f27387b","1123":"https:\/\/www.semanticscholar.org\/paper\/63776fc90b28557ab7c44d7a87271fa523831fa1","1124":"https:\/\/www.semanticscholar.org\/paper\/33951c245b5fdfb9c47183f3510feeb12bc6d820","1125":"https:\/\/www.semanticscholar.org\/paper\/dd8785b26e9efe8bf23a96850e53b4f913b8ffa5","1126":"https:\/\/www.semanticscholar.org\/paper\/956b7233536f90eca3a0100bc5ee96b055b2e018","1127":"https:\/\/www.semanticscholar.org\/paper\/9dd4499768ffaffb13699bb60cb2f307219be7b8","1128":"https:\/\/www.semanticscholar.org\/paper\/74ca163326c1e8ca076bfd7d1355f58c9a772777","1129":"https:\/\/www.semanticscholar.org\/paper\/f9700e31a1d0ae34d4571ab056dfb268c1543349","1130":"https:\/\/www.semanticscholar.org\/paper\/142cd4a2a1bf744836b2143d795742a3f5e33bae","1131":"https:\/\/www.semanticscholar.org\/paper\/d1efc73871819d4be944e23cecf5c71498bca6ea","1132":"https:\/\/www.semanticscholar.org\/paper\/79723af0e87b274403df5bcfc299eebfbc741a23","1133":"https:\/\/www.semanticscholar.org\/paper\/e4521d118deb42ddbf910f7b56d94e08dc43737a","1134":"https:\/\/www.semanticscholar.org\/paper\/053b1d7b97eb2c91fc3921d589c160b0923c70b1","1135":"https:\/\/www.semanticscholar.org\/paper\/761e606b19c48d03b077d5b9c37652260d18f073","1136":"https:\/\/www.semanticscholar.org\/paper\/387b42c3f00dc456d46929a2d44cc2f2df367722","1137":"https:\/\/www.semanticscholar.org\/paper\/e3eaf3c461114bc34675b0aa33e48ac0be003451","1138":"https:\/\/www.semanticscholar.org\/paper\/61bee52afa721d13982289497f3408e54444f85b","1139":"https:\/\/www.semanticscholar.org\/paper\/83c369bf89d10f51eda020a94c78cc5ad9439ad4","1140":"https:\/\/www.semanticscholar.org\/paper\/3eeda31b131ae2c9586195b5ee7f66e6bf4a1cfc","1141":"https:\/\/www.semanticscholar.org\/paper\/f3d824579462eb6bd0f937a72ab3628d693298f6","1142":"https:\/\/www.semanticscholar.org\/paper\/11fd262d0b19a2aab6ee708de58c277c1a649100","1143":"https:\/\/www.semanticscholar.org\/paper\/d3a51e365df8835b9ef8df3622e214e45ce94a68","1144":"https:\/\/www.semanticscholar.org\/paper\/b9b6279ccdf5b240edf417d4b72d861305ebff76","1145":"https:\/\/www.semanticscholar.org\/paper\/75ecde2254629218efbefca7ffd528f9add2fcf6","1146":"https:\/\/www.semanticscholar.org\/paper\/2f3bfd8f11cc55aea33b61e23457572236664df8","1147":"https:\/\/www.semanticscholar.org\/paper\/219358576504cb077b3a272a915ddca118b37148","1148":"https:\/\/www.semanticscholar.org\/paper\/2fab3ce1cb9435270cd9ab1e738f301216468e08","1149":"https:\/\/www.semanticscholar.org\/paper\/80122c63a7e0fb4912930e5e17da563e4fb5aec3","1150":"https:\/\/www.semanticscholar.org\/paper\/4fe2a62f644e11a6fb86755bc24907ee1ec06106","1151":"https:\/\/www.semanticscholar.org\/paper\/6f750d835cb673cd00e0f0a8ecf654dd2c7e7bbd","1152":"https:\/\/www.semanticscholar.org\/paper\/0e04f9cd65f982f604e04df5582afcfc1b6faad9","1153":"https:\/\/www.semanticscholar.org\/paper\/93c330fb4bcf8128e40b6c5a0521a95e7de94f84","1154":"https:\/\/www.semanticscholar.org\/paper\/030839a20362e90b6029deb4919d337d100f1699","1155":"https:\/\/www.semanticscholar.org\/paper\/6cb3cb4e26d10a78f536a25d5ddd826d82ae89e4","1156":"https:\/\/www.semanticscholar.org\/paper\/8c2f5ed9efe3985ded8ee724dffc6ebf1f082493","1157":"https:\/\/www.semanticscholar.org\/paper\/1d9adfeca5715ec82e2c1aa149a861af93d2f504","1158":"https:\/\/www.semanticscholar.org\/paper\/1b8e778a47482e9e15b1fae6f1a12b45c789ca78","1159":"https:\/\/www.semanticscholar.org\/paper\/5ae312a92eac01c3d4e83ee6900d5a3d1953637e","1160":"https:\/\/www.semanticscholar.org\/paper\/08bce75dca134da0f41fd03086c63b3d098b44e3","1161":"https:\/\/www.semanticscholar.org\/paper\/f2366da1c6e7d8140b240011fda83c198313a917","1162":"https:\/\/www.semanticscholar.org\/paper\/67afb6a15a0bdf85b92d772c363e84518f338154","1163":"https:\/\/www.semanticscholar.org\/paper\/7257828fc353db18052636f862239b79736e89ac","1164":"https:\/\/www.semanticscholar.org\/paper\/e187661e7f32308b27c5819dba3516dbcb05d407","1165":"https:\/\/www.semanticscholar.org\/paper\/893fa2e6543173b41fa1fb8ba0a7c0fe2b3a3bbd","1166":"https:\/\/www.semanticscholar.org\/paper\/6fc4201b44ede5e46ed82920b60b2ea24eda21e4","1167":"https:\/\/www.semanticscholar.org\/paper\/659ed8f917a504831e0e4d5e69eef79060b2cee5","1168":"https:\/\/www.semanticscholar.org\/paper\/dc5bee57f5fdca7501fd953b62061c2918ed8ff0","1169":"https:\/\/www.semanticscholar.org\/paper\/4e47dceded52c76c900fb2fc6b54afb2255aadd9","1170":"https:\/\/www.semanticscholar.org\/paper\/1bb2239de17963cf786079d133be2c26b0d08799","1171":"https:\/\/www.semanticscholar.org\/paper\/624b3420a8bf55629590eee02abe2f9d861e9493","1172":"https:\/\/www.semanticscholar.org\/paper\/34ee9f67473de616957ae1a0783eaf6857d201a2","1173":"https:\/\/www.semanticscholar.org\/paper\/d1d5d969604f2bfdc1e2f6dbd33a00fe0b4ec1c7","1174":"https:\/\/www.semanticscholar.org\/paper\/6c6006eb1739888b8cf8958b6fcfc724f02efa12","1175":"https:\/\/www.semanticscholar.org\/paper\/21fa352ae23c3f4753339d6be150ff2af484fe53","1176":"https:\/\/www.semanticscholar.org\/paper\/73d3f057e32abf9ef3f23b785a460d4722d29101","1177":"https:\/\/www.semanticscholar.org\/paper\/b828f0e23681a37193dedadbd4a1b32c3032f801","1178":"https:\/\/www.semanticscholar.org\/paper\/e77081ffee14d951d0b3e80c09b7ddd25080531f","1179":"https:\/\/www.semanticscholar.org\/paper\/a7c878eb0873546ac7342509a1a2057c81aca5c6","1180":"https:\/\/www.semanticscholar.org\/paper\/293e5e43440824b3fa19ccedec3d25ec97b66b59","1181":"https:\/\/www.semanticscholar.org\/paper\/e209dad684babb640c2181ea065e956d03b2ebeb","1182":"https:\/\/www.semanticscholar.org\/paper\/4e9d4b3d89b4dec3d313c3295c70d3afff6ae50f","1183":"https:\/\/www.semanticscholar.org\/paper\/5744b9d04f8a37cc5081a18158025a9b4252a34f","1184":"https:\/\/www.semanticscholar.org\/paper\/8cbe65f2df03ca874792a0651ed29c7c04dc6e5b","1185":"https:\/\/www.semanticscholar.org\/paper\/de70887ce7770ea99afb61319d04887bc6e850aa","1186":"https:\/\/www.semanticscholar.org\/paper\/0b11343d4f247826e725a458465174aa2578e52a","1187":"https:\/\/www.semanticscholar.org\/paper\/318d7da35307221267b6ce6ead995cc812245abb","1188":"https:\/\/www.semanticscholar.org\/paper\/25586b8f46f773876e6e7f78d8dc70e48b8630a7","1189":"https:\/\/www.semanticscholar.org\/paper\/d1234bc63fae2840b7e4b3d6956665d5f96beaf9","1190":"https:\/\/www.semanticscholar.org\/paper\/508b55bed9187adabdd1db7c7bd0bca4b1c221bf","1191":"https:\/\/www.semanticscholar.org\/paper\/987a6f8b6c5610b5ddd014b0e935d9eadfd6c6e6","1192":"https:\/\/www.semanticscholar.org\/paper\/3a86c96e20544bc597fea6ff675a6caeb017a04d","1193":"https:\/\/www.semanticscholar.org\/paper\/e08716f95a8a3b8644bcc395493332c215af4384","1194":"https:\/\/www.semanticscholar.org\/paper\/0d2e7401ffbc02ba0fec5e82e0231096240c1c36","1195":"https:\/\/www.semanticscholar.org\/paper\/2efaa3fba38290c404ba19635cb6219d33903a32","1196":"https:\/\/www.semanticscholar.org\/paper\/08b769b0017cd515b2f3fa802fb460cfb2208a63","1197":"https:\/\/www.semanticscholar.org\/paper\/51c5568260ad615954e51ea3782658f4c02cf97b","1198":"https:\/\/www.semanticscholar.org\/paper\/f1c304409006816d3c571de2f56d3959560e71cb","1199":"https:\/\/www.semanticscholar.org\/paper\/2a37d287b5852fe5863aadee5c5fdeb6b0c56400","1200":"https:\/\/www.semanticscholar.org\/paper\/0dcf170200969c29476284619dcc438070abe488","1201":"https:\/\/www.semanticscholar.org\/paper\/0ccbc077ce72212523249af52ed91d79bc2a8d43","1202":"https:\/\/www.semanticscholar.org\/paper\/c02602b2df00d450fc4dbb99124e2304d8738b45","1203":"https:\/\/www.semanticscholar.org\/paper\/50daeb780c4cc7be9f71bb5c412e460daf4b2c29","1204":"https:\/\/www.semanticscholar.org\/paper\/9ebb28851b253817f9a0ea5ddc22b0fd9a934a2f","1205":"https:\/\/www.semanticscholar.org\/paper\/93c49dab92ac5629c694a943bdc85ddcacee478f","1206":"https:\/\/www.semanticscholar.org\/paper\/662d4a9d7ee2b3f546c2256fbc4cf3f148d0975e","1207":"https:\/\/www.semanticscholar.org\/paper\/1ab77a3b287a982bec1f2800e74c63fab044c228","1208":"https:\/\/www.semanticscholar.org\/paper\/cedc6a965d17ceaba7fcf8cb96c33059dadcc992","1209":"https:\/\/www.semanticscholar.org\/paper\/985799f90821b3f8a623f074e89646a21772b3c5","1210":"https:\/\/www.semanticscholar.org\/paper\/ddcd5aba9241ea0741aa1d0a848279bea8534700","1211":"https:\/\/www.semanticscholar.org\/paper\/a13e12001c86744691cac77cf76a60b13780ec62","1212":"https:\/\/www.semanticscholar.org\/paper\/714f89ff31f36ba21326ef186e1079bf6d60def6","1213":"https:\/\/www.semanticscholar.org\/paper\/b1a85444c8e36f9ea947b754d4c28112c39d2f05","1214":"https:\/\/www.semanticscholar.org\/paper\/151cf0fee24983e5b082919ac10f5c0bb85f90ad","1215":"https:\/\/www.semanticscholar.org\/paper\/04b19040f839acced222aae998aad49f39c22eca","1216":"https:\/\/www.semanticscholar.org\/paper\/3080c78504793228de18d3a35e81ddc087f5ac92","1217":"https:\/\/www.semanticscholar.org\/paper\/b1df58f7500672d9c502399bfff2082c3078cca0","1218":"https:\/\/www.semanticscholar.org\/paper\/7535722e0ed79a2d1a232699b839667206e44e49","1219":"https:\/\/www.semanticscholar.org\/paper\/564d2cba001b646797df22395cbfdf4a3ff77c7a","1220":"https:\/\/www.semanticscholar.org\/paper\/79412a99e05399d4e08f660fbe2976eb359ecb90","1221":"https:\/\/www.semanticscholar.org\/paper\/1c313e5815279cd1734d2888ecb06949d2cdef33","1222":"https:\/\/www.semanticscholar.org\/paper\/2f6a8419704b4365b9749f5078460d158dacbddc","1223":"https:\/\/www.semanticscholar.org\/paper\/6bd91f7a0a7d22b8cd07e12b3b0c08f4f570438f","1224":"https:\/\/www.semanticscholar.org\/paper\/0a075b88574b2c38de5fedfad77adebb5b86bed8","1225":"https:\/\/www.semanticscholar.org\/paper\/d1665aebe8167ea9a08dc98bc9375b2ff007a0e5","1226":"https:\/\/www.semanticscholar.org\/paper\/56b2cf80ddabc5cdfe1764983e5f7b2042b7ea45","1227":"https:\/\/www.semanticscholar.org\/paper\/a44f885f11ee044a74df02700dbbe809f9b8bb6a","1228":"https:\/\/www.semanticscholar.org\/paper\/04ebddfdb7071eca323b88121e0f710ba4d0db4a","1229":"https:\/\/www.semanticscholar.org\/paper\/39c4719baa2fc973aefba530f4ddcd3de7267905","1230":"https:\/\/www.semanticscholar.org\/paper\/9fd449fcd992cb8e2545fb93a30a1584f5590094","1231":"https:\/\/www.semanticscholar.org\/paper\/f9a376b2ba8af79f5e40b87712249c08bb01492f","1232":"https:\/\/www.semanticscholar.org\/paper\/264b76902a45d6bad17c46702867ee5df3ba3b89","1233":"https:\/\/www.semanticscholar.org\/paper\/37315eec3dbffa94c70ea0444b70cada867d2edf","1234":"https:\/\/www.semanticscholar.org\/paper\/58558a19deb9a48f4900c8460667debd5c2b0ecc","1235":"https:\/\/www.semanticscholar.org\/paper\/86328e0c84bf97ae9b0680c06c4886bc04fb63c1","1236":"https:\/\/www.semanticscholar.org\/paper\/c483351957d782ea50c89d61e126de03eacf984b","1237":"https:\/\/www.semanticscholar.org\/paper\/659934004e30eed9f898788d2e15a1a5f69a3293","1238":"https:\/\/www.semanticscholar.org\/paper\/7d44d849cc682f57469034338612ad950cc0fed8","1239":"https:\/\/www.semanticscholar.org\/paper\/71a631d7304e94e86a224b7f09796b41d42b35b3","1240":"https:\/\/www.semanticscholar.org\/paper\/636ea99bd965806a30fb75093a868f08ce904c4d","1241":"https:\/\/www.semanticscholar.org\/paper\/1cee732d31509174da6698d48bfa2dd6282d7912","1242":"https:\/\/www.semanticscholar.org\/paper\/c5fb7b0058edd59db171acd23dfee24333b64bc1","1243":"https:\/\/www.semanticscholar.org\/paper\/47d136cba4df34a32a8319676ce195ed0f51d774","1244":"https:\/\/www.semanticscholar.org\/paper\/b8241a76cbba63814401071a5302fd992e9fc7c9","1245":"https:\/\/www.semanticscholar.org\/paper\/d6644db83ecd9f03e0a3db904fd726d10e1eb474","1246":"https:\/\/www.semanticscholar.org\/paper\/10697fa73ca2fa833c6e32097a9195e95f6fdebd","1247":"https:\/\/www.semanticscholar.org\/paper\/b07d45f2b81e2d1c725fec614b4befbc87bb57de","1248":"https:\/\/www.semanticscholar.org\/paper\/24c62a9856b25a85078b4fe18eb5494f286b4b01","1249":"https:\/\/www.semanticscholar.org\/paper\/1c88b7980f190cfb275cc1be3d34a099d086abed","1250":"https:\/\/www.semanticscholar.org\/paper\/8feaa62983ef900910cccbd73387e0b0282fafdd","1251":"https:\/\/www.semanticscholar.org\/paper\/e4738c6151ce2087d0e5076a47200766fc4e0619","1252":"https:\/\/www.semanticscholar.org\/paper\/885aa7da53d1866d51f090904bbea832bde8c7a9","1253":"https:\/\/www.semanticscholar.org\/paper\/d5167d87ab6eaacfe81424e05c2282d75ad56368","1254":"https:\/\/www.semanticscholar.org\/paper\/b9c58fc0fe1cd789352fb3464d3f7c0965205113","1255":"https:\/\/www.semanticscholar.org\/paper\/5e397b1233bc737317a4f42e872b7235c9d36d65","1256":"https:\/\/www.semanticscholar.org\/paper\/de3baa7d68f1a0b3301c4bf00b615f1fc0d06690","1257":"https:\/\/www.semanticscholar.org\/paper\/23a0b0a4d12f9b6231bcff19bc179582c63a8bca","1258":"https:\/\/www.semanticscholar.org\/paper\/c49ecde0a5fc208bf09e10e3a577b2550e64e377","1259":"https:\/\/www.semanticscholar.org\/paper\/e386e85ded4ab8eb559df2d35995bb3bf6986678","1260":"https:\/\/www.semanticscholar.org\/paper\/19375ac6b75feceb55cf93e8b9cb6e0b43457e5e","1261":"https:\/\/www.semanticscholar.org\/paper\/81b15e49d44426acd32f0adb5e15f25a15e39973","1262":"https:\/\/www.semanticscholar.org\/paper\/a80ee310c79572f9b84bd855950dd25b3beee3e4","1263":"https:\/\/www.semanticscholar.org\/paper\/fedadbfa8c7c6c58cc93e97ad7d1f37dcd98849c","1264":"https:\/\/www.semanticscholar.org\/paper\/27756e444665dceac31bccca1feed1a5a2d888c2","1265":"https:\/\/www.semanticscholar.org\/paper\/c3d6eb7261f440219228ddb62ad926004cdf09b9","1266":"https:\/\/www.semanticscholar.org\/paper\/cdf03c30aac97537926e0651dc70d5ac56f58163","1267":"https:\/\/www.semanticscholar.org\/paper\/65b3d01cdbe69afe4d7a84faff26509d5e866407","1268":"https:\/\/www.semanticscholar.org\/paper\/dd609f6355fa51f525f2804df8eaf7ddc2a57142","1269":"https:\/\/www.semanticscholar.org\/paper\/5f2d846f5473f5ddc93b99cf77341e49c7914bb0","1270":"https:\/\/www.semanticscholar.org\/paper\/787d4ec9217a7ec08ed219002fb750badab06b44","1271":"https:\/\/www.semanticscholar.org\/paper\/faca88d23ea0c626d0b354e43fe8ab154b43b4d0","1272":"https:\/\/www.semanticscholar.org\/paper\/09f1b39a2e92860acb5ad6506766ca863e751e8e","1273":"https:\/\/www.semanticscholar.org\/paper\/00522bccaae8d28c8f08356b00eda82704bdf476"},"title":{"0":"Towards Ongoing Detection of Linguistic Bias on Wikipedia","1":"Machine Translationese: Effects of Algorithmic Bias on Linguistic Complexity in Machine Translation","2":"Automated identification of bias inducing words in news articles using linguistic and context-oriented features","3":"Can neural networks acquire a structural bias from raw linguistic data?","4":"Pretraining on Non-linguistic Structure as a Tool for Analyzing Learning Bias in Language Models","5":"The spectator bias in the linguistic descriptions of information structure","6":"Causal Effects of Linguistic Properties","7":"How Can We Accelerate Progress Towards Human-like Linguistic Generalization?","8":"Bad Seeds: Evaluating Lexical Methods for Bias Measurement","9":"Using Social and Linguistic Information to Adapt Pretrained Representations for Political Perspective Identification","10":"A Framework for the Computational Linguistic Analysis of Dehumanization","11":"Mitigating Demographic Bias in AI-based Resume Filtering","12":"Media Bias in German News Articles: A Combined Approach","13":"Probing Linguistic Features of Sentence-Level Representations in Neural Relation Extraction","14":"Probing Linguistic Features of Sentence-Level Representations in Relation Extraction","15":"Unintended Bias in Misogyny Detection","16":"In Plain Sight: Media Bias Through the Lens of Factual Reporting","17":"Comments Mining With TF-IDF: The Inherent Bias and Its Removal","18":"Ordering biases in cross-linguistic perspective: The interaction of serial order and structural level","19":"Women\u2019s Syntactic Resilience and Men\u2019s Grammatical Luck: Gender-Bias in Part-of-Speech Tagging and Dependency Parsing","20":"BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models","21":"Masked Language Model Scoring","22":"BERTs of a feather do not generalize together: Large variability in generalization across models with similar test set performance","23":"Measuring Social Biases in Grounded Vision and Language Embeddings","24":"What Was Written vs. Who Read It: News Media Profiling Using Text Analysis and Social Media Context","25":"A negative case analysis of visual grounding methods for VQA","26":"The Developmental Origins of Syntactic Bootstrapping","27":"Studying the Inductive Biases of RNNs with Synthetic Variations of Natural Languages","28":"Adversarial Regularization for Visual Question Answering: Strengths, Shortcomings, and Side Effects","29":"An End-to-End Generative Architecture for Paraphrase Generation","30":"Multimodal Fusion of BERT-CNN and Gated CNN Representations for Depression Detection","31":"Automated content analysis across six languages","32":"Reducing Gender Bias in Neural Machine Translation as a Domain Adaptation Problem","33":"Unmasking Contextual Stereotypes: Measuring and Mitigating BERT's Gender Bias","34":"It\u2019s Morphin\u2019 Time! Combating Linguistic Discrimination with Inflectional Perturbations","35":"Learning Rewards from Linguistic Feedback","36":"Learning Which Features Matter: RoBERTa Acquires a Preference for Linguistic Generalizations (Eventually)","37":"DeVLBert: Learning Deconfounded Visio-Linguistic Representations","38":"Learning Music Helps You Read: Using Transfer to Study Linguistic Structure in Language Models","39":"Analyzing Political Bias and Unfairness in News Articles at Different Levels of Granularity","40":"Universal linguistic inductive biases via meta-learning","41":"Multiple\u2010attribute group decision\u2010making based on power Bonferroni operators of linguistic q\u2010rung orthopair fuzzy numbers","42":"Linguistic Cues to Deception: Identifying Political Trolls on Social Media","43":"Multiple\u2010attribute group decision\u2010making method of linguistic q\u2010rung orthopair fuzzy power Muirhead mean operators based on entropy weight","44":"Lost in Translation: Loss and Decay of Linguistic Richness in Machine Translation","45":"GeDi: Generative Discriminator Guided Sequence Generation","46":"Predicting Inductive Biases of Pre-Trained Models","47":"Probing BERT in Hyperbolic Spaces","48":"Discovering and Categorising Language Biases in Reddit","49":"Counterfactual Samples Synthesizing for Robust Visual Question Answering","50":"Towards Debiasing Sentence Representations","51":"Automating Intention Mining","52":"Hindi-English Hate Speech Detection: Author Profiling, Debiasing, and Practical Perspectives","53":"Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction","54":"Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment","55":"Finding Microaggressions in the Wild: A Case for Locating Elusive Phenomena in Social Media Posts","56":"Perturbation Sensitivity Analysis to Detect Unintended Model Biases","57":"Controlling the Output Length of Neural Machine Translation","58":"Weak biases emerging from vocal tract anatomy shape the repeated transmission of vowels","59":"Word-order Biases in Deep-agent Emergent Communication","60":"Estimating Causal Effects of Tone in Online Debates","61":"Intrinsic Quality Assessment of Arguments","62":"Linguistic Steganography Based on Adaptive Probability Distribution","63":"WeaQA: Weak Supervision via Captions for Visual Question Answering","64":"Let's talk (efficiently) about us: Person systems achieve near-optimal compression","65":"Annotating Online Misogyny","66":"Linguistic Representation and Processing of Copredication","67":"Detecting Independent Pronoun Bias with Partially-Synthetic Data Generation","68":"Case, Word Order, and Language Learnability: Insights from Connectionist Modeling","69":"Automatically Learning Data Augmentation Policies for Dialogue Tasks","70":"Finding Concept-specific Biases in Form\u2013Meaning Associations","71":"On the Inductive Bias of Masked Language Modeling: From Statistical to Syntactic Dependencies","72":"A Cognitive Regularizer for Language Modeling","73":"They Are All Armed and Dangerous!: Biased Language Use in Crime News With Ingroup and Outgroup Perpetrators","74":"Multimodal datasets: misogyny, pornography, and malignant stereotypes","75":"Multimodal Inductive Transfer Learning for Detection of Alzheimer's Dementia and its Severity","76":"Crisis-DIAS: Towards Multimodal Damage Analysis - Deployment, Challenges and Assessment","77":"Grounded PCFG Induction with Images","78":"Latent Structure Models for Natural Language Processing","79":"Neural Machine Translation Doesn\u2019t Translate Gender Coreference Right Unless You Make It","80":"Towards Automatic Detection of Misinformation in Online Medical Videos","81":"Balancing out Bias: Achieving Fairness Through Training Reweighting","82":"Finding Hierarchical Structure in Neural Stacks Using Unsupervised Parsing","83":"Artificial Language Learning in Children","84":"Promoting science with linguistic devices: A large\u2010scale study of positive and negative words in academic writing","85":"Blogs and news sources coverage in altmetrics data providers: a comparative analysis by country, language, and subject","86":"Image Schemas and Concept Invention: Cognitive, Logical, and Linguistic Investigations","87":"A Unified Speaker Adaptation Method for Speech Synthesis using Transcribed and Untranscribed Speech with Backpropagation","88":"Predicting retrosynthetic pathways using a combined linguistic model and hyper-graph exploration strategy","89":"Socially Aware Bias Measurements for Hindi Language Representations","90":"Machine learning for learner English","91":"Interpreting Silent Gesture: Cognitive Biases and Rational Inference in Emerging Language Systems","92":"Binary Image Selection (BISON): Interpretable Evaluation of Visual Grounding","93":"FrameAxis: Characterizing Framing Bias and Intensity with Word Embedding","94":"Moral Framing and Ideological Bias of News","95":"Automatically Neutralizing Subjective Bias in Text","96":"Enabling News Consumers to View and Understand Biased News Coverage: A Study on the Perception and Visualization of Media Bias","97":"From Theory Bias to Theory Dialogue: Embracing Cognitive, Situated, and Critical Framings of Computational Thinking in K-12 CS Education","98":"The echo chamber effect on social media","99":"Rarefaction, Alpha Diversity, and Statistics","100":"Social Bias Frames: Reasoning about Social and Power Implications of Language","101":"Bias in data\u2010driven artificial intelligence systems\u2014An introductory survey","102":"Framing pictures: A conceptual framework to identify and correct for biases in detection probability of camera traps enabling multi\u2010species comparison","103":"CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning","104":"Megapixel time-gated SPAD image sensor for 2D and 3D imaging applications","105":"Controlling Polarization in Personalization: An Algorithmic Framework","106":"The EC-Earth3 Earth System Model for the Climate Model\nIntercomparison Project 6","107":"Removal of high frequency contamination from motion estimates in single-band fMRI saves data without biasing functional connectivity","108":"Multiple Video Frame Interpolation via Enhanced Deformable Separable Convolution","109":"Compression based bound for non-compressed network: unified generalization error analysis of large compressible deep neural network","110":"How A\/B Tests Could Go Wrong: Automatic Diagnosis of Invalid Online Experiments","111":"Toward situated interventions for algorithmic equity: lessons from the field","112":"Nonlinear Stochastic Estimators on the Special Euclidean Group SE(3) Using Uncertain IMU and Vision Measurements","113":"Stance Detection Benchmark: How Robust Is Your Stance Detection?","114":"ScopeFlow: Dynamic Scene Scoping for Optical Flow","115":"Studying Up Machine Learning Data: Why Talk About Bias When We Mean Power?","116":"How to Assess the Epistemic Wrongness of Sponsorship Bias? The Case of Manufactured Certainty","117":"Does kindness towards robots lead to virtue? A reply to Sparrow's asymmetry argument","118":"Studying Up Machine Learning Data","119":"Topic models do not model topics: epistemological remarks and steps towards best practices","120":"Detecting race and gender bias in visual representation of AI on web search engines","121":"Media Bias Everywhere? A Vision for Dealing with the Manipulation of Public Opinion","122":"Advances in Bias and Fairness in Information Retrieval: Second International Workshop on Algorithmic Bias in Search and Recommendation, BIAS 2021, Lucca, Italy, April 1, 2021, Proceedings","123":"Measuring Bias in Contextualized Word Representations","124":"Examining Video Recommendation Bias on YouTube","125":"Mitigating Gender Bias in Machine Learning Data Sets","126":"Perception-Aware Bias Detection for Query Suggestions","127":"Preliminary Experiments to Examine the Stability of Bias-Aware Techniques","128":"Quantification of the Impact of Popularity Bias in Multi-stakeholder and Time-Aware Environments","129":"Equalizing Gender Bias in Neural Machine Translation with Word Embeddings Techniques","130":"Bias and Social Aspects in Search and Recommendation: First International Workshop, BIAS 2020, Lisbon, Portugal, April 14, Proceedings","131":"Evaluating the Underlying Gender Bias in Contextualized Word Embeddings","132":": Exploring the Bias of Web Domains Through the Eyes of Users","133":"On Measuring Gender Bias in Translation of Gender-neutral Pronouns","134":"Debiasing Embeddings for Reduced Gender Bias in Text Classification","135":"Proposed Taxonomy for Gender Bias in Text; A Filtering Methodology for the Gender Generalization Subtype","136":"The Role of Protected Class Word Lists in Bias Identification of Contextualized Word Representations","137":"Fair and Adequate Explanations","138":"Greek MOOC of Experiments with Simple Materials for Students Generates Significant Findings for Teachers and Physics Education","139":"Incentives for Item Duplication Under Fair Ranking Policies","140":"Fairness Deconstructed: A Sociotechnical View of 'Fair' Algorithms in Criminal Justice","141":"Users' Perception of Search Engine Biases and Satisfaction","142":"When Is a Recommendation Model Wrong? A Model-Agnostic Tree-Based Approach to Detecting Biases in Recommendations","143":"Adequate and fair explanations","144":"Facets of Fairness in Search and Recommendation","145":"Effect of Debiasing on Information Retrieval","146":"Recommendation Filtering \u00e0 la carte for Intelligent Tutoring Systems","147":"Look Again at the Syntax: Relational Graph Convolutional Network for Gendered Ambiguous Pronoun Resolution","148":"Transfer Learning from Pre-trained BERT for Pronoun Resolution","149":"Gendered Pronoun Resolution using BERT and an Extractive Question Answering Formulation","150":"BERT Masked Language Modeling for Co-reference Resolution","151":"Why Do We Need to Be Bots? What Prevents Society from Detecting Biases in Recommendation Systems","152":"Matchmaking Under Fairness Constraints: A Speed Dating Case Study","153":"Good Secretaries, Bad Truck Drivers? Occupational Gender Stereotypes in Sentiment Analysis","154":"Analyzing the Laws of MIL: a Five-step Scientific Conversation on Critical Information Literacy","155":"The Paradox of the \u201cTop Specialist\u201d and the Heuristics of Reputation","156":"Anonymized BERT: An Augmentation Approach to the Gendered Pronoun Resolution Challenge","157":"Machine learning to help researchers evaluate biases in clinical trials: a prospective, randomized user study","158":"Search engines, cognitive biases and the man\u2013computer interaction: a theoretical framework for empirical researches about cognitive biases in online search on health-related topics","159":"A nested computational social science approach for deep-narrative analysis in energy policy research","160":"Triangulated Rank-ordering of Web domains","161":"Not a Mirror, but an Engine: Digital Methods for Contextual Analysis of \u201cSocial Big Data\u201d","162":"Computability, Complexity, Consistency and Controllability: A Four C's Framework for cross-disciplinary Ethical Algorithm Research","163":"Promises and Challenges of Causality for Ethical Machine Learning","164":"Understanding CSCL Through the Lens of Research Syntheses","165":"Syntactic and Semantic Bias Detection and Countermeasures","166":"Self-Attention in Reconstruction Bias U-Net for Semantic Segmentation of Building Rooftops in Optical Remote Sensing Images","167":"Bias in Bios: A Case Study of Semantic Representation Bias in a High-Stakes Setting","168":"Reinforcement of Semantic Representations in Pragmatic Agents Leads to the Emergence of a Mutual Exclusivity Bias","169":"GraPPa: Grammar-Augmented Pre-Training for Table Semantic Parsing","170":"Inductive Structure Consistent Hashing via Flexible Semantic Calibration","171":"PiCIE: Unsupervised Semantic Segmentation using Invariance and Equivariance in Clustering","172":"Re-distributing Biased Pseudo Labels for Semi-supervised Semantic Segmentation: A Baseline Investigation","173":"On the Texture Bias for Few-Shot CNN Segmentation","174":"Causal Intervention for Weakly-Supervised Semantic Segmentation","175":"Mitigating Political Bias in Language Models Through Reinforced Calibration","176":"Label-Driven Reconstruction for Domain Adaptation in Semantic Segmentation","177":"Domain-Aware Visual Bias Eliminating for Generalized Zero-Shot Learning","178":"Semantic Concentration for Domain Adaptation","179":"Gender Bias in Multilingual Embeddings and Cross-Lingual Transfer","180":"Multi-Dimensional Gender Bias Classification","181":"Bias-Based Universal Adversarial Patch Attack for Automatic Check-Out","182":"FrameAxis: characterizing microframe bias and intensity with word embedding","183":"Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation","184":"Graph Transformer Networks with Syntactic and Semantic Structures for Event Argument Extraction","185":"Criminal tendency detection from facial images and the gender bias effect","186":"Set and Rebase: Determining the Semantic Graph Connectivity for Unsupervised Cross-Modal Hashing","187":"Comparative Evaluation of Label Agnostic Selection Bias in Multilingual Hate Speech Datasets","188":"Increasing the Robustness of Semantic Segmentation Models with Painting-by-Numbers","189":"Learning Unbiased Zero-Shot Semantic Segmentation Networks Via Transductive Transfer","190":"Attenuating Bias in Word Vectors","191":"Media Bias, the Social Sciences, and NLP: Automating Frame Analyses to Identify Bias by Word Choice and Labeling","192":"Scalable Zero-Shot Learning via Binary Visual-Semantic Embeddings","193":"Neutralizing Gender Bias in Word Embedding with Latent Disentanglement and Counterfactual Generation","194":"On the Transfer of Inductive Bias from Simulation to the Real World: a New Disentanglement Dataset","195":"BERT is Not an Interlingua and the Bias of Tokenization","196":"Semantically Aligned Bias Reducing Zero Shot Learning","197":"Recurrent generative adversarial network for learning imbalanced medical image semantic segmentation","198":"Learning Semantic Parsers from Denotations with Latent Structured Alignments and Abstract Programs","199":"Grid Saliency for Context Explanations of Semantic Segmentation","200":"Big BiRD: A Large, Fine-Grained, Bigram Relatedness Dataset for Examining Semantic Composition","201":"Deep Reinforcement Learning with Distributional Semantic Rewards for Abstractive Summarization","202":"Generalizable Feature Learning in the Presence of Data Bias and Domain Class Imbalance with Application to Skin Lesion Classification","203":"Center bias outperforms image salience but not semantics in accounting for attention during scene viewing","204":"Semantic variation operators for multidimensional genetic programming","205":"Illegal Aliens or Undocumented Immigrants? Towards the Automated Identification of Bias by Word Choice and Labeling","206":"Semantic influences on episodic memory distortions","207":"Global Saliency: Aggregating Saliency Maps to Assess Dataset Artefact Bias","208":"A Cognitive Model of Human Bias in Matching","209":"How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers","210":"Long-tailed Recognition by Routing Diverse Distribution-Aware Experts","211":"Good-Enough Compositional Data Augmentation","212":"Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview","213":"Re-thinking Co-Salient Object Detection","214":"Knowledge Graph Convolutional Networks for Recommender Systems","215":"Semantically-Guided Representation Learning for Self-Supervised Monocular Depth","216":"Why Normalizing Flows Fail to Detect Out-of-Distribution Data","217":"Fine-Grained Generalized Zero-Shot Learning via Dense Attribute-Based Attention","218":"PDAM: A Panoptic-Level Feature Alignment Framework for Unsupervised Domain Adaptive Instance Segmentation in Microscopy Images","219":"FREE: Feature Refinement for Generalized Zero-Shot Learning","220":"Interventional Video Relation Detection","221":"OSCaR: Orthogonal Subspace Correction and Rectification of Biases in Word Embeddings","222":"Co-Learning Non-Negative Correlated and Uncorrelated Features for Multi-View Data","223":"FairFil: Contrastive Neural Debiasing Method for Pretrained Text Encoders","224":"Zero-VAE-GAN: Generating Unseen Features for Generalized and Transductive Zero-Shot Learning","225":"Invertible Zero-Shot Recognition Flows","226":"Taking a Deeper Look at Co-Salient Object Detection","227":"A Learning Strategy for Contrast-agnostic MRI Segmentation","228":"Attention-Driven Dynamic Graph Convolutional Network for Multi-label Image Recognition","229":"Multimodal Summarization with Guidance of Multimodal Reference","230":"Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention","231":"Encoding History with Context-aware Representation Learning for Personalized Search","232":"A Variational Autoencoder with Deep Embedding Model for Generalized Zero-Shot Learning","233":"Nurse is Closer to Woman than Surgeon? Mitigating Gender-Biased Proximities in Word Embeddings","234":"Conception: Multilingually-Enhanced, Human-Readable Concept Vector Representations","235":"Attract or Distract: Exploit the Margin of Open Set","236":"Debiasing Gender biased Hindi Words with Word-embedding","237":"Towards Shape Biased Unsupervised Representation Learning for Domain Generalization","238":"GO functional similarity clustering depends on similarity measure, clustering method, and annotation completeness","239":"Domain-Specific Embedding Network for Zero-Shot Recognition","240":"Contextualized Diachronic Word Representations","241":"Compositional Generalization and Natural Language Variation: Can a Semantic Parsing Approach Handle Both?","242":"Investigating Gender Bias in BERT","243":"Exploiting a Joint Embedding Space for Generalized Zero-Shot Semantic Segmentation","244":"Modeling the Background for Incremental Learning in Semantic Segmentation","245":"Content-Consistent Matching for Domain Adaptive Semantic Segmentation","246":"Analysing Twitter semantic networks: the case of 2018 Italian elections","247":"A survey of loss functions for semantic segmentation","248":"Reducing Sentiment Bias in Language Models via Counterfactual Evaluation","249":"Implicit Attitudes Towards Robots Predict Explicit Attitudes, Semantic Distance Between Robots and Humans, Anthropomorphism, and Prosocial Behavior: From Attitudes to Human\u2013Robot Interaction","250":"Unsupervised Domain Adaptation for Semantic Segmentation by Content Transfer","251":"Interventions for ranking in the presence of implicit bias","252":"Deep Hough Transform for Semantic Line Detection","253":"Do You Think It's Biased? How To Ask For The Perception Of Media Bias","254":"Evaluation of Deep Neural Networks for Semantic Segmentation of Prostate in T2W MRI","255":"Diagnosing the Environment Bias in Vision-and-Language Navigation","256":"Domain Adaptation for Semantic Segmentation With Maximum Squares Loss","257":"Data-Free Quantization Through Weight Equalization and Bias Correction","258":"Time-Out: Temporal Referencing for Robust Modeling of Lexical Semantic Change","259":"Unbiased Scene Graph Generation via Rich and Fair Semantic Extraction","260":"Novel adversarial semantic structure deep learning for MRI-guided attenuation correction in brain PET\/MRI","261":"A Deep Learning Semantic Segmentation-Based Approach for Field-Level Sorghum Panicle Counting","262":"Biased competition in semantic representation during natural visual search","263":"Taming Transformers for High-Resolution Image Synthesis","264":"A ConvNet for the 2020s","265":"Intriguing Properties of Vision Transformers","266":"Interpreting Graph Neural Networks for NLP With Differentiable Edge Masking","267":"Generalized ODIN: Detecting Out-of-Distribution Image Without Learning From Out-of-Distribution Data","268":"Making Transformers Solve Compositional Tasks","269":"Microsoft Academic Graph: When experts are not enough","270":"Shape or Texture: Understanding Discriminative Features in CNNs","271":"CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation","272":"Global Relational Models of Source Code","273":"Reinforcement Learning Based Graph-to-Sequence Model for Natural Question Generation","274":"Reinforced active learning for image segmentation","275":"ERNIE-GEN: An Enhanced Multi-Flow Pre-training and Fine-tuning Framework for Natural Language Generation","276":"A General Framework for Implicit and Explicit Debiasing of Distributional Word Vector Spaces","277":"Unsupervised Instance Segmentation in Microscopy Images via Panoptic Domain Adaptation and Task Re-Weighting","278":"Pairwise Supervised Hashing with Bernoulli Variational Auto-Encoder and Self-Control Gradient Estimator","279":"Learning feature spaces for regression with genetic programming","280":"More is Better: Precise and Detailed Image Captioning Using Online Positive Recall and Missing Concepts Mining","281":"Query-Biased Self-Attentive Network for Query-Focused Video Summarization","282":"ProtoGAN: Towards Few Shot Learning for Action Recognition","283":"Analysing Neural Language Models: Contextual Decomposition Reveals Default Reasoning in Number and Gender Assignment","284":"Paraphrase Diversification Using Counterfactual Debiasing","285":"Zero-shot Image Recognition Using Relational Matching, Adaptation and Calibration","286":"LaTeS: Latent Space Distillation for Teacher-Student Driving Policy Learning","287":"Modeling Personal Biases in Language Use by Inducing Personalized Word Embeddings","288":"Demystifying Contrastive Self-Supervised Learning: Invariances, Augmentations and Dataset Biases","289":"GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering","290":"Compositional Explanations of Neurons","291":"GQA: a new dataset for compositional question answering over real-world images","292":"Visual Entailment: A Novel Task for Fine-Grained Image Understanding","293":"Distortion-Aware Monocular Depth Estimation for Omnidirectional Images","294":"DeepEP: a deep learning framework for identifying essential proteins","295":"Reconstruction Bias U-Net for Road Extraction From Optical Remote Sensing Images","296":"Universal Sentence Representation Learning with Conditional Masked Language Model","297":"Whose Truth is the \"Ground Truth\"? College Admissions Essays and Bias in Word Vector Evaluation Methods","298":"Targeted Adversarial Perturbations for Monocular Depth Prediction","299":"An Enhanced Neural Network Approach to Person-Job Fit in Talent Recruitment","300":"Predicting the Politics of an Image Using Webly Supervised Data","301":"Learning To Retrieve: How to Train a Dense Retrieval Model Effectively and Efficiently","302":"Structured Attention for Unsupervised Dialogue Structure Induction","303":"Tracing Antisemitic Language Through Diachronic Embedding Projections: France 1789-1914","304":"Procedural Reasoning Networks for Understanding Multimodal Procedures","305":"A Convolutional Cost-Sensitive Crack Localization Algorithm for Automated and Reliable RC Bridge Inspection","306":"BiasRV: uncovering biased sentiment predictions at runtime","307":"Novel Biased Normalized Cuts Approach for the Automatic Segmentation of the Conjunctiva","308":"Contrastive Syn-to-Real Generalization","309":"L2 Prediction during complex sentence processing","310":"Augmented example-based synthesis using relational perturbation properties","311":"Hierarchical Gated Recurrent Unit with Semantic Attention for Event Prediction","312":"Robust Semantic Interpretability: Revisiting Concept Activation Vectors","313":"Bidirectional generative transductive zero-shot learning","314":"Zero-shot classification with unseen prototype learning","315":"Few-Shot Segmentation via Cycle-Consistent Transformer","316":"Fully Convolutional Networks with Multiscale 3D Filters and Transfer Learning for Change Detection in High Spatial Resolution Satellite Images","317":"MSnet: A BERT-based Network for Gendered Pronoun Resolution","318":"Cross-Sentence Temporal and Semantic Relations in Video Activity Localisation","319":"Automated Cardiovascular Pathology Assessment Using Semantic Segmentation and Ensemble Learning","320":"On Robustness and Bias Analysis of BERT-Based Relation Extraction","321":"Joint Adversarial Learning for Domain Adaptation in Semantic Segmentation","322":"Impact of Lung Segmentation on the Diagnosis and Explanation of COVID-19 in Chest X-ray Images","323":"Towards Standardizing and Improving Classification of Bug-Fix Commits","324":"Improving Model-Based Genetic Programming for Symbolic Regression of Small Expressions","325":"Digital begriffsgeschichte: Tracing semantic change using word embeddings","326":"Things2Vec: Semantic Modeling in the Internet of Things With Graph Representation Learning","327":"Prototypical Graph Contrastive Learning","328":"Semantic web or web of data? a diachronic study (1999 to 2017) of the publications of tim berners\u2010lee and the world wide web consortium","329":"Interpretable bias mitigation for textual data: Reducing genderization in patient notes while maintaining classification performance","330":"Multiobjective Sparse Non-Negative Matrix Factorization","331":"BERT has a Moral Compass: Improvements of ethical and moral values of machines","332":"Modelling Hierarchical Structure between Dialogue Policy and Natural Language Generator with Option Framework for Task-oriented Dialogue System","333":"Visualization of Supervised and Self-Supervised Neural Networks via Attribution Guided Factorization","334":"Task-Independent Knowledge Makes for Transferable Representations for Generalized Zero-Shot Learning","335":"Knowledge, belief, and egocentric bias","336":"Text-mining forma mentis networks reconstruct public perception of the STEM gender gap in social media","337":"Simple but Effective: CLIP Embeddings for Embodied AI","338":"Egoshots, an ego-vision life-logging dataset and semantic fidelity metric to evaluate diversity in image captioning models","339":"AMR Parsing with Action-Pointer Transformer","340":"Generalised Zero-Shot Learning with Domain Classification in a Joint Semantic and Visual Space","341":"Adaptively Scheduled Multitask Learning: The Case of Low-Resource Neural Machine Translation","342":"Topic Augmented Generator for Abstractive Summarization","343":"Diagnosing Transformers in Task-Oriented Semantic Parsing","344":"Probabilistic Modeling of Semantic Ambiguity for Scene Graph Generation","345":"Physical Accuracy of Deep Neural Networks for 2D and 3D Multi-Mineral Segmentation of Rock micro-CT Images","346":"Environment of Modeling Methods for Indicating Objects Based on Displaced Concepts","347":"Personality2vec: Network Representation Learning for Personality","348":"Deep Hierarchical Encoder\u2013Decoder Network for Image Captioning","349":"Nested-Wasserstein Self-Imitation Learning for Sequence Generation","350":"The Semantics of Dynamic Space in French","351":"Can Fine-tuning Pre-trained Models Lead to Perfect NLP? A Study of the Generalizability of Relation Extraction","352":"Conditional Generative Adversarial Refinement Networks for Unbalanced Medical Image Semantic Segmentation","353":"Data based predictive models for odor perception","354":"Self-Supervised Domain-Aware Generative Network for Generalized Zero-Shot Learning","355":"Bias-Awareness for Zero-Shot Learning the Seen and Unseen","356":"Experiencers, Stimuli, or Targets: Which Semantic Roles Enable Machine Learning to Infer the Emotions?","357":"Evaluating Semantic Representations of Source Code","358":"Assessing the Semantic Space Bias Caused by ASR Error Propagation and its Effect on Spoken Document Summarization","359":"On Sentence Representations for Propaganda Detection: From Handcrafted Features to Word Embeddings","360":"BHCMDA: A New Biased Heat Conduction Based Method for Potential MiRNA-Disease Association Prediction","361":"motif2vec: Motif Aware Node Representation Learning for Heterogeneous Networks","362":"Heterogeneous Few-Shot Model Rectification With Semantic Mapping","363":"Semantic Graph-enhanced Visual Network for Zero-shot Learning","364":"Validity Fuzzing and Parametric Generators for Effective Random Testing","365":"Video Question Answering with Phrases via Semantic Roles","366":"Systematicity in a Recurrent Neural Network by Factorizing Syntax and Semantics","367":"Quantifying the Natural Sentiment Strength of Polar Term Senses Using Semantic Gloss Information and Degree Adverbs","368":"Task Adaptive Metric Space for Medium-Shot Medical Image Classification","369":"Dynamic Hybrid Relation Network for Cross-Domain Context-Dependent Semantic Parsing","370":"TransZero: Attribute-guided Transformer for Zero-Shot Learning","371":"Increasing Shape Bias to Improve the Precision of Center Pivot Irrigation System Detection","372":"Cross-lingual Alignment Methods for Multilingual BERT: A Comparative Study","373":"DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation","374":"Attribute-Induced Bias Eliminating for Transductive Zero-Shot Learning","375":"The International Workshop on Osteoarthritis Imaging Knee MRI Segmentation Challenge: A Multi-Institute Evaluation and Analysis Framework on a Standardized Dataset","376":"How voluntary spatial attention influences feature biases in object correspondence","377":"Learning Visual-Semantic Embeddings for Reporting Abnormal Findings on Chest X-rays","378":"Evaluation of CNN Performance in Semantically Relevant Latent Spaces","379":"Code Generation from Natural Language with Less Prior Knowledge and More Monolingual Data","380":"Generating Expensive Relationship Features from Cheap Objects","381":"Give the Truth: Incorporate Semantic Slot into Abstractive Dialogue Summarization","382":"An End-to-End Human Segmentation by Region Proposed Fully Convolutional Network","383":"Transformers with Competitive Ensembles of Independent Mechanisms","384":"Robust Semantic Segmentation with Superpixel-Mix","385":"Auxiliary Signal-Guided Knowledge Encoder-Decoder for Medical Report Generation","386":"Distribution-Aware Semantics-Oriented Pseudo-label for Imbalanced Semi-Supervised Learning","387":"Analysis and Evaluation of Language Models for Word Sense Disambiguation","388":"The Inductive Bias of In-Context Learning: Rethinking Pretraining Example Design","389":"PowerTransformer: Unsupervised Controllable Revision for Biased Language Correction","390":"A Survey on Bias and Fairness in Machine Learning","391":"RoB 2: a revised tool for assessing risk of bias in randomised trials","392":"The Risk of Racial Bias in Hate Speech Detection","393":"Ethics and Bias in Machine Learning: A Technical Study of What Makes Us \u201cGood\u201d","394":"Examining Social Desirability Bias in Online and Offline Surveys","395":"On Measuring and Mitigating Biased Inferences of Word Embeddings","396":"THE MEANING OF PROBABILITY FROM A FOUNDATIONAL PERSPECTIVE","397":"Sentiment Analysis on IMDb Movie Reviews Using Hybrid Feature Extraction Method","398":"Conceptor Debiasing of Word Representations Evaluated on WEAT","399":"Clustering and Stereotyping","400":"Gendered Ambiguous Pronouns Shared Task: Boosting Model Confidence by Evidence Pooling","401":"Multilingual Contextual Affective Analysis of LGBT People Portrayals in Wikipedia","402":"Exploring Communication in the Real World","403":"Examining Gender Bias in Languages with Grammatical Gender","404":"Towards Debiasing NLU Models from Unknown Biases","405":"From Gender Biases to Gender-Inclusive Design: An Empirical Investigation","406":"Don\u2019t Take the Easy Way Out: Ensemble Based Methods for Avoiding Known Dataset Biases","407":"In Need of Bias Control: Evaluating Chemical Data for Machine Learning in Structure-Based Virtual Screening","408":"Understanding the Political Ideology of Legislators from Social Media Images","409":"We Can Detect Your Bias: Predicting the Political Ideology of News Articles","410":"Multi-Task Ordinal Regression for Jointly Predicting the Trustworthiness and the Leading Political Ideology of News Media","411":"Social Media Polarization and Echo Chambers in the Context of COVID-19: Case Study","412":"Modeling echo chambers and polarization dynamics in social networks","413":"Social media polarization and echo chambers: A case study of COVID-19","414":"Rumor Propagation is Amplified by Echo Chambers in Social Media","415":"Understanding Echo Chambers in E-commerce Recommender Systems","416":"The Effect of People Recommenders on Echo Chambers and Polarization","417":"Echo Chambers and Segregation in Social Networks: Markov Bridge Models and Estimation","418":"Mechanisms and Attributes of Echo Chambers in Social Media","419":"A Survey on Echo Chambers on Social Media: Description, Detection and Mitigation","420":"Echo Chambers on Social Media: A comparative analysis","421":"Public discourse and social network echo chambers driven by socio-cognitive biases","422":"Right-wing populism, social media and echo chambers in Western democracies","423":"Understanding Echo Chambers and Filter Bubbles: The Impact of Social Media on Diversification and Partisan Shifts in News Consumption","424":"Peer Review of \u201cSocial Media Polarization and Echo Chambers in the Context of COVID-19: Case Study\u201d","425":"Viral misinformation and echo chambers: the diffusion of rumors about genetically modified organisms on social media","426":"Echo Chambers Exist! (But They're Full of Opposing Views)","427":"The Manufacture of Political Echo Chambers by Follow Train Abuse on Twitter","428":"Users\u2019 Activity in Online Social Networks and the Formation of Echo Chambers","429":"Optimal Echo Chambers","430":"Echo chambers as early warning signals of widespread vaccine refusal in social-epidemiological networks","431":"Echo Chambers in Collaborative Filtering Based Recommendation Systems","432":"Evaluating the scale, growth, and origins of right-wing echo chambers on YouTube","433":"No echo in the chambers of political interactions on Reddit","434":"Social influence and unfollowing accelerate the emergence of echo chambers","435":"On the Inevitability of Online Echo Chambers","436":"Analyzing Echo Chambers: A Logic of Strong and Weak Ties","437":"A Sociolinguistic Study of Online Echo Chambers on Twitter","438":"Towards an Understanding of Conspiracy echo Chambers on Facebook","439":"The Fallacy of Echo Chambers: Analyzing the Political Slants of User-Generated News Comments in Korean Media","440":"Quantification of echo Chambers: a Methodological Framework considering Multi-Party Systems","441":"Lexical convergence inside and across echo chambers","442":"The Influence of Social Media filter bubbles and echo Chambers on IT Identity Construction","443":"Offline Consequences of Echo Chambers","444":"From confirmation bias to echo-chambers: a data-driven approach","445":"Falling into the Echo Chamber: the Italian Vaccination Debate on Twitter","446":"Escape from An Echo Chamber","447":"ChamberBreaker: Mitigating the Echo Chamber Effect and Supporting Information Hygiene through a Gamified Inoculation System","448":"The Dual Echo Chamber: Modeling Social Media Polarization for Interventional Recommending","449":"I Want to Break Free! Recommending Friends from Outside the Echo Chamber","450":"Toward a Standard Approach for Echo Chamber Detection: Reddit Case Study","451":"Echo chamber detection and analysis","452":"Out of the Echo Chamber: Detecting Countering Debate Speeches","453":"Quantifying echo chamber effects in information spreading over political communication networks","454":"Testing popular news discourse on the \"echo chamber\" effect: Does political polarisation occur among those relying on social media as their primary politics news source?","455":"Inside the Echo Chamber: Disentangling network dynamics from polarization","456":"Contrarian effects and echo chamber formation in opinion dynamics","457":"Learning from Shared News: When Abundant Information Leads to Belief Polarization","458":"Political Depolarization of News Articles Using Attribute-aware Word Embeddings","459":"EchoFakeD: improving fake news detection in social media with an efficient deep neural network","460":"Networked partisanship and framing: A socio-semantic network analysis of the Italian debate on migration","461":"Analyzing the Impact of Filter Bubbles on Social Network Polarization","462":"Topology comparison of Twitter diffusion networks effectively reveals misleading information","463":"DeepFakE: improving fake news detection using tensor decomposition-based deep neural network","464":"Vaccination strategies against COVID-19 and the diffusion of anti-vaccination views","465":"Cross-Partisan Discussions on YouTube: Conservatives Talk to Liberals but Liberals Don't Talk to Conservatives","466":"Facebook\u2019s ethical failures are not accidental; they are part of the business model","467":"Social Bots and Social Media Manipulation in 2020: The Year in Review","468":"Preference Amplification in Recommender Systems","469":"How do climate change skeptics engage with opposing views? Understanding mechanisms of social identity and cognitive dissonance in an online forum","470":"Degenerate Feedback Loops in Recommender Systems","471":"A model of opinion and propagation structure polarization in social media","472":"Exposure to news grows less fragmented with an increase in mobile access","473":"Spread of tweets in climate discussions: A case study of the 2019 Nobel Peace Prize announcement","474":"We are the Change that we Seek: Information Interactions During a Change of Viewpoint","475":"Positive algorithmic bias cannot stop fragmentation in homophilic networks","476":"Homophily on social networks changes evolutionary advantage in competitive information diffusion","477":"Measuring Political Personalization of Google News Search","478":"Characterizing networks of propaganda on twitter: a case study","479":"Opinion-based Homogeneity on YouTube","480":"Communal Quirks and Circlejerks: A Taxonomy of Processes Contributing to Insularity in Online Communities","481":"Neutral Bots Reveal Political Bias on Social Media","482":"Opinion Diversity and Social Bubbles in Adaptive Sznajd Networks","483":"An Accurate and Fast Cardio-Views Classification System Based on Fused Deep Features and LSTM","484":"The Paradox of Information Access: Growing Isolation in the Age of Sharing","485":"Online Intellectual Virtues and the Extended Mind","486":"Human Information Interaction and the Cognitive Predicting Theory of Trust","487":"Echocardiogram Analysis Using Motion Profile Modeling","488":"CrowdForest: A Visualization Tool for Opinion Sharing based-on Semantic Figurative Metaphors","489":"Right and left, partisanship predicts vulnerability to misinformation","490":"Different Spirals of Sameness: A Study of Content Sharing in Mainstream and Alternative Media","491":"Fake News Detection using Stance Classification: A Survey","492":"Serendipity as an emerging design principle of the infosphere: challenges and opportunities","493":"A Network-centric Framework for Auditing Recommendation Systems","494":"Endogenetic structure of filter bubble in social networks","495":"Personalization of News","496":"Occam's Razor in Opinion Dynamics: The Weighted-Median Influence Process","497":"Patterns of polarization: Transnational dynamics in climate change online networks in the US and Switzerland","498":"Examining Untempered Social Media: Analyzing Cascades of Polarized Conversations","499":"The interpersonal is political: unfriending to promote civic discourse on social media","500":"GAN-enhanced Conditional Echocardiogram Generation","501":"Locally Bayesian Learning in Networks","502":"The Internet and Access to Information about Politics","503":"The Impact of Social Media on Knowledge Culture","504":"Topology comparison of Twitter diffusion networks reliably reveals disinformation news.","505":"Perspective-based search: a new paradigm for bursting the information bubble","506":"Diversity and Novelty in Social-Based Collaborative Filtering","507":"Technology-facilitated Societal Consensus","508":"Special issue on de-personalisation, diversification, filter bubbles and search","509":"Modelling Web Based Socio-Technical Systems Through Formalising Possible Sequences of Human Experience","510":"How to represent part-whole hierarchies in a neural network","511":"Link recommendation algorithms and dynamics of polarization in online social networks","512":"The effect of algorithmic bias and network structure on coexistence, consensus, and polarization of opinions","513":"A Multiplex Social Contagion Dynamics Model to Shape and Discriminate D2D Content Dissemination","514":"Selective exposure shapes the Facebook news diet","515":"Characterizing social media manipulation in the 2020 U.S. presidential election","516":"A Model for the Influence of Media on the Ideology of Content in Online Social Networks","517":"Using Retweets When Shaping Our Online Persona: Topic Modeling Approach","518":"The Volatility of Weak Ties: Co-evolution of Selection and Influence in Social Networks","519":"Links Between Users' Online Social Network Homogeneity, Ambiguity Tolerance, and Estimated Public Support for Own Opinions","520":"The SlowQin: An Interdisciplinary Approach to reinventing the Guqin","521":"Calculating Argument Diversity in Online Threads","522":"Segmentation of Cardiac Chambers in 2D Echocardiographic Images by Using a New Atlas-Based Deformable Model","523":"\"I can't keep it up anymore.\" The Voat.co dataset","524":"Belief polarization in a complex world: A learning theory perspective","525":"Are we always in strife? A longitudinal study of the echo chamber effect in the Australian Twittersphere","526":"The role of open-mindedness in shaping opinions: theory and empirical results","527":"Measuring magnetism: how social media creates echo chambers","528":"Spread of Tweets in Climate Discussions","529":"Artificial Intelligence Models for Heart Chambers Segmentation from 2D Echocardiographic Images: A Scoping Review","530":"Echo's Chambers: Architecture and the Idea of Acoustic Space","531":"Social Media Data - A Glorious Mess","532":"The Manufacture of Partisan Echo Chambers by Follow Train Abuse on Twitter","533":"Market Systems as a Source of Individual Contributive Social Capital Scores","534":"Infodemics on Youtube: Reliability of Content and Echo Chambers on COVID-19","535":"Why do echo chambers form? The role of trust, population heterogeneity, and objective truth","536":"Agent-Based Approach to Resolve the Conflicting Observations of Online Echo Chamber","537":"Conflict Detection in Linguistically Diverse On-line Social Networks: A Russia-Ukraine Case Study","538":"Predicting Voting Outcomes in the Presence of Communities, Echo Chambers and Multiple Parties","539":"Human cognition involves the dynamic integration of neural activity and neuromodulatory systems","540":"Toward a Design Space for Mitigating Cognitive Bias in Vis","541":"A Task-Based Taxonomy of Cognitive Biases for Information Visualization","542":"23 Ways to Nudge: A Review of Technology-Mediated Nudging in Human-Computer Interaction","543":"Cognitive Biases Within Decision Making During Fire Evacuations","544":"Moderation Practices as Emotional Labor in Sustaining Online Communities: The Case of AAPI Identity Work on Reddit","545":"EEG Based Emotion Recognition by Combining Functional Connectivity Network and Local Activations","546":"Crowdsourced Traffic Event Detection and Source Reputation Assessment Using Smart Contracts","547":"Combating Fake News on Social Media with Source Ratings: The Effects of User and Expert Reputation Ratings","548":"A novel dynamic reputation-based source routing protocol for mobile ad hoc networks","549":"The Shifting Sands of Motivation: Revisiting What Drives Contributors in Open Source","550":"Context-Aware Trust and Reputation Model for Fog-Based IoT","551":"Your Hometown Matters: Popularity-Difference Bias in Online Reputation Platforms","552":"The Impact of e-WOM on Hotels Management Reputation: Exploring TripAdvisor Review Credibility With the ELM Model","553":"RSMA: Reputation System-Based Lightweight Message Authentication Framework and Protocol for 5G-Enabled Vehicular Networks","554":"Ransomware and Reputation","555":"Reputation Systems Impact on Help Seeking in MOOC Discussion Forums","556":"Developer Reputation Estimator (DRE)","557":"Why Does Code Review Work for Open Source Software Communities?","558":"Multiclass Energy Management for Peer-to-Peer Energy Trading Driven by Prosumer Preferences","559":"An Empirical Analysis of Seller Advertising Strategies in an Online Marketplace","560":"Inflated Reputations: Uncertainty, Leniency, and Moral Wiggle Room in Trader Feedback Systems","561":"Blockchain-based Reputation for Intelligent Transportation Systems","562":"Incentive Scheme for Cyber Physical Social Systems Based on User Behaviors","563":"Photonic quantum information processing: A concise review","564":"A Secure Charging Scheme for Electric Vehicles With Smart Communities in Energy Blockchain","565":"Responsible Sourcing Under Supplier-Auditor Collusion","566":"Domain-Weighted Majority Voting for Crowdsourcing","567":"Cyber Security Threats Detection in Internet of Things Using Deep Learning Approach","568":"Multi-Label Fake News Detection using Multi-layered Supervised Learning","569":"MediaRank: Computational Ranking of Online News Sources","570":"Blockchain-Based Energy Trading and Load Balancing Using Contract Theory and Reputation in a Smart Community","571":"Blockchain-Based Reputation System in Agri-Food Supply Chain","572":"The More the Merrier? The Effect of Size of Core Team Subgroups on Success of Open Source Projects","573":"Reputation-Based Approach Toward Web Content Credibility Analysis","574":"A Game Theory-Based Strategic Approach to Ensure Reliable Data Transmission With Optimized Network Operations in Futuristic Mobile Adhoc Networks","575":"Reputation System for IoT Data Monetization Using Blockchain","576":"Reputation based Routing in MANET using Blockchain","577":"Early Detection of Fake News by Utilizing the Credibility of News, Publishers, and Users based on Weakly Supervised Learning","578":"Trust Perceptions of Metadata in Open-Source Software: The Role of Performance and Reputation","579":"Sources of influences on customers' trust in ride-sharing: why use experience matters?","580":"Trust in Public Policy Algorithms","581":"A Granular Approach to Source Trustworthiness for Negative Trust Assessment","582":"Effects of privacy policy visualization on users' information privacy awareness level","583":"Men Are Elected, Women Are Married: Events Gender Bias on Wikipedia","584":"The Connection Between Popularity Bias, Calibration, and Fairness in Recommendation","585":"Beyond Bias: Artificial Intelligence and Social Justice","586":"Newsalyze: Enabling News Consumers to Understand Media Bias","587":"Quantifying Ignorance in Individual-Level Causal-Effect Estimates under Hidden Confounding","588":"Quantifying cognitive bias in educational researchers","589":"Bias-Aware Loss for Training Image and Speech Quality Prediction Models from Multiple Datasets","590":"Accounting for Confirmation Bias in Crowdsourced Label Aggregation","591":"Value associations bias ensemble perception","592":"On Modelling for Bias-Aware Sentiment Analysis and Its Impact in Twitter","593":"The Impact of Popularity Bias on Fairness and Calibration in Recommendation","594":"Modeling and Mitigating Time-Dependent Variability From the Physical Level to the Circuit Level","595":"Fairness-Aware Explainable Recommendation over Knowledge Graphs","596":"Fairness-Aware Instrumentation of Preprocessing~Pipelines for Machine Learning","597":"Field-aware Calibration: A Simple and Empirically Strong Method for Reliable Probabilistic Predictions","598":"U-rank: Utility-oriented Learning to Rank with Implicit Feedback","599":"Stratified Rule-Aware Network for Abstract Visual Reasoning","600":"An All-Digital Unified Physically Unclonable Function and True Random Number Generator Featuring Self-Calibrating Hierarchical Von Neumann Extraction in 14-nm Tri-gate CMOS","601":"Uncertainty-Aware Machine Translation Evaluation","602":"Emotion-Aware Human Attention Prediction","603":"From Saturation to Zero-Shot Visual Relationship Detection Using Local Context","604":"Are flood damage models converging to \u201creality\u201d? Lessons learnt from a blind test","605":"Dynamic Guardband Selection: Thermal-Aware Optimization for Unreliable Multi-Core Systems","606":"What is Fair? Exploring Pareto-Efficiency for Fairness Constrained Classifiers","607":"A Folded Voltage-Combiners Biased Amplifier for Low Voltage and High Energy-Efficiency Applications","608":"TEI-ULP: Exploiting Body Biasing to Improve the TEI-Aware Ultralow Power Methods","609":"Fairness-Aware Demand Prediction for New Mobility","610":"Debiasing the Human-Recommender System Feedback Loop in Collaborative Filtering","611":"Fairness-Aware Dynamic Rate Control and Flow Scheduling for Network Utility Maximization in Network Service Chain","612":"Effects of an Active Visuomotor Steering Task on Covert Attention","613":"Height Measurement in Seamless Indoor\/Outdoor Infrastructure-Free Navigation","614":"FairCrowd: Fair Human Face Dataset Sampling via Batch-Level Crowdsourcing Bias Inference","615":"The performance implications of knowledge management and strategic alignment of MNC subsidiaries","616":"Disentangled Face Attribute Editing via Instance-Aware Latent Space Search","617":"The Effect of Task on Visual Attention in Interactive Virtual Environments","618":"A comparative analysis of statistical methods to estimate the reproduction number in emerging epidemics with implications for the current COVID-19 pandemic","619":"SiMRiv: an R package for mechanistic simulation of individual, spatially-explicit multistate movements in rivers, heterogeneous and homogeneous spaces incorporating landscape bias","620":"A Cloud-Based Environment-Aware Driver Profiling Framework using Ensemble Supervised Learning","621":"StructSum: Summarization via Structured Representations","622":"Knowledge-Aware Graph Collaborative Filtering for Recommender Systems","623":"Big Data Driven Detection of Trees in Suburban Scenes Using Visual Spectrum Eye Level Photography","624":"Statistics and visualizations for assessing class size uncertainty","625":"PFARS: Enhancing throughput and lifetime of heterogeneous WSNs through power\u2010aware fusion, aggregation, and routing scheme","626":"Guessing the Game: An Individual's Awareness and Assessment of a Game's Existence","627":"Diversity-aware Recommendations for Social Justice? Exploring User Diversity and Fairness in Recommender Systems","628":"Disaster Mitigation Using Interface Adaptation to Emotions: a Targeted Literature Review","629":"Fast alignment of reads to a variation graph with application to SNP detection","630":"FairXGBoost: Fairness-aware Classification in XGBoost","631":"Variability-Aware Design Method for a Constant Inversion Level Bias Current Generator","632":"Enabling Plug-and-Play and Crowdsourcing SLAM in Wireless Communication Systems","633":"Wideband signal detection for cognitive radio applications with limited resources","634":"Resource-rational analysis: Understanding human cognition as the optimal use of limited computational resources","635":"Throughput Maximization in Energy Limited Full-Duplex Cognitive Radio Networks","636":"Cognitive Load Theory, Spacing Effect, and Working Memory Resources Depletion","637":"NOMA-Based Resource Allocation for Cluster-Based Cognitive Industrial Internet of Things","638":"Uplink Resource Allocation for NOMA-Based Hybrid Spectrum Access in 6G-Enabled Cognitive Internet of Things","639":"On the ability of virtual agents to decrease cognitive load: an experimental study","640":"Artificial Intelligence Inspired Transmission Scheduling in Cognitive Vehicular Communications and Networks","641":"Joint Spectrum Resource Allocation in NOMA-based Cognitive Radio Network With SWIPT","642":"Resource Allocation in Heterogeneous Cognitive Radio Network With Non-Orthogonal Multiple Access","643":"Energy-Efficient Cooperation in Mobile Edge Computing-Enabled Cognitive Radio Networks","644":"A rate\u2010maximizing spectrum sharing algorithm for cognitive radio networks with generic resource constraints","645":"Electrophysiological correlates of the flexible allocation of visual working memory resources","646":"Analogous Study of Security Threats in Cognitive Radio","647":"Electrophysiological correlates of the flexible allocation of visual working memory resources","648":"A Step-by-Step Tutorial on Active Inference and its Application to Empirical Data","649":"A Mental Health Chatbot for Regulating Emotions (SERMO) - Concept and Usability Test","650":"Performance Evaluation of Relay-Aided CR-NOMA for Beyond 5G Communications","651":"The Efficiency of Human Cognition Reflects Planned Information Processing","652":"Mobile EEG identifies the re-allocation of attention during real-world activity","653":"From logs to Stories: Human-Centred Data Mining for Cyber Threat Intelligence","654":"Task-Driven Resource Assignment in Mobile Edge Computing Exploiting Evolutionary Computation","655":"Chapter 3: Multimedia Learning Theory and Instructional Message Design","656":"On the Sample Size for the Estimation of Primary Activity Statistics Based on Spectrum Sensing","657":"20 Years of Evolution From Cognitive to Intelligent Communications","658":"On the Rational Boundedness of Cognitive Control: Shared Versus Separated Representations","659":"A Multicomponent Model of Working Memory","660":"Implementing Remote Memory Clinics to Enhance Clinical Care During and After COVID-19","661":"Improving Deep Reinforcement Learning in Minecraft with Action Advice","662":"Untangling tradeoffs between recurrence and self-attention in neural networks","663":"The Effect of Cognitive Resource Competition Due to Dual-Tasking on the Irregularity and Control of Postural Movement Components","664":"Intelligent Spectrum Assignment Based on Dynamical Cooperation for 5G-Satellite Integrated Networks","665":"Discriminating Cognitive Disequilibrium and Flow in Problem Solving: A Semi-Supervised Approach Using Involuntary Dynamic Behavioral Signals","666":"Using Eye-Tracking for Visual Attention Feedback","667":"Optimal, resource-rational or sub-optimal? Insights from cognitive development","668":"Wait, But Why?: Assessing Behavior Explanation Strategies for Real-Time Strategy Games","669":"COMETA: An Air Traffic Controller's Mental Workload Model for Calculating and Predicting Demand and Capacity Balancing","670":"Cognitively-inspired Agent-based Service Composition for Mobile & Pervasive Computing","671":"On Robustness: An Undervalued Dimension of Human Rationality","672":"Heuristics and optimal solutions to the breadth\u2013depth dilemma","673":"Dynamic Service Composition Orchestrated by Cognitive Agents in Mobile and Pervasive Computing","674":"Reinforcement Learning for Cognitive Radar Task Scheduling","675":"Reward-Based Deception with Cognitive Bias","676":"Ranking and grouping social media requests for emergency services using serviceability model","677":"Cognitive Radio Networks: Recent Advances in Spectrum Sensing Techniques and Security","678":"Using response time modeling to understand the sources of dual-task interference in a dynamic environment.","679":"An Active Inference Approach to Modeling Structure Learning: Concept Learning as an Example Case","680":"An active inference approach to modeling structure learning: concept learning as an example case","681":"Resource-rational Task Decomposition to Minimize Planning Costs","682":"Effect of Mental Workload on Breathing Pattern and Heart Rate for a Working Memory Task: A Pilot Study","683":"Revisiting HyperDimensional Learning for FPGA and Low-Power Architectures","684":"Analysis of influencing factors in emergency management based on an integrated methodology","685":"Machine Learning for LTE Energy Detection Performance Improvement","686":"Semantic Network Analysis (SemNA): A Tutorial on Preprocessing, Estimating, and Analyzing Semantic Networks","687":"Why Higher Working Memory Capacity May Help You Learn: Sampling, Search, and Degrees of Approximation","688":"Engagement Patterns of Peer-to-Peer Interactions on Mental Health Platforms","689":"Effect of E-learning on public health and environment during COVID-19 lockdown","690":"Dynamic Control of Fraud Information Spreading in Mobile Social Networks","691":"Toward a unified framework for interpreting machine-learning models in neuroimaging","692":"Clustering-Based Emotion Recognition Micro-Service Cloud Framework for Mobile Computing","693":"Clinical practice guideline adaptation methods in resource-constrained settings: four case studies from South Africa","694":"Virtually Real, But Not Quite There: Social and Economic Barriers to Meeting Virtual Reality\u2019s True Potential for Mental Health","695":"Confirmatory bias in peer review","696":"Revisiting Few-sample BERT Fine-tuning","697":"Comparing Methods for Addressing Missingness in Longitudinal Modeling of Panel Data","698":"Limitations of Fixed-Effects Models for Panel Data","699":"Performance of missing data approaches under nonignorable missing data conditions","700":"Monitoring Bark Beetle Forest Damage in Central Europe. A Remote Sensing Approach Validated with Field Data","701":"Optimal Statistical Incorporation of Independent Feature Stability Information into Radiomics Studies","702":"Playing Text-Based Games with Common Sense","703":"Limitations of risk approaches","704":"Supervised Segmentation of Ultra-High-Density Drone Lidar for Large-Area Mapping of Individual Trees","705":"The Subject\u2013Object Asymmetry Revisited: Experimental and Computational Approaches to the Role of Information Structure in Children\u2019s Argument Omissions","706":"Unpacking the Black Box: Regulating Algorithmic Decisions","707":"A Deeper Look at Discounting Mismatch in Actor-Critic Algorithms","708":"Evaluation of Four Multiple Imputation Methods for Handling Missing Binary Outcome Data in the Presence of an Interaction between a Dummy and a Continuous Variable","709":"A Comparative Study of English-Chinese Translations of Court Texts by Machine and Human Translators and the Word2Vec Based Similarity Measure\u2019s Ability To Gauge Human Evaluation Biases","710":"Subjectivity in the Creation of Machine Learning Models","711":"Estimation of Vertical Datum Parameters Using the GBVP Approach Based on the Combined Global Geopotential Models","712":"Omission of temporal nuisance regressors from dual regression can improve accuracy of fMRI functional connectivity maps","713":"Omitted Budget Constraint Bias in Single-Unit Demand Models and Implications for Competitive Pricing and Targeting","714":"Rapid Generation of Flood Maps Using Dual-Polarimetric Synthetic Aperture Radar Imagery","715":"Designing a Social Matching System to Connect Academic Researchers with Local Community Collaborators","716":"Supplementary materials to: Performance of missing data approaches under nonignorable missing data conditions","717":"Context in Informational Bias Detection","718":"Gender Bias in Contextualized Word Embeddings","719":"On Mutual Information Maximization for Representation Learning","720":"Understanding the Limitations of Variational Mutual Information Estimators","721":"On Variational Bounds of Mutual Information","722":"Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them","723":"Accounting for missing data in statistical analyses: multiple imputation is not always the answer","724":"RUBi: Reducing Unimodal Biases in Visual Question Answering","725":"Investigating Gender Bias in Language Models Using Causal Mediation Analysis","726":"Virtual Simulation in Nursing Education: A Systematic Review Spanning 1996 to 2018","727":"Unpacking the Expressed Consequences of AI Research in Broader Impact Statements","728":"Language (Technology) is Power: A Critical Survey of \u201cBias\u201d in NLP","729":"MBIC - A Media Bias Annotation Dataset Including Annotator Characteristics","730":"A Comprehensive Study on Face Recognition Biases Beyond Demographics","731":"On Sampled Metrics for Item Recommendation","732":"On The Reasons Behind Decisions","733":"Can The Crowd Identify Misinformation Objectively?: The Effects of Judgment Scale and Assessor's Background","734":"Masking Actor Information Leads to Fairer Political Claims Detection","735":"A Framework for Understanding Unintended Consequences of Machine Learning","736":"Implicit bias of gradient descent for mean squared error regression with wide neural networks","737":"Rhythmic Temporal Expectation Boosts Neural Activity by Increasing Neural Gain","738":"Detecting Media Bias in News Articles using Gaussian Bias Distributions","739":"Some comments on: Mao et al. (2018) \u201cBibliometric analysis of insights into soil remediation\u201d Journal of Soils and Sediments, 18(7): 2520\u20132534","740":"Navo Minority Over-sampling Technique (NMOTe): A Consistent Performance Booster on Imbalanced Datasets","741":"A binned likelihood for stochastic models","742":"Revealing Persona Biases in Dialogue Systems","743":"The Ventral Visual Pathway Represents Animal Appearance over Animacy, Unlike Human Behavior and Deep Neural Networks","744":"Threshold-Based Retrieval and Textual Entailment Detection on Legal Bar Exam Questions","745":"Bias-Aware Confidence Intervals for Empirical Bayes Analysis","746":"RICA: Evaluating Robust Inference Capabilities Based on Commonsense Axioms","747":"Investigating Label Bias in Beam Search for Open-ended Text Generation","748":"SwitchNet: Learning to switch for word-level language identification in code-mixed social media text","749":"Visual context embeddings for zero-shot recognition","750":"GenderQuant: Quantifying Mention-Level Genderedness","751":"Should We Rely on Entity Mentions for Relation Extraction? Debiasing Relation Extraction with Counterfactual Analysis","752":"Research on Tourism Destination Attraction Based on Deep Learning","753":"Using case-level context to classify cancer pathology reports","754":"Identifying and Reducing Gender Bias in Word-Level Language Models","755":"Reducing Gender Bias in Word-Level Language Models with a Gender-Equalizing Loss Function","756":"Unsupervised Discovery of Implicit Gender Bias","757":"Transformer-XL: Attentive Language Models beyond a Fixed-Length Context","758":"Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning","759":"Meaningful Context, a Red Flag, or Both? Users' Preferences for Enhanced Misinformation Warnings on Twitter","760":"Study design synopsis: Bias can cast a dark shadow over studies.","761":"Enhancing Bias Detection in Political News Using Pragmatic Presupposition","762":"Editing-Based SQL Query Generation for Cross-Domain Context-Dependent Questions","763":"Good News, Everyone! Context Driven Entity-Aware Captioning for News Images","764":"Neural Text Normalization with Subword Units","765":"Context-Driven Corpus-Based Model for Automatic Text Segmentation and Part of Speech Tagging in Setswana Using OpenNLP Tool","766":"Cross-relating heterogeneous Text Streams for Credibility Assessment","767":"Block-based versus text-based programming environments on novice student learning outcomes: a meta-analysis study","768":"BOLD: Dataset and Metrics for Measuring Biases in Open-Ended Language Generation","769":"Word Embeddings: What Works, What Doesn\u2019t, and How to Tell the Difference for Applied Research","770":"Charformer: Fast Character Transformers via Gradient-based Subword Tokenization","771":"He is very intelligent, she is very beautiful? On Mitigating Social Biases in Language Modelling and Generation","772":"EVA 2.0: Emotional and rational multimodal argumentation between virtual agents","773":"Text-based inference of moral sentiment change","774":"Kleister: A novel task for Information Extraction involving Long Documents with Complex Layout","775":"Improving Multimodal Named Entity Recognition via Entity Span Detection with Unified Multimodal Transformer","776":"Detecting Emergent Intersectional Biases: Contextualized Word Embeddings Contain a Distribution of Human-like Biases","777":"Dense Hierarchical Retrieval for Open-Domain Question Answering","778":"Understanding Social Biases Behind Location Names in Contextual Word Embedding Models","779":"On Measuring Social Biases in Sentence Encoders","780":"Pooled Contextualized Embeddings for Named Entity Recognition","781":"Unmasking the Mask - Evaluating Social Biases in Masked Language Models","782":"S-conLSH: alignment-free gapped mapping of noisy long reads","783":"Assessing Social and Intersectional Biases in Contextualized Word Representations","784":"ReCoSa: Detecting the Relevant Contexts with Self-Attention for Multi-turn Dialogue Generation","785":"Computing Maximal Unique Matches with the r-index","786":"Interactive Machine Comprehension with Information Seeking Agents","787":"Evaluating Commonsense in Pre-trained Language Models","788":"Phoebe: Pronunciation-aware Contextualization for End-to-end Speech Recognition","789":"The Woman Worked as a Babysitter: On Biases in Language Generation","790":"The Moral Choice Machine","791":"Transformers in Vision: A Survey","792":"Pseudo-Convolutional Policy Gradient for Sequence-to-Sequence Lip-Reading","793":"Crowdsourcing Subjective Tasks: The Case Study of Understanding Toxicity in Online Discussions","794":"On Long-Tailed Phenomena in Neural Machine Translation","795":"Exploring the State-of-Receptivity for mHealth Interventions","796":"Detecting singleton spams in reviews via learning deep anomalous temporal aspect-sentiment patterns","797":"Large pre-trained language models contain human-like biases of what is right and wrong to do","798":"What is TEI Conformance, and Why Should You Care?","799":"Trading off accuracy and explainability in AI decision-making: findings from 2 citizens\u2019 juries","800":"Hierarchical Graph Network for Multi-hop Question Answering","801":"Defending Against Neural Fake News","802":"Taking Note: Challenges of Dealing with Graphical Content in TEI","803":"Artificial intelligence and engineering education","804":"An Integrated Word Embedding-Based Dual-Task Learning Method for Sentiment Analysis","805":"Distilling Essence of a Question: A Hierarchical Architecture for Question Quality in Community Question Answering Sites","806":"What's in a Review","807":"A Practical Guide to Hybrid Natural Language Processing: Combining Neural Models and Knowledge Graphs for NLP","808":"An Empirical Study on Algorithmic Bias","809":"Domain-Aware Word Segmentation for Chinese Language: A Document-Level Context-Aware Model","810":"Feature weighted confidence to incorporate prior knowledge into support vector machines for classification","811":"CoCoScore: context-aware co-occurrence scoring for text mining applications using distant supervision","812":"Language Models have a Moral Dimension","813":"Improving Deep CNN Networks with Long Temporal Context for Text-Independent Speaker Verification","814":"Natural Language Inference in Context - Investigating Contextual Reasoning over Long Texts","815":"Long Document Classification From Local Word Glimpses via Recurrent Attention Learning","816":"Meta-CoTGAN: A Meta Cooperative Training Paradigm for Improving Adversarial Text Generation","817":"Hierarchical Comprehensive Context Modeling for Chinese Text Classification","818":"A Single Slope ADC With Row-Wise Noise Reduction Technique for CMOS Image Sensor","819":"Text Recognition in Images Based on Transformer with Hierarchical Attention","820":"Modeling Multi-level Context for Informational Bias Detection by Contrastive Learning and Sentential Graph Network","821":"Active learning in automated text classification: a case study exploring bias in predicted model performance metrics","822":"Balancing Gender Bias in Job Advertisements With Text-Level Bias Mitigation","823":"GP: Context-free Grammar Pre-training for Text-to-SQL Parsers","824":"A Fast Ramp-Voltage-Based Current Programming Driver for AMOLED Display","825":"Trimming-Less Voltage Reference for Highly Uncertain Harvesting Down to 0.25 V, 5.4 pW","826":"Ensemble-Based Systems to Monitor Algal Bloom With Remote Sensing","827":"How much is research in the top journals of industrial\/organizational psychology dominated by authors from the U.S.?","828":"Web mining for innovation ecosystem mapping: a framework and a large-scale pilot study","829":"MultiCite: Modeling realistic citations requires moving beyond the single-sentence single-label setting","830":"Listen, Look and Deliberate: Visual Context-Aware Speech Recognition Using Pre-Trained Text-Video Representations","831":"Emotions Extracted from Text vs. True Emotions\u2013An Empirical Evaluation in SE Context","832":"Privacy Disclosures Detection in Natural-Language Text Through Linguistically-Motivated Artificial Neural Networks","833":"Text-in-Context: Token-Level Error Detection for Table-to-Text Generation","834":"A Seq2seq-based Model with Global Semantic Context for Scene Text Recognition","835":"Chinese Event Detection Based on Multi-Feature Fusion and BiLSTM","836":"A multi-layer approach to disinformation detection on Twitter","837":"An Accurate Segmentation-Based Scene Text Detector with Context Attention and Repulsive Text Border","838":"Interpreting Text Classifiers by Learning Context-sensitive Influence of Words","839":"Hierarchical Context-Aware Transformers for Non-Autoregressive Text to Speech","840":"Language Models and Word Sense Disambiguation: An Overview and Analysis","841":"Adversarial Learning for Discourse Rhetorical Structure Parsing","842":"HANet: Hierarchical Alignment Networks for Video-Text Retrieval","843":"Socially Situated Transmission: The Bias to Transmit Negative Information is Moderated by the Social Context","844":"Semi-Supervised Text Classification Framework: An Overview of Dengue Landscape Factors and Satellite Earth Observation","845":"BI-TEXTS IN THE CONTEXT OF NATIONAL-RUSSIAN BILINGUAL EDUCATION","846":"Learning Context Using Segment-Level LSTM for Neural Sequence Labeling","847":"What evidence exists on the effects of anthropogenic noise on acoustic communication in animals? A systematic map protocol","848":"Biased minds experience improved decision-making speed and confidence on social media: a heuristic approach","849":"Best Linear Unbiased Prediction of Latent Means in Three-Level Data","850":"Assessing the Severity of Software Bug Using Neural Network","851":"Sequence Prediction Model for Aspect-Level Sentiment Classification","852":"Aspect-Level Sentiment Analysis Approach via BERT and Aspect Feature Location Model","853":"A Chapter-Wise Understanding System for Text-To-Speech in Chinese Novels","854":"What Leads to a Confirmatory or Disconfirmatory Behavior of Software Testers?","855":"Generating Gender Augmented Data for NLP","856":"Citation context-based topic models: discovering cited and citing topics from full text","857":"Text-matching software in post-secondary contexts: A systematic review protocol","858":"CampNet: Context-Aware Mask Prediction for End-to-End Text-Based Speech Editing","859":"Representing the Unification of Text Featurization using a Context-Free Grammar","860":"Chase: A Large-Scale and Pragmatic Chinese Dataset for Cross-Database Context-Dependent Text-to-SQL","861":"Syntopical Graphs for Computational Argumentation Tasks","862":"IMPROVING STANCE AND BIAS DETECTION IN TEXT BY MODELING SOCIAL CONTEXT","863":"Gender bias amplification during Speed-Quality optimization in Neural Machine Translation","864":"Mitigation of Diachronic Bias in Fake News Detection Dataset","865":"Towards Detection of Subjective Bias using Contextualized Word Embeddings","866":"HypoNLI: Exploring the Artificial Patterns of Hypothesis-only Bias in Natural Language Inference","867":"Mitigating sentimental bias via a polar attention mechanism","868":"Modeling the Role of Plausibility and Verb-bias in the Direct Object\/Sentence Complement Ambiguity","869":"The rational side of decision \"bias\" based on verbal probabilities","870":"Empirical Analysis of Bias in Voice-based Personal Assistants","871":"Integrating Topic Model and Heterogeneous Information Network for Aspect Mining with Rating Bias","872":"An Experimental Analysis of Data Annotation Methodologies for Emotion Detection in Short Text Posted on Social Media","873":"Mitigating Racial Biases in Toxic Language Detection with an Equity-Based Ensemble Framework","874":"From Arabic Sentiment Analysis to Sarcasm Detection: The ArSarcasm Dataset","875":"Enforcing Consistency in Weakly Supervised Semantic Parsing","876":"End-to-end contextual asr based on posterior distribution adaptation for hybrid ctc\/attention system","877":"Improving End-to-End Contextual Speech Recognition with Fine-grained Contextual Knowledge Selection","878":"Grounding Plural Phrases: Countering Evaluation Biases by Individuation","879":"Scene Graph Generation With External Knowledge and Image Reconstruction","880":"The case for voter-centered audits of search engines during political elections","881":"An automated approach to identifying search terms for systematic reviews using keyword co\u2010occurrence networks","882":"The use of context in resolving syntactic ambiguity: structural and semantic influences","883":"A Critical Analysis of Biased Parsers in Unsupervised Parsing","884":"Event Detection without Triggers","885":"SoulMate: Short-Text Author Linking Through Multi-Aspect Temporal-Textual Embedding","886":"Destination image through social media analytics and survey method","887":"Mitigating harm in language models with conditional-likelihood filtration","888":"The paradox of second-order homophily in networks","889":"Benchmark for Compositional Text-to-Image Synthesis","890":"Minimally-Supervised Structure-Rich Text Categorization via Learning on Text-Rich Networks","891":"Speaker Information Can Guide Models to Better Inductive Biases: A Case Study On Predicting Code-Switching","892":"An Unsupervised Semantic Sentence Ranking Scheme for Text Documents","893":"Neural semi-Markov CRF for Monolingual Word Alignment","894":"Utility of Missing Concepts in Query-biased Summarization","895":"Importance Estimation from Multiple Perspectives for Keyphrase Extraction","896":"Abstractive Snippet Generation","897":"Shallow-Fusion End-to-End Contextual Biasing","898":"Experimental evidence for the influence of structure and meaning on linear order in the noun phrase","899":"High Precision Detection of Business Email Compromise","900":"Parsing Modifiers: The Case of Bare NP Adverbs","901":"What did Joseph Wright mean by meaning","902":"Graph-based Keyphrase Extraction Using Word and Document Em beddings*","903":"Neural Composition: Learning to Generate from Multiple Models","904":"SuVashantor: English to Bangla Machine Translation Systems","905":"From the world to word order: Deriving biases in\nnoun phrase order from statistical properties of the world","906":"Passivizability of Idioms: Has the Wrong Tree Been Barked Up?","907":"Sentiment in Academic Texts","908":"Designovel's system description for Fashion-IQ challenge 2019","909":"From the Myth of Babel to Google Translate: Confronting Malicious Use of Artificial Intelligence \u2013 Copyright and Algorithmic Biases in Online Translation Systems","910":"Alternatives on Demand and Locality: Resolving Discourse-Linked Wh-Phrases in Sluiced Structures","911":"Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society","912":"A Bigram-based Inference Model for Retrieving Abbreviated Phrases in Source Code","913":"Finding identity in the midst of ambiguity: case and number disambiguation in Basque","914":"On Guiding Visual Attention with Language Specification","915":"Towards Contextual Spelling Correction for Customization of End-to-end Speech Recognition Systems","916":"Resolving Gendered Ambiguous Pronouns with BERT","917":"Hierarchy in language interpretation: evidence from behavioural experiments and computational modelling","918":"Diversity Informatics: Reducing Racial and Gender Bias with Virtual Agents","919":"Who \"it\" is influences what \"it\" does: Discourse effects on children's syntactic parsing","920":"A Complete Characterization of Game-Theoretically Fair, Multi-Party Coin Toss","921":"A Rationale-Centric Framework for Human-in-the-loop Machine Learning","922":"Investigating the usage of Likert-style items within Computer Science Education Research Instruments","923":"Phrase-Level Class based Language Model for Mandarin Smart Speaker Query Recognition","924":"Expression of Feelings in Twitter: A Decision Tree Approach","925":"I Wish I Would Have Loved This One, But I Didn\u2019t \u2013 A Multilingual Dataset for Counterfactual Detection in Product Review","926":"AUTOLEX: An Automatic Framework for Linguistic Exploration","927":"Understanding COVID-19 News Coverage using Medical NLP","928":"Detection of Puffery on the English Wikipedia","929":"Modeling German Verb Argument Structures: LSTMs vs. Humans","930":"Automatically Differentiable Random Coefficient Logistic Demand Estimation","931":"Do pretrained transformers infer telicity like humans?","932":"A Hierarchical Transformer for Unsupervised Parsing","933":"Search-based fairness testing for regression-based machine learning systems","934":"A Closer Look at Debiased Temporal Sentence Grounding in Videos: Dataset, Metric, and Approach","935":"On the Language Coverage Bias for Neural Machine Translation","936":"Understanding the Under-Coverage Bias in Uncertainty Estimation","937":"Quantifying molecular bias in DNA data storage","938":"Coverage and Rate Analysis of Downlink Cellular Vehicle-to-Everything (C-V2X) Communication","939":"Managing Popularity Bias in Recommender Systems with Personalized Re-ranking","940":"The Unfairness of Popularity Bias in Recommendation","941":"The Effect of Algorithmic Bias on Recommender Systems for Massive Open Online Courses","942":"Automated Identification of Media Bias by Word Choice and Labeling in News Articles","943":"Quantifying Molecular Bias in DNA Data Storage","944":"A Quantile-Based g-Computation Approach to Addressing the Effects of Exposure Mixtures","945":"Bayesian Regression Tree Models for Causal Inference: Regularization, Confounding, and Heterogeneous Effects (with Discussion)","946":"Adversarial Training for Weakly Supervised Event Detection","947":"Toward Global Soil Moisture Monitoring With Sentinel-1: Harnessing Assets and Overcoming Obstacles","948":"TRY plant trait database \u2013 enhanced coverage and open access","949":"Inclusive GAN: Improving Data and Minority Coverage in Generative Models","950":"Is neuron coverage a meaningful measure for testing deep neural networks?","951":"Tractable Coverage Analysis for Hexagonal Macrocell-Based Heterogeneous UDNs With Adaptive Interference-Aware CoMP","952":"The STRING database in 2021: customizable protein\u2013protein networks, and functional characterization of user-uploaded gene\/measurement sets","953":"On the \"steerability\" of generative adversarial networks","954":"Improvements in the GISTEMP Uncertainty Model","955":"Commonsense Knowledge Mining from Pretrained Models","956":"Molecular Fitness Landscapes from High-Coverage Sequence Profiling.","957":"Understanding the diversity of the metal-organic framework ecosystem","958":"Leveraging Administrative Data for Bias Audits: Assessing Disparate Coverage with Mobility Data for COVID-19 Policy","959":"An evaluation of stringent filtering to improve species distribution models from citizen science data","960":"MithraCoverage: A System for Investigating Population Bias for Intersectional Fairness","961":"Identifying insufficient data coverage in databases with multiple relations","962":"Understanding and Improving Proximity Graph based Maximum Inner Product Search","963":"Data Augmentation for Discrimination Prevention and Bias Disambiguation","964":"Investment in a Smaller World: The Implications of Air Travel for Investors and Firms","965":"Broadband Acoustical MEMS Transceivers for Simultaneous Range Finding and Microphone Applications","966":"A Markov Model of Users\u2019 Interactive Behavior in Scatterplots","967":"Spatial and Temporal Patterns in Volunteer Data Contribution Activities: A Case Study of eBird","968":"Sub-graph Contrast for Scalable Self-Supervised Graph Representation Learning","969":"Collaborating with Users in Proximity for Decentralized Mobile Recommender Systems","970":"Algorithmic bias amplifies opinion polarization: A bounded confidence model","971":"The deep-space multi-object orbit determination system and its application to Hayabusa2\u2019s asteroid proximity operations","972":"Somatosensory interactions reveal feature-dependent computations.","973":"The Comprehensive Effects of Sales Force Management: A Dynamic Structural Analysis of Selection, Compensation, and Training","974":"Neural Network Classifier-Based OPC With Imbalanced Training Data","975":"Correcting for Selection Bias in Learning-to-rank Systems","976":"Client Selection in Federated Learning: Convergence Analysis and Power-of-Choice Selection Strategies","977":"Recommending what video to watch next: a multitask ranking system","978":"ModelTest-NG: a new and scalable tool for the selection of DNA and protein evolutionary models","979":"CINeMA: Software for semiautomated assessment of the confidence in the results of network meta\u2010analysis","980":"Testing DNN Image Classifiers for Confusion & Bias Errors","981":"A Multidimensional Dataset Based on Crowdsourcing for Analyzing and Detecting News Bias","982":"A Survey on Predicting the Factuality and the Bias of News Media","983":"Leveraging Lead Bias for Zero-shot Abstractive News Summarization","984":"Does Gender Matter in the News? Detecting and Examining Gender Bias in News Articles","985":"DebiasedRec: Bias-aware User Modeling and Click Prediction for Personalized News Recommendation","986":"An Integrated Approach to Detect Media Bias in German News Articles","987":"Rating Reliability and Bias in News Articles: Does AI Assistance Help Everyone?","988":"Detecting Political Bias in News Articles Using Headline Attention","989":"Make Lead Bias in Your Favor: A Simple and Effective Method for News Summarization","990":"Controlling Fairness and Bias in Dynamic Learning-to-Rank","991":"Neutral bots probe political bias on social media","992":"Using Word Embeddings to Examine Gender Bias in Dutch Newspapers, 1950-1990","993":"Fairness-aware News Recommendation with Decomposed Adversarial Learning","994":"A Digital Nudge to Counter Confirmation Bias","995":"Identification of Biased Terms in News Articles by Comparison of Outlet-Specific Word Embeddings","996":"User Preference-aware Fake News Detection","997":"BEEP! Korean Corpus of Online News Comments for Toxic Speech Detection","998":"Annotating and Analyzing Biased Sentences in News Articles using Crowdsourcing","999":"NELA-GT-2018: A Large Multi-Labelled News Dataset for The Study of Misinformation in News Articles","1000":"Says Who? The Effects of Presentation Format and Source Rating on Fake News in Social Media","1001":"Fake News on Social Media: People Believe What They Want to Believe When it Makes No Sense At All","1002":"Toward a Better Performance Evaluation Framework for Fake News Classification","1003":"Sorting the News: How Ranking by Popularity Polarizes Our Politics","1004":"A Machine Learning Approach to Fake News Detection Using Knowledge Verification and Natural Language Processing","1005":"Visual and Textual Analysis for Image Trustworthiness Assessment within Online News","1006":"Social Reinforcement Learning to Combat Fake News Spread","1007":"PIQA: Reasoning about Physical Commonsense in Natural Language","1008":"Text and Causal Inference: A Review of Using Text to Remove Confounding from Causal Estimates","1009":"Optimally Imprecise Memory and Biased Forecasts","1010":"Earlier Isn\u2019t Always Better: Sub-aspect Analysis on Corpus and System Biases in Summarization","1011":"Predicting the Leading Political Ideology of YouTube Channels Using Acoustic, Textual, and Metadata Information","1012":"PP-Rec: News Recommendation with Personalized User Interest and Time-aware News Popularity","1013":"A Reasoned Approach to Dealing With Fake News","1014":"Fake News in Social Media: Bad Algorithms or Biased Users?","1015":"Across-Time Comparative Summarization of News Articles","1016":"News2vec: News Network Embedding with Subnode Information","1017":"News Recommender System Considering Temporal Dynamics and News Taxonomy","1018":"Modeling Event Propagation via Graph Biased Temporal Point Process","1019":"Designing Ethical Algorithms","1020":"Measuring Biases in Expectation Formation","1021":"AraWEAT: Multidimensional Analysis of Biases in Arabic Word Embeddings","1022":"Early Detection of Fake News \"Before It Flies High\"","1023":"Political Bias and Factualness in News Sharing Across more then 100, 000 Online Communities","1024":"Sentiment Analysis for Fake News Detection","1025":"Correcting for Recency Bias in Job Recommendation","1026":"Countering the Effects of Lead Bias in News Summarization via Multi-Stage Training and Auxiliary Losses","1027":"Hiring is Broken: What Do Developers Say About Technical Interviews?","1028":"How Well Do My Results Generalize? Comparing Security and Privacy Survey Results from MTurk, Web, and Telephone Samples","1029":"TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising","1030":"Online Misinformation: From the Deceiver to the Victim","1031":"Detecting fake news in social media","1032":"Seeding Network Influence in Biased Networks and the Benefits of Diversity","1033":"The mass, fake news, and cognition security","1034":"Media Bias Characterization in Brazilian Presidential Elections","1035":"Female librarians and male computer programmers? Gender bias in occupational images on digital media platforms","1036":"Fighting biased news diets: Using news media literacy interventions to stimulate online cross-cutting media exposure patterns","1037":"Explaining Multimodal Deceptive News Prediction Models","1038":"Biased News Data Influence on Classifying Social Media Posts","1039":"Team QCRI-MIT at SemEval-2019 Task 4: Propaganda Analysis Meets Hyperpartisan News Detection","1040":"JUSTDeep at NLP4IF 2019 Task 1: Propaganda Detection using Ensemble Deep Learning Models","1041":"Emotion Correlation Mining Through Deep Learning Models on Natural Language Text","1042":"Unsupervised WhatsApp Fake News Detection using Semantic Search","1043":"Counterfactual Evaluation of Slate Recommendations with Sequential Reward Interactions","1044":"Neural Media Bias Detection Using Distant Supervision With BABE - Bias Annotations By Experts","1045":"Characterizing the Variability in Face Recognition Accuracy Relative to Race","1046":"Fairness in Online Social Network Timelines: Measurements, Models and Mechanism Design","1047":"Empirical Evaluation of Three Common Assumptions in Building Political Media Bias Datasets","1048":"The Impact of Increasing and Decreasing the Professionalism of News Webpage Aesthetics on the Perception of Bias in News Articles","1049":"Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2021): Workshop and Shared Task Report","1050":"Make Lead Bias in Your Favor: Zero-shot Abstractive News Summarization","1051":"The POLUSA Dataset: 0.9M Political News Articles Balanced by Time and Outlet Popularity","1052":"Fairness in Rankings and Recommenders","1053":"Screenplay Summarization Using Latent Narrative Structure","1054":"Students Assessing Digital News and Misinformation","1055":"Stance detection using improved whale optimization algorithm","1056":"Machine-Learning media bias","1057":"Hate speech detection and racial bias mitigation in social media based on BERT model","1058":"Political communication on social media: A tale of hyperactive users and bias in recommender systems","1059":"Demographic Bias in Biometrics: A Survey on an Emerging Challenge","1060":"Racial Bias in Hate Speech and Abusive Language Detection Datasets","1061":"Bias in word embeddings","1062":"Stereotypical Bias Removal for Hate Speech Detection Task using Knowledge-based Generalizations","1063":"Predicting the Topical Stance and Political Leaning of Media using Tweets","1064":"Two Half-Truths Make a Whole? On Bias in Self-Reports and Tracking Data","1065":"Is a Picture Worth a Thousand Words? An Empirical Study of Image Content and Social Media Engagement","1066":"Demographic Inference and Representative Population Estimates from Multilingual Social Media Data","1067":"Methodological Gaps in Predicting Mental Health States from Social Media: Triangulating Diagnostic Signals","1068":"HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection","1069":"Social epistemology as a new paradigm for journalism and media studies","1070":"A Taxonomy of Ethical Tensions in Inferring Mental Health States from Social Media","1071":"What settings have been linked to SARS-CoV-2 transmission clusters?","1072":"Mobile data donations: Assessing self-report accuracy and sample biases with the iOS Screen Time function","1073":"Content moderation: Social media\u2019s sexist assemblages","1074":"Centralized or Decentralized? The Contact Tracing Dilemma","1075":"Social Media as a Passive Sensor in Longitudinal Studies of Human Behavior and Wellbeing","1076":"Bias in machine learning - what is it good for?","1077":"#MigrantCaravan: The border wall and the establishment of otherness on Instagram","1078":"Intersectional Bias in Hate Speech and Abusive Language Datasets","1079":"SemEval-2020 Task 11: Detection of Propaganda Techniques in News Articles","1080":"An Emotional Analysis of False Information in Social Media and News Articles","1081":"Stock Embeddings Acquired from News Articles and Price History, and an Application to Portfolio Optimization","1082":"Discourse as a Function of Event: Profiling Discourse Structure in News Articles around the Main Event","1083":"Satire identification in Turkish news articles based on ensemble of classifiers","1084":"Word2vec convolutional neural networks for classification of news articles and tweets","1085":"Searching News Articles Using an Event Knowledge Graph Leveraged by Wikidata","1086":"Tweet Summarization of News Articles: An Objective Ordering-Based Perspective","1087":"Giveme5W1H: A Universal System for Extracting Main Events from News Articles","1088":"Vectorization of Text Documents for Identifying Unifiable News Articles","1089":"Sentiment Analysis of News Articles: A Lexicon based Approach","1090":"Classifying Fake News Articles Using Natural Language Processing to Identify In-Article Attribution as a Supervised Learning Estimator","1091":"The Ineffectiveness of Fact-Checking Labels on News Memes and Articles","1092":"Fighting an Infodemic: COVID-19 Fake News Dataset","1093":"Coherent Comments Generation for Chinese Articles with a Graph-to-Sequence Model","1094":"Empowering News Recommendation with Pre-trained Language Models","1095":"MIND: A Large-scale Dataset for News Recommendation","1096":"FakeFlow: Fake News Detection by Modeling the Flow of Affective Information","1097":"Detecting fake news stories via multimodal analysis","1098":"FakeCovid - A Multilingual Cross-domain Fact Check News Dataset for COVID-19","1099":"ReCOVery: A Multimodal Repository for COVID-19 News Credibility Research","1100":"SAFE: Similarity-Aware Multi-Modal Fake News Detection","1101":"Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model","1102":"Weak Supervision for Fake News Detection via Reinforcement Learning","1103":"Fine-Grained Analysis of Propaganda in News Article","1104":"A Finnish news corpus for named entity recognition","1105":"KRED: Knowledge-Aware Document Representation for News Recommendations","1106":"MVAE: Multimodal Variational Autoencoder for Fake News Detection","1107":"SemEval-2019 Task 4: Hyperpartisan News Detection","1108":"Privacy-Preserving News Recommendation Model Learning","1109":"SpotFake+: A Multimodal Framework for Fake News Detection via Transfer Learning (Student Abstract)","1110":"NPA: Neural News Recommendation with Personalized Attention","1111":"Where Are the Facts? Searching for Fact-checked Information to Alleviate the Spread of Fake News","1112":"The Role of Personality and Linguistic Patterns in Discriminating Between Fake News Spreaders and Fact Checkers","1113":"Context-aware Graph Embedding for Session-based News Recommendation","1114":"Generating Representative Headlines for News Stories","1115":"Unsupervised Fake News Detection: A Graph-based Approach","1116":"Measuring and Characterizing Hate Speech on News\u00a0Websites","1117":"Through a different gate: An automated content analysis of how online news and print news differ","1118":"Learning Hierarchical Discourse-level Structure for Fake News Detection","1119":"Big Data and quality data for fake news and misinformation detection","1120":"Stock Price Prediction Using News Sentiment Analysis","1121":"FA-KES: A Fake News Dataset around the Syrian War","1122":"Proppy: A System to Unmask Propaganda in Online News","1123":"Differences in Health News from Reliable and Unreliable Media","1124":"A Topic-Agnostic Approach for Identifying Fake News Pages","1125":"Enhanced news sentiment analysis using deep learning methods","1126":"Semi-Supervised Learning and Graph Neural Networks for Fake News Detection","1127":"Content based News Recommendation via Shortest Entity Distance over Knowledge Graphs","1128":"BREAKING! Presenting Fake News Corpus for Automated Fact Checking","1129":"SAMSum Corpus: A Human-annotated Dialogue Dataset for Abstractive Summarization","1130":"Cross-Domain Modeling of Sentence-Level Evidence for Document Retrieval","1131":"Clustering without Over-Representation","1132":"Comparison between Multinomial and Bernoulli Na\u00efve Bayes for Text Classification","1133":"News Recommendation Systems - Accomplishments, Challenges & Future Directions","1134":"Learning to summarize from human feedback","1135":"Inducing Document Structure for Aspect-based Summarization","1136":"An Intelligent Fuzzy Rule-Based Personalized News Recommendation Using Social Media Mining","1137":"The random forest algorithm for statistical learning","1138":"Reinforcement-Learning based Portfolio Management with Augmented Asset Movement Prediction States","1139":"DP-LSTM: Differential Privacy-inspired LSTM for Stock Prediction Using Financial News","1140":"COVID-19 publications: Database coverage, citations, readers, tweets, news, Facebook walls, Reddit posts","1141":"Fake News Detection using Deep Markov Random Fields","1142":"News Graph: An Enhanced Knowledge Graph for News Recommendation","1143":"Fake News Detection Using Sentiment Analysis","1144":"Investigating Italian disinformation spreading on Twitter in the context of 2019 European elections","1145":"Efficacy of News Sentiment for Stock Market Prediction","1146":"Text Similarity Measures in News Articles by Vector Space Model Using NLP","1147":"News Sharing User Behaviour on Twitter: A Comprehensive Data Collection of News Articles and Social Interactions","1148":"SciLens: Evaluating the Quality of Scientific News Articles Using Social Media and Scientific Literature Indicators","1149":"Designing an Algorithm-Driven Text Generation System for Personalized and Interactive News Reading","1150":"Arabic Text Classification of News Articles Using Classical Supervised Classifiers","1151":"AMUSED: An Annotation Framework of Multi-modal Social Media Data","1152":"First to \u201cRead\u201d the News: News Analytics and Algorithmic Trading","1153":"Fake News Detection: A long way to go","1154":"Fake News Detection with Semantic Features and Text Mining","1155":"Fake News Propagation and Detection: A Sequential Model","1156":"Keep Meeting Summaries on Topic: Abstractive Multi-Modal Meeting Summarization","1157":"Localization of Fake News Detection via Multitask Transfer Learning","1158":"Media Slant is Contagious","1159":"Perverse Downstream Consequences of Debunking: Being Corrected by Another User for Posting False Political News Increases Subsequent Sharing of Low Quality, Partisan, and Toxic Content in a Twitter Field Experiment","1160":"The Dynamics of Distortion: How Successive Summarization Alters the Retelling of News","1161":"Social Media as an Auxiliary News Source","1162":"Algorithmic Extremism: Examining YouTube's Rabbit Hole of Radicalization","1163":"Ideology Detection in the Indian Mass Media","1164":"How to Effectively Identify and Communicate Person-Targeting Media Bias in Daily News Consumption?","1165":"Newsalyze: Effective Communication of Person-Targeting Biases in News Articles","1166":"SIGACT News Complexity Theory Column 111","1167":"SIGACT News Online Algorithms Column 38","1168":"SIGACT News Complexity Theory Column 108","1169":"SIGACT News Complexity Theory Column 110","1170":"SIGACT News Complexity Theory Column 109","1171":"Exploiting Transformer-Based Multitask Learning for the Detection of Media Bias in News Articles","1172":"Predicting and Understanding News Social Popularity with Emotional Salience Features","1173":"SIGACT News Online Algorithms Column 36","1174":"SIGACT News Complexity Theory Column 104","1175":"SIGACT News Complexity Theory Column 106","1176":"SIGACT News Complexity Theory Column 105","1177":"SIGACT News Complexity Theory Column 107","1178":"Assessing the Diffusion of Drones in Local Television News","1179":"Are Numbers Not Trusted in a \u201cPost-Truth\u201d Era? An Experiment on the Impact of Data on News Credibility","1180":"ANALISIS ISI TINGKAT KEBERIMBANGAN BERITA RUBRIK NEWS DAN SHOWBIZ YANG DISAJIKAN DALAM PORTAL BERITA LINE TODAY","1181":"SIGACT News Complexity Theory Column 102","1182":"Adversarial Learning for Zero-Shot Stance Detection on Social Media","1183":"Algorithmic or Human Source? Examining Relative Hostile Media Effect With a Transformer-Based Framework","1184":"Bluesky's Ahead: A Multi-Facility Collaboration for an a la Carte Software Project for Data Acquisition and Management","1185":"\u201cVirtual reality in libraries is common sense\u201d","1186":"dEFEND: Explainable Fake News Detection","1187":"Fake News Detection on Social Media using Geometric Deep Learning","1188":"Supervised Learning for Fake News Detection","1189":"Unsupervised Fake News Detection on Social Media: A Generative Approach","1190":"Neural News Recommendation with Multi-Head Self-Attention","1191":"A Survey of Fake News","1192":"Fake News: Fundamental Theories, Detection Strategies and Challenges","1193":"Neural News Recommendation with Attentive Multi-View Learning","1194":"COVID-19 News Analysis Using News Big Data : Focusing on Topic Modeling Analysis","1195":"Fake News Analysis Modeling Using Quote Retweet","1196":"Pandemic Populism: Facebook Pages of Alternative News Media and the Corona Crisis - A Computational Content Analysis","1197":"An Arabic Corpus of Fake News: Collection, Analysis and Classification","1198":"Hierarchical Propagation Networks for Fake News Detection: Investigation and Exploitation","1199":"A Comparative Analysis of Logistic Regression, Random Forest and KNN Models for the Text Classification","1200":"The Brexit Botnet and User-Generated Hyperpartisan News","1201":"The Role of User Profiles for Fake News Detection","1202":"XFake: Explainable Fake News Detector with Visualizations","1203":"Fake News Detection via NLP is Vulnerable to Adversarial Attacks","1204":"Deep Learning--based Text Classification","1205":"Social media analytics: analysis and visualisation of news diffusion using NodeXL","1206":"Digital media news categorization using Bernoulli document model for web content convergence","1207":"FACT: a Framework for Analysis and Capture of Twitter Graphs","1208":"Fake News Stance Detection Using Deep Learning Architecture (CNN-LSTM)","1209":"What happened? The Spread of Fake News Publisher Content During the 2016 U.S. Presidential Election","1210":"Simulating tests to test simulation","1211":"Low Gain Ripple and DC-Grounded Slant-Polarized Formulation With 360\u00b0 Broadbeam Coverage","1212":"Sequential Domain Coverage (\u201cCover\u201d Property and \u201cCover\u201d Sequence)","1213":"Implications of Coverage Methodology","1214":"GNSS-RS Tomography: Retrieval of Tropospheric Water Vapor Fields Using GNSS and RS Observations","1215":"Backscatter Characteristics of Snow Avalanches for Mapping With Local Resolution Weighting","1216":"Right-Angled V-Shaped conformal Dual-Patch Antenna Array for RAIN RFID Doorway Portals","1217":"IRNSS information for beginners","1218":"Comparison of Tropospheric Path Delay Estimates from GNSS and Space-Borne SAR Interferometry in Alpine Conditions","1219":"Performance analysis of moving ship target signal integration and detection in geosynchronous synthetic aperture radar","1220":"Utilization of Artificial Neural Networks for Estimation of Slant-Path Rain Attenuation","1221":"A Novel Geosynchronous Spaceborne-Airborne Bistatic Multichannel Sar For Ground Moving Targets Indication","1222":"Liking the sound of their own voices: A case of TV anchors and their shows","1223":"A Dual Slant-Polarized Cylindrical Array of Tightly Coupled Dipole Antennas","1224":"Cross-Comparison and Methodological Improvement in GPS Tomography","1225":"Coverage protocols for wireless sensor networks: Review and future directions","1226":"GoodNewsEveryone: A Corpus of News Headlines Annotated with Emotions, Semantic Roles, and Reader Perception","1227":"Fake News Perception in Germany: A Representative Study of People's Attitudes and Approaches to Counteract Disinformation","1228":"Factitious: Large Scale Computer Game to Fight Fake News and Improve News Literacy","1229":"Training doctors\u2019 social skills to break bad news: evaluation of the impact of virtual environment displays on the sense of presence","1230":"Evaluation of Feature Extraction TF-IDF in Indonesian Hoax News Classification","1231":"What drives unverified information sharing and cyberchondria during the COVID-19 pandemic?","1232":"Why do People Share Misinformation during the COVID-19 Pandemic?","1233":"The curiosity effect: Information seeking in the contemporary news environment","1234":"Self Multi-Head Attention-based Convolutional Neural Networks for fake news detection","1235":"A review of mobile robots: Concepts, methods, theoretical framework, and applications","1236":"Framing Artificial Intelligence in American Newspapers","1237":"Fake news detection using deep learning models: A novel approach","1238":"The Government's Dividend: Complex Perceptions of Social Media Misinformation in China","1239":"We Don't Give a Second Thought Before Providing Our Information: Understanding Users' Perceptions of Information Collection by Apps in Urban Bangladesh","1240":"Employing a Chatbot for News Dissemination during Crisis: Design, Implementation and Evaluation","1241":"Undergraduates' News Consumption and Perceptions of Fake News in Science","1242":"Consuming Fake News: A Matter of Age? The Perception of Political Fake News Stories in Facebook Ads","1243":"Transformer-based Language Model Fine-tuning Methods for COVID-19 Fake News Detection","1244":"Perceptions of mis- or disinformation exposure predict political cynicism: Evidence from a two-wave survey during the 2018 US midterm elections","1245":"A Cross-National Study on the Perception of Algorithm News in the East and the West","1246":"Detecting Political Bias Trolls in Twitter Data","1247":"Reasoning about Political Bias in Content Moderation","1248":"Limiting Bias from Test-Control Interference in Online Marketplace Experiments","1249":"Capturing Rationalization Bias and Differential Item Functioning: A Unified Bayesian Scaling Approach","1250":"Bias Misperceived: The Role of Partisanship and Misinformation in YouTube Comment Moderation","1251":"Shadowing as a Tool for Studying Political Elites","1252":"Looking for twins: how to build better counterfactuals with matching","1253":"Impact of politically biased data on hate speech classification","1254":"Voter Registration Databases and MRP: Toward the Use of Large-Scale Databases in Public Opinion Research","1255":"Understanding, Choosing, and Unifying Multilevel and Fixed Effect Approaches","1256":"A Bayesian Alternative to Synthetic Control for Comparative Case Studies","1257":"Information gerrymandering and undemocratic decisions","1258":"Perils and Challenges of Social Media and Election Manipulation Analysis: The 2018 US Midterms","1259":"A Politics of Objectivity: Biomedicine's Attempts to Grapple with \"non-financial\" Conflicts of Interest","1260":"Preface to the papers on \u2018Causal inference from non\u2010experimental studies: challenges, developments and applications\u2019","1261":"Identifying Biases in Politically Biased Wikis through Word Embeddings","1262":"Minimizing Interference and Selection Bias in Network Experiment Design","1263":"Interference, Bias, and Variance in Two-Sided Marketplace Experimentation: Guidance for Platforms","1264":"Democratizing Algorithmic Fairness","1265":"How Partisanship and Perceived Political Bias Affect Wikipedia Entries of News Sources","1266":"Gatekeeping, Fast and Slow: An Empirical Study of Referral Errors in the Emergency Department","1267":"Hashtags for gatekeeping of information on social media","1268":"Computational News Discovery: Towards Design Considerations for Editorial Orientation Algorithms in Journalism","1269":"Auditing News Curation Systems: A Case Study Examining Algorithmic and Editorial Logic in Apple News","1270":"Algorithmic Personalization and the Two-Step Flow of Communication","1271":"Bots are less central than verified accounts during contentious political events","1272":"Out of the laboratory and into the classroom: the future of artificial intelligence in education","1273":"Facebook and virtual nationhood: social media and the Arab Canadians community"},"abstract":{"0":"Wikipedia is a critical platform for organizing and disseminating knowledge. One of the key principles of Wikipedia is neutral point of view (NPOV), so that bias is not injected into objective treatment of subject matter. As part of our research vision to develop resilient bias detection models that can self-adapt over time, we present in this paper our initial investigation of the potential of a cross-domain transfer learning approach to improve Wikipedia bias detection. The ultimate goal is to future-proof Wikipedia in the face of dynamic, evolving kinds of linguistic bias and adversarial manipulations intended to evade NPOV issues. We highlight the impact of incorporating evidence of bias from other subjectivity rich domains into further pre-training a BERT-based model, resulting in strong performance in comparison with traditional methods.","1":"Recent studies in the field of Machine Translation (MT) and Natural Language Processing (NLP) have shown that existing models amplify biases observed in the training data. The amplification of biases in language technology has mainly been examined with respect to specific phenomena, such as gender bias. In this work, we go beyond the study of gender in MT and investigate how bias amplification might affect language in a broader sense. We hypothesize that the \u2018algorithmic bias\u2019, i.e. an exacerbation of frequently observed patterns in combination with a loss of less frequent ones, not only exacerbates societal biases present in current datasets but could also lead to an artificially impoverished language: \u2018machine translationese\u2019. We assess the linguistic richness (on a lexical and morphological level) of translations created by different data-driven MT paradigms \u2013 phrase-based statistical (PB-SMT) and neural MT (NMT). Our experiments show that there is a loss of lexical and syntactic richness in the translations produced by all investigated MT paradigms for two language pairs (EN-FR and EN-ES).","2":null,"3":"We evaluate whether BERT, a widely used neural network for sentence processing, acquires an inductive bias towards forming structural generalizations through pretraining on raw data. We conduct four experiments testing its preference for structural vs. linear generalizations in different structure-dependent phenomena. We find that BERT makes a structural generalization in 3 out of 4 empirical domains---subject-auxiliary inversion, reflexive binding, and verb tense detection in embedded clauses---but makes a linear generalization when tested on NPI licensing. We argue that these results are the strongest evidence so far from artificial learners supporting the proposition that a structural bias can be acquired from raw data. If this conclusion is correct, it is tentative evidence that some linguistic universals can be acquired by learners without innate biases. However, the precise implications for human language acquisition are unclear, as humans learn language from significantly less data than BERT.","4":"We propose a novel methodology for analyzing the encoding of grammatical structure in neural language models through transfer learning. We test how a language model can leverage its internal representations to transfer knowledge across languages and symbol systems. We train LSTMs on non-linguistic, structured data and test their performance on human language to assess which kinds of data induce generalizable encodings that LSTMs can use for natural language. We find that models trained on structured data such as music and Java code have internal representations that help in modelling human language, and that, surprisingly, adding minimal amounts of structure to the training data makes a large difference in transfer to natural language. Further experiments on transfer between human languages show that zero-shot performance on a test language is highly correlated with syntactic similarity to the training language, even after removing any vocabulary overlap. This suggests that the internal representations induced from natural languages are typologically coherent: they encode the features and differences outlined in typological studies. Our results provide insights into how neural networks represent linguistic structure, and also about the kinds of structural biases that give learners the ability to model language.","5":null,"6":"We consider the problem of using observational data to estimate the causal effects of linguistic properties. For example, does writing a complaint politely lead to a faster response time? How much will a positive product review increase sales? This paper addresses two technical challenges related to the problem before developing a practical method. First, we formalize the causal quantity of interest as the effect of a writer\u2019s intent, and establish the assumptions necessary to identify this from observational data. Second, in practice, we only have access to noisy proxies for the linguistic properties of interest\u2014e.g., predictions from classifiers and lexicons. We propose an estimator for this setting and prove that its bias is bounded when we perform an adjustment for the text. Based on these results, we introduce TextCause, an algorithm for estimating causal effects of linguistic properties. The method leverages (1) distant supervision to improve the quality of noisy proxies, and (2) a pre-trained language model (BERT) to adjust for the text. We show that the proposed method outperforms related approaches when estimating the effect of Amazon review sentiment on semi-simulated sales figures. Finally, we present an applied case study investigating the effects of complaint politeness on bureaucratic response times.","7":"This position paper describes and critiques the Pretraining-Agnostic Identically Distributed (PAID) evaluation paradigm, which has become a central tool for measuring progress in natural language understanding. This paradigm consists of three stages: (1) pre-training of a word prediction model on a corpus of arbitrary size; (2) fine-tuning (transfer learning) on a training set representing a classification task; (3) evaluation on a test set drawn from the same distribution as that training set. This paradigm favors simple, low-bias architectures, which, first, can be scaled to process vast amounts of data, and second, can capture the fine-grained statistical properties of a particular data set, regardless of whether those properties are likely to generalize to examples of the task outside the data set. This contrasts with humans, who learn language from several orders of magnitude less data than the systems favored by this evaluation paradigm, and generalize to new tasks in a consistent way. We advocate for supplementing or replacing PAID with paradigms that reward architectures that generalize as quickly and robustly as humans.","8":"A common factor in bias measurement methods is the use of hand-curated seed lexicons, but there remains little guidance for their selection. We gather seeds used in prior work, documenting their common sources and rationales, and in case studies of three English-language corpora, we enumerate the different types of social biases and linguistic features that, once encoded in the seeds, can affect subsequent bias measurements. Seeds developed in one context are often re-used in other contexts, but documentation and evaluation remain necessary precursors to relying on seeds for sensitive measurements.","9":"Understanding the political perspective shaping the way events are discussed in the media is increasingly important due to the dramatic change in news distribution. With the advance in text classification models, the performance of political perspective detection is also improving rapidly. However, current deep learning based text models often require a large amount of supervised data for training, which can be very expensive to obtain for this task. Meanwhile, models pre-trained on the general source and task (e.g. BERT) lack the ability to focus on bias-related text span. In this paper, we propose a novel framework that pretrains the text model using signals from the rich social and linguistic context that is readily available, including entity mentions, news sharing, and frame indicators. The pre-trained models benefit from tasks related to bias detection and therefore are easier to train with the bias labels. We demonstrate the effectiveness of our proposed framework by experiments on two news bias datasets. The models with pre-training achieve significant improvement in performance and are capable of identifying the text span for bias better.","10":"Dehumanization is a pernicious psychological process that often leads to extreme intergroup bias, hate speech, and violence aimed at targeted social groups. Despite these serious consequences and the wealth of available data, dehumanization has not yet been computationally studied on a large scale. Drawing upon social psychology research, we create a computational linguistic framework for analyzing dehumanizing language by identifying linguistic correlates of salient components of dehumanization. We then apply this framework to analyze discussions of LGBTQ people in the New York Times from 1986 to 2015. Overall, we find increasingly humanizing descriptions of LGBTQ people over time. However, we find that the label homosexual has emerged to be much more strongly associated with dehumanizing attitudes than other labels, such as gay. Our proposed techniques highlight processes of linguistic variation and change in discourses surrounding marginalized groups. Furthermore, the ability to analyze dehumanizing language at a large scale has implications for automatically detecting and understanding media bias as well as abusive language online.","11":"With increasing diversity in the labor market as well as the work force, employers receive resumes from an increasingly diverse population. However, studies and field experiments have confirmed the presence of bias in the labor market based on gender, race, and ethnicity. Many employers use automated resume screening to filter the many possible matches. Depending on how the automated screening algorithm is trained it can potentially exhibit bias towards a particular population by favoring certain socio-linguistic characteristics. The resume writing style and socio-linguistics are a potential source of bias as they correlate with protected characteristics such as ethnicity. A biased dataset is often translated into biased AI algorithms and de-biasing algorithms are being contemplated. In this work, we study the effects of socio-linguistic bias on resume to job description matching algorithms. We develop a simple technique, called fair-tf-idf, to match resumes with job descriptions in a fair way by mitigating the socio-linguistic bias.","12":null,"13":"Despite the recent progress, little is known about the features captured by state-of-the-art neural relation extraction (RE) models. Common methods encode the source sentence, conditioned on the entity mentions, before classifying the relation. However, the complexity of the task makes it difficult to understand how encoder architecture and supporting linguistic knowledge affect the features learned by the encoder. We introduce 14 probing tasks targeting linguistic properties relevant to RE, and we use them to study representations learned by more than 40 different encoder architecture and linguistic feature combinations trained on two datasets, TACRED and SemEval 2010 Task 8. We find that the bias induced by the architecture and the inclusion of linguistic features are clearly expressed in the probing task performance. For example, adding contextualized word representations greatly increases performance on probing tasks with a focus on named entity and part-of-speech information, and yields better results in RE. In contrast, entity masking improves RE, but considerably lowers performance on entity type related probing tasks.","14":"Despite the recent progress, little is known about the features captured by state-of-the-art neural relation extraction (RE) models. Common methods encode the source sentence, conditioned on the entity mentions, before classifying the relation. However, the complexity of the task makes it difficult to understand how encoder architecture and supporting linguistic knowledge affect the features learned by the encoder. We introduce 14 probing tasks targeting linguistic properties relevant to RE, and we use them to study representations learned by more than 40 different encoder architecture and linguistic feature combinations trained on two datasets, TACRED and SemEval 2010 Task 8. We find that the bias induced by the architecture and the inclusion of linguistic features are clearly expressed in the probing task performance. For example, adding contextualized word representations greatly increases performance on probing tasks with a focus on named entity and part-of-speech information, and yields better results in RE. In contrast, entity masking improves RE, but considerably lowers performance on entity type related probing tasks.","15":"During the last years, the phenomenon of hate against women increased exponentially especially in online environments such as microblogs. Although this alarming phenomenon has triggered many studies both from computational linguistic and machine learning points of view, less effort has been spent to analyze if those misogyny detection models are affected by an unintended bias. This can lead the models to associate unreasonably high misogynous scores to a non-misogynous text only because it contains certain terms, called identity, terms. This work is the first attempt to address the problem of measuring and mitigating unintended bias in machine learning models trained for the misogyny detection task. We propose a novel synthetic test set that can be used as evaluation framework for measuring the unintended bias and different mitigation strategies specific for this task. Moreover, we provide a misogyny detection model that demonstrate to obtain the best classification performance in the state-of-the-art. Experimental results on recently introduced bias metrics confirm the ability of the bias mitigation treatment to reduce the unintended bias of the proposed misogyny detection model. CCS CONCEPTS \u2022 Social and professional topics $\\rightarrow$ Hate speech; \u2022 Computing methodologies $\\rightarrow$ Neural networks.","16":"The increasing prevalence of political bias in news media calls for greater public awareness of it, as well as robust methods for its detection. While prior work in NLP has primarily focused on the lexical bias captured by linguistic attributes such as word choice and syntax, other types of bias stem from the actual content selected for inclusion in the text. In this work, we investigate the effects of informational bias: factual content that can nevertheless be deployed to sway reader opinion. We first produce a new dataset, BASIL, of 300 news articles annotated with 1,727 bias spans and find evidence that informational bias appears in news articles more frequently than lexical bias. We further study our annotations to observe how informational bias surfaces in news articles by different media outlets. Lastly, a baseline model for informational bias prediction is presented by fine-tuning BERT on our labeled data, indicating the challenges of the task and future directions.","17":"Text mining have gained great momentum in recent years, with user-generated content becoming widely available. One key use is comment mining, with much attention being given to sentiment analysis and opinion mining. An essential step in the process of comment mining is text pre-processing; a step in which each linguistic term is assigned with a weight that commonly increases with its appearance in the studied text, yet is offset by the frequency of the term in the domain of interest. A common practice is to use the well-known tf-idf formula to compute these weights. This paper reveals the bias introduced by between-participants\u2019 discourse to the study of comments in social media, and proposes an adjustment. We find that content extracted from discourse is often highly correlated, resulting in dependency structures between observations in the study, thus introducing a statistical bias. Ignoring this bias can manifest in a non-robust analysis at best and can lead to an entirely wrong conclusion at worst. We propose an adjustment to tf-idf that accounts for this bias. We illustrate the effects of both the bias and correction with with seven Facebook fan pages data, covering different domains, including news, finance, politics, sport, shopping, and entertainment.","18":"Abstract Capitalizing upon the typological fact that the same content may be coded in different positions and at different structural levels, this study examines whether the syntactic and the morphological levels exhibit different serial-order preferences. A large-scale comparison of word and morpheme order across six grammatical categories including definiteness and negation reveals that all six categories document the same interaction effect: the syntactic level shows a significantly higher preposing rate than the morphological level does. A morphological postposing bias is observed for five categories, a syntactic preposing bias for four and a syntactic postposing bias for two. This interaction effect is not affected by a genealogical or areal bias. The empirical patterns are mainly shaped by a predilection for lexical material to precede grammatical material. Early placement may also be brought about by ultra-high token frequency. The fact that the postposing bias does occur sporadically at the syntactic level casts some doubt on the well-known suffixing preference as the appropriate level of generalization.","19":"Several linguistic studies have shown the prevalence of various lexical and grammatical patterns in texts authored by a person of a particular gender, but models for part-of-speech tagging and dependency parsing have still not adapted to account for these differences. To address this, we annotate the Wall Street Journal part of the Penn Treebank with the gender information of the articles\u2019 authors, and build taggers and parsers trained on this data that show performance differences in text written by men and women. Further analyses reveal numerous part-of-speech tags and syntactic relations whose prediction performances benefit from the prevalence of a specific gender in the training data. The results underscore the importance of accounting for gendered differences in syntactic tasks, and outline future venues for developing more accurate taggers and parsers. We release our data to the research community.","20":"We introduce BitFit, a sparse-finetuning method where only the bias-terms of the model (or a subset of them) are being modified. We show that with small-to-medium training data, applying BitFit on pre-trained BERT models is competitive with (and sometimes better than) fine-tuning the entire model. For larger data, the method is competitive with other sparse fine-tuning methods.Besides their practical utility, these findings are relevant for the question of understanding the commonly-used process of finetuning: they support the hypothesis that finetuning is mainly about exposing knowledge induced by language-modeling training, rather than learning new task-specific linguistic knowledge.","21":"Pretrained masked language models (MLMs) require finetuning for most NLP tasks. Instead, we evaluate MLMs out of the box via their pseudo-log-likelihood scores (PLLs), which are computed by masking tokens one by one. We show that PLLs outperform scores from autoregressive language models like GPT-2 in a variety of tasks. By rescoring ASR and NMT hypotheses, RoBERTa reduces an end-to-end LibriSpeech model\u2019s WER by 30% relative and adds up to +1.7 BLEU on state-of-the-art baselines for low-resource translation pairs, with further gains from domain adaptation. We attribute this success to PLL\u2019s unsupervised expression of linguistic acceptability without a left-to-right bias, greatly improving on scores from GPT-2 (+10 points on island effects, NPI licensing in BLiMP). One can finetune MLMs to give scores without masking, enabling computation in a single inference pass. In all, PLLs and their associated pseudo-perplexities (PPPLs) enable plug-and-play use of the growing number of pretrained MLMs; e.g., we use a single cross-lingual model to rescore translations in multiple languages. We release our library for language model scoring at https:\/\/github.com\/awslabs\/mlm-scoring.","22":"If the same neural network architecture is trained multiple times on the same dataset, will it make similar linguistic generalizations across runs? To study this question, we fine-tuned 100 instances of BERT on the Multi-genre Natural Language Inference (MNLI) dataset and evaluated them on the HANS dataset, which evaluates syntactic generalization in natural language inference. On the MNLI development set, the behavior of all instances was remarkably consistent, with accuracy ranging between 83.6% and 84.8%. In stark contrast, the same models varied widely in their generalization performance. For example, on the simple case of subject-object swap (e.g., determining that \u201cthe doctor visited the lawyer\u201d does not entail \u201cthe lawyer visited the doctor\u201d), accuracy ranged from 0.0% to 66.2%. Such variation is likely due to the presence of many local minima in the loss surface that are equally attractive to a low-bias learner such as a neural network; decreasing the variability may therefore require models with stronger inductive biases.","23":"We generalize the notion of measuring social biases in word embeddings to visually grounded word embeddings. Biases are present in grounded embeddings, and indeed seem to be equally or more significant than for ungrounded embeddings. This is despite the fact that vision and language can suffer from different biases, which one might hope could attenuate the biases in both. Multiple ways exist to generalize metrics measuring bias in word embeddings to this new setting. We introduce the space of generalizations (Grounded-WEAT and Grounded-SEAT) and demonstrate that three generalizations answer different yet important questions about how biases, language, and vision interact. These metrics are used on a new dataset, the first for grounded bias, created by augmenting standard linguistic bias benchmarks with 10,228 images from COCO, Conceptual Captions, and Google Images. Dataset construction is challenging because vision datasets are themselves very biased. The presence of these biases in systems will begin to have real-world consequences as they are deployed, making carefully measuring bias and then mitigating it critical to building a fair society.","24":"Predicting the political bias and the factuality of reporting of entire news outlets are critical elements of media profiling, which is an understudied but an increasingly important research direction. The present level of proliferation of fake, biased, and propagandistic content online has made it impossible to fact-check every single suspicious claim, either manually or automatically. Thus, it has been proposed to profile entire news outlets and to look for those that are likely to publish fake or biased content. This makes it possible to detect likely \u201cfake news\u201d the moment they are published, by simply checking the reliability of their source. From a practical perspective, political bias and factuality of reporting have a linguistic aspect but also a social context. Here, we study the impact of both, namely (i) what was written (i.e., what was published by the target medium, and how it describes itself in Twitter) vs. (ii) who reads it (i.e., analyzing the target medium\u2019s audience on social media). We further study (iii) what was written about the target medium (in Wikipedia). The evaluation results show that what was written matters most, and we further show that putting all information sources together yields huge improvements over the current state-of-the-art.","25":"Existing Visual Question Answering (VQA) methods tend to exploit dataset biases and spurious statistical correlations, instead of producing right answers for the right reasons. To address this issue, recent bias mitigation methods for VQA propose to incorporate visual cues (e.g., human attention maps) to better ground the VQA models, showcasing impressive gains. However, we show that the performance improvements are not a result of improved visual grounding, but a regularization effect which prevents over-fitting to linguistic priors. For instance, we find that it is not actually necessary to provide proper, human-based cues; random, insensible cues also result in similar improvements. Based on this observation, we propose a simpler regularization scheme that does not require any external annotations and yet achieves near state-of-the-art performance on VQA-CPv2.","26":"Children use syntax to learn verbs, in a process known as syntactic bootstrapping. The structure-mapping account proposes that syntactic bootstrapping begins with a universal bias to map each noun phrase in a sentence onto a participant role in a structured conceptual representation of an event. Equipped with this bias, children interpret the number of noun phrases accompanying a new verb as evidence about the semantic predicate-argument structure of the sentence, and therefore about the meaning of the verb. In this paper, we first review evidence for the structure-mapping account, and\u00a0then discuss challenges to the account arising from the existence of languages that allow verbs' arguments to be omitted, such as Korean. These challenges prompt us to (a) refine our notion of the distributional learning mechanisms that create representations of sentence structure, and (b) propose that an expectation of discourse continuity allows children to gather linguistic evidence for each verb's arguments across sentences in a coherent discourse. Taken together, the proposed learning mechanisms and biases sketch a route whereby simple aspects of sentence structure guide verb learning from the start of multi-word sentence comprehension, and do so even if some of the new verb's arguments are omitted due to discourse redundancy.","27":"How do typological properties such as word order and morphological case marking affect the ability of neural sequence models to acquire the syntax of a language? Cross-linguistic comparisons of RNNs\u2019 syntactic performance (e.g., on subject-verb agreement prediction) are complicated by the fact that any two languages differ in multiple typological properties, as well as by differences in training corpus. We propose a paradigm that addresses these issues: we create synthetic versions of English, which differ from English in one or more typological parameters, and generate corpora for those languages based on a parsed English corpus. We report a series of experiments in which RNNs were trained to predict agreement features for verbs in each of those synthetic languages. Among other findings, (1) performance was higher in subject-verb-object order (as in English) than in subject-object-verb order (as in Japanese), suggesting that RNNs have a recency bias; (2) predicting agreement with both subject and object (polypersonal agreement) improves over predicting each separately, suggesting that underlying syntactic knowledge transfers across the two tasks; and (3) overt morphological case makes agreement prediction significantly easier, regardless of word order.","28":"Visual question answering (VQA) models have been shown to over-rely on linguistic biases in VQA datasets, answering questions \u201cblindly\u201d without considering visual context. Adversarial regularization (AdvReg) aims to address this issue via an adversary sub-network that encourages the main model to learn a bias-free representation of the question. In this work, we investigate the strengths and shortcomings of AdvReg with the goal of better understanding how it affects inference in VQA models. Despite achieving a new state-of-the-art on VQA-CP, we find that AdvReg yields several undesirable side-effects, including unstable gradients and sharply reduced performance on in-domain examples. We demonstrate that gradual introduction of regularization during training helps to alleviate, but not completely solve, these issues. Through error analyses, we observe that AdvReg improves generalization to binary questions, but impairs performance on questions with heterogeneous answer distributions. Qualitatively, we also find that regularized models tend to over-rely on visual features, while ignoring important linguistic cues in the question. Our results suggest that AdvReg requires further refinement before it can be considered a viable bias mitigation technique for VQA.","29":"Generating high-quality paraphrases is a fundamental yet challenging natural language processing task. Despite the effectiveness of previous work based on generative models, there remain problems with exposure bias in recurrent neural networks, and often a failure to generate realistic sentences. To overcome these challenges, we propose the first end-to-end conditional generative architecture for generating paraphrases via adversarial training, which does not depend on extra linguistic information. Extensive experiments on four public datasets demonstrate the proposed method achieves state-of-the-art results, outperforming previous generative architectures on both automatic metrics (BLEU, METEOR, and TER) and human evaluations.","30":"Depression is a common, but serious mental disorder that affects people all over the world. Besides providing an easier way of diagnosing the disorder, a computer-aided automatic depression assessment system is demanded in order to reduce subjective bias in the diagnosis. We propose a multimodal fusion of speech and linguistic representation for depression detection. We train our model to infer the Patient Health Questionnaire (PHQ) score of subjects from AVEC 2019 DDS Challenge database, the E-DAIC corpus. For the speech modality, we use deep spectrum features extracted from a pretrained VGG-16 network and employ a Gated Convolutional Neural Network (GCNN) followed by a LSTM layer. For the textual embeddings, we extract BERT textual features and employ a Convolutional Neural Network (CNN) followed by a LSTM layer. We achieved a CCC score equivalent to 0.497 and 0.608 on the E-DAIC corpus development set using the unimodal speech and linguistic models respectively. We further combine the two modalities using a feature fusion approach in which we apply the last representation of each single modality model to a fully-connected layer in order to estimate the PHQ score. With this multimodal approach, it was possible to achieve the CCC score of 0.696 on the development set and 0.403 on the testing set of the E-DAIC corpus, which shows an absolute improvement of 0.283 points from the challenge baseline.","31":"Corpus selection bias in international relations research presents an epistemological problem: How do we know what we know? Most social science research in the field of text analytics relies on English language corpora, biasing our ability to understand international phenomena. To address the issue of corpus selection bias, we introduce results that suggest that machine translation may be used to address non-English sources. We use human translation and machine translation (Google Translate) on a collection of aligned sentences from United Nations documents extracted from the Multi-UN corpus, analyzed with a \u201cbag of words\u201d analysis tool, Linguistic Inquiry Word Count (LIWC). Overall, the LIWC indices proved relatively stable across machine and human translated sentences. We find that while there are statistically significant differences between the original and translated documents, the effect sizes are relatively small, especially when looking at psychological processes.","32":"Training data for NLP tasks often exhibits gender bias in that fewer sentences refer to women than to men. In Neural Machine Translation (NMT) gender bias has been shown to reduce translation quality, particularly when the target language has grammatical gender. The recent WinoMT challenge set allows us to measure this effect directly (Stanovsky et al, 2019) Ideally we would reduce system bias by simply debiasing all data prior to training, but achieving this effectively is itself a challenge. Rather than attempt to create a \u2018balanced\u2019 dataset, we use transfer learning on a small set of trusted, gender-balanced examples. This approach gives strong and consistent improvements in gender debiasing with much less computational cost than training from scratch. A known pitfall of transfer learning on new domains is \u2018catastrophic forgetting\u2019, which we address at adaptation and inference time. During adaptation we show that Elastic Weight Consolidation allows a performance trade-off between general translation quality and bias reduction. At inference time we propose a lattice-rescoring scheme which outperforms all systems evaluated in Stanovsky et al, 2019 on WinoMT with no degradation of general test set BLEU. We demonstrate our approach translating from English into three languages with varied linguistic properties and data availability.","33":"Contextualized word embeddings have been replacing standard embeddings as the representational knowledge source of choice in NLP systems. Since a variety of biases have previously been found in standard word embeddings, it is crucial to assess biases encoded in their replacements as well. Focusing on BERT (Devlin et al., 2018), we measure gender bias by studying associations between gender-denoting target words and names of professions in English and German, comparing the findings with real-world workforce statistics. We mitigate bias by fine-tuning BERT on the GAP corpus (Webster et al., 2018), after applying Counterfactual Data Substitution (CDS) (Maudslay et al., 2019). We show that our method of measuring bias is appropriate for languages such as English, but not for languages with a rich morphology and gender-marking, such as German. Our results highlight the importance of investigating bias and mitigation techniques cross-linguistically, especially in view of the current emphasis on large-scale, multilingual language models.","34":"Training on only perfect Standard English corpora predisposes pre-trained neural networks to discriminate against minorities from non-standard linguistic backgrounds (e.g., African American Vernacular English, Colloquial Singapore English, etc.). We perturb the inflectional morphology of words to craft plausible and semantically similar adversarial examples that expose these biases in popular NLP models, e.g., BERT and Transformer, and show that adversarially fine-tuning them for a single epoch significantly improves robustness without sacrificing performance on clean data.","35":"We explore unconstrained natural language feedback as a learning signal for artificial agents. Humans use rich and varied language to teach, yet most prior work on interactive learning from language assumes a particular form of input (e.g. commands). We propose a general framework which does not make this assumption. We decompose linguistic feedback into two components: a grounding to $\\textit{features}$ of a Markov decision process and $\\textit{sentiment}$ about those features. We then perform an analogue of inverse reinforcement learning, regressing the teacher's sentiment on the features to infer their latent reward function. To evaluate our approach, we first collect a corpus of teaching behavior in a cooperative task where both teacher and learner are human. We use our framework to implement two artificial learners: a simple \"literal\" model and a \"pragmatic\" model with additional inductive biases. We baseline these with a neural network trained end-to-end to predict latent rewards. We then repeat our initial experiment pairing human teachers with our models. We find our \"literal\" and \"pragmatic\" models successfully learn from live human feedback and offer statistically-significant performance gains over the end-to-end baseline, with the \"pragmatic\" model approaching human performance on the task. Inspection reveals the end-to-end network learns representations similar to our models, suggesting they reflect emergent properties of the data. Our work thus provides insight into the information structure of naturalistic linguistic feedback as well as methods to leverage it for reinforcement learning.","36":"One reason pretraining on self-supervised linguistic tasks is effective is that it teaches models features that are helpful for language understanding. However, we want pretrained models to learn not only to represent linguistic features, but also to use those features preferentially during fine-turning. With this goal in mind, we introduce a new English-language diagnostic set called MSGS (the Mixed Signals Generalization Set), which consists of 20 ambiguous binary classification tasks that we use to test whether a pretrained model prefers linguistic or surface generalizations during fine-tuning. We pretrain RoBERTa models from scratch on quantities of data ranging from 1M to 1B words and compare their performance on MSGS to the publicly available RoBERTa-base. We find that models can learn to represent linguistic features with little pretraining data, but require far more data to learn to prefer linguistic generalizations over surface ones. Eventually, with about 30B words of pretraining data, RoBERTa-base does demonstrate a linguistic bias with some regularity. We conclude that while self-supervised pretraining is an effective way to learn helpful inductive biases, there is likely room to improve the rate at which models learn which features matter.","37":"In this paper, we propose to investigate the problem of out-of-domain visio-linguistic pretraining, where the pretraining data distribution differs from that of downstream data on which the pretrained model will be fine-tuned. Existing methods for this problem are purely likelihood-based, leading to the spurious correlations and hurt the generalization ability when transferred to out-of-domain downstream tasks. By spurious correlation, we mean that the conditional probability of one token (object or word) given another one can be high (due to the dataset biases) without robust (causal) relationships between them. To mitigate such dataset biases, we propose a Deconfounded Visio-Linguistic Bert framework, abbreviated as DeVLBert, to perform intervention-based learning. We borrow the idea of the backdoor adjustment from the research field of causality and propose several neural-network based architectures for Bert-style out-of-domain pretraining. The quantitative results on three downstream tasks, Image Retrieval (IR), Zero-shot IR, and Visual Question Answering, show the effectiveness of DeVLBert by boosting generalization ability.","38":"We propose transfer learning as a method for analyzing the encoding of grammatical structure in neural language models. We train LSTMs on non-linguistic data and evaluate their performance on natural language to assess which kinds of data induce generalizable structural features that LSTMs can use for natural language. We find that training on non-linguistic data with latent structure (MIDI music or Java code) improves test performance on natural language, despite no overlap in surface form or vocabulary. Training on artificial languages containing recursion (hierarchical structure) also improves performance on natural language, again with no vocabulary overlap. Surprisingly, training on artificial languages consisting of sets of separated pairs of words, but with no recursion, improves performance on natural language as well as recursive languages do. Experiments on transfer between natural languages show that zero-shot performance on a test language is highly correlated with typological syntactic similarity to the training language, suggesting that representations induced from natural languages correspond to the cross-linguistic syntactic properties studied in linguistic typology. Our results provide insights into the ways that neural models represent abstract syntactic structure, and also about the kind of structural inductive biases which a learner needs to model language.","39":"Media is an indispensable source of information and opinion, shaping the beliefs and attitudes of our society. Obviously, media portals can also provide overly biased content, e.g., by reporting on political events in a selective or incomplete manner. A relevant question hence is whether and how such a form of unfair news coverage can be exposed. This paper addresses the automatic detection of bias, but it goes one step further in that it explores how political bias and unfairness are manifested linguistically. We utilize a new corpus of 6964 news articles with labels derived from adfontesmedia.com to develop a neural model for bias assessment. Analyzing the model on article excerpts, we find insightful bias patterns at different levels of text granularity, from single words to the whole article discourse.","40":"How do learners acquire languages from the limited data available to them? This process must involve some inductive biases - factors that affect how a learner generalizes - but it is unclear which inductive biases can explain observed patterns in language acquisition. To facilitate computational modeling aimed at addressing this question, we introduce a framework for giving particular linguistic inductive biases to a neural network model; such a model can then be used to empirically explore the effects of those inductive biases. This framework disentangles universal inductive biases, which are encoded in the initial values of a neural network's parameters, from non-universal factors, which the neural network must learn from data in a given language. The initial state that encodes the inductive biases is found with meta-learning, a technique through which a model discovers how to acquire new languages more easily via exposure to many possible languages. By controlling the properties of the languages that are used during meta-learning, we can control the inductive biases that meta-learning imparts. We demonstrate this framework with a case study based on syllable structure. First, we specify the inductive biases that we intend to give our model, and then we translate those inductive biases into a space of languages from which a model can meta-learn. Finally, using existing analysis techniques, we verify that our approach has imparted the linguistic inductive biases that it was intended to impart.","41":"In this paper, a new conception of linguistic q\u2010rung orthopair fuzzy number (Lq\u2010ROFN) is proposed where the membership and nonmembership of the q\u2010rung orthopair fuzzy numbers ( q\u2010ROFNs) are represented as linguistic variables. Compared with linguistic intuitionistic fuzzy numbers and linguistic Pythagorean fuzzy numbers, the Lq\u2010ROFNs can more fully describe the linguistic assessment information by considering the parameter q to adjust the range of fuzzy information. To deal with the multiple\u2010attribute group decision\u2010making (MAGDM) problems with Lq\u2010ROFNs, we proposed the linguistic score and accuracy functions of the Lq\u2010ROFNs. Further, we introduce and prove the operational rules and the related properties characters of Lq\u2010ROFNs. For aggregating the Lq\u2010ROFN assessment information, some aggregation operators are developed, involving the linguistic q\u2010rung orthopair fuzzy power Bonferroni mean (BM) operator, linguistic q\u2010rung orthopair fuzzy weighted power BM operator, linguistic q\u2010rung orthopair fuzzy power geometric BM (GBM) operator, and linguistic q\u2010rung orthopair fuzzy weighted power GBM operator, and then presents their rational properties and particular cases, which cannot only reduce the influences of some unreasonable data caused by the biased decision\u2010makers, but also can take the interrelationship between any two different attributes into account. Finally, we propose a method to handle the MAGDM under the environment of Lq\u2010ROFNs by using the new proposed operators. Further, several examples are given to show the validity and superiority of the proposed method by comparing with other existing MAGDM methods.","42":"The ease with which information can be shared on social media has opened it up to abuse and manipulation. One example of a manipulation campaign that has garnered much attention recently was the alleged Russian interference in the 2016 U.S. elections, with Russia accused of, among other things, using trolls and malicious accounts to spread misinformation and politically biased information. To take an in-depth look at this manipulation campaign, we collected a dataset of 13 million election-related posts shared on Twitter in 2016 by over a million distinct users. This dataset includes accounts associated with the identified Russian trolls as well as users sharing posts in the same time period on a variety of topics around the 2016 elections. To study how these trolls attempted to manipulate public opinion, we identified 49 theoretically grounded linguistic markers of deception and measured their use by troll and non-troll accounts. We show that deceptive language cues can help to accurately identify trolls, with average F1 score of 82% and recall 88%.","43":"Linguistic q\u2010rung orthopair fuzzy numbers (Lq\u2010ROFNs) are a qualitative form of q\u2010rung orthopair fuzzy numbers (q\u2010ROFNs) where the membership and nonmembership degrees are represented by linguistic variables. The Lq\u2010ROFNs can describe a broader range of linguistic assessment information flexibly by adjusting the parameter q based on different situations, so they are more superior to the linguistic intuitionistic fuzzy numbers and linguistic Pythagorean fuzzy numbers in real application. Based on the Lq\u2010ROFNs, we introduce the entropy measure which can be used to determine the indefiniteness of the assessment information. Then, based on the linguistic entropy measure, we further propose a method to obtain the attribute weights when the weight information is incomplete known. For aggregating the assessment information, the power average (PA) operator can reduce the influence of extreme data caused by the biased decision\u2010makers by considering the support degree of different evaluation individuals, and the Muirhead mean (MM) operator can take the interrelationship of different numbers of attributes into account by adjusting the parameter vector based on the real situations. In this paper, based on these two operators, we firstly propose the linguistic q\u2010rung orthopair fuzzy PA operator and linguistic q\u2010rung orthopair fuzzy weighted PA operator. Further, for combing the advantages of the MM operator and PA operator, we propose the linguistic q\u2010rung orthopair fuzzy power MM (PMM) operator and linguistic q\u2010rung orthopair fuzzy weighted PMM operator, and then investigate some properties of them. Finally, a new multiple\u2010attribute group decision\u2010making (MAGDM) method is proposed to process the Lq\u2010ROFNs, and some practical examples are given to illustrate the effectiveness and superiority of this new method in comparison with other existing MAGDM methods.","44":"This work presents an empirical approach to quantifying the loss of lexical richness in Machine Translation (MT) systems compared to Human Translation (HT). Our experiments show how current MT systems indeed fail to render the lexical diversity of human generated or translated text. The inability of MT systems to generate diverse outputs and its tendency to exacerbate already frequent patterns while ignoring less frequent ones, might be the underlying cause for, among others, the currently heavily debated issues related to gender biased output. Can we indeed, aside from biased data, talk about an algorithm that exacerbates seen biases?","45":"While large-scale language models (LMs) are able to imitate the distribution of natural language well enough to generate realistic text, it is difficult to control which regions of the distribution they generate. This is especially problematic because datasets used for training large LMs usually contain significant toxicity, hate, bias, and negativity. We propose GeDi as an efficient method for using smaller LMs as generative discriminators to guide generation from large LMs to make them safer and more controllable. GeDi guides generation at each step by computing classification probabilities for all possible next tokens via Bayes rule by normalizing over two class-conditional distributions; one conditioned on the desired attribute, or control code, and another conditioned on the undesired attribute, or anti control code. We find that GeDi gives stronger controllability than the state of the art method while also achieving generation speeds more than 30 times faster. Additionally, training GeDi on only four topics allows us to controllably generate new topics zero-shot from just a keyword, unlocking a new capability that previous controllable generation methods do not have. Lastly, we show that GeDi can make GPT-2 (1.5B parameters) significantly less toxic without sacrificing linguistic quality, making it by far the most practical existing method for detoxifying large language models while maintaining a fast generation speed.","46":"Most current NLP systems are based on a pre-train-then-fine-tune paradigm, in which a large neural network is first trained in a self-supervised way designed to encourage the network to extract broadly-useful linguistic features, and then finetuned for a specific task of interest. Recent work attempts to understand why this recipe works and explain when it fails. Currently, such analyses have produced two sets of apparently-contradictory results. Work that analyzes the representations that result from pre-training (via \u201cprobing classifiers\u201d) finds evidence that rich features of linguistic structure can be decoded with high accuracy, but work that analyzes model behavior after fine-tuning (via \u201cchallenge sets\u201d) indicates that decisions are often not based on such structure but rather on spurious heuristics specific to the training set. In this work, we test the hypothesis that the extent to which a feature influences a model\u2019s decisions can be predicted using a combination of two factors: The feature\u2019s extractability after pre-training (measured using information-theoretic probing techniques), and the evidence available during finetuning (defined as the feature\u2019s co-occurrence rate with the label). In experiments with both synthetic and naturalistic data, we find strong evidence (statistically significant correlations) supporting this hypothesis.","47":"Recently, a variety of probing tasks are proposed to discover linguistic properties learned in contextualized word embeddings. Many of these works implicitly assume these embeddings lay in certain metric spaces, typically the Euclidean space. This work considers a family of geometrically special spaces, the hyperbolic spaces, that exhibit better inductive biases for hierarchical structures and may better reveal linguistic hierarchies encoded in contextualized representations. We introduce a Poincar\u00e9 probe, a structural probe projecting these embeddings into a Poincar\u00e9 subspace with explicitly defined hierarchies. We focus on two probing objectives: (a) dependency trees where the hierarchy is defined as headdependent structures; (b) lexical sentiments where the hierarchy is defined as the polarity of words (positivity and negativity). We argue that a key desideratum of a probe is its sensitivity to the existence of linguistic structures. We apply our probes on BERT, a typical contextualized embedding model. In a syntactic subspace, our probe better recovers tree structures than Euclidean probes, revealing the possibility that the geometry of BERT syntax may not necessarily be Euclidean. In a sentiment subspace, we reveal two possible meta-embeddings for positive and negative sentiments and show how lexically-controlled contextualization would change the geometric localization of embeddings. We demonstrate the findings with our Poincar\u00e9 probe via extensive experiments and visualization1.","48":"We present a data-driven approach using word embeddings to discover and categorise language biases on the discussion platform Reddit. As spaces for isolated user communities, platforms such as Reddit are increasingly connected to issues of racism, sexism and other forms of discrimination. Hence, there is a need to monitor the language of these groups. One of the most promising AI approaches to trace linguistic biases in large textual datasets involves word embeddings, which transform text into high-dimensional dense vectors and capture semantic relations between words. Yet, previous studies require predefined sets of potential biases to study, e.g., whether gender is more or less associated with particular types of jobs. This makes these approaches unfit to deal with smaller and community-centric datasets such as those on Reddit, which contain smaller vocabularies and slang, as well as biases that may be particular to that community. This paper proposes a data-driven approach to automatically discover language biases encoded in the vocabulary of online discourse communities on Reddit. In our approach, protected attributes are connected to evaluative words found in the data, which are then categorised through a semantic analysis system. We verify the effectiveness of our method by comparing the biases we discover in the Google News dataset with those found in previous literature. We then successfully discover gender bias, religion bias, and ethnic bias in different Reddit communities. We conclude by discussing potential application scenarios and limitations of this data-driven bias discovery method.","49":"Despite Visual Question Answering (VQA) has realized impressive progress over the last few years, today's VQA models tend to capture superficial linguistic correlations in the train set and fail to generalize to the test set with different QA distributions. To reduce the language biases, several recent works introduce an auxiliary question-only model to regularize the training of targeted VQA model, and achieve dominating performance on VQA-CP. However, since the complexity of design, current methods are unable to equip the ensemble-based models with two indispensable characteristics of an ideal VQA model: 1) visual-explainable: the model should rely on the right visual regions when making decisions. 2) question-sensitive: the model should be sensitive to the linguistic variations in question. To this end, we propose a model-agnostic Counterfactual Samples Synthesizing (CSS) training scheme. The CSS generates numerous counterfactual training samples by masking critical objects in images or words in questions, and assigning different ground-truth answers. After training with the complementary samples (ie, the original and generated samples), the VQA models are forced to focus on all critical objects and words, which significantly improves both visual-explainable and question-sensitive abilities. In return, the performance of these models is further boosted. Extensive ablations have shown the effectiveness of CSS. Particularly, by building on top of the model LMH, we achieve a record-breaking performance of 58.95% on VQA-CP v2, with 6.5% gains.","50":"As natural language processing methods are increasingly deployed in real-world scenarios such as healthcare, legal systems, and social science, it becomes necessary to recognize the role they potentially play in shaping social biases and stereotypes. Previous work has revealed the presence of social biases in widely used word embeddings involving gender, race, religion, and other social constructs. While some methods were proposed to debias these word-level embeddings, there is a need to perform debiasing at the sentence-level given the recent shift towards new contextualized sentence representations such as ELMo and BERT. In this paper, we investigate the presence of social biases in sentence-level representations and propose a new method, Sent-Debias, to reduce these biases. We show that Sent-Debias is effective in removing biases, and at the same time, preserves performance on sentence-level downstream tasks such as sentiment analysis, linguistic acceptability, and natural language understanding. We hope that our work will inspire future research on characterizing and removing social biases from widely adopted sentence representations for fairer NLP.","51":"Developers frequently discuss aspects of the systems they are developing online. The comments they post to discussions form a rich information source about the system. Intention mining, a process introduced by Di Sorbo et al., classifies sentences in developer discussions to enable further analysis. As one example of use, intention mining has been used to help build various recommenders for software developers. The technique introduced by Di Sorbo et al. to categorize sentences is based on linguistic patterns derived from two projects. The limited number of data sources used in this earlier work introduces questions about the comprehensiveness of intention categories and whether the linguistic patterns used to identify the categories are generalizable to developer discussion recorded in other kinds of software artifacts (e.g., issue reports). To assess the comprehensiveness of the previously identified intention categories and the generalizability of the linguistic patterns for category identification, we manually created a new dataset, categorizing 5,408 sentences from issue reports of four projects in GitHub. Based on this manual effort, we refined the previous categories. We assess Di Sorbo et al.'s patterns on this dataset, finding that the accuracy rate achieved is low (0.31). To address the deficiencies of Di Sorbo et al.'s patterns, we propose and investigate a convolution neural network (CNN)-based approach to automatically classify sentences into different categories of intentions. Our approach optimizes CNN by integrating batch normalization to accelerate the training speed, and an automatic hyperparameter tuning approach to tune appropriate hyperparameters of CNN. Our approach achieves an accuracy of 0.84 on the new dataset, improving Di Sorbo et al.'s approach by 171 percent. We also apply our approach to improve an automated software engineering task, in which we use our proposed approach to rectify misclassified issue reports, thus reducing the bias introduced by such data to other studies. A case study on four open source projects with 2,076 issue reports shows that our approach achieves an average AUC score of 0.687, which improves other baselines by at least 16 percent.","52":"Code-switching in linguistically diverse, low resource languages is often semantically complex and lacks sophisticated methodologies that can be applied to real-world data for precisely detecting hate speech. In an attempt to bridge this gap, we introduce a three-tier pipeline that employs profanity modeling, deep graph embeddings, and author profiling to retrieve instances of hate speech in Hindi-English code-switched language (Hinglish) on social media platforms like Twitter. Through extensive comparison against several baselines on two real-world datasets, we demonstrate how targeted hate embeddings combined with social network-based features outperform state of the art, both quantitatively and qualitatively. Additionally, we present an expert-in-the-loop algorithm for bias elimination in the proposed model pipeline and study the prevalence and performance impact of the debiasing. Finally, we discuss the computational, practical, ethical, and reproducibility aspects of the deployment of our pipeline across the Web.","53":"Distantly supervised relation extraction is widely used to extract relational facts from text, but suffers from noisy labels. Current relation extraction methods try to alleviate the noise by multi-instance learning and by providing supporting linguistic and contextual information to more efficiently guide the relation classification. While achieving state-of-the-art results, we observed these models to be biased towards recognizing a limited set of relations with high precision, while ignoring those in the long tail. To address this gap, we utilize a pre-trained language model, the OpenAI Generative Pre-trained Transformer (GPT) (Radford et al., 2018). The GPT and similar models have been shown to capture semantic and syntactic features, and also a notable amount of \u201ccommon-sense\u201d knowledge, which we hypothesize are important features for recognizing a more diverse set of relations. By extending the GPT to the distantly supervised setting, and fine-tuning it on the NYT10 dataset, we show that it predicts a larger set of distinct relation types with high confidence. Manual and automated evaluation of our model shows that it achieves a state-of-the-art AUC score of 0.422 on the NYT10 dataset, and performs especially well at higher recall levels.","54":"A standard approach to evaluating language models analyzes how models assign probabilities to valid versus invalid syntactic constructions (i.e. is a grammatical sentence more probable than an ungrammatical sentence). Our work uses ambiguous relative clause attachment to extend such evaluations to cases of multiple simultaneous valid interpretations, where stark grammaticality differences are absent. We compare model performance in English and Spanish to show that non-linguistic biases in RNN LMs advantageously overlap with syntactic structure in English but not Spanish. Thus, English models may appear to acquire human-like syntactic preferences, while models trained on Spanish fail to acquire comparable human-like preferences. We conclude by relating these results to broader concerns about the relationship between comprehension (i.e. typical language model use cases) and production (which generates the training data for language models), suggesting that necessary linguistic biases are not present in the training signal at all.","55":"Microaggressions are subtle, often veiled, manifestations of human biases. These uncivil interactions can have a powerful negative impact on people by marginalizing minorities and disadvantaged groups. The linguistic subtlety of microaggressions in communication has made it difficult for researchers to analyze their exact nature, and to quantify and extract microaggressions automatically. Specifically, the lack of a corpus of real-world microaggressions and objective criteria for annotating them have prevented researchers from addressing these problems at scale. In this paper, we devise a general but nuanced, computationally operationalizable typology of microaggressions based on a small subset of data that we have. We then create two datasets: one with examples of diverse types of microaggressions recollected by their targets, and another with gender-based microaggressions in public conversations on social media. We introduce a new, more objective, criterion for annotation and an active-learning based procedure that increases the likelihood of surfacing posts containing microaggressions. Finally, we analyze the trends that emerge from these new datasets.","56":"Data-driven statistical Natural Language Processing (NLP) techniques leverage large amounts of language data to build models that can understand language. However, most language data reflect the public discourse at the time the data was produced, and hence NLP models are susceptible to learning incidental associations around named referents at a particular point in time, in addition to general linguistic meaning. An NLP system designed to model notions such as sentiment and toxicity should ideally produce scores that are independent of the identity of such entities mentioned in text and their social associations. For example, in a general purpose sentiment analysis system, a phrase such as I hate Katy Perry should be interpreted as having the same sentiment as I hate Taylor Swift. Based on this idea, we propose a generic evaluation framework, Perturbation Sensitivity Analysis, which detects unintended model biases related to named entities, and requires no new annotations or corpora. We demonstrate the utility of this analysis by employing it on two different NLP models \u2014 a sentiment model and a toxicity model \u2014 applied on online comments in English language from four different genres.","57":"The recent advances introduced by neural machine translation (NMT) are rapidly expanding the application fields of machine translation, as well as reshaping the quality level to be targeted. In particular, if translations have to fit some given layout, quality should not only be measured in terms of adequacy and fluency, but also length. Exemplary cases are the translation of document files, subtitles, and scripts for dubbing, where the output length should ideally be as close as possible to the length of the input text. This pa-per addresses for the first time, to the best of our knowledge, the problem of controlling the output length in NMT. We investigate two methods for biasing the output length with a transformer architecture: i) conditioning the output to a given target-source length-ratio class and ii) enriching the transformer positional embedding with length information. Our experiments show that both methods can induce the network to generate shorter translations, as well as acquiring inter- pretable linguistic skills.","58":null,"59":"Sequence-processing neural networks led to remarkable progress on many NLP tasks. As a consequence, there has been increasing interest in understanding to what extent they process language as humans do. We aim here to uncover which biases such models display with respect to \u201cnatural\u201d word-order constraints. We train models to communicate about paths in a simple gridworld, using miniature languages that reflect or violate various natural language trends, such as the tendency to avoid redundancy or to minimize long-distance dependencies. We study how the controlled characteristics of our miniature languages affect individual learning and their stability across multiple network generations. The results draw a mixed picture. On the one hand, neural networks show a strong tendency to avoid long-distance dependencies. On the other hand, there is no clear preference for the efficient, non-redundant encoding of information that is widely attested in natural language. We thus suggest inoculating a notion of \u201ceffort\u201d into neural networks, as a possible way to make their linguistic behavior more human-like.","60":"Statistical methods applied to social media posts shed light on the dynamics of online dialogue. For example, users' wording choices predict their persuasiveness and users adopt the language patterns of other dialogue participants. In this paper, we estimate the causal effect of reply tones in debates on linguistic and sentiment changes in subsequent responses. The challenge for this estimation is that a reply's tone and subsequent responses are confounded by the users' ideologies on the debate topic and their emotions. To overcome this challenge, we learn representations of ideology using generative models of text. We study debates from 4Forums.com and compare annotated tones of replying such as emotional versus factual, or reasonable versus attacking. We show that our latent confounder representation reduces bias in ATE estimation. Our results suggest that factual and asserting tones affect dialogue and provide a methodology for estimating causal effects from text.","61":"Several quality dimensions of natural language arguments have been investigated. Some are likely to be reflected in linguistic features (e.g., an argument\u2019s arrangement), whereas others depend on context (e.g., relevance) or topic knowledge (e.g., acceptability). In this paper, we study the intrinsic computational assessment of 15 dimensions, i.e., only learning from an argument\u2019s text. In systematic experiments with eight feature types on an existing corpus, we observe moderate but significant learning success for most dimensions. Rhetorical quality seems hardest to assess, and subjectivity features turn out strong, although length bias in the corpus impedes full validity. We also find that human assessors differ more clearly to each other than to our approach.","62":"Text has become one of the most extensively used digital media in Internet, which provides steganography an effective carrier to realize confidential message hiding. Nowadays, generation-based linguistic steganography has made a significant breakthrough due to the progress of deep learning. However, previous methods based on recurrent neural network have two deviations including exposure bias and embedding deviation, which seriously destroys the security of steganography. In this paper, we propose a novel linguistic steganographic model based on adaptive probability distribution and generative adversarial network, which achieves the goal of hiding secret messages in the generated text while guaranteeing high security performance. First, the steganographic generator is trained by using generative adversarial network to effectively tackle the exposure bias, and then the candidate pool is obtained by a probability similarity function at each time step, which alleviates the embedding deviation through dynamically maintaining the diversity of probability distribution. Third, to further improve the security, a novel strategy that conducts information embedding during model training is put forward. We design various experiments from different aspects to verify the performance of the proposed model, including imperceptibility, statistical distribution, anti-steganalysis ability. The experimental results demonstrate that our proposed model outperforms the current state-of-the-art steganographic schemes.","63":"Methodologies for training visual question answering (VQA) models assume the availability of datasets with human-annotated ImageQuestion-Answer (I-Q-A) triplets. This has led to heavy reliance on datasets and a lack of generalization to new types of questions and scenes. Linguistic priors along with biases and errors due to annotator subjectivity have been shown to percolate into VQA models trained on such samples. We study whether models can be trained without any human-annotated Q-A pairs, but only with images and their associated textual descriptions or captions. We present a method to train models with synthetic Q-A pairs generated procedurally from captions. Additionally, we demonstrate the efficacy of spatial-pyramid image patches as a simple but effective alternative to dense and costly object bounding box annotations used in existing VQA models. Our experiments on three VQA benchmarks demonstrate the efficacy of this weakly-supervised approach, especially on the VQA-CP challenge, which tests performance under changing linguistic priors.","64":"Systems of personal pronouns (e.g., 'you' and 'I') vary widely across languages, but at the same time not all possible systems are attested. Linguistic theories have generally accounted for this in terms of strong grammatical constraints, but recent experimental work challenges this view. Here, we take a novel approach to understanding personal pronoun systems by invoking a recent information-theoretic framework for semantic systems that predicts that languages efficiently compress meanings into forms. We find that a test set of cross-linguistically attested personal pronoun systems achieves near-optimal compression, supporting the hypothesis that efficient compression shapes semantic systems. Further, our best-fitting model includes an egocentric bias that favors a salient speaker representation, accounting for a well-known typological generalization of person systems ('Zwicky's Generalization') without the need for a hard grammatical constraint.","65":"Online misogyny, a category of online abusive language, has serious and harmful social consequences. Automatic detection of misogynistic language online, while imperative, poses complicated challenges to both data gathering, data annotation, and bias mitigation, as this type of data is linguistically complex and diverse. This paper makes three contributions in this area: Firstly, we describe the detailed design of our iterative annotation process and codebook. Secondly, we present a comprehensive taxonomy of labels for annotating misogyny in natural written language, and finally, we introduce a high-quality dataset of annotated posts sampled from social media posts.","66":"This thesis addresses the lexical and psycholinguistic properties of copredication. In particular, it explores its acceptability, frequency, crosslinguistic and electrophysiological features. It proposes a general parsing bias to account for novel acceptability data, through which Complex-Simple predicate orderings are degraded across distinct nominal types relative to the reverse order. This bias, Incremental Semantic Complexity, states that the parser seeks to process linguistic representations in incremental stages of semantic complexity. English and Italian acceptability data are presented which demonstrate that predicate order preferences are based not on sense dominance but rather sense complexity. Initial evidence is presented indicating that pragmatic factors centred on coherence relations can impact copredication acceptability when such copredications host complex (but not simple) predicates. The real-time processing and electrophysiological properties of copredication are also presented, which serve to replicate and ground the acceptability dynamics presented in the thesis.","67":"We report that state-of-the-art parsers consistently failed to identify \u201chers\u201d and \u201ctheirs\u201d as pronouns but identified the masculine equivalent \u201chis\u201d. We find that the same biases exist in recent language models like BERT. While some of the bias comes from known sources, like training data with gender imbalances, we find that the bias is _amplified_ in the language models and that linguistic differences between English pronouns that are not inherently biased can become biases in some machine learning models. We introduce a new technique for measuring bias in models, using Bayesian approximations to generate partially-synthetic data from the model itself.","68":"Case, Word Order, and Language Learnability: Insights from Connectionist Modeling Gary Lupyan (il24@cornell.edu) Morten H. Christiansen (mhc27@cornell.edu) Department of Psychology Cornell University Ithaca, NY 14853 USA Abstract How does the existence of case systems, and strict word order patterns a\u21b5ect the learnability of a given language? We present a series of connectionist sim- ulations, suggesting that both case and strict word order may facilitate syntactic acquisition by a se- quential learning device. Our results are consis- tent with typological data concerning the frequen- cies with which di\u21b5erent type of word order pat- terns occur across the languages of the world. Our model also accommodates patterns of syntactic de- velopment across several di\u21b5erent languages. We conclude that non-linguistic constraints on general sequential-learning devices may help explain the re- lationship between case, word order, and learnabil- ity of individual languages. Introduction In language acquisition, children are faced with many formidable tasks, yet they normally acquire most of their native language within the first five years of life. One of the most difficult of these tasks involves mapping a sequence of words onto some sort of interpretation of what that sequence is supposed to mean. That is, in order for the child to under- stand a sentence, she needs to determine the gram- matical roles of the individual words so that she can work out who did what to whom. Although the chil- dren appear to bring powerful statistical learning mechanisms to bear on the acquisition tasks (e.g., Sa\u21b5ran, Aslin, & Newport 1996), the existence of linguistic universals common across radically di\u21b5er- ent languages (Greenberg 1963) points to the pres- ence of innate constraints on such learning. Without such constraints, it becomes difficult to explain why there are few, if any, Object-Subject-Verb (OSV) languages (van Everbroeck, 1999) even though in principle such a language appears to be as good as any other. In this paper, we propose that these con- straints may arise from non-linguistic limitations on the sequential learning of statistical structure, and examine how this perspective may shed light on how children learn to map the words in sentences onto their appropriate grammatical roles. There are two major ways in which languages signal syntactic rela- tionships and grammatical roles\u2014word order (WO), and case markings. In a strict WO language like En- glish, declarative sentences follow a Subject-Verb- Object (SVO) pattern. It is the occurrence of the subject in the first position, and the object in the second, that allows the hearer to comprehend who did what to whom. In contrast, languages such as Russian or Japanese allow multiple word orders and rely on case markings to disambiguate subjects from objects. For instance, Masha lubit Petyoo (SVO), Petyoo lubit Masha (OVS), and Lubit Petyoo Masha (VOS) are all grammatical in Russian and all mean Mary loves Peter (albeit with di\u21b5erent emphases on the constituents), due to the nominative -a, and ac- cusative -u case markers. While long-standing theories describe acquisition of language through an innate language acquisition device (e.g., Pinker, 1995), an alternative approach that is gaining ground is the adaptation of linguistic structures to the human brain rather than vice versa (e.g., Christiansen, 1994; Kirby, 1998). On this ac- count, language universals may reflect non-linguistic cognitive constraints on learning and processing of sequential structure, rather than constraints pre- scribed by an innate universal grammar. Previ- ous work has shown that sequential-learning devices with no language-specific biases are better able to learn more universal aspects of language as com- pared to aspects encountered in rare languages (e.g., Ellefson & Christiansen, 2000; Christiansen & De- vlin, 1997; Van Everbroeck, 1999, 2001). Here, we examine the ways in which case markings and word order may function as cues for a sequen- tial learning device acquiring syntactic structure. In simulation 1, we model di\u21b5erent word orders, and hypothesize that typologically common languages should be easier to learn by a sequential-learning device than the more rare ones. We expand on this idea in simulation 2 by studying the performance of networks trained on languages of varying degrees of case markings and flexibility. Finally, in simulation 3, we establish that our trained networks are able to mimic syntactic performance of children learn- ing English, Italian, Turkish, and Serbo-Croatian (Slobin and Bever, 1982).","69":"Automatic data augmentation (AutoAugment) (Cubuk et al., 2019) searches for optimal perturbation policies via a controller trained using performance rewards of a sampled policy on the target task, hence reducing data-level model bias. While being a powerful algorithm, their work has focused on computer vision tasks, where it is comparatively easy to apply imperceptible perturbations without changing an image\u2019s semantic meaning. In our work, we adapt AutoAugment to automatically discover effective perturbation policies for natural language processing (NLP) tasks such as dialogue generation. We start with a pool of atomic operations that apply subtle semantic-preserving perturbations to the source inputs of a dialogue task (e.g., different POS-tag types of stopword dropout, grammatical errors, and paraphrasing). Next, we allow the controller to learn more complex augmentation policies by searching over the space of the various combinations of these atomic operations. Moreover, we also explore conditioning the controller on the source inputs of the target task, since certain strategies may not apply to inputs that do not contain that strategy\u2019s required linguistic features. Empirically, we demonstrate that both our input-agnostic and input-aware controllers discover useful data augmentation policies, and achieve significant improvements over the previous state-of-the-art, including trained on manually-designed policies.","70":"This work presents an information-theoretic operationalisation of cross-linguistic non-arbitrariness. It is not a new idea that there are small, cross-linguistic associations between the forms and meanings of words. For instance, it has been claimed (Blasi et al., 2016) that the word for \u201ctongue\u201d is more likely than chance to contain the phone [l]. By controlling for the influence of language family and geographic proximity within a very large concept-aligned, cross-lingual lexicon, we extend methods previously used to detect within language non-arbitrariness (Pimentel et al., 2019) to measure cross-linguistic associations. We find that there is a significant effect of non-arbitrariness, but it is unsurprisingly small (less than 0.5% on average according to our information-theoretic estimate). We also provide a concept-level analysis which shows that a quarter of the concepts considered in our work exhibit a significant level of cross-linguistic non-arbitrariness. In sum, the paper provides new methods to detect cross-linguistic associations at scale, and confirms their effects are minor.","71":"We study how masking and predicting tokens in an unsupervised fashion can give rise to linguistic structures and downstream performance gains. Recent theories have suggested that pretrained language models acquire useful inductive biases through masks that implicitly act as cloze reductions for downstream tasks. While appealing, we show that the success of the random masking strategy used in practice cannot be explained by such cloze-like masks alone. We construct cloze-like masks using task-specific lexicons for three different classification datasets and show that the majority of pretrained performance gains come from generic masks that are not associated with the lexicon. To explain the empirical success of these generic masks, we demonstrate a correspondence between the Masked Language Model (MLM) objective and existing methods for learning statistical dependencies in graphical models. Using this, we derive a method for extracting these learned statistical dependencies in MLMs and show that these dependencies encode useful inductive biases in the form of syntactic structures. In an unsupervised parsing evaluation, simply forming a minimum spanning tree on the implied statistical dependence structure outperforms a classic method for unsupervised parsing (58.74 vs. 55.91 UUAS).","72":"The uniform information density (UID) hypothesis, which posits that speakers behaving optimally tend to distribute information uniformly across a linguistic signal, has gained traction in psycholinguistics as an explanation for certain syntactic, morphological, and prosodic choices. In this work, we explore whether the UID hypothesis can be operationalized as an inductive bias for statistical language modeling. Specifically, we augment the canonical MLE objective for training language models with a regularizer that encodes UID. In experiments on ten languages spanning five language families, we find that using UID regularization consistently improves perplexity in language models, having a larger effect when training data is limited. Moreover, via an analysis of generated sequences, we find that UID-regularized language models have other desirable properties, e.g., they generate text that is more lexically diverse. Our results not only suggest that UID is a reasonable inductive bias for language modeling, but also provide an alternative validation of the UID hypothesis using modern-day NLP tools.","73":"The present research aims to verify the presence of linguistic biases in crime news reports (Study 1) and their role (Study 2) in activating a crime stereotype toward racial\/ethnic minorities. In a first content analysis study, the natural occurrence of a set of linguistic biases was analyzed in Italian news articles that described comparable crimes committed by an in- or an outgroup aggressor. Results indicated that when the crime was committed by an outgroup (vs. ingroup) member, more aggravating and less attenuating adjectives were used. Moreover, the nationality of the perpetrator was not only mentioned more frequently, it also appeared in most cases as a noun. In Study 2, participants read a fictitious news article that either described an in- or outgroup criminal act with neutral or biased language. Their implicit associations between in- and outgroup members and weapons (vs. tools) were measured immediately afterward in the weapon paradigm. Results confirmed that a biased (vs. neutral) language use increased participants\u2019 crime-related associations with the outgroup in general only when an outgroup criminal was staged. The role of media portrayals in determining the cognitive representations of racial\/ethnic minorities is discussed.","74":"We have now entered the era of trillion parameter machine learning models trained on billion-sized datasets scraped from the internet. The rise of these gargantuan datasets has given rise to formidable bodies of critical work that has called for caution while generating these large datasets. These address concerns surrounding the dubious curation practices used to generate these datasets, the sordid quality of alt-text data available on the world wide web, the problematic content of the CommonCrawl dataset often used as a source for training large language models, and the entrenched biases in large-scale visio-linguistic models (such as OpenAI\u2019s CLIP model) trained on opaque datasets (WebImageText). In the backdrop of these specific calls of caution, we examine the recently released LAION-400M dataset, which is a CLIP-filtered dataset of Image-Alt-text pairs parsed from the Common-Crawl dataset. We found that the dataset contains, troublesome and explicit images and text pairs of rape, pornography, malign stereotypes, racist and ethnic slurs, and other extremely problematic content. We outline numerous implications, concerns and downstream harms regarding the current state of large scale datasets while raising open questions for various stakeholders including the AI community, regulators, policy makers and data subjects. Warning: This paper contains NSFW content that some readers may find disturbing, distressing, and\/or offensive.","75":"Alzheimer's disease is estimated to affect around 50 million people worldwide and is rising rapidly, with a global economic burden of nearly a trillion dollars. This calls for scalable, cost-effective, and robust methods for detection of Alzheimer's dementia (AD). We present a novel architecture that leverages acoustic, cognitive, and linguistic features to form a multimodal ensemble system. It uses specialized artificial neural networks with temporal characteristics to detect AD and its severity, which is reflected through Mini-Mental State Exam (MMSE) scores. We first evaluate it on the ADReSS challenge dataset, which is a subject-independent and balanced dataset matched for age and gender to mitigate biases, and is available through DementiaBank. Our system achieves state-of-the-art test accuracy, precision, recall, and F1-score of 83.3% each for AD classification, and state-of-the-art test root mean squared error (RMSE) of 4.60 for MMSE score regression. To the best of our knowledge, the system further achieves state-of-the-art AD classification accuracy of 88.0% when evaluated on the full benchmark DementiaBank Pitt database. Our work highlights the applicability and transferability of spontaneous speech to produce a robust inductive transfer learning model, and demonstrates generalizability through a task-agnostic feature-space. The source code is available at this https URL","76":"In times of a disaster, the information available on social media can be useful for several humanitarian tasks as disseminating messages on social media is quick and easily accessible. Disaster damage assessment is inherently multi-modal, yet most existing work on damage identification has focused solely on building generic classification models that rely exclusively on text or image analysis of online social media sessions (e.g., posts). Despite their empirical success, these efforts ignore the multi-modal information manifested in social media data. Conventionally, when information from various modalities is presented together, it often exhibits complementary insights about the application domain and facilitates better learning performance. In this work, we present Crisis-DIAS, a multi-modal sequential damage identification, and severity detection system. We aim to support disaster management and aid in planning by analyzing and exploiting the impact of linguistic cues on a unimodal visual system. Through extensive qualitative, quantitative and theoretical analysis on a real-world multi-modal social media dataset, we show that the Crisis-DIAS framework is superior to the state-of-the-art damage assessment models in terms of bias, responsiveness, computational efficiency, and assessment performance.","77":"Recent work in unsupervised parsing has tried to incorporate visual information into learning, but results suggest that these models need linguistic bias to compete against models that only rely on text. This work proposes grammar induction models which use visual information from images for labeled parsing, and achieve state-of-the-art results on grounded grammar induction on several languages. Results indicate that visual information is especially helpful in languages where high frequency words are more broadly distributed. Comparison between models with and without visual information shows that the grounded models are able to use visual information for proposing noun phrases, gathering useful information from images for unknown words, and achieving better performance at prepositional phrase attachment prediction.","78":"Latent structure models are a powerful tool for modeling compositional data, discovering linguistic structure, and building NLP pipelines. They are appealing for two main reasons: they allow incorporating structural bias during training, leading to more accurate models; and they allow discovering hidden linguistic structure, which provides better interpretability. This tutorial will cover recent advances in discrete latent structure models. We discuss their motivation, potential, and limitations, then explore in detail three strategies for designing such models: gradient approximation, reinforcement learning, and end-to-end differentiable methods. We highlight connections among all these methods, enumerating their strengths and weaknesses. The models we present and analyze have been applied to a wide variety of NLP tasks, including sentiment analysis, natural language inference, language modeling, machine translation, and semantic parsing. Examples and evaluation will be covered throughout. After attending the tutorial, a practitioner will be better informed about which method is best suited for their problem.","79":"Neural Machine Translation (NMT) has been shown to struggle with grammatical gender that is dependent on the gender of human referents, which can cause gender bias effects. Many existing approaches to this problem seek to control gender inflection in the target language by explicitly or implicitly adding a gender feature to the source sentence, usually at the sentence level. In this paper we propose schemes for incorporating explicit word-level gender inflection tags into NMT. We explore the potential of this gender-inflection controlled translation when the gender feature can be determined from a human reference, or when a test sentence can be automatically gender-tagged, assessing on English-to-Spanish and English-to-German translation. We find that simple existing approaches can over-generalize a gender-feature to multiple entities in a sentence, and suggest effective alternatives in the form of tagged coreference adaptation data. We also propose an extension to assess translations of gender-neutral entities from English given a corresponding linguistic convention, such as a non-binary inflection, in the target language.","80":"Recent years have witnessed a significant increase in the online sharing of medical information, with videos representing a large fraction of such online sources. Previous studies have however shown that more than half of the health-related videos on platforms such as YouTube contain misleading information and biases. Hence, it is crucial to build computational tools that can help evaluate the quality of these videos so that users can obtain accurate information to help inform their decisions. In this study, we focus on the automatic detection of misinformation in YouTube videos. We select prostate cancer videos as our entry point to tackle this problem. The contribution of this paper is twofold. First, we introduce a new dataset consisting of 250 videos related to prostate cancer manually annotated for misinformation. Second, we explore the use of linguistic, acoustic, and user engagement features for the development of classification models to identify misinformation. Using a series of ablation experiments, we show that we can build automatic models with accuracies of up to 74%, corresponding to a 76.5% precision and 73.2% recall for misinformative instances.","81":"Bias in natural language processing arises primarily from models learning characteristics of the author such as gender and race when modelling tasks such as sentiment and syntactic parsing. This problem manifests as disparities in error rates across author demographics, typically disadvantaging minority groups. Existing methods for mitigating and measuring bias do not directly account for correlations between author demographics and linguistic variables. Moreover, evaluation of bias has been inconsistent in previous work, in terms of dataset balance and evaluation methods. This paper introduces a very simple but highly effective method for countering bias using instance reweighting, based on the frequency of both task labels and author demographics. We extend the method in the form of a gated model which incorporates the author demographic as an input, and show that while it is highly vulnerable to input data bias, it provides debiased predictions through demographic input perturbation, and outperforms all other bias mitigation techniques when combined with instance reweighting.","82":"Neural network architectures have been augmented with differentiable stacks in order to introduce a bias toward learning hierarchy-sensitive regularities. It has, however, proven difficult to assess the degree to which such a bias is effective, as the operation of the differentiable stack is not always interpretable. In this paper, we attempt to detect the presence of latent representations of hierarchical structure through an exploration of the unsupervised learning of constituency structure. Using a technique due to Shen et al. (2018a,b), we extract syntactic trees from the pushing behavior of stack RNNs trained on language modeling and classification objectives. We find that our models produce parses that reflect natural language syntactic constituencies, demonstrating that stack RNNs do indeed infer linguistically relevant hierarchical structure.","83":"Artificial language learning methods\u2014in which learners are taught miniature constructed languages in a controlled laboratory setting\u2014have become a valuable experimental tool for research on language development. These methods offer a complement to natural language acquisition data, allowing researchers to control both the input to learning and the learning environment. A large proportion of artificial language learning studies has aimed to understand the mechanisms of learning in infants. This review focuses instead on investigations into the nature of early linguistic representations and how they are influenced by both the structure of the input and the cognitive features of the learner. Looking not only at young infants but also at children beyond infancy, we discuss evidence for early abstraction, conditions on generalization, the acquisition of grammatical categories and dependencies, and recent work connecting the cognitive biases of learners to language typology. We end by outlining important areas for future research.","84":"Promotion in science has attracted increasing attention in recent years, and various linguistic devices such as boosters, hypes, or positive words were used to promote research for publication purposes. The present study examined how researchers promote their work with linguistic devices such as positive and negative words and is probably the first one that investigates such promotional devices in not only abstracts but also full texts based on a large dataset of articles (more than 2.2 million). The results showed that the use of positive words in both the abstracts and full texts exhibited a significant uptrend in the past two decades, and positive words were more frequently used than negative ones in both abstracts and full texts. However, journal impact was found to be only very weakly correlated with the use of positive and negative words in both abstracts and full texts. The preference of promotional linguistic devices such as positive words may be explained by factors such as the increasingly competitive selection process of publication, the publication bias, the outcome reporting bias, and the universal positive bias. The study argues for a fair use of such promotional linguistic devices.","85":null,"86":null,"87":"By representing speaker characteristic as a single fixed-length vector extracted solely from speech, we can train a neural multi-speaker speech synthesis model by conditioning the model on those vectors. This model can also be adapted to unseen speakers regardless of whether the transcript of adaptation data is available or not. However, this setup restricts the speaker component to just a single bias vector, which in turn limits the performance of adaptation process. In this study, we propose a novel speech synthesis model, which can be adapted to unseen speakers by fine-tuning part of or all of the network using either transcribed or untranscribed speech. Our methodology essentially consists of two steps: first, we split the conventional acoustic model into a speaker-independent (SI) linguistic encoder and a speaker-adaptive (SA) acoustic decoder; second, we train an auxiliary acoustic encoder that can be used as a substitute for the linguistic encoder whenever linguistic features are unobtainable. The results of objective and subjective evaluations show that adaptation using either transcribed or untranscribed speech with our methodology achieved a reasonable level of performance with an extremely limited amount of data and greatly improved performance with more data. Surprisingly, adaptation with untranscribed speech surpassed the transcribed counterpart in the subjective test, which reveals the limitations of the conventional acoustic model and hints at potential directions for improvements.","88":"We present an extension of our Molecular Transformer architecture combined with a hyper-graph exploration strategy for automatic retrosyn- thesis route planning without human intervention. The single-step ret- rosynthetic model sets a new state of the art for predicting reactants as well as reagents, solvents and catalysts for each retrosynthetic step. We introduce new metrics (coverage, class diversity, round-trip accuracy and Jensen-Shannon divergence) to evaluate the single-step retrosynthetic models, using the forward prediction and a reaction classification model always based on the transformer architecture. The hypergraph is con- structed on the fly, and the nodes are filtered and further expanded based on a Bayesian-like probability. We critically assessed the end-to-end framework with several retrosynthesis examples from literature and aca- demic exams. Overall, the frameworks has a very good performance with few weaknesses due to the bias induced during the training process. The use of the newly introduced metrics opens up the possibility to optimize entire retrosynthetic frameworks through focusing on the performance of the single-step model only.Available on IBM RXN for Chemistry: https:\/\/rxn.res.ibm.com.","89":"Trigger warning: This paper contains exam-ples of stereotypes and other harms that could be offensive and triggering to individuals. Language representations are ef\ufb01cient tools used across NLP applications, but they are strife with encoded societal biases. These biases are studied extensively, but with a primary focus on English language representations and biases common in the context of Western society. In this work, we investigate biases present in Hindi language representations with focuses on caste and religion-associated biases. We demonstrate how biases are unique to speci\ufb01c language representations based on the history and culture of the region they are widely spoken in, and how the same societal bias (such as binary gender-associated biases) is encoded by different words and text spans across languages. The discoveries of our work highlight the necessity of culture awareness and linguistic artifacts when modeling language representations, in order to better understand the encoded biases.","90":"Abstract This paper discusses machine learning techniques for the prediction of Common European Framework of Reference (CEFR) levels in a learner corpus. We summarise the CAp 2018 Machine Learning (ML) competition, a classification task of the six CEFR levels, which map linguistic competence in a foreign language onto six reference levels. The goal of this competition was to produce a machine learning system to predict learners\u2019 competence levels from written productions comprising between 20 and 300 words and a set of characteristics computed for each text extracted from the French component of the EFCAMDAT data (Geertzen et al., 2013). Together with the description of the competition, we provide an analysis of the results and methods proposed by the participants and discuss the benefits of this kind of competition for the learner corpus research (LCR) community. The main findings address the methods used and lexical bias introduced by the task.","91":"Natural languages make prolific use of conventional constituent-ordering patterns to indicate \"who did what to whom,\" yet the mechanisms through which these regularities arise are not well understood. A series of recent experiments demonstrates that, when prompted to express meanings through silent gesture, people bypass native language conventions, revealing apparent biases underpinning word order usage, based on the semantic properties of the information to be conveyed. We extend the scope of these studies by focusing, experimentally and computationally, on the interpretation of silent gesture. We show cross-linguistic experimental evidence that people use variability in constituent order as a cue to obtain different interpretations. To illuminate the computational principles that govern interpretation of non-conventional communication, we derive a Bayesian model of interpretation via biased inductive inference and estimate these biases from the experimental data. Our analyses suggest people's interpretations balance the ambiguity that is characteristic of emerging language systems, with ordering preferences that are skewed and asymmetric, but defeasible.","92":"Providing systems the ability to relate linguistic and visual content is one of the hallmarks of computer vision. Tasks such as image captioning and retrieval were designed to test this ability, but come with complex evaluation measures that gauge various other abilities and biases simultaneously. This paper presents an alternative evaluation task for visual-grounding systems: given a caption the system is asked to select the image that best matches the caption from a pair of semantically similar images. The system's accuracy on this Binary Image SelectiON (BISON) task is not only interpretable, but also measures the ability to relate fine-grained text content in the caption to visual content in the images. We gathered a BISON dataset that complements the COCO Captions dataset and used this dataset in auxiliary evaluations of captioning and caption-based retrieval systems. While captioning measures suggest visual grounding systems outperform humans, BISON shows that these systems are still far away from human performance.","93":"We propose FrameAxis, a method of characterizing the framing of a given text by identifying the most relevant semantic axes (\"microframes\") defined by antonym word pairs. In contrast to the traditional framing analysis, which has been constrained by a small number of manually annotated general frames, our unsupervised approach provides much more detailed insights, by considering a host of semantic axes. Our method is capable of quantitatively teasing out framing bias -- how biased a text is in each microframe -- and framing intensity -- how much each microframe is used -- from the text, offering a nuanced characterization of framing. We evaluate our approach using SemEval datasets as well as three other datasets and human evaluations, demonstrating that FrameAxis can reliably characterize documents with relevant microframes. Our method may allow scalable and nuanced computational analyses of framing across disciplines.","94":null,"95":"Texts like news, encyclopedias, and some social media strive for objectivity. Yet bias in the form of inappropriate subjectivity \u2014 introducing attitudes via framing, presupposing truth, and casting doubt \u2014 remains ubiquitous. This kind of bias erodes our collective trust and fuels social conflict. To address this issue, we introduce a novel testbed for natural language generation: automatically bringing inappropriately subjective text into a neutral point of view (\u201cneutralizing\u201d biased text). We also offer the first parallel corpus of biased language. The corpus contains 180,000 sentence pairs and originates from Wikipedia edits that removed various framings, presuppositions, and attitudes from biased sentences. Last, we propose two strong encoder-decoder baselines for the task. A straightforward yet opaque concurrent system uses a BERT encoder to identify subjective words as part of the generation process. An interpretable and controllable modular algorithm separates these steps, using (1) a BERT-based classifier to identify problematic words and (2) a novel join embedding through which the classifier can edit the hidden states of the encoder. Large-scale human evaluation across four domains (encyclopedias, news headlines, books, and political speeches) suggests that these algorithms are a first step towards the automatic identification and reduction of bias.","96":"Traditional media outlets are known to report political news in a biased way, potentially affecting the political beliefs of the audience and even altering their voting behaviors. Many researchers focus on automatically detecting and identifying media bias in the news, but only very few studies exist that systematically analyze how theses biases can be best visualized and communicated. We create three manually annotated datasets and test varying visualization strategies. The results show no strong effects of becoming aware of the bias of the treatment groups compared to the control group, although a visualization of hand-annotated bias communicated bias in-stances more effectively than a framing visualization. Showing participants an overview page, which opposes different viewpoints on the same topic, does not yield differences in respondents' bias perception. Using a multilevel model, we find that perceived journalist bias is significantly related to perceived political extremeness and impartiality of the article.","97":"The increased interest in promoting CS education for all has been coalescing around the idea of \"computational thinking.\" Several framings for promoting computational thinking in K-12 education have been proposed by practitioners and researchers that each place different emphases on either (1) skill and competence building, (2) creative expression and participation, or (3) social justice and ethics. We review each framing and how the framings structure the theory space of computational thinking. We then discuss how CS education can leverage the explanatory potential that each framing offers to the implementation and evaluation of learning, teaching, and tools in computing education. Our goal is to help CS education researchers, teachers, and designers unpack and leverage the complexities of this theory space (rather than ignoring it) while also addressing broader educational concerns regarding diversity, providing new directions for how students and teachers can actively participate in designing their digital futures, and directing current computing education efforts towards a more humanistic orientation.","98":"Significance We explore the key differences between the main social media platforms and how they are likely to influence information spreading and the formation of echo chambers. To assess the different dynamics, we perform a comparative analysis on more than 100 million pieces of content concerning controversial topics (e.g., gun control, vaccination, abortion) from Gab, Facebook, Reddit, and Twitter. The analysis focuses on two main dimensions: 1) homophily in the interaction networks and 2) bias in the information diffusion toward like-minded peers. Our results show that the aggregation in homophilic clusters of users dominates online dynamics. However, a direct comparison of news consumption on Facebook and Reddit shows higher segregation on Facebook. Social media may limit the exposure to diverse perspectives and favor the formation of groups of like-minded users framing and reinforcing a shared narrative, that is, echo chambers. However, the interaction paradigms among users and feed algorithms greatly vary across social media platforms. This paper explores the key differences between the main social media platforms and how they are likely to influence information spreading and echo chambers\u2019 formation. We perform a comparative analysis of more than 100 million pieces of content concerning several controversial topics (e.g., gun control, vaccination, abortion) from Gab, Facebook, Reddit, and Twitter. We quantify echo chambers over social media by two main ingredients: 1) homophily in the interaction networks and 2) bias in the information diffusion toward like-minded peers. Our results show that the aggregation of users in homophilic clusters dominate online interactions on Facebook and Twitter. We conclude the paper by directly comparing news consumption on Facebook and Reddit, finding higher segregation on Facebook.","99":"Understanding the drivers of diversity is a fundamental question in ecology. Extensive literature discusses different methods for describing diversity and documenting its effects on ecosystem health and function. However, it is widely believed that diversity depends on the intensity of sampling. I discuss a statistical perspective on diversity, framing the diversity of an environment as an unknown parameter, and discussing the bias and variance of plug-in and rarefied estimates. I describe the state of the statistical literature for addressing these problems, focusing on the analysis of microbial diversity. I argue that latent variable models can address issues with variance, but bias corrections need to be utilized as well. I encourage ecologists to use estimates of diversity that account for unobserved species, and to use measurement error models to compare diversity across ecosystems.","100":"Warning: this paper contains content that may be offensive or upsetting. Language has the power to reinforce stereotypes and project social biases onto others. At the core of the challenge is that it is rarely what is stated explicitly, but rather the implied meanings, that frame people\u2019s judgments about others. For example, given a statement that \u201cwe shouldn\u2019t lower our standards to hire more women,\u201d most listeners will infer the implicature intended by the speaker - that \u201cwomen (candidates) are less qualified.\u201d Most semantic formalisms, to date, do not capture such pragmatic implications in which people express social biases and power differentials in language. We introduce Social Bias Frames, a new conceptual formalism that aims to model the pragmatic frames in which people project social biases and stereotypes onto others. In addition, we introduce the Social Bias Inference Corpus to support large-scale modelling and evaluation with 150k structured annotations of social media posts, covering over 34k implications about a thousand demographic groups. We then establish baseline approaches that learn to recover Social Bias Frames from unstructured text. We find that while state-of-the-art neural models are effective at high-level categorization of whether a given statement projects unwanted social bias (80% F1), they are not effective at spelling out more detailed explanations in terms of Social Bias Frames. Our study motivates future work that combines structured pragmatic inference with commonsense reasoning on social implications.","101":"Artificial Intelligence (AI)\u2010based systems are widely employed nowadays to make decisions that have far\u2010reaching impact on individuals and society. Their decisions might affect everyone, everywhere, and anytime, entailing concerns about potential human rights issues. Therefore, it is necessary to move beyond traditional AI algorithms optimized for predictive performance and embed ethical and legal principles in their design, training, and deployment to ensure social good while still benefiting from the huge potential of the AI technology. The goal of this survey is to provide a broad multidisciplinary overview of the area of bias in AI systems, focusing on technical challenges and solutions as well as to suggest new research directions towards approaches well\u2010grounded in a legal frame. In this survey, we focus on data\u2010driven AI, as a large part of AI is powered nowadays by (big) data and powerful machine learning algorithms. If otherwise not specified, we use the general term bias to describe problems related to the gathering or processing of data that might result in prejudiced decisions on the bases of demographic features such as race, sex, and so forth.","102":"Abstract Obtaining reliable species observations is of great importance in animal ecology and wildlife conservation. An increasing number of studies use camera traps (CTs) to study wildlife communities, and an increasing effort is made to make better use and reuse of the large amounts of data that are produced. It is in these circumstances that it becomes paramount to correct for the species\u2010 and study\u2010specific variation in imperfect detection within CTs. We reviewed the literature and used our own experience to compile a list of factors that affect CT detection of animals. We did this within a conceptual framework of six distinct scales separating out the influences of (a) animal characteristics, (b) CT specifications, (c) CT set\u2010up protocols, and (d) environmental variables. We identified 40 factors that can potentially influence the detection of animals by CTs at these six scales. Many of these factors were related to only a few overarching parameters. Most of the animal characteristics scale with body mass and diet type, and most environmental characteristics differ with season or latitude such that remote sensing products like NDVI could be used as a proxy index to capture this variation. Factors that influence detection at the microsite and camera scales are probably the most important in determining CT detection of animals. The type of study and specific research question will determine which factors should be corrected. Corrections can be done by directly adjusting the CT metric of interest or by using covariates in a statistical framework. Our conceptual framework can be used to design better CT studies and help when analyzing CT data. Furthermore, it provides an overview of which factors should be reported in CT studies to make them repeatable, comparable, and their data reusable. This should greatly improve the possibilities for global scale analyses of (reused) CT data.","103":"Computer vision has undergone a dramatic revolution in performance, driven in large part through deep features trained on large-scale supervised datasets. However, much of these improvements have focused on static image analysis; video understanding has seen rather modest improvements. Even though new datasets and spatiotemporal models have been proposed, simple frame-by-frame classification methods often still remain competitive. We posit that current video datasets are plagued with implicit biases over scene and object structure that can dwarf variations in temporal structure. In this work, we build a video dataset with fully observable and controllable object and scene bias, and which truly requires spatiotemporal understanding in order to be solved. Our dataset, named CATER, is rendered synthetically using a library of standard 3D objects, and tests the ability to recognize compositions of object movements that require long-term reasoning. In addition to being a challenging dataset, CATER also provides a plethora of diagnostic tools to analyze modern spatiotemporal video architectures by being completely observable and controllable. Using CATER, we provide insights into some of the most recent state of the art deep video architectures.","104":"We present the first 1Mpixel SPAD camera ever reported. The camera features 3.8ns time gating and 24kfps frame rate; it was fabricated in 180nm CIS technology. Two pixels have been designed with a pitch of 9.4$\\mu$m in 7T and 5.75T configurations, respectively, achieving a maximum fill factor of 13.4%. The maximum PDP is 27%, median DCR 2.0cps, variation in gating length 120ps, position skew 410ps, and rise\/fall time <550ps, all FWHM at 3.3V of excess bias. The sensor was used to capture 2D\/3D scenes over 2m with an LSB of 5.4mm and a precision better than 7.8mm. Extended dynamic range is demonstrated in dual exposure operation mode. Spatially overlapped multi-object detection is experimentally demonstrated in single-photon time-gated ToF for the first time.","105":"Personalization is pervasive in the online space as it leads to higher efficiency for the user and higher revenue for the platform by individualizing the most relevant content for each user. However, recent studies suggest that such personalization can learn and propagate systemic biases and polarize opinions; this has led to calls for regulatory mechanisms and algorithms that are constrained to combat bias and the resulting echo-chamber effect. We propose a versatile framework that allows for the possibility to reduce polarization in personalized systems by allowing the user to constrain the distribution from which content is selected. We then present a scalable algorithm with provable guarantees that satisfies the given constraints on the types of the content that can be displayed to a user, but -- subject to these constraints -- will continue to learn and personalize the content in order to maximize utility. We illustrate this framework on a curated dataset of online news articles that are conservative or liberal, show that it can control polarization, and examine the trade-off between decreasing polarization and the resulting loss to revenue. We further exhibit the flexibility and scalability of our approach by framing the problem in terms of the more general diverse content selection problem and test it empirically on both a News dataset and the MovieLens dataset.","106":"Abstract. The Earth System Model EC-Earth3 for contributions to CMIP6 is documented here, with its flexible coupling framework, major model configurations, a methodology for ensuring the simulations are comparable across different HPC systems, and with the physical performance of base configurations over the historical period. The variety of possible configurations and sub-models reflects the broad interests in the EC-Earth community. EC-Earth3 key performance metrics demonstrate physical behaviour and biases well within the frame known from recent CMIP models. With improved physical and dynamic features, new ESM components, community tools, and largely improved physical performance compared to the CMIP5 version, EC-Earth3 represents a clear step forward for the only European community ESM. We demonstrate here that EC-Earth3 is suited for a range of tasks in CMIP6 and beyond.\n","107":"Denoising fMRI data requires assessment of frame-to-frame head motion and removal of the biases motion introduces. This is usually done through analysis of the parameters calculated during retrospective head motion correction (i.e., \u2018motion\u2019 parameters). However, it is increasingly recognized that respiration introduces factitious head motion via perturbations of the main (B0) field. This effect appears as a relatively high-frequency fluctuation in the motion parameters (> 0.1 Hz, here referred to as \u2018HF-motion\u2019), primarily in the phase-encoding direction. This periodicity can sometimes be obscured in standard singleband fMRI (TR 2.0 \u2013 2.5 s.) due to aliasing. Here we examined (1) how prevalent HF-motion effects are in seven single-band datasets with TR from 2.0 - 2.5 s and (2) how HF-motion affects functional connectivity. We demonstrate that HF-motion is relatively trait-like and more common in older adults, those with higher body mass index, and those with lower cardiorespiratory fitness. We propose a low-pass filtering approach to remove the contamination of high frequency effects from motion summary measures, such as framewise displacement (FD). We demonstrate that in most datasets this filtering approach saves a substantial amount of data from FD-based frame censoring, while at the same time adequately reducing motion biases in functional connectivity measures. These findings suggest that filtering motion parameters is an effective way to improve the fidelity of head motion estimates, even in single band datasets. Particularly large data savings may accrue in datasets acquired in older and less fit participants.","108":"Generating non-existing frames from a consecutive video sequence has been an interesting and challenging problem. Recent kernel-based interpolation methods predict pixels with a single convolution process that convolves source frames with spatially adaptive local kernels. However, when scene motion is larger than the pre-defined kernel size, these methods are prone to yield less plausible results and they cannot directly generate a frame at an arbitrary temporal position because the learned kernels are tied to the midpoint in time between the input frames. In this paper, we try to solve these problems and propose a novel approach that we refer to as enhanced deformable separable convolution (EDSC) to estimate not only adaptive kernels, but also offsets, masks and biases to make the network obtain information from non-local neighborhood. During the learning process, different intermediate time step can be involved as a control variable by means of the coord-conv trick, allowing the estimated components to vary with different input temporal information. This makes our method capable to produce multiple in-between frames. Experimental results show that our method performs favorably against the state-of-the-art methods across a broad range of datasets.","109":"One of the biggest issues in deep learning theory is the generalization ability of networks with huge model size. The classical learning theory suggests that overparameterized models cause overfitting. However, practically used large deep models avoid overfitting, which is not well explained by the classical approaches. To resolve this issue, several attempts have been made. Among them, the compression based bound is one of the promising approaches. However, the compression based bound can be applied only to a compressed network, and it is not applicable to the non-compressed original network. In this paper, we give a unified frame-work that can convert compression based bounds to those for non-compressed original networks. The bound gives even better rate than the one for the compressed network by improving the bias term. By establishing the unified frame-work, we can obtain a data dependent generalization error bound which gives a tighter evaluation than the data independent ones.","110":"We have seen a massive growth of online experiments at Internet companies. Although conceptually simple, A\/B tests can easily go wrong in the hands of inexperienced users and on an A\/B testing platform with little governance. An invalid A\/B test hurts the business by leading to non-optimal decisions. Therefore, it is now more important than ever to create an intelligent A\/B platform that democratizes A\/B testing and allows everyone to make quality decisions through built-in detection and diagnosis of invalid tests. In this paper, we share how we mined through historical A\/B tests and identified the most common causes for invalid tests, ranging from biased design, self-selection bias to attempting to generalize A\/B test result beyond the experiment population and time frame. Furthermore, we also developed scalable algorithms to automatically detect invalid A\/B tests and diagnose the root cause of invalidity. Surfacing up invalidity not only improved decision quality, but also served as a user education and reduced problematic experiment designs in the long run.","111":"Research to date aimed at the fairness, accountability, and transparency of algorithmic systems has largely focused on topics such as identifying failures of current systems and on technical interventions intended to reduce bias in computational processes. Researchers have given less attention to methods that account for the social and political contexts of specific, situated technical systems at their points of use. Co-developing algorithmic accountability interventions in communities supports outcomes that are more likely to address problems in their situated context and re-center power with those most disparately affected by the harms of algorithmic systems. In this paper we report on our experiences using participatory and co-design methods for algorithmic accountability in a project called the Algorithmic Equity Toolkit. The main insights we gleaned from our experiences were: (i) many meaningful interventions toward equitable algorithmic systems are non-technical; (ii) community organizations derive the most value from localized materials as opposed to what is \"scalable\" beyond a particular policy context; (iii) framing harms around algorithmic bias suggests that more accurate data is the solution, at the risk of missing deeper questions about whether some technologies should be used at all. More broadly, we found that community-based methods are important inroads to addressing algorithmic harms in their situated contexts.","112":"Two novel robust nonlinear stochastic full pose (i.e., attitude and position) estimators on the Special Euclidean Group $\\mathbb {SE}(3)$ are proposed using the available uncertain measurements. The resulting estimators utilize the basic structure of the deterministic pose estimators adopting it to the stochastic sense. The proposed estimators for six degrees of freedom (DOF) pose estimations consider the group velocity vectors to be contaminated with constant bias and Gaussian random noise, unlike nonlinear deterministic pose estimators which disregard the noise component in the estimator derivations. The proposed estimators ensure that the closed-loop error signals are semi-globally uniformly ultimately bounded in mean square. The efficiency and robustness of the proposed estimators are demonstrated by the numerical results which test the estimators against high levels of noise and bias associated with the group velocity and body-frame measurements and large initialization error.","113":null,"114":"We propose to modify the common training protocols of optical flow, leading to sizable accuracy improvements without adding to the computational complexity of the training process. The improvement is based on observing the bias in sampling challenging data that exists in the current training protocol, and improving the sampling process. In addition, we find that both regularization and augmentation should decrease during the training protocol. Using an existing low parameters architecture, the method is ranked first on the MPI Sintel benchmark among all other methods, improving the best two frames method accuracy by more than 10%. The method also surpasses all similar architecture variants by more than 12% and 19.7% on the KITTI benchmarks, achieving the lowest Average End-Point Error on KITTI2012 among two-frame methods, without using extra datasets.","115":"Research in machine learning (ML) has primarily argued that models trained on incomplete or biased datasets can lead to discriminatory outputs. In this commentary, we propose moving the research focus beyond biasoriented framings by adopting a power-aware perspective to \u201cstudy up\u201d ML datasets. This means accounting for historical inequities, labor conditions, and epistemological standpoints inscribed in data. We draw on HCI and CSCW work to support our argument, critically analyze previous research, and point at two co-existing lines of work within our community \u2014 one bias-oriented, the other power-aware. This way, we highlight the need for dialogue and cooperation in three areas: data quality, data work, and data documentation. In the first area, we argue that reducing societal problems to \u201cbias\u201d misses the context-based nature of data. In the second one, we highlight the corporate forces and market imperatives involved in the labor of data workers that subsequently shape ML datasets. Finally, we propose expanding current transparency-oriented efforts in dataset documentation to reflect the social contexts of data design and production.","116":"Although the impact of so-called \u201csponsorship bias\u201d has been the subject of increased attention in the philosophy of science, what exactly constitutes its epistemic wrongness is still debated. In this paper, I will argue that neither evidential accounts nor social\u2013epistemological accounts can fully account for the epistemic wrongness of sponsorship bias, but there are good reasons to prefer social\u2013epistemological to evidential accounts. I will defend this claim by examining how both accounts deal with a paradigm case from medical epistemology, recently discussed in a paper by Bennett Holman. I will argue that evidential accounts cannot adequately capture cases of sponsorship bias that involve the manufacturing of certainty because of their neutrality with respect to the role of non-epistemic values in scientific practice. If my argument holds, it further highlights the importance of integrating social and ethical concerns into epistemological analysis, especially in applied contexts. One can only properly grasp sponsorship bias as an epistemological problem if one resists the methodological tendency to analyze social, ethical, and epistemological issues in isolation from each other.","117":null,"118":"Research in machine learning (ML) has argued that models trained on incomplete or biased datasets can lead to discriminatory outputs. In this commentary, we propose moving the research focus beyond bias-oriented framings by adopting a power-aware perspective to \"study up\" ML datasets. This means accounting for historical inequities, labor conditions, and epistemological standpoints inscribed in data. We draw on HCI and CSCW work to support our argument, critically analyze previous research, and point at two co-existing lines of work within our research community \\,---\\,one bias-centered, the other power-aware. We highlight the need for dialogue and cooperation in three areas: data quality, data work, and data documentation. In the first area, we argue that reducing societal problems to \"bias\" misses the context-based nature of data. In the second one, we highlight the corporate forces and market imperatives involved in the labor of data workers that subsequently shape ML datasets. Finally, we propose expanding current transparency-oriented efforts in dataset documentation to reflect the social contexts of data design and production.","119":"The social sciences and digital humanities have recently adopted the machine learning technique of topic modeling to address research questions in their fields. This is problematic in a number of ways, some of which have not received much attention in the debate yet. This paper adds epistemological concerns centering around the interface between topic modeling and linguistic concepts and the argumentative embedding of evidence obtained through topic modeling. It concludes that topic modeling in its present state of methodological integration does not meet the requirements of an independent research method. It operates from relevantly unrealistic assumptions, is non-deterministic, cannot effectively be validated against a reasonable number of competing models, does not lock into a well-defined linguistic interface, and does not scholarly model topics in the sense of themes or content. These features are intrinsic and make the interpretation of its results prone to apophenia (the human tendency to perceive random sets of elements as meaningful patterns) and confirmation bias (the human tendency to perceptually prefer patterns that are in alignment with pre-existing biases). While partial validation of the statistical model is possible, a conceptual validation would require an extended triangulation with other methods and human ratings, and clarification of whether statistical distinctivity of lexical co-occurrence correlates with conceputal topics in any reliable way.","120":null,"121":null,"122":null,"123":"Contextual word embeddings such as BERT have achieved state of the art performance in numerous NLP tasks. Since they are optimized to capture the statistical properties of training data, they tend to pick up on and amplify social stereotypes present in the data as well. In this study, we (1) propose a template-based method to quantify bias in BERT; (2) show that this method obtains more consistent results in capturing social biases than the traditional cosine based method; and (3) conduct a case study, evaluating gender bias in a downstream task of Gender Pronoun Resolution. Although our case study focuses on gender bias, the proposed technique is generalizable to unveiling other biases, including in multiclass settings, such as racial and religious biases.","124":null,"125":null,"126":null,"127":null,"128":null,"129":"Neural machine translation has significantly pushed forward the quality of the field. However, there are remaining big issues with the output translations and one of them is fairness. Neural models are trained on large text corpora which contain biases and stereotypes. As a consequence, models inherit these social biases. Recent methods have shown results in reducing gender bias in other natural language processing tools such as word embeddings. We take advantage of the fact that word embeddings are used in neural machine translation to propose a method to equalize gender biases in neural machine translation using these representations. Specifically, we propose, experiment and analyze the integration of two debiasing techniques over GloVe embeddings in the Transformer translation architecture. We evaluate our proposed system on the WMT English-Spanish benchmark task, showing gains up to one BLEU point. As for the gender bias evaluation, we generate a test set of occupations and we show that our proposed system learns to equalize existing biases from the baseline system.","130":null,"131":"Gender bias is highly impacting natural language processing applications. Word embeddings have clearly been proven both to keep and amplify gender biases that are present in current data sources. Recently, contextualized word embeddings have enhanced previous word embedding techniques by computing word vector representations dependent on the sentence they appear in. In this paper, we study the impact of this conceptual change in the word embedding computation in relation with gender bias. Our analysis includes different measures previously applied in the literature to standard word embeddings. Our findings suggest that contextualized word embeddings are less biased than standard ones even when the latter are debiased.","132":null,"133":"Ethics regarding social bias has recently thrown striking issues in natural language processing. Especially for gender-related topics, the need for a system that reduces the model bias has grown in areas such as image captioning, content recommendation, and automated employment. However, detection and evaluation of gender bias in the machine translation systems are not yet thoroughly investigated, for the task being cross-lingual and challenging to define. In this paper, we propose a scheme for making up a test set that evaluates the gender bias in a machine translation system, with Korean, a language with gender-neutral pronouns. Three word\/phrase sets are primarily constructed, each incorporating positive\/negative expressions or occupations; all the terms are gender-independent or at least not biased to one side severely. Then, additional sentence lists are constructed concerning formality of the pronouns and politeness of the sentences. With the generated sentence set of size 4,236 in total, we evaluate gender bias in conventional machine translation systems utilizing the proposed measure, which is termed here as translation gender bias index (TGBI). The corpus and the code for evaluation is available on-line.","134":"(Bolukbasi et al., 2016) demonstrated that pretrained word embeddings can inherit gender bias from the data they were trained on. We investigate how this bias affects downstream classification tasks, using the case study of occupation classification (De-Arteaga et al., 2019). We show that traditional techniques for debiasing embeddings can actually worsen the bias of the downstream classifier by providing a less noisy channel for communicating gender information. With a relatively minor adjustment, however, we show how these same techniques can be used to simultaneously reduce bias and maintain high classification accuracy.","135":"The purpose of this paper is to present an empirical study on gender bias in text. Current research in this field is focused on detecting and correcting for gender bias in existing machine learning models rather than approaching the issue at the dataset level. The underlying motivation is to create a dataset which could enable machines to learn to differentiate bias writing from non-bias writing. A taxonomy is proposed for structural and contextual gender biases which can manifest themselves in text. A methodology is proposed to fetch one type of structural gender bias, Gender Generalization. We explore the IMDB movie review dataset and 9 different corpora from Project Gutenberg. By filtering out irrelevant sentences, the remaining pool of candidate sentences are sent for human validation. A total of 6123 judgments are made on 1627 sentences and after a quality check on randomly selected sentences we obtain an accuracy of 75%. Out of the 1627 sentences, 808 sentence were labeled as Gender Generalizations. The inter-rater reliability amongst labelers was of 61.14%.","136":"Systemic bias in word embeddings has been widely reported and studied, and efforts made to debias them; however, new contextualized embeddings such as ELMo and BERT are only now being similarly studied. Standard debiasing methods require heterogeneous lists of target words to identify the \u201cbias subspace\u201d. We show show that using new contextualized word embeddings in conceptor debiasing allows us to more accurately debias word embeddings by breaking target word lists into more homogeneous subsets and then combining (\u201dOr\u2019ing\u201d) the debiasing conceptors of the different subsets.","137":null,"138":"In October 2019, the first Greek Massive}O {{pen Online Course on science experiments for students took place online and lasted five weeks. Its content consisted of a substantial number of science experiments based on the school curriculum with simple, everyday materials. The audience addressed were not only students but also science teachers and people interested in science. A total of 7266 enrollments were recorded, the vast majority of participants being teachers of primary and secondary education. The data received during the course and the statistics that followed revealed notable findings on the need for epistemological development among teachers teaching science and engineering, the extent of teaching through experiments in Greek schools, the gender-biased inequalities in the communities of students and teachers, and the challenges that exist in the field. The course was repeated in March 2020 as soon as the pandemic spread in the country.","139":null,"140":"Early studies of risk assessment algorithms used in criminal justice revealed widespread racial biases. In response, machine learning researchers have developed methods for fairness, many of which rely on equalizing empirical metrics across protected attributes. Here, I recall socio-technical perspectives to delineate the significant gap between fairness in theory and practice, focusing on criminal justice. I (1) illustrate how social context can undermine analyses that are restricted to an AI system\u2019s outputs, and (2) argue that much of the fair ML literature fails to account for epistemological issues with underlying crime data. Instead of building AI that reifies power imbalances, like risk assessment algorithms, I ask whether data science can be used to understand the root causes of structural marginalization.","141":null,"142":null,"143":null,"144":null,"145":null,"146":null,"147":"Gender bias has been found in existing coreference resolvers. In order to eliminate gender bias, a gender-balanced dataset Gendered Ambiguous Pronouns (GAP) has been released and the best baseline model achieves only 66.9% F1. Bidirectional Encoder Representations from Transformers (BERT) has broken several NLP task records and can be used on GAP dataset. However, fine-tune BERT on a specific task is computationally expensive. In this paper, we propose an end-to-end resolver by combining pre-trained BERT with Relational Graph Convolutional Network (R-GCN). R-GCN is used for digesting structural syntactic information and learning better task-specific embeddings. Empirical results demonstrate that, under explicit syntactic supervision and without the need to fine tune BERT, R-GCN\u2019s embeddings outperform the original BERT embeddings on the coreference task. Our work significantly improves the snippet-context baseline F1 score on GAP dataset from 66.9% to 80.3%. We participated in the Gender Bias for Natural Language Processing 2019 shared task, and our codes are available online.","148":"The paper describes the submission of the team \u201cWe used bert!\u201d to the shared task Gendered Pronoun Resolution (Pair pronouns to their correct entities). Our final submission model based on the fine-tuned BERT (Bidirectional Encoder Representations from Transformers) ranks 14th among 838 teams with a multi-class logarithmic loss of 0.208. In this work, contribution of transfer learning technique to pronoun resolution systems is investigated and the gender bias contained in classification models is evaluated.","149":"The resolution of ambiguous pronouns is a longstanding challenge in Natural Language Understanding. Recent studies have suggested gender bias among state-of-the-art coreference resolution systems. As an example, Google AI Language team recently released a gender-balanced dataset and showed that performance of these coreference resolvers is significantly limited on the dataset. In this paper, we propose an extractive question answering (QA) formulation of pronoun resolution task that overcomes this limitation and shows much lower gender bias (0.99) on their dataset. This system uses fine-tuned representations from the pre-trained BERT model and outperforms the existing baseline by a significant margin (22.2% absolute improvement in F1 score) without using any hand-engineered features. This QA framework is equally performant even without the knowledge of the candidate antecedents of the pronoun. An ensemble of QA and BERT-based multiple choice and sequence classification models further improves the F1 (23.3% absolute improvement upon the baseline). This ensemble model was submitted to the shared task for the 1st ACL workshop on Gender Bias for Natural Language Processing. It ranked 9th on the final official leaderboard.","150":"This paper explains the TALP-UPC participation for the Gendered Pronoun Resolution shared-task of the 1st ACL Workshop on Gender Bias for Natural Language Processing. We have implemented two models for mask language modeling using pre-trained BERT adjusted to work for a classification problem. The proposed solutions are based on the word probabilities of the original BERT model, but using common English names to replace the original test names.","151":null,"152":null,"153":"In this work, we investigate the presence of occupational gender stereotypes in sentiment analysis models. Such a task has implications in reducing implicit biases in these models, which are being applied to an increasingly wide variety of downstream tasks. We release a new gender-balanced dataset of 800 sentences pertaining to specific professions and propose a methodology for using it as a test bench to evaluate sentiment analysis models. We evaluate the presence of occupational gender stereotypes in 3 different models using our approach, and explore their relationship with societal perceptions of occupations.","154":"This essay mixes epistemological considerations on truth and science, a critical information literacy exercise on the 5 Laws of MIL (Media and Information Literacy), LIS theory and international experience reports. It is constructed in five parts, in line with the 5 Laws of Media and Information Literacy (Grizzle & Singh, 2016) and Ranganathan\u2019s laws (1931). First, a critique of the Laws of MIL is presented; then a specific social context puts the first part into perspective; the feedback from the international community on the first two is followed by new research on library\/MIL laws; and finally, matters of space, readers, staff and mutation are addressed in order to open the theme to other interlocutors and experiences that enrich the conversation. It concludes that the scientific method is neither perfectly objective nor completely useless: it has to be understood as a social construction. Furthermore, to put information neutrality utopia definitely behind us, we should expose our biases, rather than pretend to erase them, as a way to build a new trust in science.","155":"This chapter contains a critical analysis of people's faith in experts. It presents many biases that influence and distort people's perception of the reputation of others. It also examines the heuristics that influence people's perceptions and lead them to classify accurately or inaccurately a person or object within a social network. Reputation can never be taken for granted and always creates uncertainty and anxiety. This is because social position is always precarious and can never be objectively determined. The chapter also distinguishes the \u201cgood\u201d from the \u201cbad\u201d uses of reputation in order to develop a proper epistemology of reputation. The objective is to identify a set of normative and descriptive instruments that can be used to classify the heuristics and establish some sort of criteria, along the lines of the classical epistemological tradition in order to distinguish between the rules of inference that place too much or too little trust in the reputations of others.","156":"We present our 7th place solution to the Gendered Pronoun Resolution challenge, which uses BERT without fine-tuning and a novel augmentation strategy designed for contextual embedding token-level tasks. Our method anonymizes the referent by replacing candidate names with a set of common placeholder names. Besides the usual benefits of effectively increasing training data size, this approach diversifies idiosyncratic information embedded in names. Using same set of common first names can also help the model recognize names better, shorten token length, and remove gender and regional biases associated with names. The system scored 0.1947 log loss in stage 2, where the augmentation contributed to an improvements of 0.04. Post-competition analysis shows that, when using different embedding layers, the system scores 0.1799 which would be third place.","157":null,"158":null,"159":"Text-based data sources like narratives and stories have become increasingly popular as critical insight generator in energy research and social science. However, their implications in policy application usually remain superficial and fail to fully exploit state-of-the-art resources which digital era holds for text analysis. This paper illustrates the potential of deep-narrative analysis in energy policy research using text analysis tools from the cutting-edge domain of computational social sciences, notably topic modelling. We argue that a nested application of topic modelling and grounded theory in narrative analysis promises advances in areas where manual-coding driven narrative analysis has traditionally struggled with directionality biases, scaling, systematisation and repeatability. The nested application of the topic model and the grounded theory goes beyond the frequentist approach of narrative analysis and introduces insight generation capabilities based on the probability distribution of words and topics in a text corpus. In this manner, our proposed methodology deconstructs the corpus and enables the analyst to answer research questions based on the foundational element of the text data structure. We verify the theoretical and epistemological fit of the proposed nested methodology through a meta-analysis of a state-of-the-art bibliographic database on energy policy and computational social science. We find that the nested application contributes to the literature gap on the need for multidisciplinary polyvalence methodologies that can systematically include qualitative evidence into policymaking.","160":"The relative popularity of web sites, as expressed in published rankings, is of fundamental value in many contexts including search, advertising and research. In this paper, we consider the surprisingly challenging problem of generating consistent and reliable web site rankings based on unique visitors per day. We illustrate the challenge this represents using data from three large and independently-sourced Internet user panels. We begin by showing that generating a website ranking based simply on the observed unique daily visitors produces highly inconsistent rankings\u2013even among the most popular sites. To mitigate the problems of bias and measurement error, we introduce a general methodology that identifies \u201ccanonical panelists\u201d: an abstract class of user that exhibits consistent behavior across panels. Our definition is based on the epistemological technique of triangulation, which refers to observing the same object from multiple perspectives at the same moment in time. We show that panelists in the canonical class exhibit desirable characteristics including improved persistence. Most significantly, we show that defining a domain\u2019s rank as a function of the aggregate behavior of canonical panelists improves overall alignment of rankings across all three of our panels.","161":"Digital media infrastructures give rise to texts that are socially interconnected in various forms of complex networks. These mediated phenomena can be analyzed through methods that trace relational data. Social network analysis (SNA) traces interconnections between social nodes, while natural language processing (NLP) traces intralinguistic properties of the text. These methods can be bracketed under the header \u201csocial big data.\u201d Empirical and theoretical rigor begs a constructionist understanding of such data. Analysis is inherently perspective-bound; it is rarely a purely objective statistical exercise. Some kind of selection is always made, primarily out of practical necessity. Moreover, the agents observed (network participants producing the texts in question) all tend to make their own encodings, based on observational inferences, situated in the network topology. Recent developments in such methods have, for example, provided social scientific scholars with innovative means to address inconsistencies in comparative surveys in different languages, addressing issues of comparability and measurement equivalence. NLP provides novel, inductive ways of understanding word meanings as a function of their relational placement in syntagmatic and paradigmatic relations, thereby identifying biases in the relative meanings of words. Reflecting on current research projects, the chapter addresses key epistemological challenges in order to improve contextual understanding.","162":"The ethical consequences, constraints upon and regulation of algorithms arguably represent the defining challenges of our age, asking us to reckon with the rise of computational technologies whose potential to radically transforming social and individual orders and identity in unforeseen ways is already being realised. Fittingly, concurrent with the emergence of such epoch-shaping technologies has emerged a rapidly expanding and multi-disciplinary set of research disciplines focused on these very questions. As the inexorable march of computational technologies encroaches across society and academic disciplines, it is natural that diverse specialisations including computer science, moral philosophy, engineering, jurisprudence and economics should turn their attention to the algorithmic zeitgeist. Yet despite the multi-disciplinary impact of this algorithmic turn, there remains some way to go in motivating cross-disciplinary collaboration is crucial to advancing feasible proposals for the ethical design, implementation and regulation of algorithmic and automated systems. In this work, we provide a framework to assist crossdisciplinary collaboration by presenting a \u2018Four C\u2019s Framework\u2019 covering key computational considerations researchers across such diverse fields should consider when approaching these questions: (i) computability, (ii) complexity, (iii) consistency and (iv) controllability. In addition, we provide examples of how insights from ethics, philosophy and population ethics are relevant to and translatable within sciences concerned with the study and design of algorithms. Our aim is to set-out a framework which we believe is useful for fostering cross-disciplinary understanding of pertinent issues in ethical algorithmic literature which is relevant considering the feasibility of ethical algorithmic governance, especially the impact of computational constraints upon algorithmic governance. The rapid acceleration of artificial intelligence and algorithmically-based technologies over the last several decades has led to an explosion in research programmes dedicated to framing, understanding and regulating the ethical, moral, philosophical and jurisprudential consequences of these powerful and epoch-defining technologies. As computational and information sciences advance throughout all facets of social, economic and political dimensions of society, it is natural that responses to this technological imperative involve multidisciplinary research fields, Copyright \u00a9 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. including the burgeoning fields of fair machine learning (Chouldechova 2017; Caton and Haas 2020), algorithmic jurisprudence (Zalnieriute, Moses, and Williams 2019), interpretability and regulatory technology. The rise of such technologies and, moreover, the increasing envelopment of technical and epistemological practice by algorithmic technologies, a phenomenon we denote as the algorithmic turn (in homage to its linguistic namesake), is as profound as it is ubiquitous. The extraordinary reach of such technologies naturally motivates cross-disciplinarity in such research programmes among ethicists, philosophers and computer scientists in order to grapple with the consequences of these technologies. While such cross-collaboration has increased over several years, there remain challenges in translating between the epistemological citadels within which each discipline is resides. Though multidisciplinary in impact, research programmes often remain less cross-disciplinary than called for. An example is within fair machine learning research, where technical results on the theory and mathematics of implementing fairness criteria algorithmically (to ameliorate bias, discrimination for example) tend to have limited, if any, engagement with the directly relevant and vast literature within ethics, social choice and decision theory, philosophy and jurisprudence. Of course, disciplinary silos are nothing new in the academe and specialised focus within disciplines is critical to pushing frontiers of research. Moreover, it is impossible for there to be a single, overarching, epistemological framework to provide direction to such a variegated topic as ethical algorithms. Nevertheless, as we contend in this work, there are benefits to be had by providing a framework where researchers in the sciences, economics and humanities can engage with common themes, protocols and domain criteria relevant to ethical consideration of algorithms. For example, seeking to ethically constrain or shape algorithms via design or regulation requires domain understanding of precisely what is meant by the term algorithm, along with familiarity with core concepts in computational science which inform algorithms themselves, such as computational complexity, computability and others. Similarly, programmes that seek to explore ethical constraints upon algorithms would benefit considerably from a consideration of how issues and dilemmas facing their field, such as the inevitability of trade-offs among fairness criteria, probabilistic approaches to ethical classification and auditing have been explored in fields such as moral philosophy, population ethics and decision theory. Indeed the very validity of fairness criteria themselves, for example, is a rich and ancient debate across ethics and associated disciplines. Our answer to this challenge is to propose a framework based upon core computational science concepts of computability, complexity, consistency and controllability, which we name the \u2018Four C\u2019s Framework\u2019. The aim of the framework is to set-out core concepts from computer science applicable to consideration of the ethical status and consequences of algorithms and automated systems, in order to provide researchers across disciplines with a series of considerations that we believe should be taken into account in any proposals for ethical regulation and assessment of algorithmic systems. Though care has been taken to address the nuances of various research fields, inevitably any crossdisciplinary synthesis that seeks to abstract key concepts will simplify, gloss over and omit any number of important results. Results and Contributions The contributions of our paper relative to the state of the art are as follows: 1. Development of a holistic framework to assist crossdisciplinary collaboration among researchers by setting out key technical research criteria concerning computability, complexity, consistency and controllability which should be taken into consideration when the ethical classification, regulation or assessment of algorithmic systems is undertaken. 2. Explication of connections among computational science, philosophical and economic science research in a way that identifies common problems both seek to address and that assists in motivating the translation of results in one field, say social choice and decision theory, to another, such as fair machine learning. Structure The structure of our paper is as follows. Part I sets out a framework for understanding how to classify and characterise algorithms as ethical. It introduces conceptualisations including ethical computation, ethical decision (deontological) procedures as distinct from ethical (consequentialist) outcomes. We connect ethical auditing to provability concepts and argue algorithmic governance in the limit will be itself necessarily algorithmic. Part II of the paper introduces the Four C\u2019s Framework described above. It unpacks concepts from computability and complexity theory, such as efficiency and feasibility as they pertain to ethical algorithmic analysis. The importancy of consistency (and completeness which we roll into consistency considerations), including the extent to which consistency in process or outcomes are ethically significant, is examined. We similarly explore how controllability is a critical element to consider when assessing ethical algorithms. We conclude the part with consideration of the ethical consequences for the inevitable reliance upon heuristics in any algorithmic regulatory context. Part III focuses on cross-disciplinary connections between algorithmic epistemology and other disciplines, such as impossibility results in social choice and social welfare theorems, contextualising population ethics\u2019 debates among other examples. Part IV concludes our paper, exploring a number of cross-disciplinary options for handling key challenges with ethical algorithms, including determining appropriate trade-offs, uncertainty in algorithmic processes or outcomes, via analogy with existing institutions, such as the law, which face similar challenges. Part I: Ethical Algorithms","163":"In recent years, there has been increasing interest in causal reasoning for designing fair decision-making systems due to its compatibility with legal frameworks, interpretability for human stakeholders, and robustness to spurious correlations inherent in observational data, among other factors. The recent attention to causal fairness, however, has been accompanied with great skepticism due to practical and epistemological challenges with applying current causal fairness approaches in the literature. Motivated by the long-standing empirical work on causality in econometrics, social sciences, and biomedical sciences, in this paper we lay out the conditions for appropriate application of causal fairness under the\"potential outcomes framework.\"We highlight key aspects of causal inference that are often ignored in the causal fairness literature. In particular, we discuss the importance of specifying the nature and timing of interventions on social categories such as race or gender. Precisely, instead of postulating an intervention on immutable attributes, we propose a shift in focus to their perceptions and discuss the implications for fairness evaluation. We argue that such conceptualization of the intervention is key in evaluating the validity of causal assumptions and conducting sound causal analysis including avoiding post-treatment bias. Subsequently, we illustrate how causality can address the limitations of existing fairness metrics, including those that depend upon statistical correlations. Specifically, we introduce causal variants of common statistical notions of fairness, and we make a novel observation that under the causal framework there is no fundamental disagreement between different notions of fairness. Finally, we conduct extensive experiments where we demonstrate our approach for evaluating and mitigating unfairness, specially when post-treatment variables are present.","164":"Computer-supported collaborative learning (CSCL) forms a diverse field with researchers from different backgrounds using a variety of learning theories and research methods to design and analyze CSCL learning environments. The dynamic and active features of the field can lead to confusion about its identity and conclusions that can be drawn from the outcomes of CSCL research. Syntheses of CSCL research can help to answer questions about the prevalent topics and outcomes in the field. There are a number of synthesis methods to choose depending on the methods used in the primary studies as well as goals of the synthesis. Meta-synthesis is also available to better integrate findings obtained using different research methods. This symposium showcases a spectrum of different synthesis methods used in CSCL. Benefits and disadvantages of the synthesis methods will be discussed along with the question of how different synthesis methods can be used to inform each other. The field of computer-supported collaborative learning (CSCL) brings together researchers from diverse disciplines (Computer Science, Psychology, Education, Linguistics, etc.) with diverse learning theories. A broad spectrum of different research methods is used in the field of CSCL depending on considerations such as the specific research goals, the maturity of the theories, the complexity of the problems and the researcher\u2019s epistemological orientation. Thus, CSCL is a dynamic and active research community and a wealth of CSCL research has been conducted to reveal the mechanisms of successful CSCL (King, 2007; Scardamalia & Bereiter, 1994). In order to achieve a more comprehensive and precise conclusion about CSCL mechanism, structured research synthesis are needed that integrate the rich amount of primary studies about specific topics in CSCL However it also became of a source of confusion and disagreement about integrative conclusions that can be drawn from CSCL research (see also Wise & Schwarz, 2017).. Goals and motivations of the synthesis may dictate the use of quantitative or qualitative synthesis methods, which, in turn, limit the type and scope of conclusions that can be drawn from them. These goals might be the generation of innovation, the building of theories, finding evidence for specific hypotheses, or informing policy and practice in education. However, even when the most adequate synthesis method might have been selected to integrate primary research done in a specific area of CSCL, challenges still remain. For instance, deciding for meta-analysis means the exclusion of a part of primary studies. Qualitative syntheses, in spite its depth and insights, lack the precision of meta-analyses. This means that even the most adequate synthesis method may lead to biased conclusions about CSCL research. This symposium showcases a spectrum of syntheses used in the field of CSCL which all have the common goal to integrate CSCL research and to contribute to the understanding of the CSCL community and its research outcomes. Firstly, three papers will be presented that depict a bibliometric analysis, a qualitative systematic review and a quantitative meta-analysis all conducted in the field of CSCL. Secondly, the fourth paper will introduce meta-synthesis as a method to integrate quantitative and qualitative research outcomes and a way to overcome the disadvantages of using only one particular synthesis method. More specifically, the first paper by H\u00e5klev et al. used bibliometric analysis to get a better understanding of the CSCL researcher community. In this paper, ICLS and CSCL proceedings are analyzed to uncover and portray patterns in co-authorship, authors\u2019 field of research, geographical location and commitment to the community. While qualitative analyses are quite common in CSCL research, few qualitative syntheses exist. In the second paper, Wan and Wan instead present a qualitative systematic review to uncover how phenomenography, a specific qualitative research method, is used in the field of CSCL. This paper presents how CSCL 2019 Proceedings 783 \u00a9 ISLS a novel qualitative research method is adopted by the field of CSCL, the depth of explanation of qualitative syntheses, and makes suggestions how phenomenography could be utilized to synthesize CSCL research. The third paper by Radkowitsch et al. represents the use of quantitative meta-analysis in the field of CSCL. Their choice of synthesis method was justified by the substantial amount of quantitative experimental studies already available. More specifically they synthesized experimental studies about the effects of CSCL scripts as a scaffold to enhance collaborative learning. Their findings provide a strong empirical argument for the effectiveness of CSCL scripts against the critic \u2013 raised in the controversial debate within the CSCL field \u2013 that CSCL scripts may be too constraining and thus ineffective. In the fourth paper, Hmelo-Silver and Jeong showcase a way to synthesize qualitative and quantitative primary studies in evaluating the outcomes of STEM CSCL. The study provides one model of meta-synthesis that takes into account both quantitative and qualitative outcomes. It aims to integrate CSCL research outcomes both from quantitative and qualitative studies and thus overcome some of the existing synthesis methods that solely uses either quantitative or qualitative outcomes. Continued efforts are needed to synthesize CSCL research outcomes across different theoretical and methodological boundaries.. Taken together, the current symposium will showcase available synthesis techniques and provide a forum to reflect on their advantages and limitations. It can help us better understand which synthesis method might be adequate for the different research goals and motivations and how the various syntheses can inform each other and the field in general. A bibliographic analysis of our community through the lens of ICLS and CSCL","165":null,"166":"Deep learning models have brought great breakthroughs in building extraction from high-resolution optical remote-sensing images. Among recent research, the self-attention module has called up a storm in many fields, including building extraction. However, most current deep learning models loading with the self-attention module still lose sight of the reconstruction bias\u2019s effectiveness. Through tipping the balance between the abilities of encoding and decoding, i.e., making the decoding network be much more complex than the encoding network, the semantic segmentation ability will be reinforced. To remedy the research weakness in combing self-attention and reconstruction-bias modules for building extraction, this paper presents a U-Net architecture that combines self-attention and reconstruction-bias modules. In the encoding part, a self-attention module is added to learn the attention weights of the inputs. Through the self-attention module, the network will pay more attention to positions where there may be salient regions. In the decoding part, multiple large convolutional up-sampling operations are used for increasing the reconstruction ability. We test our model on two open available datasets: the WHU and Massachusetts Building datasets. We achieve IoU scores of 89.39% and 73.49% for the WHU and Massachusetts Building datasets, respectively. Compared with several recently famous semantic segmentation methods and representative building extraction methods, our method\u2019s results are satisfactory.","167":"We present a large-scale study of gender bias in occupation classification, a task where the use of machine learning may lead to negative outcomes on peoples' lives. We analyze the potential allocation harms that can result from semantic representation bias. To do so, we study the impact on occupation classification of including explicit gender indicators---such as first names and pronouns---in different semantic representations of online biographies. Additionally, we quantify the bias that remains when these indicators are \"scrubbed,\" and describe proxy behavior that occurs in the absence of explicit gender indicators. As we demonstrate, differences in true positive rates between genders are correlated with existing gender imbalances in occupations, which may compound these imbalances.","168":"We present a novel framework for building pragmatic artificial agents with explicit and trainable semantic representations, using the Rational Speech Act model. We train our agents on supervised and unsupervised communication games and compare their behavior to literal agents lacking pragmatic abilities. For both types of games pragmatic but not literal agents evolve a mutual exclusivity bias. This provides a computational pragmatic account of mutual exclusivity and points out a possible direction for solving the mutual exclusivity bias challenge posed by Gandhi and Lake (2019). We find that pragmatic reasoning can cause the bias either by promoting lexical constraints during learning, or by affecting online inference. In addition we show that pragmatic abilities lead to faster learning and that this advantage is even stronger when meanings to be communicated follow a more natural distribution as described by Zipf\u2019s law.","169":"We present GraPPa, an effective pre-training approach for table semantic parsing that learns a compositional inductive bias in the joint representations of textual and tabular data. We construct synthetic question-SQL pairs over high-quality tables via a synchronous context-free grammar (SCFG) induced from existing text-to-SQL datasets. We pre-train our model on the synthetic data using a novel text-schema linking objective that predicts the syntactic role of a table field in the SQL for each question-SQL pair. To maintain the model's ability to represent real-world data, we also include masked language modeling (MLM) over several existing table-and-language datasets to regularize the pre-training process. On four popular fully supervised and weakly supervised table semantic parsing benchmarks, GraPPa significantly outperforms RoBERTa-large as the feature representation layers and establishes new state-of-the-art results on all of them.","170":"Semantic-preserving hashing establishes efficient multimedia retrieval by transferring knowledge from original data to hash codes so that the latter can preserve the underlying visual and semantic similarities. However, it becomes a crucial bottleneck: how to effectively bridge the trilateral domain gaps (i.e., the visual, semantic, and hashing spaces) to further improve the retrieval accuracy. In this article, we propose an inductive structure consistent hashing (ISCH) method, which can interactively coordinate the semantic correlations between the visual feature space, the binary class space, and the discrete hashing space. Specifically, an inductive semantic space is formulated by a simple multilayer stacking class-encoder, which transforms the naive class information into flexible semantic embeddings. Meanwhile, we design a semantic dictionary learning model to facilitate the bilateral visual-semantic bridging and guide the class-encoder toward reliable semantics, which could well alleviate the visual-semantic bias problem. In particular, the visual descriptors and respective semantic class representations are regularized with a coinciding alignment module. In order to generate privileged hash codes, we further explore semantic and prototype binary code learning to jointly quantify the semantic and latent visual representations into unified discrete hash codes. Moreover, an efficient optimization algorithm is developed to address the resulting discrete programming problem. Comprehensive experiments conducted on four large-scale data sets, i.e., CIFAR-10, NUSWIDE, ImageNet, and MSCOCO, demonstrate the superiority of our method over the state-of-the-art alternatives against different evaluation protocols.","171":"We present a new framework for semantic segmentation without annotations via clustering. Off-the-shelf clustering methods are limited to curated, single-label, and objectcentric images yet real-world data are dominantly uncurated, multi-label, and scene-centric. We extend clustering from images to pixels and assign separate cluster membership to different instances within each image. However, solely relying on pixel-wise feature similarity fails to learn high-level semantic concepts and overfits to lowlevel visual cues. We propose a method to incorporate geometric consistency as an inductive bias to learn invariance and equivariance for photometric and geometric variations. With our novel learning objective, our framework can learn high-level semantic concepts. Our method, PiCIE (Pixel-level feature Clustering using Invariance and Equivariance), is the first method capable of segmenting both things and stuff categories without any hyperparameter tuning or task-specific pre-processing. Our method largely outperforms existing baselines on COCO [31] and Cityscapes [8] with +17.5 Acc. and +4.5 mIoU. We show that PiCIE gives a better initialization for standard supervised training. The code is available at https:\/\/github.com\/janghyuncho\/PiCIE.","172":"While self-training has advanced semi-supervised semantic segmentation, it severely suffers from the long-tailed class distribution on real-world semantic segmentation datasets that make the pseudo-labeled data bias toward majority classes. In this paper, we present a simple and yet effective Distribution Alignment and Random Sampling (DARS) method to produce unbiased pseudo labels that match the true class distribution estimated from the labeled data. Besides, we also contribute a progressive data augmentation and labeling strategy to facilitate model training with pseudo-labeled data. Experiments on both Cityscapes and PASCAL VOC 2012 datasets demonstrate the effectiveness of our approach. Albeit simple, our method performs favorably in comparison with stateof-the-art approaches. Code will be available at https:\/\/github.com\/CVMI-Lab\/DARS.","173":"Despite the initial belief that Convolutional Neural Networks (CNNs) are driven by shapes to perform visual recognition tasks, recent evidence suggests that texture bias in CNNs provides higher performing models when learning on large labeled training datasets. This contrasts with the perceptual bias in the human visual cortex, which has a stronger preference towards shape components. Perceptual differences may explain why CNNs achieve human-level performance when large labeled datasets are available, but their performance significantly degrades in low-labeled data scenarios, such as few-shot semantic segmentation. To remove the texture bias in the context of few-shot learning, we propose a novel architecture that integrates a set of Difference of Gaussians (DoG) to attenuate high-frequency local components in the feature space. This produces a set of modified feature maps, whose high-frequency components are diminished at different standard deviation values of the Gaussian distribution in the spatial domain. As this results in multiple feature maps for a single image, we employ a bi-directional convolutional long-short-term-memory to efficiently merge the multi scale-space representations. We perform extensive experiments on three well-known few-shot segmentation benchmarks \u2013Pascal i5, COCO-20i and FSS-1000\u2013 and demonstrate that our method outperforms state-of-the-art approaches in two datasets under the same conditions.","174":"We present a causal inference framework to improve Weakly-Supervised Semantic Segmentation (WSSS). Specifically, we aim to generate better pixel-level pseudo-masks by using only image-level labels -- the most crucial step in WSSS. We attribute the cause of the ambiguous boundaries of pseudo-masks to the confounding context, e.g., the correct image-level classification of \"horse\" and \"person\" may be not only due to the recognition of each instance, but also their co-occurrence context, making the model inspection (e.g., CAM) hard to distinguish between the boundaries. Inspired by this, we propose a structural causal model to analyze the causalities among images, contexts, and class labels. Based on it, we develop a new method: Context Adjustment (CONTA), to remove the confounding bias in image-level classification and thus provide better pseudo-masks as ground-truth for the subsequent segmentation model. On PASCAL VOC 2012 and MS-COCO, we show that CONTA boosts various popular WSSS methods to new state-of-the-arts.","175":"Current large-scale language models can be politically bi- ased as a result of the data they are trained on, potentially causing serious problems when they are deployed in real- world settings. In this paper, we describe metrics for measuring political bias in GPT-2 generation and propose a re- inforcement learning (RL) framework for mitigating political biases in generated text. By using rewards from word em- beddings or a classi\ufb01er, our RL framework guides debiased generation without having access to the training data or re- quiring the model to be retrained. In empirical experiments on three attributes sensitive to political bias ( gender , loca- tion , and topic ), our methods reduced bias according to both our metrics and human evaluation, while maintaining read- ability and semantic coherence.","176":null,"177":"Generalized zero-shot learning aims to recognize images from seen and unseen domains. Recent methods focus on learning a unified semantic-aligned visual representation to transfer knowledge between two domains, while ignoring the effect of semantic-free visual representation in alleviating the biased recognition problem. In this paper, we propose a novel Domain-aware Visual Bias Eliminating (DVBE) network that constructs two complementary visual representations, i.e., semantic-free and semantic-aligned, to treat seen and unseen domains separately. Specifically, we explore cross-attentive second-order visual statistics to compact the semantic-free representation, and design an adaptive margin Softmax to maximize inter-class divergences. Thus, the semantic-free representation becomes discriminative enough to not only predict seen class accurately but also filter out unseen images, i.e., domain detection, based on the predicted class entropy. For unseen images, we automatically search an optimal semantic-visual alignment architecture, rather than manual designs, to predict unseen classes. With accurate domain detection, the biased recognition problem towards the seen domain is significantly reduced. Experiments on five benchmarks for classification and segmentation show that DVBE outperforms existing methods by averaged 5.7% improvement.","178":"Domain adaptation (DA) paves the way for label annotation and dataset bias issues by the knowledge transfer from a label-rich source domain to a related but unlabeled target domain. A mainstream of DA methods is to align the feature distributions of the two domains. However, the majority of them focus on the entire image features where irrelevant semantic information, e.g., the messy background, is inevitably embedded. Enforcing feature alignments in such case will negatively influence the correct matching of objects and consequently lead to the semantically negative transfer due to the confusion of irrelevant semantics. To tackle this issue, we propose Semantic Concentration for Domain Adaptation (SCDA), which encourages the model to concentrate on the most principal features via the pair-wise adversarial alignment of prediction distributions. Specifically, we train the classifier to class-wisely maximize the prediction distribution divergence of each sample pair, which enables the model to find the region with large differences among the same class of samples. Meanwhile, the feature extractor attempts to minimize that discrepancy, which suppresses the features of dissimilar regions among the same class of samples and accentuates the features of principal parts. As a general method, SCDA can be easily integrated into various DA methods as a regularizer to further boost their performance. Extensive experiments on the cross-domain benchmarks show the efficacy of SCDA.","179":"Multilingual representations embed words from many languages into a single semantic space such that words with similar meanings are close to each other regardless of the language. These embeddings have been widely used in various settings, such as cross-lingual transfer, where a natural language processing (NLP) model trained on one language is deployed to another language. While the cross-lingual transfer techniques are powerful, they carry gender bias from the source to target languages. In this paper, we study gender bias in multilingual embeddings and how it affects transfer learning for NLP applications. We create a multilingual dataset for bias analysis and propose several ways for quantifying bias in multilingual representations from both the intrinsic and extrinsic perspectives. Experimental results show that the magnitude of bias in the multilingual representations changes differently when we align the embeddings to different target spaces and that the alignment direction can also have an influence on the bias in transfer learning. We further provide recommendations for using the multilingual word representations for downstream tasks.","180":"Machine learning models are trained to find patterns in data. NLP models can inadvertently learn socially undesirable patterns when training on gender biased text. In this work, we propose a general framework that decomposes gender bias in text along several pragmatic and semantic dimensions: bias from the gender of the person being spoken about, bias from the gender of the person being spoken to, and bias from the gender of the speaker. Using this fine-grained framework, we automatically annotate eight large scale datasets with gender information. In addition, we collect a novel, crowdsourced evaluation benchmark of utterance-level gender rewrites. Distinguishing between gender bias along multiple dimensions is important, as it enables us to train finer-grained gender bias classifiers. We show our classifiers prove valuable for a variety of important applications, such as controlling for gender bias in generative models, detecting gender bias in arbitrary text, and shed light on offensive language in terms of genderedness.","181":null,"182":"Framing is a process of emphasizing a certain aspect of an issue over the others, nudging readers or listeners towards different positions on the issue even without making a biased argument. Here, we propose FrameAxis, a method for characterizing documents by identifying the most relevant semantic axes (\u201cmicroframes\u201d) that are overrepresented in the text using word embedding. Our unsupervised approach can be readily applied to large datasets because it does not require manual annotations. It can also provide nuanced insights by considering a rich set of semantic axes. FrameAxis is designed to quantitatively tease out two important dimensions of how microframes are used in the text. Microframe bias captures how biased the text is on a certain microframe, and microframe intensity shows how prominently a certain microframe is used. Together, they offer a detailed characterization of the text. We demonstrate that microframes with the highest bias and intensity align well with sentiment, topic, and partisan spectrum by applying FrameAxis to multiple datasets from restaurant reviews to political news. The existing domain knowledge can be incorporated into FrameAxis by using custom microframes and by using FrameAxis as an iterative exploratory analysis instrument. Additionally, we propose methods for explaining the results of FrameAxis at the level of individual words and documents. Our method may accelerate scalable and sophisticated computational analyses of framing across disciplines.","183":"Word embeddings derived from human-generated corpora inherit strong gender bias which can be further amplified by downstream models. Some commonly adopted debiasing approaches, including the seminal Hard Debias algorithm, apply post-processing procedures that project pre-trained word embeddings into a subspace orthogonal to an inferred gender subspace. We discover that semantic-agnostic corpus regularities such as word frequency captured by the word embeddings negatively impact the performance of these algorithms. We propose a simple but effective technique, Double Hard Debias, which purifies the word embeddings against such corpus regularities prior to inferring and removing the gender subspace. Experiments on three bias mitigation benchmarks show that our approach preserves the distributional semantics of the pre-trained word embeddings while reducing gender bias to a significantly larger degree than prior approaches.","184":"The goal of Event Argument Extraction (EAE) is to find the role of each entity mention for a given event trigger word. It has been shown in the previous works that the syntactic structures of the sentences are helpful for the deep learning models for EAE. However, a major problem in such prior works is that they fail to exploit the semantic structures of the sentences to induce effective representations for EAE. Consequently, in this work, we propose a novel model for EAE that exploits both syntactic and semantic structures of the sentences with the Graph Transformer Networks (GTNs) to learn more effective sentence structures for EAE. In addition, we introduce a novel inductive bias based on information bottleneck to improve generalization of the EAE models. Extensive experiments are performed to demonstrate the benefits of the proposed model, leading to state-of-the-art performance for EAE on standard datasets.","185":null,"186":"The label-free nature of unsupervised cross-modal hashing hinders models from exploiting the exact semantic data similarity. Existing research typically simulates the semantics by a heuristic geometric prior in the original feature space. However, this introduces heavy bias into the model as the original features are not fully representing the underlying multi-view data relations. To address the problem above, in this paper, we propose a novel unsupervised hashing method called Semantic-Rebased Cross-modal Hashing (SRCH). A novel \u2018Set-andRebase\u2019 process is defined to initialize and update the cross-modal similarity graph of training data. In particular, we set the graph according to the intramodal feature geometric basis and then alternately rebase it to update the edges within according to the hashing results. We develop an alternating optimization routine to rebase the graph and train the hashing auto-encoders with closed-form solutions so that the overall framework is efficiently trained. Our experimental results on benchmarked datasets demonstrate the superiority of our model against state-of-the-art algorithms.","187":"Work on bias in hate speech typically aims to improve classification performance while relatively overlooking the quality of the data. We examine selection bias in hate speech in a language and label independent fashion. We first use topic models to discover latent semantics in eleven hate speech corpora, then, we present two bias evaluation metrics based on the semantic similarity between topics and search words frequently used to build corpora. We discuss the possibility of revising the data collection process by comparing datasets and analyzing contrastive case studies.","188":null,"189":"Semantic segmentation aims to obtain a detailed understanding of images. Deep learning has achieved great advances in semantic segmentation over the past years. In practice, however, the classes do not always correspond to the ones in the training stage. Since it is impractical to collect sufficient labeled data for all classes, zero-shot semantic segmentation has received increasing attentions recently. Although semantic segmentation neural networks can transfer knowledge from seen classes to unseen classes by incorporating the class-level semantic information, it shows a strong bias towards seen classes. In this letter, we propose an easy-to-implement transductive approach to alleviate the prediction bias in zero-shot semantic segmentation. We assume that both source images with full pixel-level labels and unlabeled target images are available for training. The source images are used to build the relationship between visual images and class-level semantic embeddings. On the other hand, the target images are used to alleviate the bias towards seen classes. Comprehensive experiments over the PASCAL dataset clearly demonstrate the effectiveness of our approach.","190":"Word vector representations are well developed tools for various NLP and Machine Learning tasks and are known to retain significant semantic and syntactic structure of languages. But they are prone to carrying and amplifying bias which can perpetrate discrimination in various applications. In this work, we explore new simple ways to detect the most stereotypically gendered words in an embedding and remove the bias from them. We verify how names are masked carriers of gender bias and then use that as a tool to attenuate bias in embeddings. Further, we extend this property of names to show how names can be used to detect other types of bias in the embeddings such as bias based on race, ethnicity, and age.","191":"Media bias can strongly impact the public perception of topics reported in the news. A difficult to detect, yet powerful form of slanted news coverage is called bias by word choice and labeling (WCL). WCL bias can occur, for example, when journalists refer to the same semantic concept by using different terms that frame the concept differently and consequently may lead to different assessments by readers, such as the terms \u201cfreedom fighters\u201d and \u201cterrorists,\u201d or \u201cgun rights\u201d and \u201cgun control.\u201d In this research project, I aim to devise methods that identify instances of WCL bias and estimate the frames they induce, e.g., not only is \u201cterrorists\u201d of negative polarity but also ascribes to aggression and fear. To achieve this, I plan to research methods using natural language processing and deep learning while employing models and using analysis concepts from the social sciences, where researchers have studied media bias for decades. The first results indicate the effectiveness of this interdisciplinary research approach. My vision is to devise a system that helps news readers to become aware of the differences in media coverage caused by bias.","192":"Zero-shot learning aims to classify the visual instances from unseen classes in the absence of training examples. This is typically achieved by directly mapping visual features to a semantic embedding space of classes (e.g., attributes or word vectors), where the similarity between the two modalities can be readily measured. However, the semantic space may not be reliable for recognition due to the noisy class embeddings or visual bias problem. In this paper, we propose a novel binary embedding-based zero-shot learning (BZSL) method, which recognizes the visual instances from unseen classes through an intermediate discriminative Hamming space. Specifically, BZSL jointly learns two binary coding functions to encode both visual instances and class embeddings into the Hamming space, which well alleviates the visual-semantic bias problem. As a desiring property, classifying an unseen instance thereby can be efficiently done by retrieving its nearest class codes with minimal Hamming distance. During training, by introducing two auxiliary variables for the coding functions, we formulate an equivalent correlation maximization problem, which admits an analytical solution. The resulting algorithm thus enjoys both highly efficient training and scalable novel class inferring. Extensive experiments on four benchmark datasets, including the full ImageNet Fall 2011 dataset with over 20k unseen classes, demonstrate the superiority of our method on the zero-shot learning task. Particularly, we show that increasing the binary embedding dimension can inevitably improve the recognition accuracy.","193":"Recent research demonstrates that word embeddings, trained on the human-generated corpus, have strong gender biases in embedding spaces, and these biases can result in the discriminative results from the various downstream tasks. Whereas the previous methods project word embeddings into a linear subspace for debiasing, we introduce a Latent Disentanglement method with a siamese auto-encoder structure with an adapted gradient reversal layer. Our structure enables the separation of the semantic latent information and gender latent information of given word into the disjoint latent dimensions. Afterwards, we introduce a Counterfactual Generation to convert the gender information of words, so the original and the modified embeddings can produce a gender-neutralized word embedding after geometric alignment regularization, without loss of semantic information. From the various quantitative and qualitative debiasing experiments, our method shows to be better than existing debiasing methods in debiasing word embeddings. In addition, Our method shows the ability to preserve semantic information during debiasing by minimizing the semantic information losses for extrinsic NLP downstream tasks.","194":"Learning meaningful and compact representations with disentangled semantic aspects is considered to be of key importance in representation learning. Since real-world data is notoriously costly to collect, many recent state-of-the-art disentanglement models have heavily relied on synthetic toy data-sets. In this paper, we propose a novel data-set which consists of over one million images of physical 3D objects with seven factors of variation, such as object color, shape, size and position. In order to be able to control all the factors of variation precisely, we built an experimental platform where the objects are being moved by a robotic arm. In addition, we provide two more datasets which consist of simulations of the experimental setup. These datasets provide for the first time the possibility to systematically investigate how well different disentanglement methods perform on real data in comparison to simulation, and how simulated data can be leveraged to build better representations of the real world. We provide a first experimental study of these questions and our results indicate that learned models transfer poorly, but that model and hyperparameter selection is an effective means of transferring information to the real world.","195":"Multilingual transfer learning can benefit both high- and low-resource languages, but the source of these improvements is not well understood. Cananical Correlation Analysis (CCA) of the internal representations of a pre- trained, multilingual BERT model reveals that the model partitions representations for each language rather than using a common, shared, interlingual space. This effect is magnified at deeper layers, suggesting that the model does not progressively abstract semantic con- tent while disregarding languages. Hierarchical clustering based on the CCA similarity scores between languages reveals a tree structure that mirrors the phylogenetic trees hand- designed by linguists. The subword tokenization employed by BERT provides a stronger bias towards such structure than character- and word-level tokenizations. We release a subset of the XNLI dataset translated into an additional 14 languages at https:\/\/www.github.com\/salesforce\/xnli_extension to assist further research into multilingual representations.","196":"Zero shot learning (ZSL) aims to recognize unseen classes by exploiting semantic relationships between seen and unseen classes. Two major problems faced by ZSL algorithms are the hubness problem and the bias towards the seen classes. Existing ZSL methods focus on only one of these problems in the conventional and generalized ZSL setting. In this work, we propose a novel approach, Semantically Aligned Bias Reducing (SABR) ZSL, which focuses on solving both the problems. It overcomes the hubness problem by learning a latent space that preserves the semantic relationship between the labels while encoding the discriminating information about the classes. Further, we also propose ways to reduce bias of the seen classes through a simple cross-validation process in the inductive setting and a novel weak transfer constraint in the transductive setting. Extensive experiments on three benchmark datasets suggest that the proposed model significantly outperforms existing state-of-the-art algorithms by ~1.5-9% in the conventional ZSL setting and by ~2-14% in the generalized ZSL for both the inductive and transductive settings.","197":null,"198":"Semantic parsing aims to map natural language utterances onto machine interpretable meaning representations, aka programs whose execution against a real-world environment produces a denotation. Weakly-supervised semantic parsers are trained on utterance-denotation pairs treating programs as latent. The task is challenging due to the large search space and spuriousness of programs which may execute to the correct answer but do not generalize to unseen examples. Our goal is to instill an inductive bias in the parser to help it distinguish between spurious and correct programs. We capitalize on the intuition that correct programs would likely respect certain structural constraints were they to be aligned to the question (e.g., program fragments are unlikely to align to overlapping text spans) and propose to model alignments as structured latent variables. In order to make the latent-alignment framework tractable, we decompose the parsing task into (1) predicting a partial \u201cabstract program\u201d and (2) refining it while modeling structured alignments with differential dynamic programming. We obtain state-of-the-art performance on the WikiTableQuestions and WikiSQL datasets. When compared to a standard attention baseline, we observe that the proposed structured-alignment mechanism is highly beneficial.","199":"Recently, there has been a growing interest in developing saliency methods that provide visual explanations of network predictions. Still, the usability of existing methods is limited to image classification models. To overcome this limitation, we extend the existing approaches to generate grid saliencies, which provide spatially coherent visual explanations for (pixel-level) dense prediction networks. As the proposed grid saliency allows to spatially disentangle the object and its context, we specifically explore its potential to produce context explanations for semantic segmentation networks, discovering which context most influences the class predictions inside a target object area. We investigate the effectiveness of grid saliency on a synthetic dataset with an artificially induced bias between objects and their context as well as on the real-world Cityscapes dataset using state-of-the-art segmentation networks. Our results show that grid saliency can be successfully used to provide easily interpretable context explanations and, moreover, can be employed for detecting and localizing contextual biases present in the data.","200":"Bigrams (two-word sequences) hold a special place in semantic composition research since they are the smallest unit formed by composing words. A semantic relatedness dataset that includes bigrams will thus be useful in the development of automatic methods of semantic composition. However, existing relatedness datasets only include pairs of unigrams (single words). Further, existing datasets were created using rating scales and thus suffer from limitations such as in consistent annotations and scale region bias. In this paper, we describe how we created a large, fine-grained, bigram relatedness dataset (BiRD), using a comparative annotation technique called Best\u2013Worst Scaling. Each of BiRD\u2019s 3,345 English term pairs involves at least one bigram. We show that the relatedness scores obtained are highly reliable (split-half reliability r= 0.937). We analyze the data to obtain insights into bigram semantic relatedness. Finally, we present benchmark experiments on using the relatedness dataset as a testbed to evaluate simple unsupervised measures of semantic composition. BiRD is made freely available to foster further research on how meaning can be represented and how meaning can be composed.","201":"Deep reinforcement learning (RL) has been a commonly-used strategy for the abstractive summarization task to address both the exposure bias and non-differentiable task issues. However, the conventional reward Rouge-L simply looks for exact n-grams matches between candidates and annotated references, which inevitably makes the generated sentences repetitive and incoherent. In this paper, instead of Rouge-L, we explore the practicability of utilizing the distributional semantics to measure the matching degrees. With distributional semantics, sentence-level evaluation can be obtained, and semantically-correct phrases can also be generated without being limited to the surface form of the reference sentences. Human judgments on Gigaword and CNN\/Daily Mail datasets show that our proposed distributional semantics reward (DSR) has distinct superiority in capturing the lexical and compositional diversity of natural language.","202":null,"203":null,"204":"Multidimensional genetic programming represents candidate solutions as sets of programs, and thereby provides an interesting framework for exploiting building block identification. Towards this goal, we investigate the use of machine learning as a way to bias which components of programs are promoted, and propose two semantic operators to choose where useful building blocks are placed during crossover. A forward stagewise crossover operator we propose leads to significant improvements on a set of regression problems, and produces state-of-the-art results in a large benchmark study. We discuss this architecture and others in terms of their propensity for allowing heuristic search to utilize information during the evolutionary process. Finally, we look at the collinearity and complexity of the data representations that result from these architectures, with a view towards disentangling factors of variation in application.","205":null,"206":"Memory for typical category members is more biased toward category neighbors, relative to atypical members. As in Expt 1, memory for typical category members is more biased toward category neighbors, relative to atypical members. Typically-colored items are more likely to be retrieved closer to category neighbors, relative to atypically-colored items. Atypical items with incorrect item memory were more biased, whereas item memory did not influence bias of typical items. Memory is more precise for items located near other images from the same color \u2018category\u2019. Influence of consistency on precision is not modulatd by item memory. Is memory more precise when the locations of items relate to category membership? Are typical items more biased towards category neighbors than atypical items? The categories in Expt 1 were data-driven. Can we replicate Expt 1 with more validated category membership7-8 and a uniform distribution of encoding locations? Typical items share more features with category neighbors9, and thus may look more similar. Are typical items biased because they are confused with visually similar neighbors? The unique features of items consistent with prior knowledge are often forgotten10. Are typical items more biased because of more efficient\/less precise item encoding?","207":"In high-stakes applications of machine learning models, interpretability methods provide guarantees that models are right for the right reasons. In medical imaging, saliency maps have become the standard tool for determining whether a neural model has learned relevant robust features, rather than artefactual noise. However, saliency maps are limited to local model explanation because they interpret predictions on an image-by-image basis. We propose aggregating saliency globally, using semantic segmentation masks, to provide quantitative measures of model bias across a dataset. To evaluate global saliency methods, we propose two metrics for quantifying the validity of saliency explanations. We apply the global saliency method to skin lesion diagnosis to determine the effect of artefacts, such as ink, on model bias.","208":null,"209":"Vision Transformers (ViT) have been shown to attain highly competitive performance for a wide range of vision applications, such as image classification, object detection and semantic image segmentation. In comparison to convolutional neural networks, the Vision Transformer\u2019s weaker inductive bias is generally found to cause an increased reliance on model regularization or data augmentation (\u201cAugReg\u201d for short) when training on smaller training datasets. We conduct a systematic empirical study in order to better understand the interplay between the amount of training data, AugReg, model size and compute budget. 1 As one result of this study we find that the combination of increased compute and AugReg can yield models with the same performance as models trained on an order of magnitude more training data: we train ViT models of various sizes on the public ImageNet-21k dataset which either match or outperform their counterparts trained on the larger, but not publicly available JFT-300M dataset.","210":"Natural data are often long-tail distributed over semantic classes. Existing recognition methods tend to focus on tail performance gain, often at the expense of head performance loss from increased classifier variance. The low tail performance manifests itself in large inter-class confusion and high classifier variance. We aim to reduce both the bias and the variance of a long-tailed classifier by RoutIng Diverse Experts (RIDE). It has three components: 1) a shared architecture for multiple classifiers (experts); 2) a distribution-aware diversity loss that encourages more diverse decisions for classes with fewer training instances; and 3) an expert routing module that dynamically assigns more ambiguous instances to additional experts. With on-par computational complexity, RIDE significantly outperforms the state-of-the-art methods by 5% to 7% on all the benchmarks including CIFAR100-LT, ImageNet-LT and iNaturalist. RIDE is also a universal framework that can be applied to different backbone networks and integrated into various long-tailed algorithms and training mechanisms for consistent performance gains.","211":"We propose a simple data augmentation protocol aimed at providing a compositional inductive bias in conditional and unconditional sequence models. Under this protocol, synthetic training examples are constructed by taking real training examples and replacing (possibly discontinuous) fragments with other fragments that appear in at least one similar environment. The protocol is model-agnostic and useful for a variety of tasks. Applied to neural sequence-to-sequence models, it reduces error rate by as much as 87% on diagnostic tasks from the SCAN dataset and 16% on a semantic parsing task. Applied to n-gram language models, it reduces perplexity by roughly 1% on small corpora in several languages.","212":"An increasing number of natural language processing papers address the effect of bias on predictions, introducing mitigation techniques at different parts of the standard NLP pipeline (data and models). However, these works have been conducted individually, without a unifying framework to organize efforts within the field. This situation leads to repetitive approaches, and focuses overly on bias symptoms\/effects, rather than on their origins, which could limit the development of effective countermeasures. In this paper, we propose a unifying predictive bias framework for NLP. We summarize the NLP literature and suggest general mathematical definitions of predictive bias. We differentiate two consequences of bias: outcome disparities and error disparities, as well as four potential origins of biases: label bias, selection bias, model overamplification, and semantic bias. Our framework serves as an overview of predictive bias in NLP, integrating existing work into a single structure, and providing a conceptual baseline for improved frameworks.","213":"Existing CoSOD datasets often have a serious data bias, assuming that each group of images contains salient objects of similar visual appearances. This bias can lead to the ideal settings and effectiveness of models trained on existing datasets, being impaired in real-life situations, where similarities are usually semantic or conceptual. To tackle this issue, we first introduce a new benchmark, called CoSOD3k in the wild, which requires a large amount of semantic context, making it more challenging than existing CoSOD datasets. Our CoSOD3k consists of 3,316 high-quality, elaborately selected images divided into 160 groups with hierarchical annotations. The images span a wide range of categories, shapes, object sizes, and backgrounds. Second, we integrate the existing SOD techniques to build a unified, trainable CoSOD framework, which is long overdue in this field. Specifically, we propose a novel CoEG-Net that augments our prior model EGNet with a co-attention projection strategy to enable fast common information learning. CoEG-Net fully leverages previous large-scale SOD datasets and significantly improves the model scalability and stability. Third, we comprehensively summarize 34 cutting-edge algorithms, benchmarking 16 of them over three challenging CoSOD datasets, and reporting group-level performance analysis. Finally, we discuss the challenges and future works of CoSOD.","214":"To alleviate sparsity and cold start problem of collaborative filtering based recommender systems, researchers and engineers usually collect attributes of users and items, and design delicate algorithms to exploit these additional information. In general, the attributes are not isolated but connected with each other, which forms a knowledge graph (KG). In this paper, we propose Knowledge Graph Convolutional Networks (KGCN), an end-to-end framework that captures inter-item relatedness effectively by mining their associated attributes on the KG. To automatically discover both high-order structure information and semantic information of the KG, we sample from the neighbors for each entity in the KG as their receptive field, then combine neighborhood information with bias when calculating the representation of a given entity. The receptive field can be extended to multiple hops away to model high-order proximity information and capture users' potential long-distance interests. Moreover, we implement the proposed KGCN in a minibatch fashion, which enables our model to operate on large datasets and KGs. We apply the proposed model to three datasets about movie, book, and music recommendation, and experiment results demonstrate that our approach outperforms strong recommender baselines.","215":"Self-supervised learning is showing great promise for monocular depth estimation, using geometry as the only source of supervision. Depth networks are indeed capable of learning representations that relate visual appearance to 3D properties by implicitly leveraging category-level patterns. In this work we investigate how to leverage more directly this semantic structure to guide geometric representation learning, while remaining in the self-supervised regime. Instead of using semantic labels and proxy losses in a multi-task approach, we propose a new architecture leveraging fixed pretrained semantic segmentation networks to guide self-supervised representation learning via pixel-adaptive convolutions. Furthermore, we propose a two-stage training process to overcome a common semantic bias on dynamic objects via resampling. Our method improves upon the state of the art for self-supervised monocular depth prediction over all pixels, fine-grained details, and per semantic categories.","216":"Detecting out-of-distribution (OOD) data is crucial for robust machine learning systems. Normalizing flows are flexible deep generative models that often surprisingly fail to distinguish between in- and out-of-distribution data: a flow trained on pictures of clothing assigns higher likelihood to handwritten digits. We investigate why normalizing flows perform poorly for OOD detection. We demonstrate that flows learn local pixel correlations and generic image-to-latent-space transformations which are not specific to the target image dataset. We show that by modifying the architecture of flow coupling layers we can bias the flow towards learning the semantic structure of the target data, improving OOD detection. Our investigation reveals that properties that enable flows to generate high-fidelity images can have a detrimental effect on OOD detection.","217":"We address the problem of fine-grained generalized zero-shot recognition of visually similar classes without training images for some classes. We propose a dense attribute-based attention mechanism that for each attribute focuses on the most relevant image regions, obtaining attribute-based features. Instead of aligning a global feature vector of an image with its associated class semantic vector, we propose an attribute embedding technique that aligns each attribute-based feature with its attribute semantic vector. Hence, we compute a vector of attribute scores, for the presence of each attribute in an image, whose similarity with the true class semantic vector is maximized. Moreover, we adjust each attribute score using an attention mechanism over attributes to better capture the discriminative power of different attributes. To tackle the challenge of bias towards seen classes during testing, we propose a new self-calibration loss that adjusts the probability of unseen classes to account for the training bias. We conduct experiments on three popular datasets of CUB, SUN and AWA2 as well as the large-scale DeepFashion dataset, showing that our model significantly improves the state of the art.","218":"In this work, we present an unsupervised domain adaptation (UDA) method, named Panoptic Domain Adaptive Mask R-CNN (PDAM), for unsupervised instance segmentation in microscopy images. Since there currently lack methods particularly for UDA instance segmentation, we first design a Domain Adaptive Mask R-CNN (DAM) as the baseline, with cross-domain feature alignment at the image and instance levels. In addition to the image- and instance-level domain discrepancy, there also exists domain bias at the semantic level in the contextual information. Next, we, therefore, design a semantic segmentation branch with a domain discriminator to bridge the domain gap at the contextual level. By integrating the semantic- and instance-level feature adaptation, our method aligns the cross-domain features at the panoptic level. Third, we propose a task re-weighting mechanism to assign trade-off weights for the detection and segmentation loss functions. The task re-weighting mechanism solves the domain bias issue by alleviating the task learning for some iterations when the features contain source-specific factors. Furthermore, we design a feature similarity maximization mechanism to facilitate instance-level feature adaptation from the perspective of representational learning. Different from the typical feature alignment methods, our feature similarity maximization mechanism separates the domain-invariant and domain-specific features by enlarging their feature distribution dependency. Experimental results on three UDA instance segmentation scenarios with five datasets demonstrate the effectiveness of our proposed PDAM method, which outperforms state-of-the-art UDA methods by a large margin.","219":"Generalized zero-shot learning (GZSL) has achieved significant progress, with many efforts dedicated to over-coming the problems of visual-semantic domain gap and seen-unseen bias. However, most existing methods directly use feature extraction models trained on ImageNet alone, ignoring the cross-dataset bias between ImageNet and GZSL benchmarks. Such a bias inevitably results in poor-quality visual features for GZSL tasks, which potentially limits the recognition performance on both seen and unseen classes. In this paper, we propose a simple yet effective GZSL method, termed feature refinement for generalized zero-shot learning (FREE), to tackle the above problem. FREE employs a feature refinement (FR) module that in-corporates semantic\u2192visual mapping into a unified generative model to refine the visual features of seen and unseen class samples. Furthermore, we propose a self-adaptive margin center loss (SAMC-loss) that cooperates with a semantic cycle-consistency loss to guide FR to learn class- and semantically-relevant representations, and concatenate the features in FR to extract the fully refined features. Extensive experiments on five benchmark datasets demonstrate the significant performance gain of FREE over its baseline and current state-of-the-art methods. The code is available at https:\/\/github.com\/shiming-chen\/FREE.","220":"Video Visual Relation Detection (VidVRD) aims to semantically describe the dynamic interactions across visual concepts localized in a video in the form of subject, predicate, object. It can help to mitigate the semantic gap between vision and language in video understanding, thus receiving increasing attention in multimedia communities. Existing efforts primarily leverage the multimodal\/spatio-temporal feature fusion to augment the representation of object trajectories as well as their interactions and formulate the prediction of predicates as a multi-class classification task. Despite their effectiveness, existing models ignore the severe long-tailed bias in VidVRD datasets. As a result, the models' prediction will be easily biased towards the popular head predicates (e.g., next-to and in-front-of), thus leading to poor generalizability. To fill the research gap, this paper proposes an Interventional Video Relation Detection (IVRD) approach that aims to improve not only the accuracy but also the robustness of the model prediction. Specifically, to better model the high-level visual predicate, our IVRD consists of two key components: 1) we first learn a set of predicate prototypes, where each prototype vector describes a set of relation references with the same predicate; and 2) we apply a causality-inspired intervention on the model input subject, object, which forces the model to fairly incorporate each possible predicate prototype into consideration. We expect the model to focus more on the visual content of the dynamic interaction between subject and object, rather than the spurious correlations between the model input and predicate labels. Extensive experiments on two popular benchmark datasets show the effectiveness of IVRD and also its advantages in reducing the bad long-tailed bias.","221":"Language representations are known to carry stereotypical biases and, as a result, lead to biased predictions in downstream tasks. While existing methods are effective at mitigating biases by linear projection, such methods are too aggressive: they not only remove bias, but also erase valuable information from word embeddings. We develop new measures for evaluating specific information retention that demonstrate the tradeoff between bias removal and information retention. To address this challenge, we propose OSCaR (Orthogonal Subspace Correction and Rectification), a bias-mitigating method that focuses on disentangling biased associations between concepts instead of removing concepts wholesale. Our experiments on gender biases show that OSCaR is a well-balanced approach that ensures that semantic information is retained in the embeddings and bias is also effectively mitigated.","222":"Multi-view data can represent objects from different perspectives and thus provide complementary information for data analysis. A topic of great importance in multi-view learning is to locate a low-dimensional latent subspace, where common semantic features are shared by multiple data sets. However, most existing methods ignore uncorrelated items (i.e., view-specific features) and may cause semantic bias during the process of common feature learning. In this article, we propose a non-negative correlated and uncorrelated feature co-learning (CoUFC) method to address this concern. More specifically, view-specific (uncorrelated) features are identified for each view when learning the common (correlated) feature across views in the latent semantic subspace. By eliminating the effects of uncorrelated information, useful inter-view feature correlations can be captured. We design a new objective function in CoUFC and derive an optimization approach to solve the objective with the analysis on its convergence. Experiments on real-world sensor, image, and text data sets demonstrate that the proposed method outperforms the state-of-the-art multiview learning methods.","223":"Pretrained text encoders, such as BERT, have been applied increasingly in various natural language processing (NLP) tasks, and have recently demonstrated significant performance gains. However, recent studies have demonstrated the existence of social bias in these pretrained NLP models. Although prior works have made progress on word-level debiasing, improved sentence-level fairness of pretrained encoders still lacks exploration. In this paper, we proposed the first neural debiasing method for a pretrained sentence encoder, which transforms the pretrained encoder outputs into debiased representations via a fair filter (FairFil) network. To learn the FairFil, we introduce a contrastive learning framework that not only minimizes the correlation between filtered embeddings and bias words but also preserves rich semantic information of the original sentences. On real-world datasets, our FairFil effectively reduces the bias degree of pretrained text encoders, while continuously showing desirable performance on downstream tasks. Moreover, our post hoc method does not require any retraining of the text encoders, further enlarging FairFil\u2019s application space.","224":"Zero-shot learning (ZSL) is a challenging task due to the lack of unseen class data during training. Existing works attempt to establish a mapping between the visual and class spaces through a common intermediate semantic space. The main limitation of existing methods is the strong bias towards seen class, known as the domain shift problem, which leads to unsatisfactory performance in both conventional and generalized ZSL tasks. To tackle this challenge, we propose to convert ZSL to the conventional supervised learning by generating features for unseen classes. To this end, a joint generative model that couples variational autoencoder (VAE) and generative adversarial network (GAN), called Zero-VAE-GAN, is proposed to generate high-quality unseen features. To enhance the class-level discriminability, an adversarial categorization network is incorporated into the joint framework. Besides, we propose two self-training strategies to augment unlabeled unseen features for the transductive extension of our model, addressing the domain shift problem to a large extent. Experimental results on five standard benchmarks and a large-scale dataset demonstrate the superiority of our generative model over the state-of-the-art methods for conventional, especially generalized ZSL tasks. Moreover, the further improvement of the transductive setting demonstrates the effectiveness of the proposed self-training strategies.","225":null,"226":"Co-salient object detection (CoSOD) is a newly emerging and rapidly growing branch of salient object detection (SOD), which aims to detect the co-occurring salient objects in multiple images. However, existing CoSOD datasets often have a serious data bias, which assumes that each group of images contains salient objects of similar visual appearances. This bias results in the ideal settings and the effectiveness of the models, trained on existing datasets, may be impaired in real-life situations, where the similarity is usually semantic or conceptual. To tackle this issue, we first collect a new high-quality dataset, named CoSOD3k, which contains 3,316 images divided into 160 groups with multiple level annotations, i.e., category, bounding box, object, and instance levels. CoSOD3k makes a significant leap in terms of diversity, difficulty and scalability, benefiting related vision tasks. Besides, we comprehensively summarize 34 cutting-edge algorithms, benchmarking 19 of them over four existing CoSOD datasets (MSRC, iCoSeg, Image Pair and CoSal2015) and our CoSOD3k with a total of \u223c61K images (largest scale), and reporting group-level performance analysis. Finally, we discuss the challenge and future work of CoSOD. Our study would give a strong boost to growth in the CoSOD community. Benchmark toolbox and results are available on our project page.","227":"We present a deep learning strategy that enables, for the first time, contrast-agnostic semantic segmentation of completely unpreprocessed brain MRI scans, without requiring additional training or fine-tuning for new modalities. Classical Bayesian methods address this segmentation problem with unsupervised intensity models, but require significant computational resources. In contrast, learning-based methods can be fast at test time, but are sensitive to the data available at training. Our proposed learning method, SynthSeg, leverages a set of training segmentations (no intensity images required) to generate synthetic sample images of widely varying contrasts on the fly during training. These samples are produced using the generative model of the classical Bayesian segmentation framework, with randomly sampled parameters for appearance, deformation, noise, and bias field. Because each mini-batch has a different synthetic contrast, the final network is not biased towards any MRI contrast. We comprehensively evaluate our approach on four datasets comprising over 1,000 subjects and four types of MR contrast. The results show that our approach successfully segments every contrast in the data, performing slightly better than classical Bayesian segmentation, and three orders of magnitude faster. Moreover, even within the same type of MRI contrast, our strategy generalizes significantly better across datasets, compared to training using real images. Finally, we find that synthesizing a broad range of contrasts, even if unrealistic, increases the generalization of the neural network. Our code and model are open source at this https URL.","228":null,"229":"Multimodal summarization with multimodal output (MSMO) is to generate a multimodal summary for a multimodal news report, which has been proven to effectively improve users' satisfaction. The existing MSMO methods are trained by the target of text modality, leading to the modality-bias problem that ignores the quality of model-selected image during training. To alleviate this problem, we propose a multimodal objective function with the guidance of multimodal reference to use the loss from the summary generation and the image selection. Due to the lack of multimodal reference data, we present two strategies, i.e., ROUGE-ranking and Order-ranking, to construct the multimodal reference by extending the text reference. Meanwhile, to better evaluate multimodal outputs, we propose a novel evaluation metric based on joint multimodal representation, projecting the model output and multimodal reference into a joint semantic space during evaluation. Experimental results have shown that our proposed model achieves the new state-of-the-art on both automatic and manual evaluation metrics. Besides, our proposed evaluation method can effectively improve the correlation with human judgments.","230":"Semantically controlled neural response generation on limited-domain has achieved great performance. However, moving towards multi-domain large-scale scenarios is shown to be difficult because the possible combinations of semantic inputs grow exponentially with the number of domains. To alleviate such scalability issue, we exploit the structure of dialog acts to build a multi-layer hierarchical graph, where each act is represented as a root-to-leaf route on the graph. Then, we incorporate such graph structure prior as an inductive bias to build a hierarchical disentangled self-attention network, where we disentangle attention heads to model designated nodes on the dialog act graph. By activating different (disentangled) heads at each layer, combinatorially many dialog act semantics can be modeled to control the neural response generation. On the largescale Multi-Domain-WOZ dataset, our algorithm can yield an improvement of over 5.0 BLEU score, and in human evaluation, it also significantly outperforms other baselines over various metrics including consistency, etc.","231":"The key to personalized search is to clarify the meaning of current query based on user's search history. Previous personalized studies tried to build user profiles on the basis of historical data to tailor the ranking. However, we argue that the user profile based methods do not really disambiguate the current query. They still retain some semantic bias when building user profiles. In this paper, we propose to encode history with context-aware representation learning to enhance the representation of current query, which is a direct way to clarify the user's information need. Specifically, endowed with the benefit from transformer on aggregating contextual information, we devise a query disambiguation model to parse the meaning of current query in multiple stages. Moreover, for covering the cases that current query is not sufficient to express the intent, we train a personalized language model to predict user intent from existing queries. Under the interaction of two sub-models, we can generate the context-aware representation of current query and re-rank the results based on it. Experimental results show the significant improvement of our model compared with previous methods.","232":"Generalized zero-shot learning (GZSL) is a challenging task that aims to recognize not only unseen classes unavailable during training, but also seen classes used at training stage. It is achieved by transferring knowledge from seen classes to unseen classes via a shared semantic space (e.g. attribute space). Most existing GZSL methods usually learn a cross-modal mapping between the visual feature space and the semantic space. However, the mapping model learned only from the seen classes will produce an inherent bias when used in the unseen classes. In order to tackle such a problem, this paper integrates a deep embedding network (DE) and a modified variational autoencoder (VAE) into a novel model (DE-VAE) to learn a latent space shared by both image features and class embeddings. Specifically, the proposed model firstly employs DE to learn the mapping from the semantic space to the visual feature space, and then utilizes VAE to transform both original visual features and the features obtained by the mapping into latent features. Finally, the latent features are used to train a softmax classifier. Extensive experiments on four GZSL benchmark datasets show that the proposed model significantly outperforms the state of the arts.","233":"Abstract Word embeddings are the standard model for semantic and syntactic representations of words. Unfortunately, these models have been shown to exhibit undesirable word associations resulting from gender, racial, and religious biases. Existing post-processing methods for debiasing word embeddings are unable to mitigate gender bias hidden in the spatial arrangement of word vectors. In this paper, we propose RAN-Debias, a novel gender debiasing methodology that not only eliminates the bias present in a word vector but also alters the spatial distribution of its neighboring vectors, achieving a bias-free setting while maintaining minimal semantic offset. We also propose a new bias evaluation metric, Gender-based Illicit Proximity Estimate (GIPE), which measures the extent of undue proximity in word vectors resulting from the presence of gender-based predilections. Experiments based on a suite of evaluation metrics show that RAN-Debias significantly outperforms the state-of-the-art in reducing proximity bias (GIPE) by at least 42.02%. It also reduces direct bias, adding minimal semantic disturbance, and achieves the best performance in a downstream application task (coreference resolution).","234":"To date, the most successful word, word sense, and concept modelling techniques have used large corpora and knowledge resources to produce dense vector representations that capture semantic similarities in a relatively low-dimensional space. Most current approaches, however, suffer from a monolingual bias, with their strength depending on the amount of data available across languages. In this paper we address this issue and propose Conception, a novel technique for building language-independent vector representations of concepts which places multilinguality at its core while retaining explicit relationships between concepts. Our approach results in high-coverage representations that outperform the state of the art in multilingual and cross-lingual Semantic Word Similarity and Word Sense Disambiguation, proving particularly robust on low-resource languages. Conception \u2013 its software and the complete set of representations \u2013 is available at https:\/\/github.com\/SapienzaNLP\/conception.","235":"Open set domain adaptation aims to diminish the domain shift across domains, with partially shared classes. There exist unknown target samples out of the knowledge of source domain. Compared to the close set setting, how to separate the unknown (unshared) class from the known (shared) ones plays the key role. Whereas, previous methods did not emphasize the semantic structure of the open set data, which may introduce bias into the domain alignment and confuse the classifier around the decision boundary. In this paper, we exploit the semantic structure of open set data from two aspects: 1) Semantic Categorical Alignment, which aims to achieve good separability of target known classes by categorically aligning the centroid of target with the source. 2) Semantic Contrastive Mapping, which aims to push the unknown class away from the decision boundary. Empirically, we demonstrate that our method performs favourably against the state-of-the-art methods on representative benchmarks, e.g. Digits and Office-31 datasets.","236":"Word-embedding is a major machine learning technique for computational applications of languages. For a given corpus, the process of word-embedding is to embed each word onto multi-dimensional space such that semantic similarities between similar words are retained. While learning the similarity as encapsulated in the training corpus, the embedding process inadvertently captures many other inherent features present in the corpus. One such thing is the bias arising out of stereotyping present in almost all the corpus no matter how extensively used and trusted they are. We study this aspect of word-embedding in the context of Hindi language. We show that many gender-neutral words in Hindi are mapped to vectors which are inclined towards one gender or the other in multi-dimensional space. We propose a new algorithm of debiasing and demonstrate its efficacy in the context of Hindi language. Further, we build a SVM-based classifier that determines whether a gender-neutral word is classified as neutral or otherwise. We corroborate our claim with experimental results on large number of individual words. This work is first ever result on debiasing in Hindi Language and our new debiasing algorithm can be applicable in the context of any language.","237":"It is known that, without awareness of the process, our brain appears to focus on the general shape of objects rather than superficial statistics of context. On the other hand, learning autonomously allows discovering invariant regularities which help generalization. In this work, we propose a learning framework to improve the shape bias property of self-supervised methods. Our method learns semantic and shape biased representations by integrating domain diversification and jigsaw puzzles. The first module enables the model to create a dynamic environment across arbitrary domains and provides a domain exploration vs. exploitation trade-off, while the second module allows the model to explore this environment autonomously. This universal framework does not require prior knowledge of the domain of interest. Extensive experiments are conducted on several domain generalization datasets, namely, PACS, Office-Home, VLCS, and Digits. We show that our framework outperforms state-of-the-art domain generalization methods by a large margin.","238":null,"239":"Zero-Shot Learning (ZSL) seeks to recognize a sample from either seen or unseen domain by projecting the image data and semantic labels into a joint embedding space. However, most existing methods directly adapt a well-trained projection from one domain to another, thereby ignoring the serious bias problem caused by domain differences. To address this issue, we propose a novel Domain-Specific Embedding Network (DSEN) that can apply specific projections to different domains for unbiased embedding, as well as several domain constraints. In contrast to previous methods, the DSEN decomposes the domain-shared projection function into one domain-invariant and two domain-specific sub-functions to explore the similarities and differences between two domains. To prevent the two specific projections from breaking the semantic relationship, a semantic reconstruction constraint is proposed by applying the same decoder function to them in a cycle consistency way. Furthermore, a domain division constraint is developed to directly penalize the margin between real and pseudo image features in respective seen and unseen domains, which can enlarge the inter-domain difference of visual features. Extensive experiments on four public benchmarks demonstrate the effectiveness of DSEN with an average of $9.2%$ improvement in terms of harmonic mean. The code is available in \\urlhttps:\/\/github.com\/mboboGO\/DSEN-for-GZSL.","240":"Diachronic word embeddings play a key role in capturing interesting patterns about how language evolves over time. Most of the existing work focuses on studying corpora spanning across several decades, which is understandably still not a possibility when working on social media-based user-generated content. In this work, we address the problem of studying semantic changes in a large Twitter corpus collected over five years, a much shorter period than what is usually the norm in diachronic studies. We devise a novel attentional model, based on Bernoulli word embeddings, that are conditioned on contextual extra-linguistic (social) features such as network, spatial and socio-economic variables, which are associated with Twitter users, as well as topic-based features. We posit that these social features provide an inductive bias that helps our model to overcome the narrow time-span regime problem. Our extensive experiments reveal that our proposed model is able to capture subtle semantic shifts without being biased towards frequency cues and also works well when certain contextual features are absent. Our model fits the data better than current state-of-the-art dynamic word embedding models and therefore is a promising tool to study diachronic semantic changes over small time periods.","241":"Sequence-to-sequence models excel at handling natural language variation, but have been shown to struggle with out-of-distribution compositional generalization. This has motivated new specialized architectures with stronger compositional biases, but most of these approaches have only been evaluated on synthetically-generated datasets, which are not representative of natural language variation. In this work we ask: can we develop a semantic parsing approach that handles both natural language variation and compositional generalization? To better assess this capability, we propose new train and test splits of non-synthetic datasets. We demonstrate that strong existing approaches do not perform well across a broad set of evaluations. We also propose NQG-T5, a hybrid model that combines a high-precision grammar-based approach with a pre-trained sequence-to-sequence model. It outperforms existing approaches across several compositional generalization challenges on non-synthetic data, while also being competitive with the state-of-the-art on standard evaluations. While still far from solving this problem, our study highlights the importance of diverse evaluations and the open challenge of handling both compositional generalization and natural language variation in semantic parsing.","242":null,"243":"We address the problem of generalized zero-shot semantic segmentation (GZS3) predicting pixel-wise semantic labels for seen and unseen classes. Most GZS3 methods adopt a generative approach that synthesizes visual features of unseen classes from corresponding semantic ones (e.g., word2vec) to train novel classifiers for both seen and unseen classes. Although generative methods show decent performance, they have two limitations: (1) the visual features are biased towards seen classes; (2) the classifier should be retrained whenever novel unseen classes appear. We propose a discriminative approach to address these limitations in a unified framework. To this end, we leverage visual and semantic encoders to learn a joint embedding space, where the semantic encoder transforms semantic features to semantic prototypes that act as centers for visual features of corresponding classes. Specifically, we introduce boundary-aware regression (BAR) and semantic consistency (SC) losses to learn discriminative features. Our approach to exploiting the joint embedding space, together with BAR and SC terms, alleviates the seen bias problem. At test time, we avoid the retraining process by exploiting semantic prototypes as a nearest-neighbor (NN) classifier. To further alleviate the bias problem, we also propose an inference technique, dubbed Apollonius calibration (AC), that modulates the decision boundary of the NN classifier to the Apollonius circle adaptively. Experimental results demonstrate the effectiveness of our framework, achieving a new state of the art on standard benchmarks.","244":"Despite their effectiveness in a wide range of tasks, deep architectures suffer from some important limitations. In particular, they are vulnerable to catastrophic forgetting, i.e. they perform poorly when they are required to update their model as new classes are available but the original training set is not retained. This paper addresses this problem in the context of semantic segmentation. Current strategies fail on this task because they do not consider a peculiar aspect of semantic segmentation: since each training step provides annotation only for a subset of all possible classes, pixels of the background class (i.e. pixels that do not belong to any other classes) exhibit a semantic distribution shift. In this work we revisit classical incremental learning methods, proposing a new distillation-based framework which explicitly accounts for this shift. Furthermore, we introduce a novel strategy to initialize classifier's parameters, thus preventing biased predictions toward the background class. We demonstrate the effectiveness of our approach with an extensive evaluation on the Pascal-VOC 2012 and ADE20K datasets, significantly outperforming state of the art incremental learning methods.","245":null,"246":null,"247":"Image Segmentation has been an active field of research as it has a wide range of applications, ranging from automated disease detection to self driving cars. In the past five years, various papers came up with different objective loss functions used in different cases such as biased data, sparse segmentation, etc. In this paper, we have summarized some of the well-known loss functions widely used for Image Segmentation and listed out the cases where their usage can help in fast and better convergence of a model. Furthermore, we have also introduced a new log-cosh dice loss function and compared its performance on NBFS skull-segmentation open source data-set with widely used loss functions. We also showcased that certain loss functions perform well across all data-sets and can be taken as a good baseline choice in unknown data distribution scenarios.","248":"Advances in language modeling architectures and the availability of large text corpora have driven progress in automatic text generation. While this results in models capable of generating coherent texts, it also prompts models to internalize social biases present in the training corpus. This paper aims to quantify and reduce a particular type of bias exhibited by language models: bias in the sentiment of generated text. Given a conditioning context (e.g., a writing prompt) and a language model, we analyze if (and how) the sentiment of the generated text is affected by changes in values of sensitive attributes (e.g., country names, occupations, genders) in the conditioning context using a form of counterfactual evaluation. We quantify sentiment bias by adopting individual and group fairness metrics from the fair machine learning literature, and demonstrate that large-scale models trained on two different corpora (news articles, and Wikipedia) exhibit considerable levels of bias. We then propose embedding and sentiment prediction-derived regularization on the language model\u2019s latent representations. The regularizations improve fairness metrics while retaining comparable levels of perplexity and semantic similarity.","249":null,"250":"In this paper, we tackle the unsupervised domain adaptation (UDA) for semantic segmentation, which aims to segment the unlabeled real data using labeled synthetic data. The main problem of UDA for semantic segmentation relies on reducing the domain gap between the real image and synthetic image. To solve this problem, we focused on separating information in an image into content and style. Here, only the content has cues for semantic segmentation, and the style makes the domain gap. Thus, precise separation of content and style in an image leads to effect as supervision of real data even when learning with synthetic data. To make the best of this effect, we propose a zero-style loss. Even though we perfectly extract content for semantic segmentation in the real domain, another main challenge, the class imbalance problem, still exists in UDA for semantic segmentation. We address this problem by transferring the contents of tail classes from synthetic to real domain. Experimental results show that the proposed method achieves the state-of-the-art performance in semantic segmentation on the major two UDA settings. Introduction Semantic segmentation is a task of classifying each pixel of an image into semantic categories (e.g., sky, road, traffic sign, etc.). Training the segmentation model (Chen et al. 2017) requires large amounts of pixel-level annotated data, but pixelwise image labeling is extremely laborintensive and time-consuming. To reduce the labeling cost, the model learned with automatically labeled synthetic datasets (Richter et al. 2016; Ros et al. 2016) can be used in real-world environments (Cordts et al. 2016). In this case, the domain gap between synthetic data and real data causes the model to behave poorly in real-world environments, so unsupervised domain adaptation (UDA) methods have been proposed to solve this problem (Chang et al. 2019; Du et al. 2019; Lin et al. 2017; Luo et al. 2019). UDA for semantic segmentation aims to train a segmentation model that performs on the real domain by using unlabeled real images and labeled synthetic images. Since the supervision of semantic information comes only from synthetic data, reducing the domain gap between the real image *Corresponding author Copyright \u00a9 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. and synthetic image is a major problem. That is, if we completely adapt the real and synthetic domains, learning with synthetic data would be the same as learning with real data. We address this problem by forcing networks to extract content and style from an image separately. An image includes content and style (Gatys, Ecker, and Bethge 2016; Isola et al. 2017). The content has cues for semantic segmentation regardless of style. The style is a cue to represent a characteristic for a domain of an image regardless of content. The style makes a domain gap, so separating style from content further enhances the alignment between the two domains in the content space. However, separating content and style in an image is challenging because we cannot directly supervise what content or style is. In this paper, we introduce zero-style loss to capture content and style separately. To do this, we set one content encoder and two style encoders. By learning with our proposed zero-style loss, the content encoder and style encoders can capture domaininvariant content feature and domain-specific style features, respectively. With the UDA for semantic segmentation, we can provide a large number of additional labeled synthetic images for training. However, this method overlooks a serious problem. In the urban scene dataset, the number of samples per class is not equally distributed. Head classes (e.g., road, sky) exist in most of the data, but tail classes (e.g., traffic sign, bicycle) are rarely shown. The model learned with the class-imbalanced dataset would be biased toward head classes (Cui et al. 2019). To further boost the performance on the target (real) domain, the self-training strategy has recently been applied to the UDA methods (Li, Yuan, and Vasconcelos 2019; French, Mackiewicz, and Fisher 2018). This strategy generates the target pseudo labels using the segmentation model, which is trained with labeled source (synthetic) data. The class imbalance problem is further accelerated when using this selftraining technique. Since the segmentation model is already biased toward the head classes, we cannot expect the correct generation of pseudo labels for the tail classes. Thus, selftraining makes networks to be further biased toward head classes. To solve this problem, we propose the tail-class content transfer. Since we trained our model to separate the content and style from an image, our model can extract the content The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)","251":"Implicit bias is the unconscious attribution of particular qualities (or lack thereof) to a member from a particular social group (e.g., defined by gender or race). Studies on implicit bias have shown that these unconscious stereotypes can have adverse outcomes in various social contexts, such as job screening, teaching, or policing. Recently, [34] considered a mathematical model for implicit bias and showed the effectiveness of the Rooney Rule as a constraint to improve the utility of the outcome for certain cases of the subset selection problem. Here we study the problem of designing interventions for the generalization of subset selection - ranking - that requires to output an ordered set and is a central primitive in various social and computational contexts. We present a family of simple and interpretable constraints and show that they can optimally mitigate implicit bias for a generalization of the model studied in [34]. Subsequently, we prove that under natural distributional assumptions on the utilities of items, simple, Rooney Rule-like, constraints can also surprisingly recover almost all the utility lost due to implicit biases. Finally, we augment our theoretical results with empirical findings on real-world distributions from the IIT-JEE (2009) dataset and the Semantic Scholar Research corpus.","252":null,"253":"Media coverage possesses a substantial effect on the public perception of events. The way media frames events can significantly alter the beliefs and perceptions of our society. Nevertheless, nearly all media outlets are known to report news in a biased way. While such bias can be introduced by altering the word choice or omitting information, the perception of bias also varies largely depending on a reader's personal background. Therefore, media bias is a very complex construct to identify and analyze. Even though media bias has been the subject of many studies, previous assessment strategies are oversimplified, lack overlap and empirical evaluation. Thus, this study aims to develop a scale that can be used as a reliable standard to evaluate article bias. To name an example: Intending to measure bias in a news article, should we ask, \u201cHow biased is the article?\u201d or should we instead ask, \u201cHow did the article treat the American president?\u201d. We conducted a literature search to find 824 relevant questions about text perception in previous research on the topic. In a multi-iterative process, we summarized and condensed these questions semantically to conclude a complete and representative set of possible question types about bias. The final set consisted of 25 questions with varying answering formats, 17 questions using semantic differentials, and six ratings of feelings. We tested each of the questions on 190 articles with overall 663 participants to identify how well the questions measure an article's perceived bias. Our results show that 21 final items are suitable and reliable for measuring the perception of media bias. We publish the final set of questions on http:\/\/bias-guestion-tree.gipplab.org\/.","254":"In this paper, we present an evaluation of four encoder\u2013decoder CNNs in the segmentation of the prostate gland in T2W magnetic resonance imaging (MRI) image. The four selected CNNs are FCN, SegNet, U-Net, and DeepLabV3+, which was originally proposed for the segmentation of road scene, biomedical, and natural images. Segmentation of prostate in T2W MRI images is an important step in the automatic diagnosis of prostate cancer to enable better lesion detection and staging of prostate cancer. Therefore, many research efforts have been conducted to improve the segmentation of the prostate gland in MRI images. The main challenges of prostate gland segmentation are blurry prostate boundary and variability in prostate anatomical structure. In this work, we investigated the performance of encoder\u2013decoder CNNs for segmentation of prostate gland in T2W MRI. Image pre-processing techniques including image resizing, center-cropping and intensity normalization are applied to address the issues of inter-patient and inter-scanner variability as well as the issue of dominating background pixels over prostate pixels. In addition, to enrich the network with more data, to increase data variation, and to improve its accuracy, patch extraction and data augmentation are applied prior to training the networks. Furthermore, class weight balancing is used to avoid having biased networks since the number of background pixels is much higher than the prostate pixels. The class imbalance problem is solved by utilizing weighted cross-entropy loss function during the training of the CNN model. The performance of the CNNs is evaluated in terms of the Dice similarity coefficient (DSC) and our experimental results show that patch-wise DeepLabV3+ gives the best performance with DSC equal to 92.8%. This value is the highest DSC score compared to the FCN, SegNet, and U-Net that also competed the recently published state-of-the-art method of prostate segmentation.","255":"Vision-and-Language Navigation (VLN) requires an agent to follow natural-language instructions, explore the given environments, and reach the desired target locations. These step-by-step navigational instructions are crucial when the agent is navigating new environments about which it has no prior knowledge. Most recent works that study VLN observe a significant performance drop when tested on unseen environments (i.e., environments not used in training), indicating that the neural agent models are highly biased towards training environments. Although this issue is considered as one of the major challenges in VLN research, it is still under-studied and needs a clearer explanation. In this work, we design novel diagnosis experiments via environment re-splitting and feature replacement, looking into possible reasons for this environment bias. We observe that neither the language nor the underlying navigational graph, but the low-level visual appearance conveyed by ResNet features directly affects the agent model and contributes to this environment bias in results. According to this observation, we explore several kinds of semantic representations that contain less low-level visual information, hence the agent learned with these features could be better generalized to unseen testing environments. Without modifying the baseline agent model and its training method, our explored semantic features significantly decrease the performance gaps between seen and unseen on multiple datasets (i.e. R2R, R4R, and CVDN) and achieve competitive unseen results to previous state-of-the-art models. Our code and features are available at: this https URL","256":"Deep neural networks for semantic segmentation always require a large number of samples with pixel-level labels, which becomes the major difficulty in their real-world applications. To reduce the labeling cost, unsupervised domain adaptation (UDA) approaches are proposed to transfer knowledge from labeled synthesized datasets to unlabeled real-world datasets. Recently, some semi-supervised learning methods have been applied to UDA and achieved state-of-the-art performance. One of the most popular approaches in semi-supervised learning is the entropy minimization method. However, when applying the entropy minimization to UDA for semantic segmentation, the gradient of the entropy is biased towards samples that are easy to transfer. To balance the gradient of well-classified target samples, we propose the maximum squares loss. Our maximum squares loss prevents the training process being dominated by easy-to-transfer samples in the target domain. Besides, we introduce the image-wise weighting ratio to alleviate the class imbalance in the unlabeled target domain. Both synthetic-to-real and cross-city adaptation experiments demonstrate the effectiveness of our proposed approach. The code is released at https:\/\/github. com\/ZJULearning\/MaxSquareLoss.","257":"We introduce a data-free quantization method for deep neural networks that does not require fine-tuning or hyperparameter selection. It achieves near-original model performance on common computer vision architectures and tasks. 8-bit fixed-point quantization is essential for efficient inference on modern deep learning hardware. However, quantizing models to run in 8-bit is a non-trivial task, frequently leading to either significant performance reduction or engineering time spent on training a network to be amenable to quantization. Our approach relies on equalizing the weight ranges in the network by making use of a scale-equivariance property of activation functions. In addition the method corrects biases in the error that are introduced during quantization. This improves quantization accuracy performance, and can be applied to many common computer vision architectures with a straight forward API call. For common architectures, such as the MobileNet family, we achieve state-of-the-art quantized model performance. We further show that the method also extends to other computer vision architectures and tasks such as semantic segmentation and object detection.","258":"State-of-the-art models of lexical semantic change detection suffer from noise stemming from vector space alignment. We have empirically tested the Temporal Referencing method for lexical semantic change and show that, by avoiding alignment, it is less affected by this noise. We show that, trained on a diachronic corpus, the skip-gram with negative sampling architecture with temporal referencing outperforms alignment models on a synthetic task as well as a manual testset. We introduce a principled way to simulate lexical semantic change and systematically control for possible biases.","259":"Extracting graph representation of visual scenes in image is a challenging task in computer vision. Although there has been encouraging progress of scene graph generation in the past decade, we surprisingly find that the performance of existing approaches is largely limited by the strong biases, which mainly stem from (1) unconsciously assuming relations with certain semantic properties such as symmetric and (2) imbalanced annotations over different relations. To alleviate the negative effects of these biases, we proposed a new and simple architecture named Rich and Fair semantic extraction network (RiFa for short), to not only capture rich semantic properties of the relations, but also fairly predict relations with different scale of annotations. Using pseudo-siamese networks, RiFa embeds the subject and object respectively to distinguish their semantic differences and meanwhile preserve their underlying semantic properties. Then, it further predicts subject-object relations based on both the visual and semantic features of entities under certain contextual area, and fairly ranks the relation predictions for those with a few annotations. Experiments on the popular Visual Genome dataset show that RiFa achieves state-of-the-art performance under several challenging settings of scene graph task. Especially, it performs significantly better on capturing different semantic properties of relations, and obtains the best overall per relation performance.","260":null,"261":"Small unmanned aerial systems (UAS) have emerged as high-throughput platforms for the collection of high-resolution image data over large crop fields to support precision agriculture and plant breeding research. At the same time, the improved efficiency in image capture is leading to massive datasets, which pose analysis challenges in providing needed phenotypic data. To complement these high-throughput platforms, there is an increasing need in crop improvement to develop robust image analysis methods to analyze large amount of image data. Analysis approaches based on deep learning models are currently the most promising and show unparalleled performance in analyzing large image datasets. This study developed and applied an image analysis approach based on a SegNet deep learning semantic segmentation model to estimate sorghum panicles counts, which are critical phenotypic data in sorghum crop improvement, from UAS images over selected sorghum experimental plots. The SegNet model was trained to semantically segment UAS images into sorghum panicles, foliage and the exposed ground using 462, 250 \u00d7 250 labeled images, which was then applied to field orthomosaic to generate a field-level semantic segmentation. Individual panicle locations were obtained after post-processing the segmentation output to remove small objects and split merged panicles. A comparison between model panicle count estimates and manually digitized panicle locations in 60 randomly selected plots showed an overall detection accuracy of 94%. A per-plot panicle count comparison also showed high agreement between estimated and reference panicle counts (Spearman correlation \u03c1 = 0.88, mean bias = 0.65). Misclassifications of panicles during the semantic segmentation step and mosaicking errors in the field orthomosaic contributed mainly to panicle detection errors. Overall, the approach based on deep learning semantic segmentation showed good promise and with a larger labeled dataset and extensive hyper-parameter tuning, should provide even more robust and effective characterization of sorghum panicle counts.","262":"Humans divide their attention among multiple visual targets in daily life, and visual search gets more difficult as the number of targets increases. The biased competition hypothesis (BC) has been put forth as an explanation for this phenomenon. BC suggests that brain responses during divided attention are a weighted linear combination of the responses during search for each target individually. Furthermore, this combination is biased by the intrinsic selectivity of cortical regions. Yet, it is unknown whether attentional modulations of semantic representations of cluttered and dynamic natural scenes are consistent with this hypothesis. Here, we investigated whether BC accounts for semantic representation during natural category-based visual search. Human subjects viewed natural movies, and their whole-brain BOLD responses were recorded while they attended to \u201chumans\u201d, \u201cvehicles\u201d (i.e. single-target attention tasks), or \u201cboth humans and vehicles\u201d (i.e. divided attention) in separate runs. We computed a voxelwise linearity index to assess whether semantic representation during divided attention can be modeled as a weighted combination of representations during the two single-target attention tasks. We then examined the bias in weights of this linear combination across cortical ROIs. We find that semantic representations during divided attention are linear to a substantial degree, and that they are biased toward the preferred target in category-selective areas across ventral temporal cortex. Taken together, these results suggest that the biased competition hypothesis is a compelling account for attentional modulations of semantic representation across cortex. Significance Statement Natural vision is a complex task that involves splitting attention between multiple search targets. According to the biased competition hypothesis (BC), limited representational capacity of the cortex inevitably leads to a competition among representation of these targets and the competition is biased by intrinsic selectivity of cortical areas. Here we examined BC for semantic representation of hundreds of object and action categories in natural movies. We observed that: 1) semantic representation during simultaneous attention to two object categories is a weighted linear combination of representations during attention to each of them alone, and 2) the linear combination is biased toward semantic representation of the preferred object category in strongly category-selective areas. These findings suggest BC as a compelling account for attentional modulations of semantic representation across cortex in natural vision.","263":"Designed to learn long-range interactions on sequential data, transformers continue to show state-of-the-art results on a wide variety of tasks. In contrast to CNNs, they contain no inductive bias that prioritizes local interactions. This makes them expressive, but also computationally infeasible for long sequences, such as high-resolution images. We demonstrate how combining the effectiveness of the inductive bias of CNNs with the expressivity of transformers enables them to model and thereby synthesize high-resolution images. We show how to (i) use CNNs to learn a context-rich vocabulary of image constituents, and in turn (ii) utilize transformers to efficiently model their composition within high-resolution images. Our approach is readily applied to conditional synthesis tasks, where both non-spatial information, such as object classes, and spatial information, such as segmentations, can control the generated image. In particular, we present the first results on semantically-guided synthesis of megapixel images with transformers. Project page at https:\/\/git.io\/JLlvY.","264":"The \u201cRoaring 20s\u201d of visual recognition began with the introduction of Vision Transformers (ViTs), which quickly superseded ConvNets as the state-of-the-art image classification model. A vanilla ViT, on the other hand, faces difficulties when applied to general computer vision tasks such as object detection and semantic segmentation. It is the hierarchical Transformers (e.g., Swin Transformers) that reintroduced several ConvNet priors, making Transformers practically viable as a generic vision backbone and demonstrating remarkable performance on a wide variety of vision tasks. However, the effectiveness of such hybrid approaches is still largely credited to the intrinsic superiority of Transformers, rather than the inherent inductive biases of convolutions. In this work, we reexamine the design spaces and test the limits of what a pure ConvNet can achieve. We gradually \u201cmodernize\u201d a standard ResNet toward the design of a vision Transformer, and discover several key components that contribute to the performance difference along the way. The outcome of this exploration is a family of pure ConvNet models dubbed ConvNeXt. Constructed entirely from standard ConvNet modules, ConvNeXts compete favorably with Transformers in terms of accuracy and scalability, achieving 87.8% ImageNet top-1 accuracy and outperforming Swin Transformers on COCO detection and ADE20K segmentation, while maintaining the simplicity and efficiency of standard ConvNets. Code: https:\/\/github.com\/facebookresearch\/ConvNeXt","265":"Vision transformers (ViT) have demonstrated impressive performance across numerous machine vision tasks. These models are based on multi-head self-attention mechanisms that can flexibly attend to a sequence of image patches to encode contextual cues. An important question is how such flexibility (in attending image-wide context conditioned on a given patch) can facilitate handling nuisances in natural images e.g., severe occlusions, domain shifts, spatial permutations, adversarial and natural perturbations. We systematically study this question via an extensive set of experiments encompassing three ViT families and provide comparisons with a high-performing convolutional neural network (CNN). We show and analyze the following intriguing properties of ViT: (a) Transformers are highly robust to severe occlusions, perturbations and domain shifts, e.g., retain as high as 60% top-1 accuracy on ImageNet even after randomly occluding 80% of the image content. (b) The robustness towards occlusions is not due to texture bias, instead we show that ViTs are significantly less biased towards local textures, compared to CNNs. When properly trained to encode shape-based features, ViTs demonstrate shape recognition capability comparable to that of human visual system, previously unmatched in the literature. (c) Using ViTs to encode shape representation leads to an interesting consequence of accurate semantic segmentation without pixel-level supervision. (d) Off-the-shelf features from a single ViT model can be combined to create a feature ensemble, leading to high accuracy rates across a range of classification datasets in both traditional and few-shot learning paradigms. We show effective features of ViTs are due to flexible and dynamic receptive fields possible via self-attention mechanisms. Code: https:\/\/git.io\/Js15X","266":"Graph neural networks (GNNs) have become a popular approach to integrating structural inductive biases into NLP models. However, there has been little work on interpreting them, and specifically on understanding which parts of the graphs (e.g. syntactic trees or co-reference structures) contribute to a prediction. In this work, we introduce a post-hoc method for interpreting the predictions of GNNs which identifies unnecessary edges. Given a trained GNN model, we learn a simple classifier that, for every edge in every layer, predicts if that edge can be dropped. We demonstrate that such a classifier can be trained in a fully differentiable fashion, employing stochastic gates and encouraging sparsity through the expected $L_0$ norm. We use our technique as an attribution method to analyze GNN models for two tasks -- question answering and semantic role labeling -- providing insights into the information flow in these models. We show that we can drop a large proportion of edges without deteriorating the performance of the model, while we can analyse the remaining edges for interpreting model predictions.","267":"Deep neural networks have attained remarkable performance when applied to data that comes from the same distribution as that of the training set, but can significantly degrade otherwise. Therefore, detecting whether an example is out-of-distribution (OoD) is crucial to enable a system that can reject such samples or alert users. Recent works have made significant progress on OoD benchmarks consisting of small image datasets. However, many recent methods based on neural networks rely on training or tuning with both in-distribution and out-of-distribution data. The latter is generally hard to define a-priori, and its selection can easily bias the learning. We base our work on a popular method ODIN, proposing two strategies for freeing it from the needs of tuning with OoD data, while improving its OoD detection performance. We specifically propose to decompose confidence scoring as well as a modified input pre-processing method. We show that both of these significantly help in detection performance. Our further analysis on a larger scale image dataset shows that the two types of distribution shifts, specifically semantic shift and non-semantic shift, present a significant difference in the difficulty of the problem, providing an analysis of when ODIN-like strategies do or do not work.","268":"Several studies have reported the inability of Transformer models to generalize compositionally, a key type of generalization in many NLP tasks such as semantic parsing. In this paper we explore the design space of Transformer models showing that the inductive biases given to the model by several design decisions significantly impact compositional generalization. We identified Transformer configurations that generalize compositionally significantly better than previously reported in the literature in many compositional tasks. We achieve state-of-the-art results in a semantic parsing compositional generalization benchmark (COGS), and a string edit operation composition benchmark (PCFG).","269":"An ongoing project explores the extent to which artificial intelligence (AI), specifically in the areas of natural language processing and semantic reasoning, can be exploited to facilitate the studies of science by deploying software agents equipped with natural language understanding capabilities to read scholarly publications on the web. The knowledge extracted by these AI agents is organized into a heterogeneous graph, called Microsoft Academic Graph (MAG), where the nodes and the edges represent the entities engaging in scholarly communications and the relationships among them, respectively. The frequently updated data set and a few software tools central to the underlying AI components are distributed under an open data license for research and commercial applications. This paper describes the design, schema, and technical and business motivations behind MAG and elaborates how MAG can be used in analytics, search, and recommendation scenarios. How AI plays an important role in avoiding various biases and human induced errors in other data sets and how the technologies can be further improved in the future are also discussed.","270":"Contrasting the previous evidence that neurons in the later layers of a Convolutional Neural Network (CNN) respond to complex object shapes, recent studies have shown that CNNs actually exhibit a \u2018texture bias\u2019: given an image with both texture and shape cues (e.g., a stylized image), a CNN is biased towards predicting the category corresponding to the texture. However, these previous studies conduct experiments on the final classification output of the network, and fail to robustly evaluate the bias contained (i) in the latent representations, and (ii) on a per-pixel level. In this paper, we design a series of experiments that overcome these issues. We do this with the goal of better understanding what type of shape information contained in the network is discriminative, where shape information is encoded, as well as when the network learns about object shape during training. We show that a network learns the majority of overall shape information at the first few epochs of training and that this information is largely encoded in the last few layers of a CNN. Finally, we show that the encoding of shape does not imply the encoding of localized per-pixel semantic information. The experimental results and findings provide a more accurate understanding of the behaviour of current CNNs, thus helping to inform future design choices.","271":"Scene graphs are semantic abstraction of images that encourage visual understanding and reasoning. However, the performance of Scene Graph Generation (SGG) is unsatisfactory when faced with biased data in real-world scenarios. Conventional debiasing research mainly studies from the view of balancing data distribution or learning unbiased models and representations, ignoring the correlations among the biased classes. In this work, we analyze this problem from a novel cognition perspective: automatically building a hierarchical cognitive structure from the biased predictions and navigating that hierarchy to locate the relationships, making the tail relationships receive more attention in a coarse-to-fine mode. To this end, we propose a novel debiasing Cognition Tree (CogTree) loss for unbiased SGG. We first build a cognitive structure CogTree to organize the relationships based on the prediction of a biased SGG model. The CogTree distinguishes remarkably different relationships at first and then focuses on a small portion of easily confused ones. Then, we propose a debiasing loss specially for this cognitive structure, which supports coarse-to-fine distinction for the correct relationships. The loss is model-agnostic and consistently boosting the performance of several state-of-the-art models. The code is available at: https:\/\/github.com\/CYVincent\/Scene-Graph-Transformer-CogTree.","272":"Models of code can learn distributed representations of a program's syntax and semantics to predict many non-trivial properties of a program. Recent state-of-the-art models leverage highly structured representations of programs, such as trees, graphs and paths therein (e.g. data-flow relations), which are precise and abundantly available for code. This provides a strong inductive bias towards semantically meaningful relations, yielding more generalizable representations than classical sequence-based models. Unfortunately, these models primarily rely on graph-based message passing to represent relations in code, which makes them de facto local due to the high cost of message-passing steps, quite in contrast to modern, global sequence-based models, such as the Transformer. In this work, we bridge this divide between global and structured models by introducing two new hybrid model families that are both global and incorporate structural bias: Graph Sandwiches, which wrap traditional (gated) graph message-passing layers in sequential message-passing layers; and Graph Relational Embedding Attention Transformers (GREAT for short), which bias traditional Transformers with relational information from graph edge types. By studying a popular, non-trivial program repair task, variable-misuse identification, we explore the relative merits of traditional and hybrid model families for code representation. Starting with a graph-based model that already improves upon the prior state-of-the-art for this task by 20%, we show that our proposed hybrid models improve an additional 10-15%, while training both faster and using fewer parameters.","273":"Natural question generation (QG) aims to generate questions from a passage and an answer. Previous works on QG either (i) ignore the rich structure information hidden in text, (ii) solely rely on cross-entropy loss that leads to issues like exposure bias and inconsistency between train\/test measurement, or (iii) fail to fully exploit the answer information. To address these limitations, in this paper, we propose a reinforcement learning (RL) based graph-to-sequence (Graph2Seq) model for QG. Our model consists of a Graph2Seq generator with a novel Bidirectional Gated Graph Neural Network based encoder to embed the passage, and a hybrid evaluator with a mixed objective combining both cross-entropy and RL losses to ensure the generation of syntactically and semantically valid text. We also introduce an effective Deep Alignment Network for incorporating the answer information into the passage at both the word and contextual levels. Our model is end-to-end trainable and achieves new state-of-the-art scores, outperforming existing methods by a significant margin on the standard SQuAD benchmark.","274":"Learning-based approaches for semantic segmentation have two inherent challenges. First, acquiring pixel-wise labels is expensive and time-consuming. Second, realistic segmentation datasets are highly unbalanced: some categories are much more abundant than others, biasing the performance to the most represented ones. In this paper, we are interested in focusing human labelling effort on a small subset of a larger pool of data, minimizing this effort while maximizing performance of a segmentation model on a hold-out set. We present a new active learning strategy for semantic segmentation based on deep reinforcement learning (RL). An agent learns a policy to select a subset of small informative image regions -- opposed to entire images -- to be labeled, from a pool of unlabeled data. The region selection decision is made based on predictions and uncertainties of the segmentation model being trained. Our method proposes a new modification of the deep Q-network (DQN) formulation for active learning, adapting it to the large-scale nature of semantic segmentation problems. We test the proof of concept in CamVid and provide results in the large-scale dataset Cityscapes. On Cityscapes, our deep RL region-based DQN approach requires roughly 30% less additional labeled data than our most competitive baseline to reach the same performance. Moreover, we find that our method asks for more labels of under-represented categories compared to the baselines, improving their performance and helping to mitigate class imbalance.","275":"Current pre-training works in natural language generation pay little attention to the problem of exposure bias on downstream tasks. To address this issue, we propose an enhanced multi-flow sequence to sequence pre-training and fine-tuning framework named ERNIE-GEN, which bridges the discrepancy between training and inference with an infilling generation mechanism and a noise-aware generation method. To make generation closer to human writing patterns, this framework introduces a span-by-span generation flow that trains the model to predict semantically-complete spans consecutively rather than predicting word by word. Unlike existing pre-training methods, ERNIE-GEN incorporates multi-granularity target sampling to construct pre-training data, which enhances the correlation between encoder and decoder. Experimental results demonstrate that ERNIE-GEN achieves state-of-the-art results with a much smaller amount of pre-training data and parameters on a range of language generation tasks, including abstractive summarization (Gigaword and CNN\/DailyMail), question generation (SQuAD), dialogue generation (Persona-Chat) and generative question answering (CoQA).","276":"Distributional word vectors have recently been shown to encode many of the human biases, most notably gender and racial biases, and models for attenuating such biases have consequently been proposed. However, existing models and studies (1) operate on under-specified and mutually differing bias definitions, (2) are tailored for a particular bias (e.g., gender bias) and (3) have been evaluated inconsistently and non-rigorously. In this work, we introduce a general framework for debiasing word embeddings. We operationalize the definition of a bias by discerning two types of bias specification: explicit and implicit. We then propose three debiasing models that operate on explicit or implicit bias specifications and that can be composed towards more robust debiasing. Finally, we devise a full-fledged evaluation framework in which we couple existing bias metrics with newly proposed ones. Experimental findings across three embedding methods suggest that the proposed debiasing models are robust and widely applicable: they often completely remove the bias both implicitly and explicitly without degradation of semantic information encoded in any of the input distributional spaces. Moreover, we successfully transfer debiasing models, by means of cross-lingual embedding spaces, and remove or attenuate biases in distributional word vector spaces of languages that lack readily available bias specifications.","277":"Unsupervised domain adaptation (UDA) for nuclei instance segmentation is important for digital pathology, as it alleviates the burden of labor-intensive annotation and domain shift across datasets. In this work, we propose a Cycle Consistency Panoptic Domain Adaptive Mask R-CNN (CyC-PDAM) architecture for unsupervised nuclei segmentation in histopathology images, by learning from fluorescence microscopy images. More specifically, we first propose a nuclei inpainting mechanism to remove the auxiliary generated objects in the synthesized images. Secondly, a semantic branch with a domain discriminator is designed to achieve panoptic-level domain adaptation. Thirdly, in order to avoid the influence of the source-biased features, we propose a task re-weighting mechanism to dynamically add trade-off weights for the task-specific loss functions. Experimental results on three datasets indicate that our proposed method outperforms state-of-the-art UDA methods significantly, and demonstrates a similar performance as fully supervised methods.","278":"Semantic hashing has become a crucial component of fast similarity search in many large-scale information retrieval systems, in particular, for text data. Variational auto-encoders (VAEs) with binary latent variables as hashing codes provide state-of-the-art performance in terms of precision for document retrieval. We propose a pairwise loss function with discrete latent VAE to reward within-class similarity and between-class dissimilarity for supervised hashing. Instead of solving the optimization relying on existing biased gradient estimators, an unbiased low-variance gradient estimator is adopted to optimize the hashing function by evaluating the non-differentiable loss function over two correlated sets of binary hashing codes to control the variance of gradient estimates. This new semantic hashing framework achieves superior performance compared to the state-of-the-arts, as demonstrated by our comprehensive experiments.","279":null,"280":"Recently, a great progress in automatic image captioning has been achieved by using semantic concepts detected from the image. However, we argue that existing concepts-to-caption framework, in which the concept detector is trained using the image-caption pairs to minimize the vocabulary discrepancy, suffers from the deficiency of insufficient concepts. The reasons are two-fold: 1) the extreme imbalance between the number of occurrence positive and negative samples of the concept and 2) the incomplete labeling in training captions caused by the biased annotation and usage of synonyms. In this paper, we propose a method, termed online positive recall and missing concepts mining, to overcome those problems. Our method adaptively re-weights the loss of different samples according to their predictions for online positive recall and uses a two-stage optimization strategy for missing concepts mining. In this way, more semantic concepts can be detected and a high accuracy will be expected. On the caption generation stage, we explore an element-wise selection process to automatically choose the most suitable concepts at each time step. Thus, our method can generate more precise and detailed caption to describe the image. We conduct extensive experiments on the MSCOCO image captioning data set and the MSCOCO online test server, which shows that our method achieves superior image captioning performance compared with other competitive methods.","281":"This paper addresses the task of query-focused video summarization, which takes user queries and long videos as inputs and generates query-focused video summaries. Compared to video summarization, which mainly concentrates on finding the most diverse and representative visual contents as a summary, the task of query-focused video summarization considers the user\u2019s intent and the semantic meaning of generated summary. In this paper, we propose a method, named query-biased self-attentive network (QSAN) to tackle this challenge. Our key idea is to utilize the semantic information from video descriptions to generate a generic summary and then to combine the information from the query to generate a query-focused summary. Specifically, we first propose a hierarchical self-attentive network to model the relative relationship at three levels, which are different frames from a segment, different segments of the same video, textual information of video description and its related visual contents. We train the model on video caption dataset and employ a reinforced caption generator to generate a video description, which can help us locate important frames or shots. Then we build a query-aware scoring module to compute the query-relevant score for each shot and generate the query-focused summary. Extensive experiments on the benchmark dataset demonstrate the competitive performance of our approach compared to some methods.","282":"Few-shot learning (FSL) for action recognition is a challenging task of recognizing novel action categories which are represented by few instances in the training data. In a more generalized FSL setting (G-FSL), both seen as well as novel action categories need to be recognized. Conventional classifiers suffer due to inadequate data in FSL setting and inherent bias towards seen action categories in G-FSL setting. In this paper, we address this problem by proposing a novel ProtoGAN framework which synthesizes additional examples for novel categories by conditioning a conditional generative adversarial network with class prototype vectors. These class prototype vectors are learnt using a Class Prototype Transfer Network (CPTN) from examples of seen categories. Our synthesized examples for a novel class are semantically similar to real examples belonging to that class and is used to train a model exhibiting better generalization towards novel classes. We support our claim by performing extensive experiments on three datasets: UCF101, HMDB51 and Olympic-Sports. To the best of our knowledge, we are the first to report the results for G-FSL and provide a strong benchmark for future research. We also outperform the state-of-the-art method in FSL for all the aforementioned datasets.","283":"Extensive research has recently shown that recurrent neural language models are able to process a wide range of grammatical phenomena. How these models are able to perform these remarkable feats so well, however, is still an open question. To gain more insight into what information LSTMs base their decisions on, we propose a generalisation of Contextual Decomposition (GCD). In particular, this setup enables us to accurately distil which part of a prediction stems from semantic heuristics, which part truly emanates from syntactic cues and which part arise from the model biases themselves instead. We investigate this technique on tasks pertaining to syntactic agreement and co-reference resolution and discover that the model strongly relies on a default reasoning effect to perform these tasks.","284":"The problem of generating a set of diverse paraphrase sentences while (1) not compromising the original meaning of the original sentence, and (2) imposing diversity in various semantic aspects, such as a lexical or syntactic structure, is examined. Existing work on paraphrase generation has focused more on the former, and the latter was trained as a fixed style transfer, such as transferring from positive to negative sentiments, even at the cost of losing semantics. In this work, we consider style transfer as a means of imposing diversity, with a paraphrasing correctness constraint that the target sentence must remain a paraphrase of the original sentence. However, our goal is to maximize the diversity for a set of k generated paraphrases, denoted as the diversified paraphrase (DP) problem. Our key contribution is deciding the style guidance at generation towards the direction of increasing the diversity of output with respect to those generated previously. As pre-materializing training data for all style decisions is impractical, we train with biased data, but with debiasing guidance. Compared to state-of-the-art methods, our proposed model can generate more diverse and yet semantically consistent paraphrase sentences. That is, our model, trained with the MSCOCO dataset, achieves the highest embedding scores, .94\/.95\/.86, similar to state-of-the-art results, but with a lower mBLEU score (more diverse) by 8.73%.","285":"Zero-shot learning (ZSL) for image classification focuses on recognizing novel categories that have no labeled data available for training. The learning is generally carried out with the help of mid-level semantic descriptors associated with each class. This semantic-descriptor space is generally shared by both seen and unseen categories. However, ZSL suffers from hubness, domain discrepancy and biased-ness towards seen classes. To tackle these problems, we propose a three-step approach to zero-shot learning. Firstly, a mapping is learned from the semantic-descriptor space to the image-feature space. This mapping learns to minimize both one-to-one and pairwise distances between semantic embeddings and the image features of the corresponding classes. Secondly, we propose test-time domain adaptation to adapt the semantic embedding of the unseen classes to the test data. This is achieved by finding correspondences between the semantic descriptors and the image features. Thirdly, we propose scaled calibration on the classification scores of the seen classes. This is necessary because the ZSL model is biased towards seen classes as the unseen classes are not used in the training. Finally, to validate the proposed three-step approach, we performed experiments on four benchmark datasets where the proposed method outperformed previous results. We also studied and analyzed the performance of each component of our proposed ZSL framework.","286":"We describe a policy learning approach to map visual inputs to driving controls that leverages side information on semantics and affordances of objects in the scene from a secondary teacher model. While the teacher receives semantic segmentation and stop \"intention\" values as inputs and produces an estimate of the driving controls, the primary student model only receives images as inputs, and attempts to imitate the controls while being biased towards the latent representation of the teacher model. The latent representation encodes task-relevant information in the inputs of the teacher model, which are semantic segmentation of the image, and intention values for driving controls in the presence of objects in the scene such as vehicles, pedestrians and traffic lights. Our student model does not attempt to infer semantic segmentation or intention values from its inputs, nor to mimic the output behavior of the teacher. It instead attempts to capture the representation of the teacher inputs that are relevant for driving. Our training does not require laborious annotations such as maps or objects in three dimensions; even the teacher model just requires two-dimensional segmentation and intention values. Moreover, our model runs in real time of 59 FPS. We test our approach on recent simulated and real-world driving datasets, and introduce a more challenging but realistic evaluation protocol that considers a run that reaches the destination successful only if it does not violate common traffic rules.","287":"There exist biases in individual\u2019s language use; the same word (e.g., cool) is used for expressing different meanings (e.g., temperature range) or different words (e.g., cloudy, hazy) are used for describing the same meaning. In this study, we propose a method of modeling such personal biases in word meanings (hereafter, semantic variations) with personalized word embeddings obtained by solving a task on subjective text while regarding words used by different individuals as different words. To prevent personalized word embeddings from being contaminated by other irrelevant biases, we solve a task of identifying a review-target (objective output) from a given review. To stabilize the training of this extreme multi-class classification, we perform a multi-task learning with metadata identification. Experimental results with reviews retrieved from RateBeer confirmed that the obtained personalized word embeddings improved the accuracy of sentiment analysis as well as the target task. Analysis of the obtained personalized word embeddings revealed trends in semantic variations related to frequent and adjective words.","288":"Self-supervised representation learning approaches have recently surpassed their supervised learning counterparts on downstream tasks like object detection and image classification. Somewhat mysteriously the recent gains in performance come from training instance classification models, treating each image and it's augmented versions as samples of a single class. In this work, we first present quantitative experiments to demystify these gains. We demonstrate that approaches like MOCO and PIRL learn occlusion-invariant representations. However, they fail to capture viewpoint and category instance invariance which are crucial components for object recognition. Second, we demonstrate that these approaches obtain further gains from access to a clean object-centric training dataset like Imagenet. Finally, we propose an approach to leverage unstructured videos to learn representations that possess higher viewpoint invariance. Our results show that the learned representations outperform MOCOv2 trained on the same data in terms of invariances encoded and the performance on downstream image classification and semantic segmentation tasks.","289":"We introduce GQA, a new dataset for real-world visual reasoning and compositional question answering, seeking to address key shortcomings of previous VQA datasets. We have developed a strong and robust question engine that leverages Visual Genome scene graph structures to create 22M diverse reasoning questions, which all come with functional programs that represent their semantics. We use the programs to gain tight control over the answer distribution and present a new tunable smoothing technique to mitigate question biases. Accompanying the dataset is a suite of new metrics that evaluate essential qualities such as consistency, grounding and plausibility. A careful analysis is performed for baselines as well as state-of-the-art models, providing fine-grained results for different question types and topologies. Whereas a blind LSTM obtains a mere 42.1%, and strong VQA models achieve 54.1%, human performance tops at 89.3%, offering ample opportunity for new research to explore. We hope GQA will provide an enabling resource for the next generation of models with enhanced robustness, improved consistency, and deeper semantic understanding of vision and language.","290":"We describe a procedure for explaining neurons in deep representations by identifying compositional logical concepts that closely approximate neuron behavior. Compared to prior work that uses atomic labels as explanations, analyzing neurons compositionally allows us to more precisely and expressively characterize their behavior. We use this procedure to answer several questions on interpretability in models for vision and natural language processing. First, we examine the kinds of abstractions learned by neurons. In image classification, we find that many neurons learn highly abstract but semantically coherent visual concepts, while other polysemantic neurons detect multiple unrelated features; in natural language inference (NLI), neurons learn shallow lexical heuristics from dataset biases. Second, we see whether compositional explanations give us insight into model performance: vision neurons that detect human-interpretable concepts are positively correlated with task performance, while NLI neurons that fire for shallow heuristics are negatively correlated with task performance. Finally, we show how compositional explanations provide an accessible way for end users to produce simple \"copy-paste\" adversarial examples that change model behavior in predictable ways.","291":"We introduce GQA, a new dataset for real-world visual reasoning and compositional question answering, seeking to address key shortcomings of previous VQA datasets. We have developed a strong and robust question engine that leverages scene graph structures to create 22M diverse reasoning questions, all come with functional programs that represent their semantics. We use the programs to gain tight control over the answer distribution and present a new tunable smoothing technique to mitigate language biases. Accompanying the dataset is a suite of new metrics that evaluate essential qualities such as consistency, grounding and plausibility. An extensive analysis is performed for baselines as well as state-of-the-art models, providing fine-grained results for different question types and topologies. Whereas a blind LSTM obtains mere 42.1%, and strong VQA models achieve 54.1%, human performance tops at 89.3\\%, offering ample opportunity for new research to explore. We strongly hope GQA will provide an enabling resource for the next generation of models with enhanced robustness, improved consistency, and deeper semantic understanding for images and language.","292":"Existing visual reasoning datasets such as Visual Question Answering (VQA), often suffer from biases conditioned on the question, image or answer distributions. The recently proposed CLEVR dataset addresses these limitations and requires fine-grained reasoning but the dataset is synthetic and consists of similar objects and sentence structures across the dataset. \nIn this paper, we introduce a new inference task, Visual Entailment (VE) - consisting of image-sentence pairs whereby a premise is defined by an image, rather than a natural language sentence as in traditional Textual Entailment tasks. The goal of a trained VE model is to predict whether the image semantically entails the text. To realize this task, we build a dataset SNLI-VE based on the Stanford Natural Language Inference corpus and Flickr30k dataset. We evaluate various existing VQA baselines and build a model called Explainable Visual Entailment (EVE) system to address the VE task. EVE achieves up to 71% accuracy and outperforms several other state-of-the-art VQA based models. Finally, we demonstrate the explainability of EVE through cross-modal attention visualizations. The SNLI-VE dataset is publicly available at this https URL necla-ml\/SNLI-VE.","293":"Image distortion is a main challenge for tasks on panoramas. In this work, we propose a Distortion-Aware Monocular Omnidirectional (DAMO) network to estimate dense depth maps from indoor panoramas. First, we introduce a distortion-aware module to extract semantic features from omnidirectional images. Specifically, we exploit deformable convolution to adjust its sampling grids to geometric distortions on panoramas. We also utilize a strip pooling module to sample against horizontal distortion introduced by inverse gnomonic projection. Second, we introduce a plug-and-play spherical-aware weight matrix for our loss function to handle the uneven distribution of areas projected from a sphere. Experiments on the 360D dataset show that the proposed method can effectively extract semantic features from distorted panoramas and alleviate the supervision bias caused by distortion. It achieves the state-of-the-art performance on the 360D dataset with high efficiency.","294":null,"295":"Automatic road extraction from remote sensing images plays an important role for navigation, intelligent transportation, and road network update, etc. Convolutional neural network (CNN)-based methods have presented many achievements for road extraction from remote sensing images. CNN-based methods require a large dataset with high quality labels for model training. However, there is still few standard and large dataset, which is specially designed for road extraction from optical remote sensing images. Besides, the existing end-to-end CNN models for road extraction from remote sensing images are usually with symmetric structure, studying on asymmetric structure between encoding and decoding is rare. To address the above problems, this article first provides a publicly available dataset LRSNY for road extraction from optical remote sensing images with manually labelled labels. Second, we propose a reconstruction bias U-Net for road extraction from remote sensing images. In our model, we increase the decoding branches to obtain multiple semantic information from different upsamplings. Experimental results show that our method achieves better performance compared with other six state-of-the-art segmentation models when testing on our LRSNY dataset. We also test on Massachusetts and Shaoshan datasets. The good performances on the two datasets further prove the effectiveness of our method.","296":"This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval (BR) and natural language inference (NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin, e.g. 10% improvement upon baseline models on cross-lingual semantic search. We explore the same language bias of the learned representations, and propose a simple, post-training and model agnostic approach to remove the language identifying information from the representation while still retaining sentence semantics.","297":"Word vectors are widely used as input features in natural language processing (NLP) tasks. Researchers have found that word vectors often encode the biases of society, and steps have been taken towards debiasing the vectors themselves. However, little has been said about the fairness of the methods used to evaluate the quality of vectors. Analogical and word similarity tasks are commonplace, but both rely on purportedly ground truth statements about the semantic relationships between words (e.g. \u201cman is to woman as king is to queen\u201d). These analogies look reasonable when only taking into account the literal meanings of words, but two issues arise: (1) people don\u2019t always use words in a literal sense, and (2) the same word may be used differently by different groups of people. In this paper, we split a dataset of over 800,000 college admissions essays into quartiles based on reported household income (RHI) and train sets of word vectors on each quartile. We then test these sets of vectors on common intrinsic evaluation tasks. We find that vectors trained on the essays of higher income students encode more of each task\u2019s target semantic relationships than vectors trained on the essays of lower income students. These results hold even when controlling for word frequency. We conclude that the tasks themselves are biased towards the writing of higher income students, and we challenge the notion that there exist ground truth semantic relationships that word vectors must encode in order to be useful.","298":"We study the effect of adversarial perturbations on the task of monocular depth prediction. Specifically, we explore the ability of small, imperceptible additive perturbations to selectively alter the perceived geometry of the scene. We show that such perturbations can not only globally re-scale the predicted distances from the camera, but also alter the prediction to match a different target scene. We also show that, when given semantic or instance information, perturbations can fool the network to alter the depth of specific categories or instances in the scene, and even remove them while preserving the rest of the scene. To understand the effect of targeted perturbations, we conduct experiments on state-of-the-art monocular depth prediction methods. Our experiments reveal vulnerabilities in monocular depth prediction networks, and shed light on the biases and context learned by them.","299":"The widespread use of online recruitment services has led to an information explosion in the job market. As a result, recruiters have to seek intelligent ways for Person-Job Fit, which is the bridge for adapting the right candidates to the right positions. Existing studies on Person-Job Fit usually focus on measuring the matching degree between talent qualification and job requirements mainly based on the manual inspection of human resource experts, which could be easily misguided by the subjective, incomplete, and inefficient nature of human judgment. To that end, in this article, we propose a novel end-to-end Topic-based Ability-aware Person-Job Fit Neural Network (TAPJFNN) framework, which has a goal of reducing the dependence on manual labor and can provide better interpretability about the fitting results. The key idea is to exploit the rich information available in abundant historical job application data. Specifically, we propose a word-level semantic representation for both job requirements and job seekers\u2019 experiences based on Recurrent Neural Network (RNN). Along this line, two hierarchical topic-based ability-aware attention strategies are designed to measure the different importance of job requirements for semantic representation, as well as measure the different contribution of each job experience to a specific ability requirement. In addition, we design a refinement strategy for Person-Job Fit prediction based on historical recruitment records. Furthermore, we introduce how to exploit our TAPJFNN framework for enabling two specific applications in talent recruitment: talent sourcing and job recommendation. Particularly, in the application of job recommendation, a novel training mechanism is designed for addressing the challenge of biased negative labels. Finally, extensive experiments on a large-scale real-world dataset clearly validate the effectiveness and interpretability of the TAPJFNN and its variants compared with several baselines.","300":"The news media shape public opinion, and often, the visual bias they contain is evident for human observers. This bias can be inferred from how different media sources portray different subjects or topics. In this paper, we model visual political bias in contemporary media sources at scale, using webly supervised data. We collect a dataset of over one million unique images and associated news articles from left- and right-leaning news sources, and develop a method to predict the image's political leaning. This problem is particularly challenging because of the enormous intra-class visual and semantic diversity of our data. We propose a two-stage method to tackle this problem. In the first stage, the model is forced to learn relevant visual concepts that, when joined with document embeddings computed from articles paired with the images, enable the model to predict bias. In the second stage, we remove the requirement of the text domain and train a visual classifier from the features of the former model. We show this two-stage approach facilitates learning and outperforms several strong baselines. We also present extensive qualitative results demonstrating the nuances of the data.","301":"Ranking has always been one of the top concerns in information retrieval research. For decades, lexical matching signal has dominated the ad-hoc retrieval process, but it also has inherent defects, such as the vocabulary mismatch problem. Recently, Dense Retrieval (DR) technique has been proposed to alleviate these limitations by capturing the deep semantic relationship between queries and documents. The training of most existing Dense Retrieval models relies on sampling negative instances from the corpus to optimize a pairwise loss function. Through investigation, we find that this kind of training strategy is biased and fails to optimize full retrieval performance effectively and efficiently. To solve this problem, we propose a Learning To Retrieve (LTRe) training technique. LTRe constructs the document index beforehand. At each training iteration, it performs full retrieval without negative sampling and then updates the query representation model parameters. Through this process, it teaches the DR model how to retrieve relevant documents from the entire corpus instead of how to rerank a potentially biased sample of documents. Experiments in both passage retrieval and document retrieval tasks show that: 1) in terms of effectiveness, LTRe significantly outperforms all competitive sparse and dense baselines. It even gains better performance than the BM25-BERT cascade system under reasonable latency constraints. 2) in terms of training efficiency, compared with the previous state-of-the-art DR method, LTRe provides more than 170x speed-up in the training process. Training with a compressed index further saves computing resources with minor performance loss.","302":"Inducing a meaningful structural representation from one or a set of dialogues is a crucial but challenging task in computational linguistics. Advancement made in this area is critical for dialogue system design and discourse analysis. It can also be extended to solve grammatical inference. In this work, we propose to incorporate structured attention layers into a Variational Recurrent Neural Network (VRNN) model with discrete latent states to learn dialogue structure in an unsupervised fashion. Compared to a vanilla VRNN, structured attention enables a model to focus on different parts of the source sentence embeddings while enforcing a structural inductive bias. Experiments show that on two-party dialogue datasets, VRNN with structured attention learns semantic structures that are similar to templates used to generate this dialogue corpus. While on multi-party dialogue datasets, our model learns an interactive structure demonstrating its capability of distinguishing speakers or addresses, automatically disentangling dialogues without explicit human annotation.","303":"We investigate some aspects of the history of antisemitism in France, one of the cradles of modern antisemitism, using diachronic word embeddings. We constructed a large corpus of French books and periodicals issues that contain a keyword related to Jews and performed a diachronic word embedding over the 1789-1914 period. We studied the changes over time in the semantic spaces of 4 target words and performed embedding projections over 6 streams of antisemitic discourse. This allowed us to track the evolution of antisemitic bias in the religious, economic, socio-politic, racial, ethic and conspiratorial domains. Projections show a trend of growing antisemitism, especially in the years starting in the mid-80s and culminating in the Dreyfus affair. Our analysis also allows us to highlight the peculiar adverse bias towards Judaism in the broader context of other religions.","304":"This paper addresses the problem of comprehending procedural commonsense knowledge. This is a challenging task as it requires identifying key entities, keeping track of their state changes, and understanding temporal and causal relations. Contrary to most of the previous work, in this study, we do not rely on strong inductive bias and explore the question of how multimodality can be exploited to provide a complementary semantic signal. Towards this end, we introduce a new entity-aware neural comprehension model augmented with external relational memory units. Our model learns to dynamically update entity states in relation to each other while reading the text instructions. Our experimental analysis on the visual reasoning tasks in the recently proposed RecipeQA dataset reveals that our approach improves the accuracy of the previously reported models by a large margin. Moreover, we find that our model learns effective dynamic representations of entities even though we do not use any supervision at the level of entity states.","305":"Bridges are an essential part of the transportation infrastructure and need to be monitored periodically. Visual inspections by dedicated teams have been one of the primary tools in structural health monitoring (SHM) of bridge structures. However, such conventional methods have certain shortcomings. Manual inspections may be challenging in harsh environments and are commonly biased in nature. In the last decade, camera-equipped unmanned aerial vehicles (UAVs) have been widely used for visual inspections; however, the task of automatically extracting useful information from raw images is still challenging. In this paper, a deep learning semantic segmentation framework is proposed to automatically localize surface cracks. Due to the high imbalance of crack and background classes in images, different strategies are investigated to improve performance and reliability. The trained models are tested on real-world crack images showing impressive robustness in terms of the metrics defined by the concepts of precision and recall. These techniques can be used in SHM of bridges to extract useful information from the unprocessed images taken from UAVs.","306":"Sentiment analysis (SA) systems, though widely applied in many domains, have been demonstrated to produce biased results. Some research works have been done in automatically generating test cases to reveal unfairness in SA systems, but the community still lacks tools that can monitor and uncover biased predictions at runtime. This paper fills this gap by proposing BiasRV, the first tool to raise an alarm when a deployed SA system makes a biased prediction on a given input text. To implement this feature, BiasRV dynamically extracts a template from an input text and generates gender-discriminatory mutants (semantically-equivalent texts that only differ in gender information) from the template. Based on popular metrics used to evaluate the overall fairness of an SA system, we define the distributional fairness property for an individual prediction of an SA system. This property specifies a requirement that for one piece of text, mutants from different gender classes should be treated similarly. Verifying the distributional fairness property causes much overhead to the running system. To run more efficiently, BiasRV adopts a two-step heuristic: (1) sampling several mutants from each gender and checking if the system predicts them as of the same sentiment, (2) checking distributional fairness only when sampled mutants have conflicting results. Experiments show that when compared to directly checking the distributional fairness property for each input text, our two-step heuristic can decrease the overhead used for analyzing mutants by 73.81% while only resulting in 6.7% of biased predictions being missed. Besides, BiasRV can be used conveniently without knowing the implementation of SA systems. Future researchers can easily extend BiasRV to detect more types of bias, e.g., race and occupation. The demo video for BiasRV can be viewed at https:\/\/youtu.be\/WPe4Ml77d3U and the source code can be found at https:\/\/github.com\/soarsmu\/BiasRV.","307":"Anemia is a common public health disease diffused worldwide. In many cases it affects the daily lives of patients needing medical assistance and continuous monitoring. Medical literature states empirical evidence of a correlation between conjunctival pallor on physical examinations and its association with anemia diagnosis. Although humans exhibit a natural expertise in pattern recognition and associative skills based on hue properties, the variance of estimates is high, requiring blood sampling even for monitoring. To design automatic systems for the objective evaluation of pallor utilizing digital images of the conjunctiva, it is necessary to obtain reliable automatic segmentation of the eyelid conjunctiva. In this study, we propose a graph partitioning segmentation approach. The semantic segmentation procedure of a diagnostically meaningful region of interest has been proposed for exploiting normalized cuts for perceptual grouping, thereby introducing a bias towards spectrophotometry features of hemoglobin. The reliability of the identification of the region of interest is demonstrated both with standard metrics and by measuring the correlation between the color of the ROI and the hemoglobin level based on 94 samples distributed in relation to age, sex and hemoglobin concentration. The region of interest automatically segmented is suitable for diagnostic procedures based on quantitative hemoglobin estimation of exposed tissues of the conjunctiva.","308":"Training on synthetic data can be beneficial for label or data-scarce scenarios. However, synthetically trained models often suffer from poor generalization in real domains due to domain gaps. In this work, we make a key observation that the diversity of the learned feature embeddings plays an important role in the generalization performance. To this end, we propose contrastive synthetic-to-real generalization (CSG), a novel framework that leverages the pre-trained ImageNet knowledge to prevent overfitting to the synthetic domain, while promoting the diversity of feature embeddings as an inductive bias to improve generalization. In addition, we enhance the proposed CSG framework with attentional pooling (A-pool) to let the model focus on semantically important regions and further improve its generalization. We demonstrate the effectiveness of CSG on various synthetic training tasks, exhibiting state-of-the-art performance on zero-shot domain generalization.","309":null,"310":"Example-based specifications for program synthesis are inherently ambiguous and may cause synthesizers to generate programs that do not exhibit intended behavior on unseen inputs. Existing synthesis techniques attempt to address this problem by either placing a domain-specific syntactic bias on the hypothesis space or heavily relying on user feedback to help resolve ambiguity. We present a new framework to address the ambiguity\/generalizability problem in example-based synthesis. The key feature of our framework is that it places a semantic bias on the hypothesis space using \"relational perturbation properties\" that relate the perturbation\/change in a program output to the perturbation\/change in a program input. An example of such a property is permutation invariance: the program output does not change when the elements of the program input (array) are permuted. The framework is portable across multiple domains and synthesizers and is based on two core steps: (1) automatically augment the set of user-provided examples by \"applying\" relational perturbation properties and (2) use a generic example-based synthesizer to generate a program consistent with the augmented set of examples. Our framework can be instantiated with three different user interfaces, with varying degrees of user engagement to help infer relevant relational perturbation properties. This includes an interface in which the user only provides examples and our framework automatically infers relevant properties. We implement our framework in a tool SKETCHAX specialized to the SKETCH synthesizer and demonstrate that SKETCHAX is effective in significantly boosting the performance of SKETCH for all three user interfaces.","311":"Event prediction plays an important role in financial risk assessment and disaster warning, which can help government decision-making and economic investment. Previous works are mainly based on time series for event prediction such as statistical language model and recurrent neural network, while ignoring the impact of prior knowledge on event prediction. This makes the direction of event prediction often biased or wrong. In this paper, we propose a hierarchical event prediction model based on time series and prior knowledge. To ensure the accuracy of the event prediction, the model obtains the time-based event information and prior knowledge of events by Gated Recurrent Unit and Associated Link Network respectively. The semantic selective attention mechanism is used to fuse the time-based event information and prior knowledge, and finally generate predicted events. Experimental results on Chinese News datasets demonstrate that our model significantly outperforms the state-of-the-art methods, and increases the accuracy by 2.8%.","312":"Interpretability methods for image classification assess model trustworthiness by attempting to expose whether the model is systematically biased or attending to the same cues as a human would. Saliency methods for feature attribution dominate the interpretability literature, but these methods do not address semantic concepts such as the textures, colors, or genders of objects within an image. Our proposed Robust Concept Activation Vectors (RCAV) quantifies the effects of semantic concepts on individual model predictions and on model behavior as a whole. RCAV calculates a concept gradient and takes a gradient ascent step to assess model sensitivity to the given concept. By generalizing previous work on concept activation vectors to account for model non-linearity, and by introducing stricter hypothesis testing, we show that RCAV yields interpretations which are both more accurate at the image level and robust at the dataset level. RCAV, like saliency methods, supports the interpretation of individual predictions. To evaluate the practical use of interpretability methods as debugging tools, and the scientific use of interpretability methods for identifying inductive biases (e.g. texture over shape), we construct two datasets and accompanying metrics for realistic benchmarking of semantic interpretability methods. Our benchmarks expose the importance of counterfactual augmentation and negative controls for quantifying the practical usability of interpretability methods.1","313":null,"314":null,"315":"Few-shot segmentation aims to train a segmentation model that can fast adapt to novel classes with few exemplars. The conventional training paradigm is to learn to make predictions on query images conditioned on the features from support images. Previous methods only utilized the semantic-level prototypes of support images as the conditional information. These methods cannot utilize all pixel-wise support information for the query predictions, which is however critical for the segmentation task. In this paper, we focus on utilizing pixel-wise relationships between support and query images to facilitate the few-shot semantic segmentation task. We design a novel Cycle-Consistent Transformer (CyCTR) module to aggregate pixel-wise support features into query ones. CyCTR performs cross-attention between features from different images, i.e. support and query images. We observe that there may exist unexpected irrelevant pixel-level support features. Directly performing crossattention may aggregate these features from support to query and bias the query features. Thus, we propose using a novel cycle-consistent attention mechanism to filter out possible harmful support features and encourage query features to attend to the most informative pixels from support images. Experiments on all few-shot segmentation benchmarks demonstrate that our proposed CyCTR leads to remarkable improvement compared to previous state-of-the-arts. Specifically, on Pascal-5 and COCO-20 datasets, we achieve 66.6% and 45.6% mIoU for 5-shot segmentation, outperforming previous state-of-the-art by 4.6% and 7.1% respectively.","316":"Remote sensing images having high spatial resolution are acquired, and large amounts of data are extracted from their region of interest. For processing these images, objects of various sizes, from very small neighborhoods to large regions composed of thousands of pixels, should be considered. To this end, this study proposes change detection method using transfer learning and recurrent fully convolutional networks with multiscale three-dimensional (3D) filters. The initial convolutional layer of the change detection network with multiscale 3D filters was designed to extract spatial and spectral features of materials having different sizes; the layer exploits pre-trained weights and biases of semantic segmentation network trained on an open benchmark dataset. The 3D filter sizes were defined in a specialized way to extract spatial and spectral information, and the optimal size of the filter was determined using highly accurate semantic segmentation results. To demonstrate the effectiveness of the proposed method, binary change detection was performed on images obtained from multi-temporal Korea multipurpose satellite-3A. Results revealed that the proposed method outperformed the traditional deep learning-based change detection methods and the change detection accuracy improved using multiscale 3D filters and transfer learning.","317":"The pre-trained BERT model achieves a remarkable state of the art across a wide range of tasks in natural language processing. For solving the gender bias in gendered pronoun resolution task, I propose a novel neural network model based on the pre-trained BERT. This model is a type of mention score classifier and uses an attention mechanism with no parameters to compute the contextual representation of entity span, and a vector to represent the triple-wise semantic similarity among the pronoun and the entities. In stage 1 of the gendered pronoun resolution task, a variant of this model, trained in the fine-tuning approach, reduced the multi-class logarithmic loss to 0.3033 in the 5-fold cross-validation of training set and 0.2795 in testing set. Besides, this variant won the 2nd place with a score at 0.17289 in stage 2 of the task. The code in this paper is available at: https:\/\/github.com\/ziliwang\/MSnet-for-Gendered-Pronoun-Resolution","318":"Video activity localisation has recently attained increasing attention due to its practical values in automatically localising the most salient visual segments corresponding to their language descriptions (sentences) from untrimmed and unstructured videos. For supervised model training, a temporal annotation of both the start and end time index of each video segment for a sentence (a video moment) must be given. This is not only very expensive but also sensitive to ambiguity and subjective annotation bias, a much harder task than image labelling. In this work, we develop a more accurate weakly-supervised solution by introducing Cross-Sentence Relations Mining (CRM) in video moment proposal generation and matching when only a paragraph description of activities without per-sentence temporal annotation is available. Specifically, we explore two cross-sentence relational constraints: (1) Temporal ordering and (2) semantic consistency among sentences in a paragraph description of video activities. Existing weakly-supervised techniques only consider within-sentence video segment correlations in training without considering cross-sentence paragraph context. This can mislead due to ambiguous expressions of individual sentences with visually indiscriminate video moment proposals in isolation. Experiments on two publicly available activity localisation datasets show the advantages of our approach over the state-of-the-art weakly supervised methods, especially so when the video activity descriptions become more complex.","319":null,"320":null,"321":"Unsupervised domain adaptation in semantic segmentation is to exploit the pixel-level annotated samples in the source domain to aid the segmentation of unlabeled samples in the target domain. For such a task, the key point is to learn domain-invariant representations and adversarial learning is usually used, in which the discriminator is to distinguish which domain the input comes from, and the segmentation model targets to deceive the domain discriminator. In this work, we first propose a novel joint adversarial learning (JAL) to boost the domain discriminator in output space by introducing the information of domain discriminator from low-level features. Consequently, the training of the high-level decoder would be enhanced. Then we propose a weight transfer module (WTM) to alleviate the inherent bias of the trained decoder towards source domain. Specifically, WTM changes the original decoder into a new decoder, which is learned only under the supervision of adversarial loss and thus mainly focuses on reducing domain divergence. The extensive experiments on two widely used benchmarks show that our method can bring considerable performance improvement over different baseline methods, which well demonstrates the effectiveness of our method in the output space adaptation.","322":"COVID-19 frequently provokes pneumonia, which can be diagnosed using imaging exams. Chest X-ray (CXR) is often useful because it is cheap, fast, widespread, and uses less radiation. Here, we demonstrate the impact of lung segmentation in COVID-19 identification using CXR images and evaluate which contents of the image influenced the most. Semantic segmentation was performed using a U-Net CNN architecture, and the classification using three CNN architectures (VGG, ResNet, and Inception). Explainable Artificial Intelligence techniques were employed to estimate the impact of segmentation. A three-classes database was composed: lung opacity (pneumonia), COVID-19, and normal. We assessed the impact of creating a CXR image database from different sources, and the COVID-19 generalization from one source to another. The segmentation achieved a Jaccard distance of 0.034 and a Dice coefficient of 0.982. The classification using segmented images achieved an F1-Score of 0.88 for the multi-class setup, and 0.83 for COVID-19 identification. In the cross-dataset scenario, we obtained an F1-Score of 0.74 and an area under the ROC curve of 0.9 for COVID-19 identification using segmented images. Experiments support the conclusion that even after segmentation, there is a strong bias introduced by underlying factors from different sources.","323":"Background: Open source software repositories like GitHub are mined to gain useful empirical software engineering insights and answer critical research questions. However, the present state of the art mining approaches suffers from high error rate in the labeling of data that is used for such analysis. This is particularly true when labels are automatically generated from the commit message, and seriously undermines the results of these studies. Aim: Our goal is to label commit comments with high accuracy automatically. In this work, we focus on classifying a commit as a \u201cBug-Fix commit\u201d or not. Method: Traditionally, researchers have utilized keyword-based approaches to identify bug fix commits that leads to a significant increase in the error rate. We present an alternative methodology leveraging a deep neural network model called Bidirectional Encoder Representations from Transformers (BERT) that can understand the context of the commit message. We provide the rules for semantic interpretation of commit comments. We construct a hand-labeled dataset from real GitHub commits according to these rules and fine-tune BERT for classification. Results: Our initial evaluation shows that our approach significantly reduces the error rate, with up to 10% relative improvement in classification over keyword-based approaches. Future Direction: We plan on extending our dataset to cover more corner cases and reduce programming language specific biases. We also plan on refining the semantic rules. In this work, we have only considered a simple binary classification problem (Bug-Fix or not), which we plan to extend to other classes and extend the approach to consider multiclass problems. Conclusion: The rules, data, and the model proposed in this paper have the potential to be used by people analyzing open source repositories to improve the labeling of data used in their analysis.","324":"Abstract The Gene-pool Optimal Mixing Evolutionary Algorithm (GOMEA) is a model-based EA framework that has been shown to perform well in several domains, including Genetic Programming (GP). Differently from traditional EAs where variation acts blindly, GOMEA learns a model of interdependencies within the genotype, that is, the linkage, to estimate what patterns to propagate. In this article, we study the role of Linkage Learning (LL) performed by GOMEA in Symbolic Regression (SR). We show that the non-uniformity in the distribution of the genotype in GP populations negatively biases LL, and propose a method to correct for this. We also propose approaches to improve LL when ephemeral random constants are used. Furthermore, we adapt a scheme of interleaving runs to alleviate the burden of tuning the population size, a crucial parameter for LL, to SR. We run experiments on 10 real-world datasets, enforcing a strict limitation on solution size, to enable interpretability. We find that the new LL method outperforms the standard one, and that GOMEA outperforms both traditional and semantic GP. We also find that the small solutions evolved by GOMEA are competitive with tuned decision trees, making GOMEA a promising new approach to SR.","325":"Abstract Recently, the use of word embedding models (WEM) has received ample attention in the natural language processing community. These models can capture semantic information in large corpora of text by learning distributional properties of words, that is how often particular words appear in specific contexts. Scholars have pointed out the potential of WEMs for historical research. In particular, their ability to capture semantic change might assist historians studying conceptual change or specific discursive formations over time. Concurrently, others voiced their criticism and pointed out that WEMs require large amounts of training data, that they are challenging to evaluate, and they lack the specificity looked for by historians. The ability to examine semantic change resonates with the goals of historians such as Reinhart Koselleck, whose research focused on the formation of concepts and the transformation of semantic fields. However, word embeddings can only be used to study particular types of semantic change, and the model\u2019s use is dependent on the size, quality, and bias in training data. In this article, we examine what is required of historical data to produce reliable WEMs, and we describe the types of questions that can be answered using WEMs.","326":"The advent of fifth generation (5G) enables the Internet of Things (IoT) to connect a massive number of things. The interaction and communication among these things generate an enormous amount of context-aware data that is semantically diverse. Traditional data representation approaches, such as semantic annotation, ontology, and semantic Web technology are rule based, which lack flexibility and adaptability when applied to IoT. To address the challenge, this article mainly focuses on the problem of semantic representation, which is essential for processing and fusion of IoT data. To serve as a bridge, we propose a high-level framework, namely, Things2Vec, which aims to produce the latent semantic representations from the interaction of things through the graph embedding technique. These semantic representations benefit various IoT semantic analysis tasks, such as the IoT service recommendation and automation of things. In Things2Vec, we utilize the graph to model the function sequence relationships that are generated by the interaction of things, which is called the IoT context graph. Since these function sequence relationships are heterogeneous in terms of semantics, it causes general graph embeddings to fail to learn complete information. Thus, we propose a biased random walk procedure, which is tailored to capture the neighborhoods of nodes with different types of semantic relationships. Extensive experiments are carried out, and our results show that the proposed method can effectively capture the semantic relationships among context-aware data in IoT.","327":"Graph-level representations are critical in various real-world applications, such as predicting the properties of molecules. But in practice, precise graph annotations are generally very expensive and time-consuming. To address this issue, graph contrastive learning constructs instance discrimination task which pulls together positive pairs (augmentation pairs of the same graph) and pushes away negative pairs (augmentation pairs of different graphs) for unsupervised representation learning. However, since for a query, its negatives are uniformly sampled from all graphs, existing methods suffer from the critical sampling bias issue, i.e., the negatives likely having the same semantic structure with the query, leading to performance degradation. To mitigate this sampling bias issue, in this paper, we propose a Prototypical Graph Contrastive Learning (PGCL) approach. Specifically, PGCL models the underlying semantic structure of the graph data via clustering semantically similar graphs into the same group, and simultaneously encourages the clustering consistency for different augmentations of the same graph. Then given a query, it performs negative sampling via drawing the graphs from those clusters that differ from the cluster of query, which ensures the semantic difference between query and its negative samples. Moreover, for a query, PGCL further reweights its negative samples based on the distance between their prototypes (cluster centroids) and the query prototype such that those negatives having moderate prototype distance enjoy relatively large weights. This reweighting strategy is proved to be more effective than the uniform sampling. Experimental results on various graph benchmarks testify the advantages of our PGCL over state-of-the-art methods.","328":"The web has been, in the last decades, the place where information retrieval achieved its maximum importance, given its ubiquity and the sheer volume of information. However, its exponential growth made the retrieval task increasingly hard, relying in its effectiveness on idiosyncratic and somewhat biased ranking algorithms. To deal with this problem, a \u201cnew\u201d web, called the Semantic Web (SW), was proposed, bringing along concepts like \u201cWeb of Data\u201d and \u201cLinked Data,\u201d although the definitions and connections among these concepts are often unclear. Based on a qualitative approach built over a literature review, a definition of SW is presented, discussing the related concepts sometimes used as synonyms. It concludes that the SW is a comprehensive and ambitious construct that includes the great purpose of making the web a global database. It also follows the specifications developed and\/or associated with its operationalization and the necessary procedures for the connection of data in an open format on the web. The goals of this comprehensive SW are the union of two outcomes still tenuously connected: the virtually unlimited possibility of connections between data\u2014the web domain\u2014with the potentiality of the automated inference of \u201cintelligent\u201d systems\u2014the semantic component.","329":"Medical systems in general, and patient treatment decisions and outcomes in particular, can be affected by bias based on gender and other demographic elements. As language models are increasingly applied to medicine, there is a growing interest in building algorithmic fairness into processes impacting patient care. Much of the work addressing this question has focused on biases encoded in language models\u2014statistical estimates of the relationships between concepts derived from distant reading of corpora. Building on this work, we investigate how differences in gender-specific word frequency distributions and language models interact with regards to bias. We identify and remove gendered language from two clinical-note datasets and describe a new debiasing procedure using BERT-based gender classifiers. We show minimal degradation in health condition classification tasks for low- to medium-levels of dataset bias removal via data augmentation. Finally, we compare the bias semantically encoded in the language models with the bias empirically observed in health records. This work outlines an interpretable approach for using data augmentation to identify and reduce biases in natural language processing pipelines.","330":"Non-negative matrix factorization (NMF) is becoming increasingly popular in many research fields due to its particular properties of semantic interpretability and part-based representation. Sparseness constraints are usually imposed on the NMF problems in order to achieve potential features and sparse representation. These constrained NMF problems are usually reformulated as regularization models to solve conveniently. However, the regularization parameters in the regularization model are difficult to tune and the frequently used sparse-inducing terms in the regularization model generally have bias effects on the induced matrix and need an extra restricted isometry property (RIP). This paper proposes a multiobjective sparse NMF paradigm which refrains from the regularization parameter issues, bias effects, and the RIP condition. A novel multiobjective memetic algorithm is also proposed to generate a set of solutions with diverse sparsity and high factorization accuracy. A masked projected gradient local search scheme is specially designed to accelerate the convergence rate. In addition, a priori knowledge is also integrated in the algorithm to reduce the computational time in discovering our interested region in the objective space. The experimental results show that the proposed paradigm has better performance than some regularization algorithms in producing solutions with different degrees of sparsity as well as high factorization accuracy, which are favorable for making the final decisions.","331":"Allowing machines to choose whether to kill humans would be devastating for world peace and security. But how do we equip machines with the ability to learn ethical or even moral choices? Jentzsch et al.(2019) showed that applying machine learning to human texts can extract deontological ethical reasoning about \"right\" and \"wrong\" conduct by calculating a moral bias score on a sentence level using sentence embeddings. The machine learned that it is objectionable to kill living beings, but it is fine to kill time; It is essential to eat, yet one might not eat dirt; it is important to spread information, yet one should not spread misinformation. However, the evaluated moral bias was restricted to simple actions -- one verb -- and a ranking of actions with surrounding context. Recently BERT ---and variants such as RoBERTa and SBERT--- has set a new state-of-the-art performance for a wide range of NLP tasks. But has BERT also a better moral compass? In this paper, we discuss and show that this is indeed the case. Thus, recent improvements of language representations also improve the representation of the underlying ethical and moral values of the machine. We argue that through an advanced semantic representation of text, BERT allows one to get better insights of moral and ethical values implicitly represented in text. This enables the Moral Choice Machine (MCM) to extract more accurate imprints of moral choices and ethical values.","332":"Designing task-oriented dialogue systems is a challenging research topic, since it needs not only to generate utterances fulfilling user requests but also to guarantee the comprehensibility. Many previous works trained end-to-end (E2E) models with supervised learning (SL), however, the bias in annotated system utterances remains as a bottleneck. Reinforcement learning (RL) deals with the problem through using non-differentiable evaluation metrics (e.g., the success rate) as rewards. Nonetheless, existing works with RL showed that the comprehensibility of generated system utterances could be corrupted when improving the performance on fulfilling user requests. In o gur work, we (1) propose modelling the hierarchical structure between dialogue policy and natural language generator (NLG) with the option framework, called HDNO, where the latent dialogue act is applied to avoid designing specific dialogue act representations; (2) train HDNO via hierarchical reinforcement learning (HRL), as well as suggest the asynchronous updates between dialogue policy and NLG during training to theoretically guarantee their convergence to a local maximizer; and (3) propose using a discriminator modelled with language models as an additional reward to further improve the comprehensibility. We test HDNO on MultiWoz 2.0 and MultiWoz 2.1, the datasets on multi-domain dialogues, in comparison with word-level E2E model trained with RL, LaRL and HDSA, showing improvements on the performance evaluated by automatic evaluation metrics and human evaluation. Finally, we demonstrate the semantic meanings of latent dialogue acts to show the ability of explanation.","333":"Neural network visualization techniques mark image locations by their relevancy to the network's classification. Existing methods are effective in highlighting the regions that affect the resulting classification the most. However, as we show, these methods are limited in their ability to identify the support for alternative classifications, an effect we name {\\em the saliency bias} hypothesis. In this work, we integrate two lines of research: gradient-based methods and attribution-based methods, and develop an algorithm that provides per-class explainability. The algorithm back-projects the per pixel local influence, in a manner that is guided by the local attributions, while correcting for salient features that would otherwise bias the explanation. In an extensive battery of experiments, we demonstrate the ability of our methods to class-specific visualization, and not just the predicted label. Remarkably, the method obtains state of the art results in benchmarks that are commonly applied to gradient-based methods as well as in those that are employed mostly for evaluating attribution methods. Using a new unsupervised procedure, our method is also successful in demonstrating that self-supervised methods learn semantic information.","334":"Generalized Zero-Shot Learning (GZSL) targets recognizing new categories by learning transferable image representations. Existing methods find that, by aligning image representations with corresponding semantic labels, the semanticaligned representations can be transferred to unseen categories. However, supervised by only seen category labels, the learned semantic knowledge is highly task-specific, which makes image representations biased towards seen categories. In this paper, we propose a novel Dual-Contrastive Embedding Network (DCEN) that simultaneously learns taskspecific and task-independent knowledge via semantic alignment and instance discrimination. First, DCEN leverages task labels to cluster representations of the same semantic category by cross-modal contrastive learning and exploring semantic-visual complementarity. Besides task-specific knowledge, DCEN then introduces task-independent knowledge by attracting representations of different views of the same image and repelling representations of different images. Compared to high-level seen category supervision, this instance discrimination supervision encourages DCEN to capture low-level visual knowledge, which is less biased toward seen categories and alleviates the representation bias. Consequently, the task-specific and task-independent knowledge jointly make for transferable representations of DCEN, which obtains averaged 4.1% improvement on four public benchmarks.","335":null,"336":"Mindset reconstruction maps how individuals structure and perceive knowledge, a map unfolded here by investigating language and its cognitive reflection in the human mind, i.e., the mental lexicon. Textual forma mentis networks (TFMN) are glass boxes introduced for extracting and understanding mindsets\u2019 structure (in Latin forma mentis) from textual data. Combining network science, psycholinguistics and Big Data, TFMNs successfully identified relevant concepts in benchmark texts, without supervision. Once validated, TFMNs were applied to the case study of distorted mindsets about the gender gap in science. Focusing on social media, this work analysed 10,000 tweets mostly representing individuals\u2019 opinions at the beginning of posts. \u201cGender\u201d and \u201cgap\u201d elicited a mostly positive, trustful and joyous perception, with semantic associates that: celebrated successful female scientists, related gender gap to wage differences, and hoped for a future resolution. The perception of \u201cwoman\u201d highlighted jargon of sexual harassment and stereotype threat (a form of implicit cognitive bias) about women in science \u201csacrificing personal skills for success\u201d. The semantic frame of \u201cman\u201d highlighted awareness of the myth of male superiority in science. No anger was detected around \u201cperson\u201d, suggesting that tweets got less tense around genderless terms. No stereotypical perception of \u201cscientist\u201d was identified online, differently from real-world surveys. This analysis thus identified that Twitter discourse mostly starting conversations promoted a majorly stereotype-free, positive\/trustful perception of gender disparity, aimed at closing the gap. Hence, future monitoring against discriminating language should focus on other parts of conversations like users\u2019 replies. TFMNs enable new ways for monitoring collective online mindsets, offering data-informed ground for policy making.","337":"Contrastive language image pretraining (CLIP) encoders have been shown to be bene\ufb01cial for a range of visual tasks from classi\ufb01cation and detection to caption-ing and image manipulation. We investigate the effectiveness of CLIP visual backbones for Embodied AI tasks. We build incredibly simple baselines, named EmbCLIP, with no task speci\ufb01c architectures, inductive biases (such as the use of semantic maps), auxiliary tasks during training, or depth maps\u2014yet we \ufb01nd that our improved baselines perform very well across a range of tasks and simulators. EmbCLIP tops the RoboTHOR ObjectNav leaderboard by a huge margin of 20 pts (Success Rate). It tops the iTHOR 1-Phase Rearrangement leaderboard, beating the next best submission, which employs Active Neural Mapping, and more than doubling the % Fixed Strict metric (0.08 to 0.17). It also beats the winners of the 2021 Habitat ObjectNav Challenge, which employ auxiliary tasks, depth maps, and human demonstrations, and those of the 2019 Habitat PointNav Challenge. We evaluate the ability of CLIP\u2019s visual representations at capturing semantic information about input observations\u2014primitives that are useful for navigation-heavy embodied tasks\u2014and \ufb01nd that CLIP\u2019s representations encode these primitives more ef-fectively than ImageNet-pretrained backbones. Finally, we extend one of our baselines, producing an agent capable of zero-shot object navigation that can navigate to objects that were not used as targets during training. Our code and models are available at https:\/\/github.com\/ allenai\/embodied-clip .","338":"Image captioning models have been able to generate grammatically correct and human understandable sentences. However most of the captions convey limited information as the model used is trained on datasets that do not caption all possible objects existing in everyday life. Due to this lack of prior information most of the captions are biased to only a few objects present in the scene, hence limiting their usage in daily life. In this paper, we attempt to show the biased nature of the currently existing image captioning models and present a new image captioning dataset, Egoshots, consisting of 978 real life images with no captions. We further exploit the state of the art pre-trained image captioning and object recognition networks to annotate our images and show the limitations of existing works. Furthermore, in order to evaluate the quality of the generated captions, we propose a new image captioning metric, object based Semantic Fidelity (SF). Existing image captioning metrics can evaluate a caption only in the presence of their corresponding annotations; however, SF allows evaluating captions generated for images without annotations, making it highly useful for real life generated captions.","339":"Abstract Meaning Representation parsing is a sentence-to-graph prediction task where target nodes are not explicitly aligned to sentence tokens. However, since graph nodes are semantically based on one or more sentence tokens, implicit alignments can be derived. Transition-based parsers operate over the sentence from left to right, capturing this inductive bias via alignments at the cost of limited expressiveness. In this work, we propose a transition-based system that combines hard-attention over sentences with a target-side action pointer mechanism to decouple source tokens from node representations and address alignments. We model the transitions as well as the pointer mechanism through straightforward modifications within a single Transformer architecture. Parser state and graph structure information are efficiently encoded using attention heads. We show that our action-pointer approach leads to increased expressiveness and attains large gains (+1.6 points) against the best transition-based AMR parser in very similar conditions. While using no graph re-categorization, our single model yields the second best Smatch score on AMR 2.0 (81.8), which is further improved to 83.4 with silver data and ensemble decoding.","340":"Generalised zero-shot learning (GZSL) is a classification problem where the learning stage relies on a set of seen visual classes and the inference stage aims to identify both the seen visual classes and a new set of unseen visual classes. Critically, both the learning and inference stages can leverage a semantic representation that is available for the seen and unseen classes. Most state-of-the-art GZSL approaches rely on a mapping between latent visual and semantic spaces without considering if a particular sample belongs to the set of seen or unseen classes. In this paper, we propose a novel GZSL method that learns a joint latent representation that combines both visual and semantic information. This mitigates the need for learning a mapping between the two spaces. Our method also introduces a domain classification that estimates whether a sample belongs to a seen or an unseen class. Our classifier then combines a class discriminator with this domain classifier with the goal of reducing the natural bias that GZSL approaches have toward the seen classes. Experiments show that our method achieves state-of-the-art results in terms of harmonic mean, the area under the seen and unseen curve and unseen classification accuracy on public GZSL benchmark data sets. Our code will be available upon acceptance of this paper.","341":"Neural Machine Translation (NMT), a data-hungry technology, suffers from the lack of bilingual data in low-resource scenarios. Multitask learning (MTL) can alleviate this issue by injecting inductive biases into NMT, using auxiliary syntactic and semantic tasks. However, an effective training schedule is required to balance the importance of tasks to get the best use of the training signal. The role of training schedule becomes even more crucial in biased-MTL where the goal is to improve one (or a subset) of tasks the most, e.g. translation quality. Current approaches for biased-MTL are based on brittle hand-engineered heuristics that require trial and error, and should be (re-)designed for each learning scenario. To the best of our knowledge, ours is the first work on adaptively and dynamically changing the training schedule in biased-MTL. We propose a rigorous approach for automatically reweighing the training data of the main and auxiliary tasks throughout the training process based on their contributions to the generalisability of the main NMT task. Our experiments on translating from English to Vietnamese\/Turkish\/Spanish show improvements of up to +1.2 BLEU points, compared to strong baselines. Additionally, our analyses shed light on the dynamic of needs throughout the training of NMT: from syntax to semantic.","342":"Steady progress has been made in abstractive summarization with attention-based sequence-to-sequence learning models. In this paper, we propose a new decoder where the output summary is generated by conditioning on both the input text and the latent topics of the document. The latent topics, identified by a topic model such as LDA, reveals more global semantic information that can be used to bias the decoder to generate words. In particular, they enable the decoder to have access to additional word co-occurrence statistics captured at document corpus level. We empirically validate the advantage of the proposed approach on both the CNN\/Daily Mail and the WikiHow datasets. Concretely, we attain strongly improved ROUGE scores when compared to state-of-the-art models.","343":"Modern task-oriented semantic parsing approaches typically use seq2seq transformers to map textual utterances to semantic frames comprised of intents and slots. While these models are empirically strong, their specific strengths and weaknesses have largely remained unexplored. In this work, we study BART (Lewis et al., 2020) and XLM-R (Conneau et al., 2020), two state-of-the-art parsers, across both monolingual and multilingual settings. Our experiments yield several key results: transformer-based parsers struggle not only with disambiguating intents\/slots, but surprisingly also with producing syntacticallyvalid frames. Though pre-training imbues transformers with syntactic inductive biases, we find the ambiguity of copying utterance spans into frames often leads to tree invalidity, indicating span extraction is a major bottleneck for current parsers. However, as a silver lining, we show transformer-based parsers give sufficient indicators for whether a frame is likely to be correct or incorrect, making them easier to deploy in production settings.","344":"To generate \"accurate\" scene graphs, almost all existing methods predict pairwise relationships in a deterministic manner. However, we argue that visual relationships are often semantically ambiguous. Specifically, inspired by linguistic knowledge, we classify the ambiguity into three types: Synonymy Ambiguity, Hyponymy Ambiguity, and Multi-view Ambiguity. The ambiguity naturally leads to the issue of implicit multi-label, motivating the need for diverse predictions. In this work, we propose a novel plug-and-play Probabilistic Uncertainty Modeling (PUM) module. It models each union region as a Gaussian distribution, whose variance measures the uncertainty of the corresponding visual content. Compared to the conventional deterministic methods, such uncertainty modeling brings stochasticity of feature representation, which naturally enables diverse predictions. As a byproduct, PUM also manages to cover more fine-grained relationships and thus alleviates the issue of bias towards frequent relationships. Extensive experiments on the large-scale Visual Genome benchmark show that combining PUM with newly proposed ResCAGCN can achieve state-of-the-art performances, especially under the mean recall metric. Furthermore, we show the universal effectiveness of PUM by plugging it into some existing models and provide insightful analysis of its ability to generate diverse yet plausible visual relationships.","345":"Segmentation of 3D micro-Computed Tomographic uCT) images of rock samples is essential for further Digital Rock Physics (DRP) analysis, however, conventional methods such as thresholding, watershed segmentation, and converging active contours are susceptible to user-bias. Deep Convolutional Neural Networks (CNNs) have produced accurate pixelwise semantic segmentation results with natural images and $\\mu$CT rock images, however, physical accuracy is not well documented. The performance of 4 CNN architectures is tested for 2D and 3D cases in 10 configurations. Manually segmented uCT images of Mt. Simon Sandstone are treated as ground truth and used as training and validation data, with a high voxelwise accuracy (over 99%) achieved. Downstream analysis is then used to validate physical accuracy. The topology of each segmented phase is calculated, and the absolute permeability and multiphase flow is modelled with direct simulation in single and mixed wetting cases. These physical measures of connectivity, and flow characteristics show high variance and uncertainty, with models that achieve 95\\%+ in voxelwise accuracy possessing permeabilities and connectivities orders of magnitude off. A new network architecture is also introduced as a hybrid fusion of U-net and ResNet, combining short and long skip connections in a Network-in-Network configuration. The 3D implementation outperforms all other tested models in voxelwise and physical accuracy measures. The network architecture and the volume fraction in the dataset (and associated weighting), are factors that not only influence the accuracy trade-off in the voxelwise case, but is especially important in training a physically accurate model for segmentation.","346":null,"347":"Online social networks have made tremendous progress in recent years. People generate a large amount of text information in which the linguistic and the semantic information could convey a great deal of information about the users\u2019 personality. Studies on personality analysis based on text information from online social networks have gradually increased in recent years. However, the previous works do not leverage the text information comprehensively and thus limits the prediction accuracy. In this paper, we propose personality2vec, a novel model that is based on network representation learning and makes full use of the semantic, the personality, and the structural information in users\u2019 texts. The model utilizes a new biased walk algorithm and an improved skip-gram algorithm to train on the network and eventually generates a personality vector for each user. We feed the personality vectors into regression algorithms to predict users\u2019 Big Five personality scores. Experimental results show that personality2vec outperforms seven popular methods on three personality datasets.","348":"Encoder\u2013decoder models have been widely used in image captioning, and most of them are designed via single long short term memory (LSTM). The capacity of single-layer network, whose encoder and decoder are integrated together, is limited for such a complex task of image captioning. Moreover, how to effectively increase the \u201cvertical depth\u201d of encoder\u2013decoder remains to be solved. To deal with these problems, a novel deep hierarchical encoder\u2013decoder network is proposed for image captioning, where a deep hierarchical structure is explored to separate the functions of encoder and decoder. This model is capable of efficiently exerting the representation capacity of deep networks to fuse high level semantics of vision and language in generating captions. Specifically, visual representations in top levels of abstraction are simultaneously considered, and each of these levels is associated to one LSTM. The bottom-most LSTM is applied as the encoder of textual inputs. The application of the middle layer in encoder\u2013decoder is to enhance the decoding ability of top-most LSTM. Furthermore, depending on the introduction of semantic enhancement module of image feature and distribution combine module of text feature, variants of architectures of our model are constructed to explore the impacts and mutual interactions among the visual representation, textual representations, and the output of the middle LSTM layer. Particularly, the framework is training under a reinforcement learning method to address the exposure bias problem between the training and the testing by the policy gradient optimization. Qualitative analyses indicate the process that our model \u201ctranslates\u201d image to sentence and further visualization presents the evolution of the hidden states from different hierarchical LSTMs over time. Extensive experiments demonstrate that our model outperforms current state-of-the-art models on three benchmark datasets: Flickr8K, Flickr30K, and MSCOCO. On both image captioning and retrieval tasks, our method achieves the best results. On MSCOCO captioning Leaderboard, our method also achieves superior performance.","349":"Reinforcement learning (RL) has been widely studied for improving sequence-generation models. However, the conventional rewards used for RL training typically cannot capture sufficient semantic information and therefore render model bias. Further, the sparse and delayed rewards make RL exploration inefficient. To alleviate these issues, we propose the concept of nested-Wasserstein distance for distributional semantic matching. To further exploit it, a novel nested-Wasserstein self-imitation learning framework is developed, encouraging the model to exploit historical high-rewarded sequences for enhanced exploration and better semantic matching. Our solution can be understood as approximately executing proximal policy optimization with Wasserstein trust-regions. Experiments on a variety of unconditional and conditional sequence-generation tasks demonstrate the proposed approach consistently leads to improved performance.","350":"Research on the semantics of spatial markers in French is mainly known through Vandeloise\u2019s (1986, 1991) work on static prepositions. However, interest in the expression of space in French goes back to the mid-1970s and focused first on verbs denoting changes in space, whose syntactic properties were related to specific semantic distinctions, such as the opposition between \"movement\" and \"displacement\". This volume provides an overview of recent studies on the semantics of dynamic space in French and addresses important questions about motion expression, among which \"goal bias\" and asymmetry of motion, the status of locative PPs, the expression of manner, fictive or non-actual motion... Descriptive, experimental and formal or computational analyses are presented, providing complementary perspectives on the main issue. The volume is intended for researchers and advanced students wishing to learn about both spatial semantics in French and recent debates on the representation of motion events in language and cognition.","351":"Fine-tuning pre-trained models have achieved impressive performance on standard natural language processing benchmarks. However, the resultant model generalizability remains poorly understood. We do not know, for example, how excellent performance can lead to the perfection of generalization models. In this study, we analyze a fine-tuned BERT model from different perspectives using relation extraction. We also characterize the differences in generalization techniques according to our proposed improvements. From empirical experimentation, we find that BERT suffers a bottleneck in terms of robustness by way of randomizations, adversarial and counterfactual tests, and biases (i.e., selection and semantic). These findings highlight opportunities for future improvements. Our open-sourced testbed DiagnoseRE is available in this https URL.","352":"We propose a new generative adversarial architecture to mitigate imbalance data problem in medical image semantic segmentation where the majority of pixels belongs to a healthy region and few belong to lesion or non-health region. A model trained with imbalanced data tends to bias towards healthy data which is not desired in clinical applications and predicted outputs by these networks have high precision and low sensitivity. We propose a new conditional generative refinement network with three components: a generative, a discriminative, and a refinement networks to mitigate imbalanced data problem through ensemble learning. The generative network learns to the segment at the pixel level by getting feedback from the discriminative network according to the true positive and true negative maps. On the other hand, the refinement network learns to predict the false positive and the false negative masks produced by the generative network that has significant value, especially in medical application. The final semantic segmentation masks are then composed by the output of the three networks. The proposed architecture shows state-of-the-art results on LiTS-2017 for simultaneous liver and lesion segmentation, and MDA231 for microscopic cell segmentation. We have achieved competitive results on BraTS-2017 for brain tumor segmentation.","353":null,"354":"Generalized Zero-Shot Learning (GZSL) aims at recognizing both seen and unseen classes by constructing correspondence between visual and semantic embedding. However, existing methods have severely suffered from the strong bias problem, where unseen instances in target domain tend to be recognized as seen classes in source domain. To address this issue, we propose an end-to-end Self-supervised Domain-aware Generative Network (SDGN) by integrating self-supervised learning into feature generating model for unbiased GZSL. The proposed SDGN model enjoys several merits. First, we design a cross-domain feature generating module to synthesize samples with high fidelity based on class embeddings, which involves a novel target domain discriminator to preserve the domain consistency. Second, we propose a self-supervised learning module to investigate inter-domain relationships, where a set of anchors are introduced as a bridge between seen and unseen categories. In the shared space, we pull the distribution of target domain away from source domain, and obtain domain-aware features with high discriminative power for both seen and unseen classes. To our best knowledge, this is the first work to introduce self-supervised learning into GZSL as a learning guidance. Extensive experimental results on five standard benchmarks demonstrate that our model performs favorably against state-of-the-art GZSL methods.","355":"Generalized zero-shot learning recognizes inputs from both seen and unseen classes. Yet, existing methods tend to be biased towards the classes seen during training. In this paper, we strive to mitigate this bias. We propose a bias-aware learner to map inputs to a semantic embedding space for generalized zero-shot learning. During training, the model learns to regress to real-valued class prototypes in the embedding space with temperature scaling, while a margin-based bidirectional entropy term regularizes seen and unseen probabilities. Relying on a real-valued semantic embedding space provides a versatile approach, as the model can operate on different types of semantic information for both seen and unseen classes. Experiments are carried out on four benchmarks for generalized zero-shot learning and demonstrate the benefits of the proposed bias-aware classifier, both as a stand-alone method or in combination with generated features.","356":"Emotion recognition is predominantly formulated as text classification in which textual units are assigned to an emotion from a predefined inventory (e.g., fear, joy, anger, disgust, sadness, surprise, trust, anticipation). More recently, semantic role labeling approaches have been developed to extract structures from the text to answer questions like: \u201cwho is described to feel the emotion?\u201d (experiencer), \u201cwhat causes this emotion?\u201d (stimulus), and at which entity is it directed?\u201d (target). Though it has been shown that jointly modeling stimulus and emotion category prediction is beneficial for both subtasks, it remains unclear which of these semantic roles enables a classifier to infer the emotion. Is it the experiencer, because the identity of a person is biased towards a particular emotion (X is always happy)? Is it a particular target (everybody loves X) or a stimulus (doing X makes everybody sad)? We answer these questions by training emotion classification models on five available datasets annotated with at least one semantic role by masking the fillers of these roles in the text in a controlled manner and find that across multiple corpora, stimuli and targets carry emotion information, while the experiencer might be considered a confounder. Further, we analyze if informing the model about the position of the role improves the classification decision. Particularly on literature corpora we find that the role information improves the emotion classification.","357":"Learned representations of source code enable various software developer tools, e.g., to detect bugs or to predict program properties. At the core of code representations often are word embeddings of identifier names in source code, because identifiers account for the majority of source code vocabulary and convey important semantic information. Unfortunately, there currently is no generally accepted way of evaluating the quality of word embeddings of identifiers, and current evaluations are biased toward specific downstream tasks. This paper presents IdBench, the first benchmark for evaluating to what extent word embeddings of identifiers represent semantic relatedness and similarity. The benchmark is based on thousands of ratings gathered by surveying 500 software developers. We use IdBench to evaluate state-of-the-art embedding techniques proposed for natural language, an embedding technique specifically designed for source code, and lexical string distance functions, as these are often used in current developer tools. Our results show that the effectiveness of embeddings varies significantly across different embedding techniques and that the best available embeddings successfully represent semantic relatedness. On the downside, no existing embedding provides a satisfactory representation of semantic similarities, e.g., because embeddings consider identifiers with opposing meanings as similar, which may lead to fatal mistakes in downstream developer tools. IdBench provides a gold standard to guide the development of novel embeddings that address the current limitations.","358":"Ambitions in artificial intelligence involve machine understanding of human language. The state-of-the-art approach for Spoken Language Understanding is using an Automatic Speech Recognizer (ASR) to generate transcripts, which are further processed with text-based tools. ASR yields error prone transcripts, these errors then propagate further into the processing pipeline. Subjective tests show on the other hand, that humans understand quite well ASR closed captions despite the word and punctuation errors. Our goal is to assess and quantify the loss in the semantic space resulting from error propagation and also analyze error propagation into speech summarization as a special use-case. We show, that word errors cause a slight shift in the semantic space, which is fairly below the average semantic distance between the sentences within a document. We also show, that punctuation errors have higher impact on summarization performance, which suggests that proper sentence level tokenization is crucial for this task.","359":"Bias is ubiquitous in most online sources of natural language, from news media to social networks. Given the steady shift in news consumption behavior from traditional outlets to online sources, the automatic detection of propaganda, in which information is shaped to purposefully foster a predetermined agenda, is an increasingly crucial task. To this goal, we explore the task of sentence-level propaganda detection, and experiment with both handcrafted features and learned dense semantic representations. We also experiment with random undersampling of the majority class (non-propaganda) to curb the influence of class distribution on the system\u2019s performance, leading to marked improvements on the minority class (propaganda). Our best performing system uses pre-trained ELMo word embeddings, followed by a bidirectional LSTM and an attention layer. We have submitted a 5-model ensemble of our best performing system to the NLP4IF shared task on sentence-level propaganda detection (team LIACC), achieving rank 10 among 25 participants, with 59.5 F1-score.","360":"Recent studies have indicated that microRNAs (miRNAs) are closely related to sundry human sophisticated diseases. According to the surmise that functionally similar miRNAs are more likely associated with phenotypically similar diseases, researchers have proposed a variety of valid computational models through integrating known miRNA-disease associations, disease semantic similarity, miRNA functional similarity, and Gaussian interaction profile kernel similarity to discover the potential miRNA-disease relationships in biomedical researches. Taking account of the limitations of previous computational models, a new computational model based on biased heat conduction for MiRNA-Disease Association prediction (BHCMDA) was proposed in this paper, which can achieve the AUC of 0.8890 in LOOCV (Leave-One-Out Cross Validation) and the mean AUC of 0.9060, 0.8931 under the framework of twofold cross validation, fivefold cross validation, respectively. In addition, BHCMDA was further implemented to the case studies of three vital human cancers, and simulation results illustrated that there were 88% (Esophageal Neoplasms), 92% (Colonic Neoplasms) and 92% (Lymphoma) out of top 50 predicted miRNAs having been confirmed by experimental literatures, separately, which demonstrated the good performance of BHCMDA as well. Thence, BHCMDA would be a useful calculative resource for potential miRNA-disease association prediction.","361":"Recent years have witnessed a surge of interest in machine learning on graphs and networks with applications ranging from IoT traffic management to social network recommendations. Supervised machine learning tasks in networks such as node classification and link prediction require us to perform feature engineering that is known and agreed to be the key to success in applied machine learning. Research efforts dedicated to representation learning, especially representation learning using deep learning, has shown us ways to automatically learn relevant features from vast amounts of potentially noisy, raw data. However, most of the methods are inadequate to handle heterogeneous information networks which pretty much represents most real world data today. The methods cannot preserve the structure and semantic of multiple types of nodes and links well enough, capture higher-order heterogeneous connectivity patterns, and ensure coverage of nodes for which representations are generated. In this paper, we propose a novel efficient algorithm, motif2vec that learns node representations or embeddings for heterogeneous networks. Specifically, we leverage higher-order, recurring, and statistically significant network connectivity patterns in the form of motifs to transform the original graph to motif graph(s), conduct biased random walk to efficiently explore higher order neighborhoods, and then employ heterogeneous skip-gram model to generate the embeddings. We evaluate the proposed algorithm on multiple real-world networks from diverse domains and against existing state-of-the-art methods on multi-class node classification and link prediction tasks, and demonstrate its consistent superiority over prior work.","362":"There still involve lots of challenges when applying machine learning algorithms in unknown environments, especially those with limited training data. To handle the data insufficiency and make a further step towards robust learning, we adopt the learnware notion Z.-H. Zhou, \u201cLearnware: On the future of machine learning,\u201d Front. Comput. Sci., vol. 10, no. 4 pp. 589\u2013590, 2016 which equips a model with an essential reusable property\u2014the model learned in a related task could be easily adapted to the current data-scarce environment without data sharing. To this end, we propose the REctiFy via heterOgeneous pRedictor Mapping (ReForm) framework enabling the current model to take advantage of a related model from two kinds of heterogeneous environment, i.e., either with different sets of features or labels. By Encoding Meta InformaTion (Emit) of features and labels as the model specification, we utilize an optimal transported semantic mapping to characterize and bridge the environment changes. After fine-tuning over a few labeled examples through a biased regularization objective, the transformed heterogeneous model adapts to the current task efficiently. We apply ReForm over both synthetic and real-world tasks such as few-shot image classification with either learned or pre-defined specifications. Experimental results validate the effectiveness and practical utility of the proposed ReForm framework.","363":"Zero-shot learning uses semantic attributes to connect the search space of unseen objects. In recent years, although the deep convolutional network brings powerful visual modeling capabilities to the ZSL task, its visual features have severe pattern inertia and lack of representation of semantic relationships, which leads to severe bias and ambiguity. In response to this, we propose the Graph-based Visual-Semantic Entanglement Network to conduct graph modeling of visual features, which is mapped to semantic attributes by using a knowledge graph, it contains several novel designs: 1. it establishes a multi-path entangled network with the convolutional neural network (CNN) and the graph convolutional network (GCN), which input the visual features from CNN to GCN to model the implicit semantic relations, then GCN feedback the graph modeled information to CNN features; 2. it uses attribute word vectors as the target for the graph semantic modeling of GCN, which forms a self-consistent regression for graph modeling and supervise GCN to learn more personalized attribute relations; 3. it fuses and supplements the hierarchical visual-semantic features refined by graph modeling into visual embedding. By promoting the semantic linkage modeling of visual features, our method outperforms state-of-the-art approaches on multiple representative ZSL datasets: AwA2, CUB, and SUN.","364":"Programs expecting structured inputs often consist of both a syntactic analysis stage, in which raw input is parsed into an internal data structure, and a semantic analysis stage, which conducts checks on this data structure and executes the core logic of the program. Existing random testing tools tend to produce inputs that are rejected early in this pipeline. We propose Zest, a random testing methodology for effectively exploring the semantic analysis stages of such programs. Zest combines two key innovations to achieve this. First, we introduce validity fuzzing, which biases coverage-guided fuzzing (CGF) towards generating semantically valid inputs. Second, we introduce parametric generators, which convert input from a simple parameter domain, such as an un-typed sequence of bits, into a more structured domain, such as syntactically valid XML. These generators enable bit-level mutations of the parameters to map to structural mutations in syntactically valid test inputs. In our experiments with Zest on six popular JVM-based projects, we find 18 new bugs, of which 7 are not found by baseline CGF and generator-based techniques.","365":"Video Question Answering (VidQA) evaluation metrics have been limited to a single-word answer or selecting a phrase from a fixed set of phrases. These metrics limit the VidQA models\u2019 application scenario. In this work, we leverage semantic roles derived from video descriptions to mask out certain phrases, to introduce VidQAP which poses VidQA as a fill-in-the-phrase task. To enable evaluation of answer phrases, we compute the relative improvement of the predicted answer compared to an empty string. To reduce the influence of language bias in VidQA datasets, we retrieve a video having a different answer for the same question. To facilitate research, we construct ActivityNet-SRL-QA and Charades-SRL-QA and benchmark them by extending three vision-language models. We perform extensive analysis and ablative studies to guide future work. Code and data are public.","366":"Standard methods in deep learning fail to capture compositional or systematic structure in their training data, as shown by their inability to generalize outside of the training distribution. However, human learners readily generalize in this way, e.g. by applying known grammatical rules to novel words. The inductive biases that might underlie this powerful cognitive capacity remain unclear. Inspired by work in cognitive science suggesting a functional distinction between systems for syntactic and semantic processing, we implement a modification to an existing deep learning architecture, imposing an analogous separation. The resulting architecture substantially outperforms standard recurrent networks on the SCAN dataset, a compositional generalization task, without any additional supervision. Our work suggests that separating syntactic from semantic learning may be a useful heuristic for capturing compositional structure, and highlights the potential of using cognitive principles to inform inductive biases in deep learning.","367":"In Sentiment Analysis (SA), a vague assignment of a text to a set of n-ary discrete classes is insufficient. A great deal of research is concentrated on the automated assignment of strength to both terms and the finer-grained term senses, but these strength values rely purely on statistical means, and there is no semantic mechanism involved, leading to potentially biased results. As a solution, this works proposes a model that utilizes only the semantic information manually encoded within the human-defined glosses of term senses, a semantic network, and a set of predefined degree adverbs, in order to quantify their \u2018Natural\u2019 Sentiment Strength (NSS) values. The \u2018natural\u2019 sentiment strength of a term sense here refers to the strength value derived in a \u2018semantically natural\u2019 manner, i.e. the NSS is assigned based on the agreed-upon meanings that humans have naturally assigned to words; and not \u2018artificially statistical\u2019, i.e. based a simple metric of probabilistic computation. Intrinsic evaluation against a manually-annotated gold standard benchmark demonstrates that the model outperforms related sense-level lexicon generation models against this same benchmark, and that it is in agreement with human intuition.","368":null,"369":"Semantic parsing has long been a fundamental problem in natural language processing. Recently, cross-domain contextdependent semantic parsing has become a new focus of research. Central to the problem is the challenge of leveraging contextual information of both natural language utterance and database schemas in the interaction history. In this paper, we present a dynamic graph framework that is capable of effectively modelling contextual utterances, tokens, database schemas, and their complicated interaction as the conversation proceeds. The framework employs a dynamic memory decay mechanism that incorporates inductive bias to integrate enriched contextual relation representation, which is further enhanced with a powerful reranking model. At the time of writing, we demonstrate that the proposed framework outperforms all existing models by large margins, achieving new state-of-the-art performance on two large-scale benchmarks, the SParC and CoSQL datasets. Specifically, the model attains a 55.8% question-match and 30.8% interaction-match accuracy on SParC, and a 46.8% question-match and 17.0% interaction-match accuracy on CoSQL.","370":"Zero-shot learning (ZSL) aims to recognize novel classes by transferring semantic knowledge from seen classes to unseen ones. Semantic knowledge is learned from attribute descriptions shared between different classes, which act as strong priors for localizing object attributes that represent discriminative region features, enabling significant visual-semantic interaction. Although some attention-based models have attempted to learn such region features in a single image, the transferability and discriminative attribute localization of visual features are typically neglected. In this paper, we propose an attribute-guided Transformer network, termed TransZero, to refine visual features and learn attribute localization for discriminative visual embedding representations in ZSL. Specifically, TransZero takes a feature augmentation encoder to alleviate the cross-dataset bias between ImageNet and ZSL benchmarks, and improves the transferability of visual features by reducing the entangled relative geometry relationships among region features. To learn locality-augmented visual features, TransZero employs a visual-semantic decoder to localize the image regions most relevant to each attribute in a given image, under the guidance of semantic attribute information. Then, the locality-augmented visual features and semantic vectors are used to conduct effective visual-semantic interaction in a visual-semantic embedding network. Extensive experiments show that TransZero achieves the new state of the art on three ZSL benchmarks. The codes are available at: https:\/\/github.com\/shiming-chen\/TransZero.","371":"Irrigation is indispensable in agriculture. Center pivot irrigation systems are popular means of irrigation since they are water-efficient and labor-saving. Monitoring center pivot irrigation systems provides important information for the understanding of agricultural production, water resources consumption and environmental change. Deep learning has become an effective approach for object detection and semantic segmentation. Recent studies have shown that convolutional neural networks (CNNs) are prone to be texture-biased rather than shape-biased, and increasing shape bias can improve the robustness and performance of CNNs. In this study, a simple yet effective method was proposed to increase shape bias in object detection networks to improve the precision of center pivot irrigation system detection. We extracted edge images of training samples and integrated them into the training data to increase shape bias in the networks. With the proposed shape increasing training scheme, we evaluated and compared PVANET and YOLOv4. Experiments with the images in Mato Grosso have shown that both PVANET and YOLOv4 achieved improved performance, which demonstrated the validity of the proposed method.","372":"Multilingual BERT (mBERT) has shown reasonable capability for zero-shot cross-lingual transfer when fine-tuned on downstream tasks. Since mBERT is not pre-trained with explicit cross-lingual supervision, transfer performance can further be improved by aligning mBERT with cross-lingual signal. Prior work propose several approaches to align contextualised embeddings. In this paper we analyse how different forms of cross-lingual supervision and various alignment methods influence the transfer capability of mBERT in zero-shot setting. Specifically, we compare parallel corpora vs dictionary-based supervision and rotational vs fine-tuning based alignment methods. We evaluate the performance of different alignment methodologies across eight languages on two tasks: Name Entity Recognition and Semantic Slot Filling. In addition, we propose a novel normalisation method which consistently improves the performance of rotation-based alignment including a notable 3% F1 improvement for distant and typologically dissimilar languages. Importantly we identify the biases of the alignment methods to the type of task and proximity to the transfer language. We also find that supervision from parallel corpus is generally superior to dictionary alignments.","373":"As acquiring pixel-wise annotations of real-world images for semantic segmentation is a costly process, a model can instead be trained with more accessible synthetic data and adapted to real images without requiring their annotations. This process is studied in unsupervised domain adaptation (UDA). Even though a large number of methods propose new adaptation strategies, they are mostly based on outdated network architectures. As the in\ufb02uence of recent network architectures has not been systematically studied, we \ufb01rst benchmark different network architectures for UDA and newly reveal the potential of Transformers for UDA semantic segmentation. Based on the \ufb01ndings, we propose a novel UDA method, DAFormer. The network architecture of DAFormer consists of a Transformer encoder and a multi-level context-aware feature fusion decoder. It is enabled by three simple but crucial training strategies to stabilize the training and to avoid over\ufb01tting to the source domain: While (1) Rare Class Sampling on the source domain improves the quality of the pseudo-labels by mitigating the con\ufb01rmation bias of self-training toward common classes, (2) a Thing-Class ImageNet Feature Distance and (3) a learning rate warmup promote feature transfer from ImageNet pretraining. DAFormer represents a major advance in UDA. It improves the state of the art by 10.8 mIoU for GTA \u2192 Cityscapes and 5.4 mIoU for Synthia \u2192 Cityscapes and enables learning even dif\ufb01cult classes such as train, bus, and truck well. The implementation is available at","374":"Transductive zero-shot learning is designed to recognize unseen categories by aligning both visual and semantic information in a joint embedding space. Four types of domain biases exist in Transductive ZSL, i.e., visual bias and semantic bias in two domains, and two visual-semantic biases exist in the seen and unseen domains. However, the existing work has only focused on specific components of these topics, leading to severe semantic ambiguity during knowledge transfer. To solve this problem, we propose a novel attribute-induced bias eliminating (AIBE) module for Transductive ZSL. Specifically, for the visual bias between the two domains, the mean-teacher module is first used to bridge the visual representation discrepancy between the two domains using unsupervised learning and unlabeled images. Then, an attentional graph attribute embedding process is proposed to reduce the semantic bias between seen and unseen categories using a graph operation to describe the semantic relationship between categories. To reduce semantic-visual bias in the seen domain, we align the visual center of each category with the corresponding semantic attributes instead of with the individual visual data point, which preserves the semantic relationship in the embedding space. Finally, for the semantic-visual bias in the unseen domain, an unseen semantic alignment constraint is designed to align visual and semantic space using an unsupervised process. The evaluations on several benchmarks demonstrate the effectiveness of the proposed method, e.g., 82.8%\/75.5%, 97.1%\/82.5%, and 73.2%\/52.1% for Conventional\/Generalized ZSL settings for CUB, AwA2, and SUN datasets, respectively.","375":"Purpose\nTo organize a multi-institute knee MRI segmentation challenge for characterizing the semantic and clinical efficacy of automatic segmentation methods relevant for monitoring osteoarthritis progression.\n\n\nMaterials and Methods\nA dataset partition consisting of three-dimensional knee MRI from 88 retrospective patients at two time points (baseline and 1-year follow-up) with ground truth articular (femoral, tibial, and patellar) cartilage and meniscus segmentations was standardized. Challenge submissions and a majority-vote ensemble were evaluated against ground truth segmentations using Dice score, average symmetric surface distance, volumetric overlap error, and coefficient of variation on a holdout test set. Similarities in automated segmentations were measured using pairwise Dice coefficient correlations. Articular cartilage thickness was computed longitudinally and with scans. Correlation between thickness error and segmentation metrics was measured using the Pearson correlation coefficient. Two empirical upper bounds for ensemble performance were computed using combinations of model outputs that consolidated true positives and true negatives.\n\n\nResults\nSix teams (T 1-T 6) submitted entries for the challenge. No differences were observed across any segmentation metrics for any tissues (P = .99) among the four top-performing networks (T 2, T 3, T 4, T 6). Dice coefficient correlations between network pairs were high (> 0.85). Per-scan thickness errors were negligible among networks T 1-T 4 (P = .99), and longitudinal changes showed minimal bias (< 0.03 mm). Low correlations (\u03c1 < 0.41) were observed between segmentation metrics and thickness error. The majority-vote ensemble was comparable to top-performing networks (P = .99). Empirical upper-bound performances were similar for both combinations (P = .99).\n\n\nConclusion\nDiverse networks learned to segment the knee similarly, where high segmentation accuracy did not correlate with cartilage thickness accuracy and voting ensembles did not exceed individual network performance.See also the commentary by Elhalawani and Mak in this issue.Keywords: Cartilage, Knee, MR-Imaging, Segmentation \u00a9 RSNA, 2020Supplemental material is available for this article.","376":null,"377":"Automatic medical image report generation has drawn growing attention due to its potential to alleviate radiologists\u2019 workload. Existing work on report generation often trains encoder-decoder networks to generate complete reports. However, such models are affected by data bias (e.g. label imbalance) and face common issues inherent in text generation models (e.g. repetition). In this work, we focus on reporting abnormal findings on radiology images; instead of training on complete radiology reports, we propose a method to identify abnormal findings from the reports in addition to grouping them with unsupervised clustering and minimal rules. We formulate the task as cross-modal retrieval and propose Conditional Visual-Semantic Embeddings to align images and fine-grained abnormal findings in a joint embedding space. We demonstrate that our method is able to retrieve abnormal findings and outperforms existing generation models on both clinical correctness and text generation metrics.","378":null,"379":"Training datasets for semantic parsing are typically small due to the higher expertise required for annotation than most other NLP tasks. As a result, models for this application usually need additional prior knowledge to be built into the architecture or algorithm. The increased dependency on human experts hinders automation and raises the development and maintenance costs in practice. This work investigates whether a generic transformer-based seq2seq model can achieve competitive performance with minimal code-generation-specific inductive bias design. By exploiting a relatively sizeable monolingual corpus of the target programming language, which is cheap to mine from the web, we achieved 81.03% exact match accuracy on Django and 32.57 BLEU score on CoNaLa. Both are SOTA to the best of our knowledge. This positive evidence highlights a potentially easier path toward building accurate semantic parsers in practice.","380":"We investigate the problem of object relationship classification of visual scenes. For a relationship object1-predicate-object2 that captures the object interaction, its representation is composed by the combination of object1 and object2 features. As a result, relationship classification models usually bias to the frequent objects, leading to poor generalization to rare or unseen objects. Inspired by the data augmentation methods, we propose a novel Semantic Transform Generative Adversarial Network (ST-GAN) that synthesizes relationship features for rare objects, conditioned on the features from random instances of the objects. Specifically, ST-GAN essentially offers a semantic transform function from cheap object features to expensive relationship features. Here, \u201ccheap\u201d means any easy-to-collect object which possesses an original but undesired relationship attribute, e.g., a sitting person; \u201cexpensive\u201d means a target relationship on this object, e.g., person-riding-horse. By generating massive triplet combinations from any object pair with larger variance, ST-GAN can reduce the data bias. Extensive experiments on two benchmarks \u2013 Visual Relationship Detection (VRD) and Visual Genome (VG), show that using our synthesized features for data augmentation, the relationship classification model can be consistently improved in various settings such as zero-shot and low-shot.","381":"Abstractive dialogue summarization suffers from a lots of factual errors, which are due to scattered salient elements in the multi-speaker information interaction process. In this work, we design a heterogeneous semantic slot graph with a slot-level mask cross-attention to enhance the slot features for more correct summarization. We also propose a slot-driven beam search algorithm in the decoding process to give priority to generating salient elements in a limited length by \u201cfilling-in-the-blanks\u201d. Besides, an adversarial contrastive learning assisting the training process is introduced to alleviate the exposure bias. Experimental performance on different types of factual errors shows the effectiveness of our methods and human evaluation further verifies the results.ive dialogue summarization suffers from a lots of factual errors, which are due to scattered salient elements in the multi-speaker information interaction process. In this work, we design a heterogeneous semantic slot graph with a slot-level mask cross-attention to enhance the slot features for more correct summarization. We also propose a slot-driven beam search algorithm in the decoding process to give priority to generating salient elements in a limited length by \u201cfilling-in-the-blanks\u201d. Besides, an adversarial contrastive learning assisting the training process is introduced to alleviate the exposure bias. Experimental performance on different types of factual errors shows the effectiveness of our methods and human evaluation further verifies the results.","382":"Person segmentation in images has various applications, for example, smart home, human\u2013computer interaction, and scene perception for self-driving cars, which are a key feature of the Internet of Things. Due to limitations in performance, such as accuracy and runtime, most traditional methods do not fulfill the practical requirements. Deep learning-based modern segmentation systems become prevalent. Fully convolutional network (FCN), as a classic image semantic segmentation method, directly optimizes the semantic map from the original image in a pixel-wise manner without using pixel-correlations or global object information. In this paper, we propose an efficient end-to-end person segmentation network structure fusing the person detection network with the FCN. The person detection network estimates the region of interest of persons and enforces the segmentation network to focus on the optimization of person segmentation. The loss function of the proposed network considers both the segmentation error and the detection bias error. In addition, the lightweight design of the detection network that optimizes only person bounding-box coordinates enables real-time person detection. The experimental comparison and analysis of several different networks on several datasets show the effectiveness of the proposed fusion strategy. The approach shows a promising practical application potential by fast running time and high segmentation accuracy.","383":"An important development in deep learning from the earliest MLPs has been a move towards architectures with structural inductive biases which enable the model to keep distinct sources of information and routes of processing well-separated. This structure is linked to the notion of independent mechanisms from the causality literature, in which a mechanism is able to retain the same processing as irrelevant aspects of the world are changed. For example, convnets enable separation over positions, while attention-based architectures (especially Transformers) learn which combination of positions to process dynamically. In this work we explore a way in which the Transformer architecture is deficient: it represents each position with a large monolithic hidden representation and a single set of parameters which are applied over the entire hidden representation. This potentially throws unrelated sources of information together, and limits the Transformer\u2019s ability to capture independent mechanisms. To address this, we propose Transformers with Independent Mechanisms (TIM), a new Transformer layer which divides the hidden representation and parameters into multiple mechanisms, which only exchange information through attention. Additionally, we propose a competition mechanism which encourages these mechanisms to specialize over time steps, and thus be more independent. We study TIM on a large-scale BERT model, on the Image Transformer, and on speech enhancement and find evidence for semantically meaningful specialization as well as improved performance. Mila, University of Montreal Microsoft Research Asia Research Center for Information Technology Innovation, Academia Sinica. Correspondence to: Alex Lamb <lambalex@iro.umontreal.ca>, Di He <dihe@microsoft.com>.","384":"Along with predictive performance and runtime speed, robustness is a key requirement for real-world semantic segmentation. Robustness encompasses accuracy, predictive uncertainty, stability under data perturbation and distribution shift, and reduced bias. To improve robustness, we introduce Superpixel-mix, a new superpixel-based data augmentation method with teacher-student consistency training. Unlike other mixingbased augmentation techniques, mixing superpixels between images is aware of object boundaries, while yielding consistent gains in segmentation accuracy. Our proposed technique achieves state-of-the-art results in semi-supervised semantic segmentation on the Cityscapes dataset. Moreover, Superpixel-mix improves the robustness of semantic segmentation by reducing network uncertainty and bias, as confirmed by competitive results under strong distributions shift (adverse weather, image corruptions) and when facing out-of-distribution data.","385":"Beyond the common difficulties faced in the natural image captioning, medical report generation specifically requires the model to describe a medical image with a fine-grained and semantic-coherence paragraph that should satisfy both medical commonsense and logic. Previous works generally extract the global image features and attempt to generate a paragraph that is similar to referenced reports; however, this approach has two limitations. Firstly, the regions of primary interest to radiologists are usually located in a small area of the global image, meaning that the remainder parts of the image could be considered as irrelevant noise in the training procedure. Secondly, there are many similar sentences used in each medical report to describe the normal regions of the image, which causes serious data bias. This deviation is likely to teach models to generate these inessential sentences on a regular basis. To address these problems, we propose an Auxiliary Signal-Guided Knowledge Encoder-Decoder (ASGK) to mimic radiologists' working patterns. In more detail, ASGK integrates internal visual feature fusion and external medical linguistic information to guide medical knowledge transfer and learning. The core structure of ASGK consists of a medical graph encoder and a natural language decoder, inspired by advanced Generative Pre-Training (GPT). Experiments on the CX-CHR dataset and our COVID-19 CT Report dataset demonstrate that our proposed ASGK is able to generate a robust and accurate report, and moreover outperforms state-of-the-art methods on both medical terminology classification and paragraph generation metrics.","386":"The capability of the traditional semi-supervised learning (SSL) methods is far from real-world application since they do not consider (1) class imbalance and (2) class distribution mismatch between labeled and unlabeled data. This paper addresses such a relatively under-explored problem, imbalanced semi-supervised learning, where heavily biased pseudo-labels can harm the model performance. Interestingly, we find that the semantic pseudo-labels from a similarity-based classifier in feature space and the traditional pseudo-labels from the linear classifier show the complementary property. To this end, we propose a general pseudo-labeling framework to address the bias motivated by this observation. The key idea is to class-adaptively blend the semantic pseudo-label to the linear one, depending on the current pseudo-label distribution. Thereby, the increased semantic pseudo-label component suppresses the false positives in the majority classes and vice versa. We term the novel pseudo-labeling framework for imbalanced SSL as Distribution-Aware Semantics-Oriented (DASO) Pseudo-label. Extensive evaluation on CIFAR10\/100-LT and STL10-LT shows that DASO consistently outperforms both recently proposed re-balancing methods for label and pseudo-label. Moreover, we demonstrate that typical SSL algorithms can effectively benefit from unlabeled data with DASO, especially when (1) class imbalance and (2) class distribution mismatch exist and even on recent real-world Semi-Aves benchmark.","387":"Abstract Transformer-based language models have taken many fields in NLP by storm. BERT and its derivatives dominate most of the existing evaluation benchmarks, including those for Word Sense Disambiguation (WSD), thanks to their ability in capturing context-sensitive semantic nuances. However, there is still little knowledge about their capabilities and potential limitations in encoding and recovering word senses. In this article, we provide an in-depth quantitative and qualitative analysis of the celebrated BERT model with respect to lexical ambiguity. One of the main conclusions of our analysis is that BERT can accurately capture high-level sense distinctions, even when a limited number of examples is available for each word sense. Our analysis also reveals that in some cases language models come close to solving coarse-grained noun disambiguation under ideal conditions in terms of availability of training data and computing resources. However, this scenario rarely occurs in real-world settings and, hence, many practical challenges remain even in the coarse-grained setting. We also perform an in-depth comparison of the two main language model-based WSD strategies, namely, fine-tuning and feature extraction, finding that the latter approach is more robust with respect to sense bias and it can better exploit limited available training data. In fact, the simple feature extraction strategy of averaging contextualized embeddings proves robust even using only three training sentences per word sense, with minimal improvements obtained by increasing the size of this training data.","388":"Pretraining Neural Language Models (NLMs) over a large corpus involves chunking the text into training examples, which are contiguous text segments of sizes processable by the neural architecture. We highlight a bias introduced by this common practice: we prove that the pretrained NLM can model much stronger dependencies between text segments that appeared in the same training example, than it can between text segments that appeared in different training examples. This intuitive result has a twofold role. First, it formalizes the motivation behind a broad line of recent successful NLM training heuristics, proposed for the pretraining and fine-tuning stages, which do not necessarily appear related at first glance. Second, our result clearly indicates further improvements to be made in NLM pretraining for the benefit of Natural Language Understanding tasks. As an example, we propose \u201ckNN-Pretraining\": we show that including semantically related non-neighboring sentences in the same pretraining example yields improved sentence representations and open domain question answering abilities. This theoretically motivated degree of freedom for pretraining example design indicates new training schemes for self-improving representations.","389":"Unconscious biases continue to be prevalent in modern text and media, calling for algorithms that can assist writers with bias correction. For example, a female character in a story is often portrayed as passive and powerless (\u201c_She daydreams about being a doctor_\u201d) while a man is portrayed as more proactive and powerful (\u201c_He pursues his dream of being a doctor_\u201d). We formulate **Controllable Debiasing**, a new revision task that aims to rewrite a given text to correct the implicit and potentially undesirable bias in character portrayals. We then introduce PowerTransformer as an approach that debiases text through the lens of connotation frames (Sap et al., 2017), which encode pragmatic knowledge of implied power dynamics with respect to verb predicates. One key challenge of our task is the lack of parallel corpora. To address this challenge, we adopt an unsupervised approach using auxiliary supervision with related tasks such as paraphrasing and self-supervision based on a reconstruction loss, building on pretrained language models. Through comprehensive experiments based on automatic and human evaluations, we demonstrate that our approach outperforms ablations and existing methods from related tasks. Furthermore, we demonstrate the use of PowerTransformer as a step toward mitigating the well-documented gender bias in character portrayal in movie scripts.","390":"With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.","391":"Assessment of risk of bias is regarded as an essential component of a systematic review on the effects of an intervention. The most commonly used tool for randomised trials is the Cochrane risk-of-bias tool. We updated the tool to respond to developments in understanding how bias arises in randomised trials, and to address user feedback on and limitations of the original tool.","392":"We investigate how annotators\u2019 insensitivity to differences in dialect can lead to racial bias in automatic hate speech detection models, potentially amplifying harm against minority populations. We first uncover unexpected correlations between surface markers of African American English (AAE) and ratings of toxicity in several widely-used hate speech datasets. Then, we show that models trained on these corpora acquire and propagate these biases, such that AAE tweets and tweets by self-identified African Americans are up to two times more likely to be labelled as offensive compared to others. Finally, we propose *dialect* and *race priming* as ways to reduce the racial bias in annotation, showing that when annotators are made explicitly aware of an AAE tweet\u2019s dialect they are significantly less likely to label the tweet as offensive.","393":null,"394":null,"395":"Word embeddings carry stereotypical connotations from the text they are trained on, which can lead to invalid inferences in downstream models that rely on them. We use this observation to design a mechanism for measuring stereotypes using the task of natural language inference. We demonstrate a reduction in invalid inferences via bias mitigation strategies on static word embeddings (GloVe). Further, we show that for gender bias, these techniques extend to contextualized embeddings when applied selectively only to the static components of contextualized embeddings (ELMo, BERT).","396":"We focus on the ways in which we can use a frequentist interpretation of probability to develop suitable methods for statistical inference. The discussion about the controversy in the foundations reveals that a frequentist conception is highly prone to dispute, as a justification of it fails from a rational perspective when the explication of probability integrates statistical inference. We give an overview on the dispute and the crucial examples that highlight the deficiencies of a purely frequentist position towards probability. The concept of probability emerges from a mixture of meanings. A shift in connotation of probability towards a biased frequentist meaning decreases the scope of probability or the quality of applications. Probability is a complementary concept, which falls apart if we reduce it to one view. This gives rise to investigate approaches towards teaching from a wider perspective on the range of meanings of probability apart from frequentist aspects. Empirical studies show the shortcomings of educational approaches that ignore subjectivist aspects of probability, which leads to far-reaching misconceptions not only about the use of Bayes\u2019 formula but also in the perception of probabilities at large.","397":"Social Networking sites have become popular and common places for sharing wide range of emotions through \nshort texts. These emotions include happiness, sadness, anxiety, fear, etc. Analyzing short texts helps in identifying \nthe sentiment expressed by the crowd. Sentiment Analysis on IMDb movie reviews identifies the overall sentiment \nor opinion expressed by a reviewer towards a movie. Many researchers are working on pruning the sentiment \nanalysis model that clearly identifies and distinguishes between a positive review and a negative review. In the \nproposed work, we show that the use of Hybrid features obtained by concatenating Machine Learning features (TF, \nTF-IDF) with Lexicon features (Positive-Negative word count, Connotation) gives better results both in terms of \naccuracy and complexity when tested against classifiers like SVM, Naive Bayes, KNN and Maximum Entropy. \nThe proposed model clearly differentiates between a positive review and negative review. Since understanding the \ncontext of the reviews plays an important role in classification, using hybrid features helps in capturing the context \nof the movie reviews and hence increases the accuracy of classification.","398":"Bias in word representations, such as Word2Vec, has been widely reported and investigated, and efforts made to debias them. We apply the debiasing conceptor for post-processing both traditional and contextualized word embeddings. Our method can simultaneously remove racial and gender biases from word representations. Unlike standard debiasing methods, the debiasing conceptor can utilize heterogeneous lists of biased words without loss in performance. Finally, our empirical experiments show that the debiasing conceptor diminishes racial and gender bias of word representations as measured using the Word Embedding Association Test (WEAT) of Caliskan et al. (2017).","399":"Social clustering and stereotyping are both unavoidable and necessary to navigate and try to make sense of the social world and yet also a source of major moral blind spots. It is part of the necessity to parse to predict, make decisions, and, ultimately, create meanings. This process leads to our natural inclination to cluster and create an information amalgam leading to much illusory correlations and biased attitudes in thinking about Blacks, Whites, Russians, Chinese, women, men, gays, straights, or Europeans as wholes having in common elusive essential characteristics. Social stereotypes have typically a negative connotation, linked to racism and all sorts of prejudices and discrimination toward minorities. However, they can be both negative and\/or positive (e.g., Jews tend to be smart; Blacks are prone to be criminals). The ultimate function of social clustering and stereotypes is always to create contrasts that typically uphold one\u2019s own group advantage, ultimately in defense of one\u2019s own group sense of superiority and ascendance. Social stereotypes do not just help us in thinking about the social world; they can also hinder how we perform as individuals and foresee obstacles for oneself.","400":"This paper presents a strong set of results for resolving gendered ambiguous pronouns on the Gendered Ambiguous Pronouns shared task. The model presented here draws upon the strengths of state-of-the-art language and coreference resolution models, and introduces a novel evidence-based deep learning architecture. Injecting evidence from the coreference models compliments the base architecture, and analysis shows that the model is not hindered by their weaknesses, specifically gender bias. The modularity and simplicity of the architecture make it very easy to extend for further improvement and applicable to other NLP problems. Evaluation on GAP test data results in a state-of-the-art performance at 92.5% F1 (gender bias of 0.97), edging closer to the human performance of 96.6%. The end-to-end solution presented here placed 1st in the Kaggle competition, winning by a significant lead.","401":"Specific lexical choices in how people are portrayed both reflect the writer's attitudes towards people in the narrative and influence the audience's reactions. Prior work has examined descriptions of people in English using contextual affective analysis, a natural language processing (NLP) technique that seeks to analyze how people are portrayed along dimensions of power, agency, and sentiment. Our work presents an extension of this methodology to multilingual settings, which is enabled by a new corpus that we collect and a new multilingual model. We additionally show how word connotations differ across languages and cultures, which makes existing English datasets and methods difficult to generalize. We then demonstrate the usefulness of our method by analyzing Wikipedia biography pages of members of the LGBT community across three languages: English, Russian, and Spanish. Our results show systematic differences in how the LGBT community is portrayed across languages, surfacing cultural differences in narratives and signs of social biases. Practically, this model can be used to surface Wikipedia articles for further manual analysis---articles that might contain content gaps or an imbalanced representation of particular social groups.","402":"language language that evokes many different visual images in the minds of your audience democratic republic. The word \u201cliberal\u201d has shifted meaning, another trait of language, since meaning exists in the minds of users, not in some protected, never-changing space or form. In the majority of Americans\u2019 minds, \u201cliberal\u201d has become associated with specific political positions rather than a form of government in general. To most people \u201cprogressive\u201d sounds better, although an historian could argue the word is technically being used incorrectly. It doesn\u2019t matter, because a word doesn\u2019t \u201chave\u201d meaning; meaning exists in the minds of people using the word. If \u201cprogressive\u201d hits people and evokes or stirs up ideas of forward-thinking, young, active, problemsolving people, then good. For most people it doesn\u2019t bring up pictures of Woodrow Wilson and suffragists. These examples bring up another issue with language: words change meaning over time, or more specifically, the meaning we attached to them changes. \u201cPretty\u201d used to mean \u201cclever\u201d 250 years ago. \u201cPrevent\u201d meant to \u201cprecede,\u201d not to keep from happening. Language is simply not static, as much as we might like it to be. One of the main reasons we find Shakespeare daunting is that so many of the Elizabethan words either no longer are used or they have changed meanings. With regard to the use of language for power, even unknowingly, feminists in the 1970s argued that the common way we use English language was biased against women. King-sized means \u201cbig and powerful,\u201d but \u201cqueensized\u201d means \u201cfor overweight women.\u201d \u201cMaster\u201d was not equivalent to \u201cmistress.\u201d \u201cMadame\u201d had taken on a bad connotation, even though it should have been equivalent to \u201csir.\u201d Many words referring to women had to add a suffix that was often \u201cless than,\u201d such as \u201c-ess\u201d or \u201c-ette\u201d or \u201cco-ed.\u201d In the last thirty years we have gotten away from that, so that you often hear a female actor referred to as \u201cactor\u201d rather than \u201cactress,\u201d but old habits die hard. We see another example of power in language in the abortion debate. Prior to 1973, abortions could be obtained legally, to some extent, in three states: California, New York, and Hawaii. After the Roe v. Wade decision in January of 1973, they could, at least theoretically, be obtained in all fifty states. Roe v. Wade did not make abortions legal so much as it made anti-abortion laws illegal or unconstitutional, so the effect was generally the same. The people who were against abortion were now on the defensive, and they had to start fighting. It\u2019s generally better to be \u201cpro-\u201dsomething rather than \u201canti-\u201dsomething, so they became \u201cpro-life.\u201d Those favoring abortion rights then automatically became \u201cpro-death.\u201d One side had defined the terms of the debate, and the other had to come up with something comparable. \u201cPro-choice\u201d takes advantage of the American belief in capitalism and freedoms. These examples show how \u201cdefining the terms\u201d gives a person control of the discourse. As you progress as a public speaker, you will become more aware of the power certain words have over audiences. An ethical communicator will use language in a way that encourages respect for others, freedom of thought, and informed decision making. First, however, a speaker should seek to meet the standards of clarity, effectiveness, appropriateness, and elegance in language, which are discussed in the next section. Standards for Language in Public Speaking Clear language is powerful language. Clarity is the first concern of a public speaker when it comes to choosing how to phrase the ideas of his or her speech. If you are not clear, specific, precise, detailed, and sensory with your language, you won\u2019t have to worry about being emotional or persuasive, because you won\u2019t be understood. There are many aspects of clarity in language, listed below.","403":"Recent studies have shown that word embeddings exhibit gender bias inherited from the training corpora. However, most studies to date have focused on quantifying and mitigating such bias only in English. These analyses cannot be directly extended to languages that exhibit morphological agreement on gender, such as Spanish and French. In this paper, we propose new metrics for evaluating gender bias in word embeddings of these languages and further demonstrate evidence of gender bias in bilingual embeddings which align these languages with English. Finally, we extend an existing approach to mitigate gender bias in word embedding of these languages under both monolingual and bilingual settings. Experiments on modified Word Embedding Association Test, word similarity, word translation, and word pair translation tasks show that the proposed approaches can effectively reduce the gender bias while preserving the utility of the original embeddings.","404":"NLU models often exploit biases to achieve high dataset-specific performance without properly learning the intended task. Recently proposed debiasing methods are shown to be effective in mitigating this tendency. However, these methods rely on a major assumption that the types of bias should be known a-priori, which limits their application to many NLU tasks and datasets. In this work, we present the first step to bridge this gap by introducing a self-debiasing framework that prevents models from mainly utilizing biases without knowing them in advance. The proposed framework is general and complementary to the existing debiasing methods. We show that it allows these existing methods to retain the improvement on the challenge datasets (i.e., sets of examples designed to expose models' reliance on biases) without specifically targeting certain biases. Furthermore, the evaluation suggests that applying the framework results in improved overall robustness.","405":"In recent years, research has revealed gender biases in numerous software products. But although some researchers have found ways to improve gender participation in specific software projects, general methods focus mainly on detecting gender biases -- not fixing them. To help fill this gap, we investigated whether the GenderMag bias detection method can lead directly to designs with fewer gender biases. In our 3-step investigation, two HCI researchers analyzed an industrial software product using GenderMag; we derived design changes to the product using the biases they found; and ran an empirical study of participants using the original product versus the new version. The results showed that using the method in this way did improve the software's inclusiveness: women succeeded more often in the new version than in the original; men's success rates improved too; and the gender gap entirely disappeared.","406":"State-of-the-art models often make use of superficial patterns in the data that do not generalize well to out-of-domain or adversarial settings. For example, textual entailment models often learn that particular key words imply entailment, irrespective of context, and visual question answering models learn to predict prototypical answers, without considering evidence in the image. In this paper, we show that if we have prior knowledge of such biases, we can train a model to be more robust to domain shift. Our method has two stages: we (1) train a naive model that makes predictions exclusively based on dataset biases, and (2) train a robust model as part of an ensemble with the naive one in order to encourage it to focus on other patterns in the data that are more likely to generalize. Experiments on five datasets with out-of-domain test sets show significantly improved robustness in all settings, including a 12 point gain on a changing priors visual question answering dataset and a 9 point gain on an adversarial question answering test set.","407":"Reports of successful applications of machine learning (ML) methods in structure-based virtual screening (SBVS) are increasing. ML methods such as convolutional neural networks show promising results and often outperform traditional methods such as empirical scoring functions in retrospective validation. However, trained ML models are often treated as black boxes and are not straightforwardly interpretable. In most cases, it is unknown which features in the data are decisive and whether a model's predictions are right for the right reason. Hence, we re-evaluated three widely used benchmark data sets in the context of ML methods and came to the conclusion that not every benchmark data set is suitable. Moreover, we demonstrate on two examples from current literature that bias is learned implicitly and unnoticed from standard benchmarks. On the basis of these results, we conclude that there is a need for eligible validation experiments and benchmark data sets suited to ML for more bias-controlled validation in ML-based SBVS. Therefore, we provide guidelines for setting up validation experiments and give a perspective on how new data sets could be generated.","408":"In this paper, we seek to understand how politicians use images to express ideological rhetoric through Facebook images posted by members of the U.S. House and Senate. In the era of social media, politics has become saturated with imagery, a potent and emotionally salient form of political rhetoric which has been used by politicians and political organizations to influence public sentiment and voting behavior for well over a century. To date, however, little is known about how images are used as political rhetoric. Using deep learning techniques to automatically predict Republican or Democratic party affiliation solely from the Facebook photographs of the members of the 114th U.S. Congress, we demonstrate that predicted class probabilities from our model function as an accurate proxy of the political ideology of images along a left-right (liberal-conservative) dimension. After controlling for the gender and race of politicians, our method achieves an accuracy of 59.28% from single photographs and 82.35% when aggregating scores from multiple photographs (up to 150) of the same person. To better understand image content distinguishing liberal from conservative images, we also perform in-depth content analyses of the photographs. Our findings suggest that conservatives tend to use more images supporting status quo political institutions and hierarchy maintenance, featuring individuals from dominant social groups, and displaying greater happiness than liberals.","409":"We explore the task of predicting the leading political ideology or bias of news articles. First, we collect and release a large dataset of 34,737 articles that were manually annotated for political ideology -left, center, or right-, which is well-balanced across both topics and media. We further use a challenging experimental setup where the test examples come from media that were not seen during training, which prevents the model from learning to detect the source of the target news article instead of predicting its political ideology. From a modeling perspective, we propose an adversarial media adaptation, as well as a specially adapted triplet loss. We further add background information about the source, and we show that it is quite helpful for improving article-level prediction. Our experimental results show very sizable improvements over using state-of-the-art pre-trained Transformers in this challenging setup.","410":"In the context of fake news, bias, and propaganda, we study two important but relatively under-explored problems: (i) trustworthiness estimation (on a 3-point scale) and (ii) political ideology detection (left\/right bias on a 7-point scale) of entire news outlets, as opposed to evaluating individual articles. In particular, we propose a multi-task ordinal regression framework that models the two problems jointly. This is motivated by the observation that hyper-partisanship is often linked to low trustworthiness, e.g., appealing to emotions rather than sticking to the facts, while center media tend to be generally more impartial and trustworthy. We further use several auxiliary tasks, modeling centrality, hyper-partisanship, as well as left-vs.-right bias on a coarse-grained scale. The evaluation results show sizable performance gains by the joint models over models that target the problems in isolation.","411":"Background Social media chatter in 2020 has been largely dominated by the COVID-19 pandemic. Existing research shows that COVID-19 discourse is highly politicized, with political preferences linked to beliefs and disbeliefs about the virus. As it happens with topics that become politicized, people may fall into echo chambers, which is the idea that one is only presented with information they already agree with, thereby reinforcing one\u2019s confirmation bias. Understanding the relationship between information dissemination and political preference is crucial for effective public health communication. Objective We aimed to study the extent of polarization and examine the structure of echo chambers related to COVID-19 discourse on Twitter in the United States. Methods First, we presented Retweet-BERT, a scalable and highly accurate model for estimating user polarity by leveraging language features and network structures. Then, by analyzing the user polarity predicted by Retweet-BERT, we provided new insights into the characterization of partisan users. Results We observed that right-leaning users were noticeably more vocal and active in the production and consumption of COVID-19 information. We also found that most of the highly influential users were partisan, which may contribute to further polarization. Importantly, while echo chambers exist in both the right- and left-leaning communities, the right-leaning community was by far more densely connected within their echo chamber and isolated from the rest. Conclusions We provided empirical evidence that political echo chambers are prevalent, especially in the right-leaning community, which can exacerbate the exposure to information in line with pre-existing users\u2019 views. Our findings have broader implications in developing effective public health campaigns and promoting the circulation of factual information online.","412":"Echo chambers and opinion polarization recently quantified in several sociopolitical contexts and across different social media raise concerns on their potential impact on the spread of misinformation and on the openness of debates. Despite increasing efforts, the dynamics leading to the emergence of these phenomena remain unclear. We propose a model that introduces the dynamics of radicalization as a reinforcing mechanism driving the evolution to extreme opinions from moderate initial conditions. Inspired by empirical findings on social interaction dynamics, we consider agents characterized by heterogeneous activities and homophily. We show that the transition between a global consensus and emerging radicalized states is mostly governed by social influence and by the controversialness of the topic discussed. Compared with empirical data of polarized debates on Twitter, the model qualitatively reproduces the observed relation between users' engagement and opinions, as well as opinion segregation in the interaction network. Our findings shed light on the mechanisms that may lie at the core of the emergence of echo chambers and polarization in social media.","413":"During 2020, social media chatter has been largely dominated by the COVID-19 pandemic. In this paper, we study the extent of polarization of COVID-19 discourse on Twitter in the U.S. First, we propose Retweet-BERT, a scalable and highly accurate model for estimating user polarity by leveraging language features and network structures. Then, by analyzing the user polarity predicted by Retweet-BERT, we provide new insights into the characterization of partisan users. Right-leaning users, we find, are noticeably more vocal and active in the production and consumption of COVID-19 information. Our analysis also shows that most of the highly influential users are partisan, which may contribute to further polarization. Crucially, we provide empirical evidence that political echo chambers are prevalent, exacerbating the exposure to information in line with pre-existing users' views. Our findings have broader implications in developing effective public health campaigns and promoting the circulation of factual information online.","414":null,"415":"Personalized recommendation benefits users in accessing contents of interests effectively. Current research on recommender systems mostly focuses on matching users with proper items based on user interests. However, significant efforts are missing to understand how the recommendations influence user preferences and behaviors, e.g., if and how recommendations result in echo chambers. Extensive efforts have been made in examining the phenomenon in online media and social network systems. Meanwhile, there are growing concerns that recommender systems might lead to the self-reinforcing of user's interests due to narrowed exposure of items, which may be the potential cause of echo chamber. In this paper, we aim to analyze the echo chamber phenomenon in Alibaba Taobao --- one of the largest e-commerce platforms in the world. Echo chamber means the effect of user interests being reinforced through repeated exposure to similar contents. Based on the definition, we examine the presence of echo chamber in two steps. First, we explore whether user interests have been reinforced. Second, we check whether the reinforcement results from the exposure of similar contents. Our evaluations are enhanced with robust metrics, including cluster validity and statistical significance. Experiments are performed on extensive collections of real-world data consisting of user clicks, purchases, and browse logs from Alibaba Taobao. Evidence suggests the tendency of echo chamber in user click behaviors, while it is relatively mitigated in user purchase behaviors. Insights from the results guide the refinement of recommendation algorithms in real-world e-commerce systems.","416":"The effects of social media on critical issues, such as polarization and misinformation, are under scrutiny due to the disruptive consequences that these phenomena can have on our societies. Among the algorithms routinely used by social media platforms, people-recommender systems are of special interest, as they directly contribute to the evolution of the social network structure, affecting the information and the opinions users are exposed to. In this paper, we propose a framework to assess the effect of people recommenders on the evolution of opinions. Our proposal is based on Monte Carlo simulations combining link recommendation and opinion-dynamics models. In order to control initial conditions, we define a random network model to generate graphs with opinions, with tunable amounts of modularity and homophily. We join these elements into a methodology to study the effects of the recommender system on echo chambers and polarization. We also show how to use our framework to measure, by means of simulations, the impact of different intervention strategies. Our thorough experimentation shows that people recommenders can in fact lead to a significant increase in echo chambers. However, this happens only if there is considerable initial homophily in the network. Also, we find that if the network already contains echo chambers, the effect of the recommendation algorithm is negligible. Such findings are robust to two very different opinion dynamics models, a bounded confidence model and an epistemological model.","417":"This paper deals with the modeling and estimation of the sociological phenomena called echo chambers and segregation in social networks. Specifically, we present a novel community-based graph model that represents the emergence of segregated echo chambers as a Markov bridge process. A Markov bridge is a one-dimensional Markov random field that facilitates modeling the formation and disassociation of communities at deterministic times which is important in social networks with known timed events. We justify the proposed model with six real world examples and examine its performance on a recent Twitter dataset. We provide model parameter estimation algorithm based on maximum likelihood and, a Bayesian filtering algorithm for recursively estimating the level of segregation using noisy samples obtained from the network. Numerical results indicate that the proposed filtering algorithm outperforms the conventional hidden Markov modeling in terms of the mean-squared error. The proposed filtering method is useful in computational social science where data-driven estimation of the level of segregation from noisy data is required.","418":"Echo chambers may exclude social media users from being exposed to other opinions, therefore, can cause rampant negative effects. Among abundant evidence are the 2016 and 2020 US presidential elections conspiracy theories and polarization, as well as the COVID-19 disinfodemic. To help better detect echo chambers and mitigate its negative effects, this paper explores the mechanisms and attributes of echo chambers in social media. In particular, we first illustrate four primary mechanisms related to three main factors: human psychology, social networks, and automatic systems. We then depict common attributes of echo chambers with a focus on the diffusion of misinformation, spreading of conspiracy theory, creation of social trends, political polarization, and emotional contagion of users. We illustrate each mechanism and attribute in a multi-perspective of sociology, psychology, and social computing with recent case studies. Our analysis suggest an emerging need to detect echo chambers and mitigate their negative effects.","419":"Echo chambers on social media are a significant problem that can elicit a number of negative consequences, most recently affecting the response to COVID-19. Echo chambers promote conspiracy theories about the virus and are found to be linked to vaccine hesitancy, less compliance with mask mandates, and the practice of social distancing. Moreover, the problem of echo chambers is connected to other pertinent issues like political polarization and the spread of misinformation. An echo chamber is defined as a network of users in which users only interact with opinions that support their pre-existing beliefs and opinions, and they exclude and discredit other viewpoints. This survey aims to examine the echo chamber phenomenon on social media from a social computing perspective and provide a blueprint for possible solutions. We survey the related literature to understand the attributes of echo chambers and how they affect the individual and society at large. Additionally, we show the mechanisms, both algorithmic and psychological, that lead to the formation of echo chambers. These mechanisms could be manifested in two forms: (1) the bias of social media's recommender systems and (2) internal biases such as confirmation bias and homophily. While it is immensely challenging to mitigate internal biases, there has been great efforts seeking to mitigate the bias of recommender systems. These recommender systems take advantage of our own biases to personalize content recommendations to keep us engaged in order to watch more ads. Therefore, we further investigate different computational approaches for echo chamber detection and prevention, mainly based around recommender systems.","420":"Recent studies have shown that online users tend to select information adhering to their system of beliefs, ignore information that does not, and join groups - i.e., echo chambers - around a shared narrative. Although a quantitative methodology for their identification is still missing, the phenomenon of echo chambers is widely debated both at scientific and political level. To shed light on this issue, we introduce an operational definition of echo chambers and perform a massive comparative analysis on more than 1B pieces of contents produced by 1M users on four social media platforms: Facebook, Twitter, Reddit, and Gab. We infer the leaning of users about controversial topics - ranging from vaccines to abortion - and reconstruct their interaction networks by analyzing different features, such as shared links domain, followed pages, follower relationship and commented posts. Our method quantifies the existence of echo-chambers along two main dimensions: homophily in the interaction networks and bias in the information diffusion toward likely-minded peers. We find peculiar differences across social media. Indeed, while Facebook and Twitter present clear-cut echo chambers in all the observed dataset, Reddit and Gab do not. Finally, we test the role of the social media platform on news consumption by comparing Reddit and Facebook. Again, we find support for the hypothesis that platforms implementing news feed algorithms like Facebook may elicit the emergence of echo-chambers.","421":"In recent years, social media has increasingly become an important platform for political campaigns, especially elections. It remains elusive how exactly public discourse is driven by the intricate interplay between individual socio-cognitive biases, dueling campaign efforts, and social media platforms. We examine this complex socio-political process by integrating observed retweet networks from the 2016 political networks with an agent-based model of political opinion formation and network structure. Here we show that the range of political viewpoints individuals are willing to consider is a key determinant in the formation of polarized networks and the emergence of echo chambers. We also find that winning majority support in public discourse is determined by both the effort exerted by campaigns and the relative ideological positioning of opposing campaigns. Our results demonstrate how public discourse and political polarization can be modeled as an interactive process of shifting individual opinions, evolving social networks, and political campaigns.","422":"Many observers are concerned that echo chamber effects in digital media are contributing to the polarization of publics and, in some places, to the rise of right-wing populism. This study employs survey data collected in France, the United Kingdom and the United States (1500 respondents in each country) from April to May 2017. Overall, we do not find evidence that online\/social media explain support for right-wing populist candidates and parties. Instead, in the United States, use of online media decreases support for right-wing populism. Looking specifically at echo chamber measures, we find offline discussion with those who are similar in race, ethnicity and class positively correlates with support for populist candidates and parties in the United Kingdom and France. The findings challenge claims about the role of social media and the rise of populism.","423":"Echo chambers and filter bubbles are potent metaphors that encapsulate widespread public fear that the use of social media may limit the information that users encounter or consume online. Specifically, the concern is that social media algorithms combined with tendencies to interact with like-minded others both limits users\u2019 exposure to diverse viewpoints and encourages the adoption of more extreme ideological positions. Yet empirical evidence about how social media shapes information consumption is inconclusive. We articulate how characteristics of platform algorithms and users\u2019 online social networks may combine to shape user behavior. We bring greater conceptual clarity to this phenomenon by expanding beyond discussion of a binary presence or absence of echo chambers and filter bubbles to a richer set of outcomes incorporating changes in both diversity and slant of users\u2019 information sources. Using a data set with over four years of web browsing history for a representative panel of nearly 200,000 U.S. adults, we analyzed how individuals\u2019 social media usage was associated with changes in the information sources they chose to consume. We find differentiated impacts on news consumption by platform. Increased use of Facebook was associated with increased information source diversity and a shift toward more partisan sites in news consumption; increased use of Reddit with increased diversity and a shift toward more moderate sites; and increased use of Twitter with little to no change in either. Our results demonstrate the value of adopting a nuanced multidimensional view of how social media use may shape information consumption.","424":"<jats:p \/>","425":"The spread of rumors on social media has caused increasing concerns about an under-informed or even misinformed public when it comes to scientific issues. However, researchers have rarely investigated their diffusion in non-western contexts. This study aims to systematically examine the content and network structure of rumor-related discussions around genetically modified organisms (GMOs) on Chinese social media.,This study identified 21,837 rumor-related posts of GMOs on Weibo, one of China's most popular social media platforms. An approach combining social network analysis and content analysis was employed to classify user attitudes toward rumors, measure the level of homophily of their attitudes and examine the nature of their interactions.,Though a certain level of homophily existed in the interaction networks, referring to the observed echo chamber effect, Weibo also served as a public forum for GMO discussions in which cross-cutting ties between communities existed. A considerable amount of interactions emerged between the pro- and anti-GMO camps, and most of them involved providing or requesting information, which could mitigate the likelihood of opinion polarization. Moreover, this study revealed the declining role of traditional opinion leaders and pointed toward the need for alternative strategies for efficient fact-checking.,In general, the findings of this study suggested that microblogging platforms such as Weibo can function as public forums for discussing GMOs that expose users to ideologically cross-cutting viewpoints. This study stands to provide important insights into the viral processes of scientific rumors on social media.","426":"The theory of echo chambers, which suggests that online political discussions take place in conditions of ideological homogeneity, has recently gained popularity as an explanation for patterns of political polarization and radicalization observed in many democratic countries. However, while micro-level experimental work has shown evidence that individuals may gravitate towards information that supports their beliefs, recent macro-level studies have cast doubt on whether this tendency generates echo chambers in practice, instead suggesting that cross-cutting exposures are a common feature of digital life. In this article, we offer an explanation for these diverging results. Building on cognitive dissonance theory, and making use of observational trace data taken from an online white nationalist website, we explore how individuals in an ideological 'echo chamber' engage with opposing viewpoints. We show that this type of exposure, far from being detrimental to radical online discussions, is actually a core feature of such spaces that encourages people to stay engaged. The most common 'echoes' in this echo chamber are in fact the sound of opposing viewpoints being undermined and marginalized. Hence echo chambers exist not only in spite of but thanks to the unifying presence of oppositional viewpoints. We conclude with reflections on policy implications of our study for those seeking to promote a more moderate political internet.","427":"A growing body of evidence points to critical vulnerabilities of social media, such as the emergence of partisan echo chambers and the viral spread of misinformation. We show that these vulnerabilities are amplified by abusive behaviors associated with so-called ''follow trains'' on Twitter, in which long lists of like-minded accounts are mentioned for others to follow. This leads to the formation of highly dense and hierarchical echo chambers. We present the first systematic analysis of U.S. political train networks, which involve many thousands of hyper-partisan accounts. These accounts engage in various suspicious behaviors, including some that violate platform policies: we find evidence of inauthentic automated accounts, artificial inflation of friends and followers, and abnormal content deletion. The networks are also responsible for amplifying toxic content from low-credibility and conspiratorial sources. Platforms may be reluctant to curb this kind of abuse for fear of being accused of political bias. As a result, the political echo chambers manufactured by follow trains grow denser and train accounts accumulate influence; even political leaders occasionally engage with them.","428":"In this paper, we develop an agent-based model to explore how agents\u2019 activity patterns affect echo chamber formation when their mutual interactions are controlled using a personalization system algorithm that decides what information users will be exposed to. In our model, agents can undertake two types of actions: publish a post and like a post. Our experiments revealed that the key parameter that guides agents\u2019 opinion dynamics is the probability of publishing a post: agents who often publish posts tend to enter echo chambers. In contrast, the roles of network topology and liking behavior are far less influential.","429":"This paper studies some benefits of ignoring those who disagree with you. We model a decision maker who draws a signal about the (real-valued) state of the world from a collection of unbiased sources of heterogeneous quality. Exclusively sampling signals close to the prior expectation can be beneficial, as they are more likely high quality. Since echo chambers are a rational response to uncertain information quality, eliminating them can backfire. Signals close to the prior expectation can move beliefs further than more contrary views; limiting the ability to ignore opposing views can make beliefs less accurate and reduce the extent to which signals are heeded.","430":"Sudden shifts in population health and vaccination rates occur as the dynamics of some epidemiological models go through a critical point; literature shows that this is sometimes foreshadowed by early warning signals (EWS). We investigate different structural measures of a network as candidate EWS of infectious disease outbreaks and changes in popular vaccine sentiment. We construct a multiplex disease model coupling infectious disease spread and social contact dynamics. We find that the number and mean size of echo chambers predict transitions in the infection dynamics, as do opinion-based communities. Graph modularity also gives early warnings, though the clustering coefficient shows no significant pre-outbreak changes. Change point tests applied to the EWS show decreasing efficacy as social norms strengthen. Therefore, many measures of social network connectivity can predict approaching critical changes in vaccine uptake and aggregate health, thereby providing valuable tools for improving public health.","431":"Recommendation systems underpin the serving of nearly all online content in the modern age. From Youtube and Netflix recommendations, to Facebook feeds and Google searches, these systems are designed to filter content to the predicted preferences of users. Recently, these systems have faced growing criticism with respect to their impact on content diversity, social polarization, and the health of public discourse. In this work we simulate the recommendations given by collaborative filtering algorithms on users in the MovieLens data set. We find that prolonged exposure to system-generated recommendations substantially decreases content diversity, moving individual users into \"echo-chambers\" characterized by a narrow range of content. Furthermore, our work suggests that once these echo-chambers have been established, it is difficult for an individual user to break out by manipulating solely their own rating vector.","432":"Although it is understudied relative to other social media platforms, YouTube is arguably the largest and most engaging online media consumption platform in the world. Recently, YouTube's outsize influence has sparked concerns that its recommendation algorithm systematically directs users to radical right-wing content. Here we investigate these concerns with large scale longitudinal data of individuals' browsing behavior spanning January 2016 through December 2019. Consistent with previous work, we find that political news content accounts for a relatively small fraction (11%) of consumption on YouTube, and is dominated by mainstream and largely centrist sources. However, we also find evidence for a small but growing \"echo chamber\" of far-right content consumption. Users in this community show higher engagement and greater \"stickiness\" than users who consume any other category of content. Moreover, YouTube accounts for an increasing fraction of these users' overall online news consumption. Finally, while the size, intensity, and growth of this echo chamber present real concerns, we find no evidence that they are caused by YouTube recommendations. Rather, consumption of radical content on YouTube appears to reflect broader patterns of news consumption across the web. Our results emphasize the importance of measuring consumption directly rather than inferring it from recommendations.","433":null,"434":null,"435":"While social media make it easy to connect with and access information from anyone, they also facilitate basic influence and unfriending mechanisms that may lead to segregated and polarized clusters known as \"echo chambers.\" Here we study the conditions in which such echo chambers emerge by introducing a simple model of information sharing in online social networks with the two ingredients of influence and unfriending. Users can change both opinions and social connections based on the information to which they are exposed through sharing. Model dynamics demonstrate that even with minimal amounts of influence and unfriending, the social network rapidly devolves into segregated, homogeneous communities. These predictions are consistent with empirical data from Twitter. Although our findings suggest that echo chambers are somewhat inevitable given the mechanisms at play in online social media, they also provide insights into possible mitigation strategies.","436":null,"437":"Online social media platforms such as Facebook and Twitter are increasingly facing criticism for polarization of users. One particular aspect which has caught the attention of various critics is presence of users in echo chambers - a situation wherein users are exposed mostly to the opinions which are in sync with their own views. In this paper, we perform a sociolinguistic study by comparing the tweets of users in echo chambers with the tweets of users not in echo chambers with similar levels of polarity on a broad topic. Specifically, we carry out a comparative analysis of tweet structure, lexical choices, and focus issues, and provide possible explanations for the results.","438":"Selective online exposure to information that serves to only affirm people\u2019s opinions or is strongly aligned with their interests is considered to be a major issue in modern societies. Echo chambers, for example, are online environments in which users are only exposed to confirming opinions and alternative voices are excluded or discredited. Echo chambers are considered to be particularly dangerous, because they may lead to polarization and even radicalization. Social media facilitate the formation of echo chambers as described in the Social Identity Theory by means of homophily and depersonalization. This can be especially harmful in the case of conspiracy beliefs, where particularly extreme opinions lead to a stronger seclusion from society, encourage socially destructive actions, and curate Fake News. In our research we will assess different echo chambers in terms of actively established common patterns of consumed online information sources. To that end, we analyse the news source Likes from over 7,000 users with their approximately 1,450,000 Likes on Facebook. We intend to identify different types of Facebook echo chambers with a focus on conspiracy groups, understand distinguishing characteristics in communicative behaviour of the conspiracy groups on Facebook and explore unique characteristics of users in conspiracy echo chambers.","439":"This study analyzes the political slants of user comments on Korean partisan media. We built a BERT-based classifier to detect political leaning of short comments via the use of semi-unsupervised deep learning methods that produced an F1 score of 0.83. As a result of classifying 21.6K comments, we found the high presence of conservative bias on both conservative and liberal news outlets. Moreover, this study discloses an asymmetry across the partisan spectrum in that more liberals (48.0%) than conservatives (23.6%) comment not only on news stories resonating with their political perspectives but also on those challenging their viewpoints. These findings advance the current understanding of online echo chambers.","440":"The possibility of distributing user-generated content through online social networks (OSNs) has had liberating effects on society, with prominent examples such as the Arab Spring. Yet, since then, many dark sides of OSNs have been brought up. An example is the echo chambers phenomenon. Theory suggests that cognitive dissonance causes individuals to associate themselves with groups of like-minded individuals that are only exposed to content that confirms their previously held beliefs. In turn, deliberation amongst segregated groups increases social extremism and causes polarization, rather than moderation. Previous research endeavors to identify echo chambers in OSNs have scarcely investigated the community structures of a network on a fine granular level, specifically in the context of multi-party systems. To contribute to the scientific body of knowledge, we propose a framework that summarizes existing work and outlines a way for future research to fill this void. We further propose a new way to measure homophily in multi-party systems based on the cosine similarity between users. We evaluate our framework through real world data and find that members of the political right experience the least amount of crosscutting communication and the highest degrees of homophily.","441":"Recent studies, targeting Facebook, showed the tendency of users to interact with information adhering to their preferred narrative and to ignore dissenting information. Confirmation bias seems to account for user decisions about consuming and spreading content and, at the same time, aggregation of favored information within groups of like-minded people (echo chambers) reinforces selective exposure and group polarization. To gain a deeper understanding of the perspectives of these clustered communities, in this work we analyze the language of users engaged in the echo chambers emerging on Facebook around two distinct and conflicting narratives -- i.e., Science and Conspiracy news. Despite the high level of segregation of such communities, we show that users from both the echo chambers adopt very similar vocabularies and use the same word with almost the same frequency in their commenting activity, both at the individual and the collective level. Moreover, zooming in at the conversation level, we observe the emergence of lexical convergence between users who consistently interact with each other through co-commenting activity not only inside, but also across the echo chambers. Thus, the fact that even users with opposite views gradually coordinate their linguistic behavior when joining a discussion, suggests that users always aim to achieve communication when engaging in a conversation.","442":"Social media sites are extending social structures from physical to virtual environments. The leading social media platforms use customized algorithms to improve their users experience online. The filter algorithms analyze restricted to individuals online habits. Thus, ignoring more subjective personality traits. Moreover, social media technological features allow individuals to receive constant feedback loops that influence their self-concept and reflects on their identity construction while online. The understanding of how a dynamic Information Technology (IT) artifact \u2014 created and continuously modified by interpersonal relationships \u2014 influence individuals identity, demands a multidisciplinary approach. Based on a broad bibliographic review, this research-in-progress paper proposes a conceptual model encompassing the cognitive and motivational processes involved during the use of social media to investigate the influence of filter bubbles and echo chambers on Information Technology (IT) Identity construction. In the next phase of research, we intend \u2014 throughout a mixmethods approach \u2014 investigate empirically the relations presented in the conceptual model. Given the interconnected and embedded nature of social media in today\u2019s world, we believe that findings from this research will be of interest to Information System(IS) researchers and practitioners engaged in the study of the relationship between social media and identity.","443":"Echo chambers exist both online and offline, and in both situations they can affect individuals' opinions and behavior. There is a need for an assessment of the relative strength of online and offline echo chambers, and their interaction, on offline consequences.","444":null,"445":"The reappearance of measles in the US and Europe, a disease considered eliminated in early 2000s, has been accompanied by a growing debate on the merits of vaccination on social media. In this study we examine the extent to which the vaccination debate on Twitter is conductive to potential outreach to the vaccination hesitant. We focus on Italy, one of the countries most affected by the latest measles outbreaks. We discover that the vaccination skeptics, as well as the advocates, reside in their own distinct \"echo chambers\". The structure of these communities differs as well, with skeptics arranged in a tightly connected cluster, and advocates organizing themselves around few authoritative hubs. At the center of these echo chambers we find the ardent supporters, for which we build highly accurate network- and content-based classifiers (attaining 95% cross-validated accuracy). Insights of this study provide several avenues for potential future interventions, including network-guided targeting, accounting for the political context, and monitoring of alternative sources of information.","446":"An echo chamber effect refers to the phenomena that online users revealed selective exposure and ideological segregation on political issues. Prior studies indicate the connection between the spread of misinformation and online echo chambers. In this paper, to help users escape from an echo chamber, we propose a novel news-analysis platform that provides a panoramic view of stances towards a particular event from different news media sources. Moreover, to help users better recognize the stances of news sources which published these news articles, we adopt a news stance classification model to categorize their stances into \u201cagree\u201d, \u201cdisagree\u201d, \u201cdiscuss\u201d, or \u201cunrelated\u201d to a relevant claim for specified events with political stances. Finally, we proposed two ways showing the echo chamber effects: 1) visualizing the event and the associated pieces of news; and 2) visualizing the stance distribution of news from news sources of different political ideology. By making the echo chamber effect explicit, we expect online users will become exposed to more diverse perspectives toward a specific event. The demo video of our platform is available on youtube1.","447":"Because of the increasingly negative impacts of the echo chamber effect, such as the dissemination of fake news and political polarization occurring in social networking services (SNSs), considerable efforts are being made to mitigate this effect. Prior HCI studies have presented the development of user interfaces to display information that reflects various standpoints, with the aim of nudging people to consume information in a more objective fashion. However, these efforts still lack the ability to highlight the characteristics, generation processes, and negative effects of echo chambers, so they may not be effective in helping people become sufficiently aware of the echo chamber effect and those who are already in an echo chamber. In this paper, we present ChamberBreaker (CB), which has been designed to help increase a player's awareness of and preemptively respond to an echo chamber effect based on psychological concepts: inoculation, heuristics for judging, and gamification. Through a user study with 882 participants (control group: 446, experimental group: 436), we demonstrated the feasibility of our game-based methodology to support the awareness of the echo chamber effect and the importance of maintaining diverse perspectives when consuming information. Our findings highlight the externalization of psychological standpoints in mitigating an echo chamber effect and suggest design implications for system development---the consideration of demographics, playing time, and the connection to fake news recognition---for digital literacy education. You can play CB at http:\/\/tiny.cc\/chamberbreaker (The game only works with Chrome.)","448":"Echo chambers are social phenomena that amplify agreement and suppress opposing views in social media which may lead to fragmentation and polarization of the user population. In prior research, echo chambers have mainly been modeled as a result of social information diffusion. While most scientific work has framed echo chambers as a result of epistemic imbalances between polarized communities, we argue that members of echo chambers often actively discredit outside sources to maintain coherent world views. We therefore argue that two different types of echo chambers occur in social media contexts: Epistemic echo chambers create information gaps mainly through their structure whereas ideological echo chambers systematically exclude counter-attitudinal information. Diversifying recommendations by simply widening the scope of topics and viewpoints covered to counteract the echo chamber effect may be ineffective in such contexts. To investigate the characteristics of this dual echo chamber view and to assess the depolarizing effects of diversified recommendations, we apply an agent-based modeling approach. We rely on knowledge graph embedding techniques not only to generate recommendations, but also to show how to utilize logical graph queries in embedding spaces to diversify recommendations aimed at challenging polarization in online discussions. The results of our evaluation indicate that counteracting the two different types of echo chambers requires fundamentally different diversification strategies.","449":"Recommender systems serve as mediators of information consumption and propagation. In this role, these systems have been recently criticized for introducing biases and promoting the creation of echo chambers and filter bubbles, thus lowering the diversity of both content and potential new social relations users are exposed to. Some of these issues are a consequence of the fundamental concepts on which recommender systems are based on. Assumptions like the homophily principle might lead users to content that they already like or friends they already know, which can be na\u00efve in the era of ideological uniformity and fake news. A significant challenge in this context is how to effectively learn the dynamic representations of users based on the content they share and their echo chamber or community interactions to recommend potentially relevant and diverse friends from outside the network of influence of the users\u2019 echo chamber. To address this, we devise FRediECH (a Friend RecommenDer for breakIng Echo CHambers), an echo chamber-aware friend recommendation approach that learns users and echo chamber representations from the shared content and past users\u2019 and communities\u2019 interactions. Comprehensive evaluations over Twitter data showed that our approach achieved better performance (in terms of relevance and novelty) than state-of-the-art alternatives, validating its effectiveness.","450":"In a digital environment, the term echo chamber refers to an alarming phenomenon in which beliefs are amplified or reinforced by communication repetition inside a closed system and insulated from rebuttal. Up to date, a formal definition, as well as a platform-independent approach for its detection, is still lacking. This paper proposes a general framework to identify echo chambers on online social networks built on top of features they commonly share. Our approach is based on a four-step pipeline that involves (i) the identification of a controversial issue; (ii) the inference of users\u2019 ideology on the controversy; (iii) the construction of users\u2019 debate network; and (iv) the detection of homogeneous meso-scale communities. We further apply our framework in a detailed case study on Reddit, covering the first two and a half years of Donald Trump\u2019s presidency. Our main purpose is to assess the existence of Pro-Trump and Anti-Trump echo chambers among three sociopolitical issues, as well as to analyze their stability and consistency over time. Even if users appear strongly polarized with respect to their ideology, most tend not to insulate themselves in echo chambers. However, the found polarized communities were proven to be definitely stable over time.","451":null,"452":"An educated and informed consumption of media content has become a challenge in modern times. With the shift from traditional news outlets to social media and similar venues, a major concern is that readers are becoming encapsulated in \u201cecho chambers\u201d and may fall prey to fake news and disinformation, lacking easy access to dissenting views. We suggest a novel task aiming to alleviate some of these concerns \u2013 that of detecting articles that most effectively counter the arguments \u2013 and not just the stance \u2013 made in a given text. We study this problem in the context of debate speeches. Given such a speech, we aim to identify, from among a set of speeches on the same topic and with an opposing stance, the ones that directly counter it. We provide a large dataset of 3,685 such speeches (in English), annotated for this relation, which hopefully would be of general interest to the NLP community. We explore several algorithms addressing this task, and while some are successful, all fall short of expert human performance, suggesting room for further research. All data collected during this work is freely available for research.","453":null,"454":"Since 2016, online social networks (OSNs), especially their \u201cbig data\u201d algorithms, have been intensively blamed in popular news discourse for acting as echo chambers. These chambers entrap like-minded voters in closed ideological circles that cause serious damage to democratic processes. This study examines this \u201cecho chamber\u201d argument through the rather divisive case of EU politics among EU citizens. Based on an exploratory secondary analysis of the Eurobarometer 86.2 survey dataset, we investigate whether the reliance on OSNs as a primary EU political news source can lead people to more polarisation in EU-related political beliefs and attitudes than a reliance on traditional media. We found little evidence for this polarisation, lending credence to a rejection of social media\u2019s \u201cecho chamber\u201d effect.","455":"Echo chambers are defined by the simultaneous presence of opinion polarization with respect to a controversial topic and homophily, i.e. the preference of individuals to interact with like-minded peers. While recent efforts have been devoted to detecting the presence of echo chambers in polarized debates on online social media, the dynamics leading to the emergence of these phenomena remain unclear. Here, we contribute to this endeavor by proposing novel metrics to single out the effect of the network dynamics from the opinion polarization. By using a Twitter data set collected during a controversial political debate in Brazil in 2016, we employ a temporal network approach to gauge the strength of the echo chamber effect over time. We define a measure of opinion coherence in the network showing how the echo chamber becomes weaker across the observed period. The analysis of the hashtags diffusion in the network shows that this is due to the increase of social interactions between users with opposite opinions. Finally, the analysis of the mutual entropy between the opinions expressed and received by the users permits to quantify the social contagion effect. We find empirical evidence that the polarization of the users and the dynamics of their interactions may evolve independently. Our findings may be of interest to the broad array of researchers studying the dynamics of echo chambers and polarization in online social networks.","456":"The relationship between the topology of a network and specific types of dynamics unfolding in networks constitutes a subject of substantial interest. One type of dynamics that has attracted increasing attention because of its several potential implications is opinion formation. A phenomenon of particular importance, known to take place in opinion formation, is echo chambers\u2019 appearance. In the present work, we approach this phenomenon, while emphasizing the influence of contrarian opinions in a multi-opinion scenario. To define the contrarian opinion, we considered the underdog effect, which is the eventual tendency of people to support the less popular option. We also considered an adaptation of the Sznajd dynamics with the possibility of friendship rewiring, performed on several network models. We analyze the relationship between topology and opinion dynamics by considering two measurements: opinion diversity and network modularity. Two specific situations have been addressed: (i) the agents can reconnect only with others sharing the same opinion; and (ii) same as in the previous case, but with the agents reconnecting only within a limited neighborhood. This choice can be justified because, in general, friendship is a transitive property along with subsequent neighborhoods (e.g., two friends of a person tend to know each other). As the main results, we found that the underdog effect, if strong enough, can balance the agents\u2019 opinions. On the other hand, this effect decreases the possibilities of echo chamber formation. We also found that the restricted reconnection case reduced the chances of echo chamber formation and led to smaller echo chambers.","457":"We study learning via shared news. Each period agents receive the same quantity and quality of first-hand information and can share it with friends. Some friends (possibly few) share selectively, generating heterogeneous news diets across agents akin to echo chambers. Agents are aware of selective sharing and update beliefs by Bayes\u2019 rule. Contrary to standard learning results, we show that beliefs can diverge in this environment leading to polarization. This requires that (i) agents hold misperceptions (even minor) about friends' sharing and (ii) information quality is sufficiently low. Polarization can worsen when agents' social connections expand. When the quantity of first-hand information becomes large, agents can hold opposite extreme beliefs resulting in severe polarization. Our results hold without media bias or fake news, so eliminating these is not sufficient to reduce polarization. When fake news is included, we show that it can lead to polarization but only through misperceived selective sharing. News aggregators can curb polarization caused by shared news. \n \nInstitutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at www.nber.org.","458":"Political polarization in the US is on the rise. This polarization negatively affects the public sphere by contributing to the creation of ideological echo chambers. In this paper, we focus on addressing one of the factors that contributes to this polarity, polarized media. We introduce a framework for depolarizing news articles. Given an article on a certain topic with a particular ideological slant (eg., liberal or conservative), the framework first detects polar language in the article and then generates a new article with the polar language replaced with neutral expressions. To detect polar words, we train a multiattribute-aware word embedding model that is aware of ideology and topics on 360k full-length media articles. Then, for text generation, we propose a new algorithm called Text Annealing Depolarization Algorithm (TADA). TADA retrieves neutral expressions from the word embedding model that not only decrease ideological polarity but also preserve the original argument of the text, while maintaining grammatical correctness. We evaluate our framework by comparing the depolarized output of our model in two modes, fully-automatic and semi-automatic, on 99 stories spanning 11 topics. Based on feedback from 161 human testers, our framework successfully depolarized 90.1% of paragraphs in semi-automatic mode and 78.3% of paragraphs in fully-automatic mode. Furthermore, 81.2% of the testers agree that the non-polar content information is well-preserved and 79% agree that depolarization does not harm semantic correctness when they compare the original text and the depolarized text. Our work shows that data-driven methods can help to locate political polarity and aid in the depolarization of articles.","459":null,"460":"The huge amount of data made available by the massive usage of social media has opened up the unprecedented possibility to carry out a data-driven study of political processes. While particular attention has been paid to phenomena like elite and mass polarization during online debates and echo-chambers formation, the interplay between online partisanship and framing practices, jointly sustaining adversarial dynamics, still remains overlooked. With the present paper, we carry out a socio-semantic analysis of the debate about migration policies observed on the Italian Twittersphere, across the period May-November 2019. As regards the social analysis, our methodology allows us to extract relevant information about the political orientation of the communities of users\u2014hereby called partisan communities\u2014without resorting upon any external information. Remarkably, our community detection technique is sensitive enough to clearly highlight the dynamics characterizing the relationship among different political forces. As regards the semantic analysis, our networks of hashtags display a mesoscale structure organized in a core-periphery fashion, across the entire observation period. Taken altogether, our results point at different, yet overlapping, trajectories of conflict played out using migration issues as a backdrop. A first line opposes communities discussing substantively of migration to communities approaching this issue just to fuel hostility against political opponents; within the second line, a mechanism of distancing between partisan communities reflects shifting political alliances within the governmental coalition. Ultimately, our results contribute to shed light on the complexity of the Italian political context characterized by multiple poles of partisan alignment.","461":"While social networks have increased the diversity of ideas and information available to users, they are also blamed for increasing the polarization of user opinions. Eli Pariser's \"filter bubble\" hypothesis [55] explains this counterintuitive phenomenon by linking user polarization to algorithmic filtering: to increase user engagement, social media companies connect users with ideas they are already likely to agree with, thus creating echo chambers of users with very similar beliefs. In this paper, we introduce a mathematical framework to assess the impact of this popular, yet unverified, hypothesis. We augment the classical Friedkin-Johnsen opinion dynamics model to include algorithmic filtering by introducing a network administrator --- an external actor that models social media companies by dynamically adjusting the strength of edges in a social network graph. When the network administrator is incentivized to reduce disagreement among interacting users, we experimentally demonstrate on networks from Reddit and Twitter that even small changes by the administrator to social network graphs can increase user polarization. We support our experiments with theoretical results by showing that social networks generated from the stochastic block model are provably sensitive to algorithmic filtering. Finally, we propose a simple modification to the incentives of the network administrator that limits the filter bubble effect without significantly affecting user engagement.","462":null,"463":null,"464":"Miss-information is usually adjusted to fit distinct narratives and can propagate rapidly through communities of interest, which work as echo chambers, cause reinforcement and foster confirmation bias. False beliefs, once adopted, are rarely corrected. Amidst the COVID-19 crisis, pandemic-deniers and people who oppose wearing face masks or quarantines have already been a substantial aspect of the development of the pandemic. With a potential vaccine for COVID-19, different anti-vaccine narratives will be created and, likely, adopted by large population groups, with critical consequences. Here, we analyse epidemic spreading and optimal vaccination strategies, measured with the average years of life lost, in two network topologies (scale-free and small-world) assuming full adherence to vaccine administration. We consider the spread of anti-vaccine views in the network, using a similar diffusion model as the one used in epidemics, which are adopted based on a persuasiveness parameter of anti-vaccine views. Results show that even if an anti-vaccine narrative has a small persuasiveness, a large part of the population will be rapidly exposed to them. Assuming that all individuals are equally likely to adopt anti-vaccine views after being exposed, more central nodes in the network are more exposed and therefore are more likely to adopt them. Comparing years of life lost, anti-vaccine views could have a significant cost not only on those who share them, since the core social benefits of a limited vaccination strategy (reduction of susceptible hosts, network disruptions and slowing the spread of the disease) are substantially shortened.","465":"We present the first large-scale measurement study of crosspartisan discussions between liberals and conservatives on YouTube, based on a dataset of 274,241 political videos from 973 channels of US partisan media and 134M comments from 9.3M users over eight months in 2020. Contrary to a simple narrative of echo chambers, we find a surprising amount of cross-talk: most users with at least 10 comments posted at least once on both left-leaning and right-leaning YouTube channels. Cross-talk, however, was not symmetric. Based on the user leaning predicted by a hierarchical attention model, we find that conservatives were much more likely to comment on left-leaning videos than liberals on right-leaning videos. Secondly, YouTube\u2019s comment sorting algorithm made crosspartisan comments modestly less visible; for example, comments from conservatives made up 26.3% of all comments on left-leaning videos but just over 20% of the comments were in the top 20 positions. Lastly, using Perspective API\u2019s toxicity score as a measure of quality, we find that conservatives were not significantly more toxic than liberals when users directly commented on the content of videos. However, when users replied to comments from other users, we find that crosspartisan replies were more toxic than co-partisan replies on both left-leaning and right-leaning videos, with cross-partisan replies being especially toxic on the replier\u2019s home turf.","466":null,"467":"The year 2020 will be remembered for two events of global significance: the COVID-19 pandemic and 2020 U.S. Presidential Election. In this chapter, we summarize recent studies using large public Twitter data sets on these issues. We have three primary objectives. First, we delineate epistemological and practical considerations when combining the traditions of computational research and social science research. A sensible balance should be struck when the stakes are high between advancing social theory and concrete, timely reporting of ongoing events. We additionally comment on the computational challenges of gleaning insight from large amounts of social media data. Second, we characterize the role of social bots in social media manipulation around the discourse on the COVID-19 pandemic and 2020 U.S. Presidential Election. Third, we compare results from 2020 to prior years to note that, although bot accounts still contribute to the emergence of echo-chambers, there is a transition from state-sponsored campaigns to domestically emergent sources of distortion. Furthermore, issues of public health can be confounded by political orientation, especially from localized communities of actors who spread misinformation. We conclude that automation and social media manipulation pose issues to a healthy and democratic discourse, precisely because they distort representation of pluralism within the public sphere.","468":"Recommender systems have become increasingly accurate in suggesting content to users, resulting in users primarily consuming content through recommendations. This can cause the user's interest to narrow toward the recommended content, something we refer to as preference amplification. While this can contribute to increased engagement, it can also lead to negative experiences such as lack of diversity and echo chambers. We propose a theoretical framework for studying such amplification in a matrix factorization based recommender system. We model the dynamics of the system, where users interact with the recommender systems and gradually \"drift'' toward the recommended content, with the recommender system adapting, based on user feedback, to the updated preferences. We study the conditions under which preference amplification manifests, and validate our results with simulations. Finally, we evaluate mitigation strategies that prevent the adverse effects of preference amplification and present experimental results using a real-world large-scale video recommender system showing that by reducing exposure to potentially objectionable content we can increase user engagement by up to 2%.","469":"Does engagement with opposing views help break down ideological \u2018echo chambers\u2019; or does it backfire and reinforce them? This question remains critical as academics, policymakers and activists grapple with the question of how to regulate political discussion on social media. In this study, we contribute to the debate by examining the impact of opposing views within a major climate change skeptic online community on \u2018Reddit\u2019. A large sample of posts (N = 3000) was manually coded as either dissonant or consonant which allowed the automated classification of the full dataset of more than 50,000 posts, with codes inferred from linked websites. We find that ideologically dissonant submissions act as a stimulant to activity in the community: they received more attention (comments) than consonant submissions, even though they received lower scores through up-voting and down-voting. Users who engaged with dissonant submissions were also more likely to return to the forum. Consistent with identity theory, confrontation with opposing views triggered activity in the forum, particularly among users that are highly engaged with the community. In light of the findings, theory of social identity and echo chambers is discussed and enhanced.","470":"Machine learning is used extensively in recommender systems deployed in products. The decisions made by these systems can influence user beliefs and preferences which in turn affect the feedback the learning system receives - thus creating a feedback loop. This phenomenon can give rise to the so-called \"echo chambers\" or \"filter bubbles\" that have user and societal implications. In this paper, we provide a novel theoretical analysis that examines both the role of user dynamics and the behavior of recommender systems, disentangling the echo chamber from the filter bubble effect. In addition, we offer practical solutions to slow down system degeneracy. Our study contributes toward understanding and developing solutions to commonly cited issues in the complex temporal scenario, an area that is still largely unexplored.","471":null,"472":"Significance Access to diverse news strengthens democratic citizenship. Whether digital technologies have narrowed or widened news diets fosters contentious debates. Previous research shows the abundance of digital news sources might be leading to more fragmented audiences, ideological segregation, and echo chambers. Our study resorts to an unprecedented combination of data to show that the increase in mobile access to news actually leads to higher exposure to diverse content and that ideological self-selection explains only a small percentage of co-exposure to news. We also find that more than half of Internet users in the United States do not use online news. Future research should avoid generalizations from desktop-only data and pay attention to the increasing divide between informed citizens and news avoiders. The abundance of media options is a central feature of today\u2019s information environment. Many accounts, often based on analysis of desktop-only news use, suggest that this increased choice leads to audience fragmentation, ideological segregation, and echo chambers with no cross-cutting exposure. Contrary to many of those claims, this paper uses observational multiplatform data capturing both desktop and mobile use to demonstrate that coexposure to diverse news is on the rise, and that ideological self-selection does not explain most of that coexposure. We show that mainstream media outlets offer the common ground where ideologically diverse audiences converge online, though our analysis also reveals that more than half of the US online population consumes no online news, underlining the risk of increased information inequality driven by self-selection along lines of interest. For this study, we use an unprecedented combination of observed data from the United States comprising a 5-y time window and involving tens of thousands of panelists. Our dataset traces news consumption across different devices and unveils important differences in news diets when multiplatform or desktop-only access is used. We discuss the implications of our findings for how we think about the current communication environment, exposure to news, and ongoing attempts to limit the effects of misinformation.","473":"Abstract Characterising the spreading of ideas within echo chambers is essential for understanding polarisation. In this article, we explore the characteristics of popular and viral content in climate change discussions on Twitter around the 2019 announcement of the Nobel Peace Prize, where we find the retweet network of users to be polarised into two well-separated groups of activists and sceptics. Operationalising popularity as the number of retweets and virality as the spreading probability inferred using an independent cascade model, we find that the viral themes echo and differ from the popular themes in interesting ways. Most importantly, we find that the most viral themes in the two groups reflect different types of bonds that tie the community together, yet both function to enhance ingroup connections while repulsing outgroup engagement. With this, our study sheds light, from an information-spreading perspective, on the formation and upkeep of echo chambers in climate discussions.","474":"There has been considerable hype about filter bubbles and echo chambers influencing the views of information consumers. The fear is that these technologies are undermining democracy by swaying opinion and creating an uninformed, polarised populace. The literature in this space is mostly techno-centric, addressing the impact of technology. In contrast, our work is the first research in the information interaction field to examine changing viewpoints from a human-centric perspective. It provides a new understanding of view change and how we might support informed, autonomous view change behaviour. We interviewed 18 participants about a self-identified change of view, and the information touchpoints they engaged with along the way. In this paper we present the information types and sources that informed changes of viewpoint, and the ways in which our participants interacted with that information. We describe our findings in the context of the techno-centric literature and suggest principles for designing digital information environments that support user autonomy and reflection in viewpoint formation.","475":"ABSTRACT Fragmentation, echo chambers, and their amelioration in social networks have been a growing concern in the academic and non-academic world. This paper shows how, under the assumption of homophily, echo chambers and fragmentation are system-immanent phenomena of highly flexible social networks, even under ideal conditions for heterogeneity. We achieve this by finding an analytical, network-based solution to the Schelling model and by proving that weak ties do not hinder the process. Furthermore, we derive that no level of positive algorithmic bias in the form of rewiring is capable of preventing fragmentation and its effect on reducing the fragmentation speed is negligible.","476":"Competitive information diffusion on large-scale social networks reveals fundamental characteristics of rumor contagions and has profound influence on public opinion formation. There has been growing interest in exploring dynamical mechanisms of the competing evolutions recently. Nevertheless, the impacts of population homophily, which determines powerful collective human behaviors, remains unclear. In this paper, we incorporate homophily effects into a modified competitive ignorant-spreader-ignorant (SIS) rumor diffusion model with generalized population preference. Using microscopic Markov chain approach, we first derive the phase diagram of competing diffusion results and examine how competitive information spreads and evolves on social networks. We then explore the detailed effects of homophily, which is modeled by a rewiring mechanism. Results show that homophily promotes the formation of divided \"echo chambers\" and protects the disadvantaged information from extinction, which further changes or even reverses the evolutionary advantage, i.e., the difference of final proportions of the competitive information. We highlight the conclusion that the reversals may happen only when the initially disadvantaged information has stronger transmission ability, owning diffusion advantage over the other one. Our framework provides profound insight into competing dynamics with population homophily, which may pave ways for further controlling misinformation and guiding public belief systems. Moreover, the reversing condition sheds light on designing effective competing strategies in many real scenarios.","477":"There is a growing concern about the extent to which algorithmic personalization limits people's exposure to diverse viewpoints, thereby creating \u201cfilter bubbles\u201d or \u201cecho chambers.\u201d Prior research on web search personalization has mainly reported location-based personalization of search results. In this paper, we investigate whether web search results are personalized based on a user's browsing history, which can be inferred by search engines via third-party tracking. Specifically, we develop a \u201csock puppet\u201d auditing system in which a pair of fresh browser profiles, first, visits web pages that reflect divergent political discourses and, second, executes identical politically oriented Google News searches. Comparing the search results returned by Google News for distinctly trained browser profiles, we observe statistically significant personalization that tends to reinforce the presumed partisanship.","478":null,"479":"The growing complexity of political communication online goes along with increasing methodological challenges to process communication data properly in order to investigate public concerns such as the existence of echo chambers. To cover the full range of political diversity in online communication, we argue that it is necessary to focus on specific political issues. This study proposes an innovative combination of computational methods, including natural language processing and social network analysis, that serves as a model for future research on the evolution of opinion climates in online networks. Data were gathered on YouTube, enabling the assessment of users\u2019 expressed opinions on two political issues. Results provided very limited evidence for the existence of opinion-based homogeneity on YouTube. This was true even when the whole network was divided into sub-networks. Findings are discussed in light of current computational communication research and the vigorous debate on echo chambers in online networks.","480":"Online communication offers the potential for bridging con-nections, exposing users to new views and experiences by fostering socially heterogenous communities. However, in the absence of deliberate attempts to promote diversity, communities may tend towards insularity: a state where members and content are similar or homogenous, and where deviation from these norms is discouraged. This paper presents a taxonomy of processes contributing to insularity, synthesizing findings from a broader longitudinal interview study on engagement with online communities over time with previous literature. Using thematic analysis, sixteen processes were identified which were associated with four broad stages: formation (selective connections, network homophily, shared interests, audience segmentation); propagation (circlejerking, upholding community standards, avoiding conflict, tailoring content); reaction (individual avoidance, collective reaction, mocking deviance, derogating outsiders); and perpetuation (modelling, prior feedback, echo chambers, gatekeeping). These findings highlight the need to consider more diverse mechanisms by which communities become insular, and the role that platform features play in facilitating these processes.","481":"Social media platforms attempting to curb abuse and misinformation have been accused of political bias. We deploy neutral social bots on Twitter to probe biases that may emerge from interactions between users, platform mechanisms, and manipulation by inauthentic actors. We find evidence of bias affecting the news and information to which U.S. Twitter users are likely to be exposed, depending on their own political alignment. Partisan accounts, especially conservative ones, tend to receive more followers, follow more automated accounts, and find themselves in echo chambers. Conservative accounts are exposed to more low-credibility content. Liberal accounts are exposed to moderate content shifting their experience toward the political center, while the interactions of conservative accounts are skewed toward the right. We find some evidence of central bias in the news feed ranking algorithm for partisan accounts. These findings help inform the public debate about how social media shape exposure to political information.","482":"Among the several approaches that have been attempted at studying opinion dynamics, the Sznajd model provides some particularly interesting features, such as its simplicity and ability to represent some of the mechanisms believed to be involved in opinion dynamics. The standard Sznajd model at zero temperature is characterized by converging to one stable state, implying null diversity of opinions. In the present work, we develop an approach -- namely the adaptive Sznajd model -- in which changes of opinion by an individual (i.e. a network node) implies in possible alterations in the network topology. This is accomplished by allowing agents to change their connections preferentially to other neighbors with the same state. The diversity of opinions along time is quantified in terms of the exponential of the entropy of the opinions density. Several interesting results are reported, including the possible formation of echo chambers or social bubbles. Additionally, depending on the parameters configuration, the dynamics may converge to different equilibrium states for the same parameter setting, which suggests that this phenomenon can be a phase transition. The average degree of the network strongly influences the resultant opinion distribution, which means that echo chambers are easily formed in lower connected systems.","483":"Echocardiography is an ultrasound-based imaging modality that helps the physician to visualize heart chambers and valves motion activity. Recently, deep learning plays an important role in several clinical computer-assisted diagnostic systems. There is a real need to employ deep learning methodologies to increase such systems. In this paper, we proposed a deep learning system to classify several echocardiography views and identify its physiological location. Firstly, the spatial CNN features are extracted from each frame in the echo-motion. Secondly, we proposed novel temporal features based on neutrosophic sets. The neutrosophic temporal motion features are extracted from echo-motion activity. To extract the deep CNN features, we activated a pre-trained deep ResNet model. Then, both spatial and neutrosophic temporal CNN features were fused based on features concatenation technique. Finally, the fused CNN features were fed into deep long short-term memory network to classify echo-cardio views and identify their location. During our experiments, we employed a public echocardiography dataset that consisted of 432 videos for eight cardio-views. We have investigated several pre-trained network activation performance. ResNet architecture activation achieved the best accuracy score among several pre-trained networks. The Proposed system based on fused spatial neutrosophic temporal deep features achieved 96.3% accuracy and 95.75% sensitivity. For the classification of cardio-views location, the proposed system achieved 99.1% accuracy. The proposed system achieved more accuracy than previous deep learning methods with a significant decrease in the training time cost. The experimental results showed promising results for our proposed approach.","484":"Modern online media, such as Twitter, Instagram, and YouTube, enable anyone to become an information producer and to offer online content for potentially global consumption. By increasing the amount of globally accessible real-time information, today's ubiquitous producers contribute to a world, where an individual consumes vanishingly smaller fractions of all produced content. In general, consumers preferentially select information that closely matches their individual views and values. The bias inherent in such selection is further magnified by today's information curation services that maximize user engagement (and thus service revenue) by filtering new content in accordance with observed consumer preferences. Consequently, individuals get exposed to increasingly narrower bands of the ideology spectrum. Societies get fragmented into increasingly ideologically isolated enclaves. These enclaves (or echo-chambers) then become vulnerable to misinformation spread, which in turn further magnifies polarization and bias. We call this dynamic the paradox of information access; a growing ideological fragmentation in the age of sharing. This article describes the technical, economic, and socio-cognitive contributors to this paradox, and explores research directions towards its mitigation.","485":"ABSTRACT The internet has become an ubiquitous epistemic source. However, it comes with several drawbacks. For instance, the world wide web seems to foster filter bubbles and echo chambers and includes search results that promote bias and spread misinformation. Richard Heersmink suggests online intellectual virtues to combat these epistemically detrimental effects . These are general epistemic virtues applied to the online environment based on our background knowledge of this online environment. I argue that these online intellectual virtues also demand a particular view of cognitive integration. Online intellectual virtues are incompatible with a popular conception of extended minds proposed by Andy Clark and David Chalmers . I suggest that if we want to hold on to both a conception of online intellectual virtues and some conception of the extended mind, we have to accept a more gradual theory of cognitive integration along the lines of second-wave theories of the extended mind .","486":"This perspectives paper proposes a conceptualization of trust that does not require a predefined feature space, but rather is dynamically formed at the point of information interaction through a cognitive predicting mechanism. Trust is a significant issue in the current information context due to fake news, echo chambers, filter bubbles, and confirmation biases which can result in a disconnect between human trust expectations and information trustworthiness, making it difficult to establish a feature space within which trust might be modeled. In response to this, we present our Cognitive Predicting Theory of Trust (CPTT) which allows trust to be modeled without the requirement of a predefined feature space. Drawn from the cognitive theory of Predictive Processing, CPTT describes how people form trust judgments based on cognitive predictions within a system of information interactions. We outline how this CPTT view of trust might be modeled using complex systems and provide examples showing how curation of the information interaction environment can affect the trust associated with the system. We conclude by proposing that our perspective opens up two avenues for exploration in Computer Human Information Interaction and Retrieval: (1) the need for alternative models, and (2) the value of curating the information environment.","487":"Echocardiography is a widely used and cost-effective medical imaging procedure that is used to diagnose cardiac irregularities. To capture the various chambers of the heart, echocardiography videos are captured from different angles called views to generate standard images\/videos. Automatic classification of these views allows for faster diagnosis and analysis. In this work, we propose a representation for echo videos which encapsulates the motion profile of various chambers and valves that helps effective view classification. This variety of motion profiles is captured in a large Gaussian mixture model called universal motion profile model (UMPM). In order to extract only the relevant motion profiles for each view, a factor analysis based decomposition is applied to the means of the UMPM. This results in a low-dimensional representation called motion profile vector (MPV) which captures the distinctive motion signature for a particular view. To evaluate MPVs, a dataset called ECHO 1.0 is introduced which contains around 637 video clips of the four major views: a) parasternal long-axis view (PLAX), b) parasternal short-axis (PSAX), c) apical four-chamber view (A4C), and d) apical two-chamber view (A2C). We demonstrate the efficacy of motion profile-vectors over other spatio-temporal representations. Further, motion profile-vectors can classify even poorly captured videos with high accuracy which shows the robustness of the proposed representation.","488":"The large number of social platforms developed enable users to express their opinions and access information more freely. However, their algorithmic strategies can have a high possibility of exacerbating a filter bubble or echo chambers which may evoke distinctive emotions response with others. Herein, we present a new online visualization tool for opinion sharing, called CrowdForest, which allows users to visualize their opinions, interacting with others based on semantic figurative metaphors driven by sentiment analysis.","489":"We analyze the relationship between partisanship, echo chambers, and vulnerability to online misinformation by studying news sharing behavior on Twitter. While our results confirm prior findings that online misinformation sharing is strongly correlated with right-leaning partisanship, we also uncover a similar, though weaker trend among left-leaning users. Because of the correlation between a user's partisanship and their position within a partisan echo chamber, these types of influence are confounded. To disentangle their effects, we perform a regression analysis and find that vulnerability to misinformation is most strongly influenced by partisanship for both left- and right-leaning users.","490":"In this paper, we analyze content sharing between news sources in the alternative and mainstream media using a dataset of 713K articles and 194 sources. We find that content sharing happens in tightly formed communities, and these communities represent relatively homogeneous portions of the media landscape. Through a mix-method analysis, we find several primary content sharing behaviors. First, we find that the vast majority of shared articles are only shared with similar news sources (i.e. same community). Second, we find that despite these echo-chambers of sharing, specific sources, such as The Drudge Report, mix content from both mainstream and conspiracy communities. Third, we show that while these differing communities do not always share news articles, they do report on the same events, but often with competing and counter-narratives. Overall, we find that the news is homogeneous within communities and diverse in between, creating different spirals of sameness.","491":"This paper surveys and presents recent academic work carried out within the field of stance classification and fake news detection. Echo chambers and the model organism problem are examples that pose challenges to acquire data with high quality, due to opinions being polarised in microblogs. Nevertheless it is shown that several machine learning approaches achieve promising results in classifying stance. Some use crowd stance for fake news detection, such as the approach in [Dungs et al., 2018] using Hidden Markov Models. Furthermore feature engineering have significant importance in several approaches, which is shown in [Aker et al., 2017]. This paper additionally includes a proposal of a system implementation based on the presented survey.","492":null,"493":"To improve the experience of consumers, all social media, commerce and entertainment sites deploy Recommendation Systems (RSs) that aim to help users locate interesting content. These RSs are black-boxes \u2013 the way a chunk of information is filtered out and served to a user from a large information base is mostly opaque. No one except the parent company generally has access to the entire information required for auditing these systems \u2013 neither the details of the algorithm nor the user-item interactions are ever made publicly available for third-party auditors. Hence auditing RSs remains an important challenge, especially with the recent concerns about how RSs are affecting the views of the society at large with new technical jargons like \u201cecho chambers\u201d, \u201cconfirmation biases\u201d, \u201cfilter bubbles\u201d etc. in place. Many prior works have evaluated different properties of RSs such as diversity, novelty, etc. However, most of these have focused on evaluating static snapshots of RSs. Today, auditors are not only interested in these static evaluations on a snapshot of the system, but also interested in how these systems are affecting the society in course of time. In this work, we propose a novel network-centric framework which is not only able to quantify various static properties of RSs, but also is able to quantify dynamic properties such as how likely RSs are to lead to polarization or segregation of information among their users. We apply the framework to several popular movie RSs to demonstrate its utility.","494":"The filter bubble is an intermediate structure to provoke polarization and echo chambers in social networks, and it has become one of today's most urgent issues for social media. Previous studies usually equated filter bubbles with community structures and emphasized this exogenous isolation effect, but there is a lack of full discussion of the internal organization of filter bubbles. Here, we design an experiment for analysing filter bubbles taking advantage of social bots. We deployed 128 bots to Weibo (the largest microblogging network in China), and each bot consumed a specific topic (entertainment or sci-tech) and ran for at least two months. In total, we recorded about 1.3 million messages exposed to these bots and their social networks. By analysing the text received by the bots and motifs in their social networks, we found that a filter bubble is not only a dense community of users with the same preferences but also presents an endogenetic unidirectional star-like structure. The structure could spontaneously exclude non-preferred information and cause polarization. Moreover, our work proved that the felicitous use of artificial intelligence technology could provide a useful experimental approach that combines privacy protection and controllability in studying social media.","495":"The development of interactive, networked, digital communication allowed news to be personalized to individual users at scale and with unprecedented speed and efficiency. From modest beginnings in the pre-Web era, news personalization has increased in volume, sophistication, and reach, not least because of social networks, in particular Facebook. This increase has prompted a mixture of reactions, some optimistic about the effects on individuals and society, and others less so. Some research indicates that we have not\u2014yet\u2014become especially enclosed within echo chambers or filter bubbles that isolate us from alternative viewpoints and common experiences. However, concerns persist, especially about the content curation role of social networks with their increasingly user-centric personalization algorithms. It may be that traditional news providers, more so than social networks, will provide\u2014within an increasingly personalized information environment\u2014the common set of experiences and exposure to challenging viewpoints required in well functioning systems of free expression.","496":"Nowadays public opinion formation is deeply influenced by social networks and faces unprecedented challenges such as opinion radicalization, echo chambers, and ideologization of public debates. Mathematical modeling of opinion dynamics plays a fundamental role in understanding the microscopic mechanisms of social interactions behind these macroscopic phenomena. The weighted-averaging opinion update is arguably the most widely adopted microscopic mechanism for opinion dynamics. However, such models based on weighted averaging are restricted in their predictive power and limited to stylized continuous opinion spectra. Here we point out that these models' limitation in predictability is not due to the lack of complexity, but because the weighted-averaging mechanism itself features a non-negligible unrealistic implication. By resolving this unrealistic feature in the framework of cognitive dissonance theory, we propose a novel opinion dynamics model based on a weighted-median mechanism instead. Surprisingly, such an inconspicuous change in microscopic mechanism leads to dramatic macroscopic consequences. In the spirit of Occam's razor, our new model, despite its simplicity in form, exhibits a sophisticated consensus-disagreement phase transition depending on the influence network structure. Our model gives perhaps the simplest answers to various open problems in sociology and political science, such as the connection between social marginalization and opinion radicalization, the mechanism for echo chambers, and the formation of multipolar opinion distributions. Remarkably, the weighted-median opinion dynamics are the first model applicable to ordered multiple-choice issues, which are prevalent in modern-day public debates and elections.","497":"Abstract Research into hyperlink interaction patterns has been particularly interested in whether they integrate the online space or segregate it into \u201cecho chambers.\u201d Concentrating on contentious politics in national settings, the existing studies have mainly examined the relationships between domestic actors, mostly bloggers. This study seeks to expand the focus by including several actor types, allowing their connective actions to reach beyond national borders, and employing a comparative approach that contrasts high- with low-contentious contexts. Analyzing climate change hyperlink networks originating in the US and Switzerland, the results show that their transnational dimension plays a crucial role in polarizing the discourse, regardless of the specific political context. We find similar patterns that segregate climate advocates from skeptics and lead to distinct transnational relationships within the camps. The results demonstrate that countermovement actors in particular are able to forge strong transnational alliances.","498":"Online social media, periodically serves as a platform for cascading polarizing topics of conversation. The inherent community structure present in online social networks (ho-mophily) and the advent of fringe outlets like Gab have created online \u201cecho chambers\u201d that amplify the effects of polarization, which fuels detrimental behavior. Recently, in October 2018, Gab made headlines when it was revealed that Robert Bowers, the individual behind the Pittsburgh Synagogue massacre, was an active member of this social media site and used it to express his anti-Semitic views and discuss conspiracy theories. Thus to address the need of automated data-driven analyses of such fringe outlets, this research proposes novel methods to discover topics that are prevalent in Gab and how they cascade within the network. Specifically, using approximately 34 million posts, and 3.7 million cascading conversation threads with close to 300k users; we demonstrate that there are essentially five cascading patterns that manifest in Gab and the most \u201cviral\u201d ones begin with an echo-chamber pattern and grow out to the entire network. Also, we empirically show, through two models viz. Susceptible-Infected and Bass, how the cascades structurally evolve from one of the five patterns to the other based on the topic of the conversation with upto 84% accuracy.","499":null,"500":"Echocardiography (echo) is a common means of evaluating cardiac conditions. Due to the label scarcity, semi-supervised paradigms in automated echo analysis are getting traction. One of the most sought-after problems in echo is the segmentation of cardiac structures (e.g. chambers). Accordingly, we propose an echocardiogram generation approach using generative adversarial networks with a conditional patch-based discriminator. In this work, we validate the feasibility of GAN-enhanced echo generation with different conditions (segmentation masks), namely, the left ventricle, ventricular myocardium, and atrium. Results show that the proposed adversarial algorithm can generate high-quality echo frames whose cardiac structures match the given segmentation masks. This method is expected to facilitate the training of other machine learning models in a semi-supervised fashion as suggested in similar researches.","501":"Agents in a network want to learn the true state of the world from their own signals and their neighbors' reports. Agents know only their local networks, consisting of their neighbors and the links among them. Every agent is Bayesian with the (possibly misspecified) prior belief that her local network is the entire network. We present a tractable learning rule to implement such locally Bayesian learning: each agent extracts new information using the full history of observed reports in her local network. Despite their limited network knowledge, agents learn correctly when the network is a social quilt, a tree-like union of cliques. But they fail to learn when a network contains interlinked circles (echo chambers), despite an arbitrarily large number of correct signals.","502":"Concern over filter bubbles, echo chambers, and misinformation on the Internet are not new. However, as noted by Howard and Bradshaw (Chapter 12), events around the 2016 US presidential election and the UK\u2019s Brexit referendum brought these concerns up again to near-panic levels, raising questions about the political implications of the algorithms that drive search engines and social media. To address these issues, the authors conducted an extensive survey of Internet users in Britain, France, Germany, Italy, Poland, Spain, and the US, asking respondents how they use search, social media, and other media for getting information about politics, and what difference these media have made for them. Their findings demonstrate that search is one among many media gateways and outlets deployed by those interested in politics, and that Internet users with an interest in politics and search skills are unlikely to be trapped in a filter bubble, or cocooned in a political echo chamber.","503":"Culture is not static and technological innovations have greatly changed culture throughout history, no more so than in recent years. Modern culture is very much influenced and defined by recent technology and media use, primarily through social media applications such as Facebook, Instagram, LinkedIn, Snapchat and Twitter. Although use and impact vary around the world, globalization brings this cultural change into wider and faster channels. Social media has transformed the way people interact and learn in local, national and international terms as well as evolving new social practices. Echo chambers, filter bubbles, and fake news dominate the internet and people's lives, determining and even limiting the content of learning that people are exposed to on social media platforms. This, in itself, channels cultural practice into homogenized tranches creating a cyclical influence which feeds back into evolving technology. This article sets out to discuss the current cultural impact of social media, its limitation on learning and surface the ethical issues surrounding its use.","504":"In recent years, malicious information had an explosive growth in social media, with serious social and political backlashes. Recent important studies, featuring large-scale analyses, have produced deeper knowledge about this phenomenon, showing that disinformation spreads faster, deeper and more broadly than the truth on social media, where bots and echo chambers play an important role in diffusion networks. Following these directions, we explore the possibility of classifying news articles circulating on social media based exclusively on a topological analysis of their diffusion networks. To this aim we collected a large dataset of networks on Twitter pertaining to news articles published on two distinct classes of sources, namely outlets that convey mainstream, reliable and objective information and those that fabricate and disseminate various kinds of disinformation stories. We carried out an extensive comparison of these networks using several alignment-free approaches including basic network properties, centrality measures distributions, and network distances. We accordingly evaluated to what extent these features allow to discriminate between the networks associated to the aforementioned news domains. Our results highlight that the communities of users spreading mainstream rather than disinformation news tend to shape diffusion networks with subtle yet systematic differences. This opens the way to promptly and correctly identifying disinformation on social media by solely inspecting the resulting diffusion networks.","505":"Nowadays, individuals heavily rely on search engines for seeking information. The presence of information bubbles (filter bubbles and echo chambers) can threaten the effectiveness of these systems in providing unbiased information and damage healthy civic discourse and open-minded deliberation. In this paper, we propose a new paradigm for search that aims at mitigating the information bubble in the search. The paradigm, which we call perspective-based search (PBS), is based on the intuition that in a fair search the user should not be limited to the results corresponding to a specific perspective of the search topic. Briefly, in PBS, different perspectives of the search topic are identified and presented to the user and the user can select a perspective for the search results. In this paper, we focus on the paradigm itself, why it is an appropriate solution, and how it differs from other solutions. We raise new questions and call for research on the paradigm and on providing solutions for implementing its required components. We do not aim at providing any specific implementation for it, although we provide some hints on implementing it. We also provide a survey of the related concepts and methods and discuss their differences with PBS.","506":"Social-based recommenders seek to exploit the mechanisms of homophily and influence observed in social networks in order to provide more accurate recommendations. The way they achieve this is by enforcing similar preferences among users that are socially connected. It is thus reasonable to question whether such approaches lead to the formation of echo chambers, i.e., social groups with a narrow set of preferences and which receive recommendations with low diversity and novelty. This work studies this research question and quantifies the diversity and novelty of existing methods. An important finding is that it is possible to increase accuracy without sacrificing diversity and novelty.","507":"The spread of radical opinions, facilitated by homophilic Internet communities (echo chambers), has become a threat to the stability of societies around the globe. The concept of choice architecture--the design of choice information for consumers with the goal of facilitating societally beneficial decisions--provides a promising (although not uncontroversial) general concept to address this problem. The choice architecture approach is reflected in recent proposals advocating for recommender systems that consider the societal impact of their recommendations and not only strive to optimize revenue streams. However, the precise nature of the goal state such systems should work towards remains an open question. In this paper, we suggest that this goal state can be defined by considering target opinion spread in a society on different topics of interest as a multivariate normal distribution; i.e., while there is a diversity of opinions, most people have similar opinions on most topics. We explain why this approach is promising, and list a set of cross-disciplinary research challenges that need to be solved to advance the idea.","508":null,"509":"When people interact through technical infrastructure such as that of organisations or the World Wide Web, this infrastructure will change and in some cases new identifiable structures or even eco-systems may emerge. Examples of such emergent socio-technical systems on the Web include some social machines and phenomena such as echo chambers. To model these complex social systems we develop a method for formalising the moments, or occasions, of experience of an individual person by contriving a 'chemistry' encoding possible sequences of their external stimuli, internal experience and reactions to this internal experience. We take a process oriented approach and formalise this as a stochastic Petri net. We wire together a number of these to form a fixed social network in which experience is shared. The resulting model unfolds into many possible causal graphs of occasions of experience which we show using an interactive visualisation. We demonstrate the utility of this method by encoding models exhibiting information diffusion and what we call multiple phase diffusion, and then consensus formation, before encoding a mechanism of echo chamber formation. We then demonstrate the conflation of individuals' positions on otherwise separate issues through emotion. The approach results in a single Petri net model which may be analysed using qualitative and quantitative techniques supporting web science research. It provides a way to describe and reason about the internal experience of individuals within multi-scale socio-technical systems.","510":"This paper does not describe a working system. Instead, it presents a single idea about representation which allows advances made by several different groups to be combined into an imaginary system called GLOM. The advances include transformers, neural fields, contrastive representation learning, distillation and capsules. GLOM answers the question: How can a neural network with a fixed architecture parse an image into a partwhole hierarchy which has a different structure for each image? The idea is simply to use islands of identical vectors to represent the nodes in the parse tree. If GLOM can be made to work, it should significantly improve the interpretability of the representations produced by transformer-like systems when applied to vision or language. 1 Overview of the idea There is strong psychological evidence that people parse visual scenes into partwhole hierarchies and model the viewpoint-invariant spatial relationship between a part and a whole as the coordinate transformation between intrinsic coordinate frames that they assign to the part and the whole [Hinton, 1979]. If we want to make neural networks that understand images in the same way as people do, we need to figure out how neural networks can represent part-whole 1GLOM is derived from the slang \u201dglom together\u201d which may derive from the word \u201dagglomerate\u201d. 1 ar X iv :2 10 2. 12 62 7v 1 [ cs .C V ] 2 5 Fe b 20 21 hierarchies. This is difficult because a real neural network cannot dynamically allocate a group of neurons to represent a node in a parse tree. The inability of neural nets to dynamically allocate neurons was the motivation for a series of models that used \u201ccapsules\u201d [Sabour et al., 2017, Hinton et al., 2018, Kosiorek et al., 2019]. These models made the assumption that a group of neurons called a capsule would be permanently dedicated to a part of a particular type occurring in a particular region of the image. A parse tree could then be created by activating a subset of these pre-existing, type-specific capsules and the appropriate connections between them. This paper describes a very different way of using capsules to represent the part-whole hierarchy in a neural net. Even though this paper is primarily concerned with the perception of a single static image, GLOM is most easily understood as a pipeline for processing a sequence of frames, so a static image will be treated as a sequence of identical frames. The GLOM architecture is composed of a large number of columns which all use exactly the same weights. Each column is a stack of spatially local autoencoders that learn multiple levels of representation for what is happening in a small image patch. Each autoencoder transforms the embedding at one level into the embedding at an adjacent level using a multilayer bottom-up encoder and a multilayer top-down decoder. These levels correspond to the levels in a part-whole hierarchy. When shown an image of a face, for example, a single column might converge on embedding vectors representing a nostril, a nose, a face, and a person. Figure 1 shows how the embeddings at different levels interact in a single column. Figure 1 does not show the interactions between embeddings at the same level in different columns. These are much simpler than the interactions within a column because they do not need to implement part-whole coordinate transforms. They are like the attention-weighted interactions between columns representing different word fragments in a multi-headed transformer [Devlin et al., 2018], but they are simpler because the query, key and value vectors are all identical to the embedding vector. The role of the inter-column interactions is to produce islands of identical embeddings at a level by making each embedding vector at that level regress towards other similar vectors at nearby locations. This creates multiple local \u201decho chambers\u201d in which embeddings at a level attend mainly to other like-minded embeddings. 2What neurons do is determined by their incoming and outgoing weights and real neurons cannot completely change these weights rapidly. 3The GLOM architecture has some similarity to models that use the errors in top-down predictions as their bottom-up signals [Rao and Ballard, 1999], but in a nonlinear system the bottom-up signals cannot just carry the prediction error because the full activity vector is required to select the right operating regime for the non-linear units. 4Each level in a column bears some resemblance to a hypercolumn as described by neuroscientists. 5An embedding vector is the activity vector of a capsule.","511":"Significance Polarization is rising while political debates are moving to online social platforms. In such settings, algorithms are used to recommend new connections to users, through so-called link recommendation algorithms. Users are often recommended based on structural similarity (e.g., nodes sharing many neighbors are similar). We show that preferentially establishing links with structurally similar nodes potentiates opinion polarization by stimulating network topologies with well-defined communities (even in the absence of opinion-based rewiring). When networks are composed of nodes that react differently to out-group contacts\u2014either converging or polarizing\u2014connecting structurally dissimilar nodes enhances moderate opinions. Our study sheds light on the impacts of social-network algorithms in opinion dynamics and unveils avenues to steer polarization in online social networks. The level of antagonism between political groups has risen in the past years. Supporters of a given party increasingly dislike members of the opposing group and avoid intergroup interactions, leading to homophilic social networks. While new connections offline are driven largely by human decisions, new connections on online social platforms are intermediated by link recommendation algorithms, e.g., \u201cPeople you may know\u201d or \u201cWhom to follow\u201d suggestions. The long-term impacts of link recommendation in polarization are unclear, particularly as exposure to opposing viewpoints has a dual effect: Connections with out-group members can lead to opinion convergence and prevent group polarization or further separate opinions. Here, we provide a complex adaptive\u2013systems perspective on the effects of link recommendation algorithms. While several models justify polarization through rewiring based on opinion similarity, here we explain it through rewiring grounded in structural similarity\u2014defined as similarity based on network properties. We observe that preferentially establishing links with structurally similar nodes (i.e., sharing many neighbors) results in network topologies that are amenable to opinion polarization. Hence, polarization occurs not because of a desire to shield oneself from disagreeable attitudes but, instead, due to the creation of inadvertent echo chambers. When networks are composed of nodes that react differently to out-group contacts, either converging or polarizing, we find that connecting structurally dissimilar nodes moderates opinions. Overall, our study sheds light on the impacts of social-network algorithms and unveils avenues to steer dynamics of radicalization and polarization in online social networks.","512":"Individuals of modern societies share ideas and participate in collective processes within a pervasive, variable, and mostly hidden ecosystem of content filtering technologies that determine what information we see online. Despite the impact of these algorithms on daily life and society, little is known about their effect on information transfer and opinion formation. It is thus unclear to what extent algorithmic bias has a harmful influence on collective decision-making, such as a tendency to polarize debate. Here we introduce a general theoretical framework to systematically link models of opinion dynamics, social network structure, and content filtering. We showcase the flexibility of our framework by exploring a family of binary-state opinion dynamics models where information exchange lies in a spectrum from pairwise to group interactions. All models show an opinion polarization regime driven by algorithmic bias and modular network structure. The role of content filtering is, however, surprisingly nuanced; for pairwise interactions it leads to polarization, while for group interactions it promotes coexistence of opinions. This allows us to pinpoint which social interactions are robust against algorithmic bias, and which ones are susceptible to bias-enhanced opinion polarization. Our framework gives theoretical ground for the development of heuristics to tackle harmful effects of online bias, such as information bottlenecks, echo chambers, and opinion radicalization.","513":"5G network technology is growing fast, thus the number of devices and the traffic are likely to pose impressive challenges. A new paradigm called \u201cInternet-of-People\u201d (IoP) represents a valid approach to include the social aspect. Following an IoP perspective, we believe that the knowledge of social multiplex interactions and dynamics could drive more sustainable growth. By merging this with the Device-to-Device communication (D2D), we originate a new paradigm presented in this work. We propose a novel bio-inspired approach for quantifying the impact of the social multiplex structure on D2D contents\u2019 dissemination. Through rigorous mathematical modelling, we have shaped the D2D data dissemination process as a social contagion dynamics of two co-evolving spreading processes. We weigh the dynamic interactions by including the concepts of homophily and awareness. We have measured the effect of homophily, awareness and network heterogeneity on information diffusion. The bio-inspired mechanism is evaluated through a rigorous mathematical and algorithm analysis, and a meaningful simulation. We show that this mechanism is effective in tuning network awareness and alertness, breaking the \u201cecho chambers\u201d effect. Through our model, we have defined and proposed the guidelines to discriminate the nature of the contents based on contents\u2019 dissemination.","514":"The social brain hypothesis approximates the total number of social relationships we are able to maintain at 150. Similar cognitive constraints emerge in several aspects of our daily life, from our mobility to the way we communicate, and might even affect the way we consume information online. Indeed, despite the unprecedented amount of information we can access online, our attention span still remains limited. Furthermore, recent studies have shown that online users are more likely to ignore dissenting information, choosing instead to interact with information adhering to their own point of view. In this paper, we quantitatively analyse users\u2019 attention economy in news consumption on social media by analysing 14 million users interacting with 583 news outlets (pages) on Facebook over a time span of six years. In particular, we explore how users distribute their activity across news pages and topics. On the one hand, we find that, independently of their activity, users show a tendency to follow a very limited number of pages. On the other hand, users tend to interact with almost all the topics presented by their favoured pages. Finally, we introduce a taxonomy accounting for users\u2019 behaviour to distinguish between patterns of selective exposure and interest. Our findings suggest that segregation of users in echo chambers might be an emerging effect of users\u2019 activity on social media and that selective exposure\u2014i.e. the tendency of users to consume information adhering to their preferred narratives\u2014could be a major driver in their consumption patterns.","515":"Democracies are postulated upon the ability to carry out fair elections, free from any form of interference or manipulation. Social media have been reportedly used to distort public opinion nearing election events in the United States and beyond. With over 240 million election-related tweets recorded between 20 June and 9 September 2020, in this study we chart the landscape of social media manipulation in the context of the upcoming 3 November 2020 U.S. presidential election. We focus on characterizing two salient dimensions of social media manipulation, namely (i) automation (e.g., the prevalence of bots), and (ii) distortion (e.g., manipulation of narratives, injection of conspiracies or rumors). Despite being outnumbered by several orders of magnitude, just a few thousands of bots generated spikes of conversations around real-world political events in all comparable with the volume of activity of humans. We discover that bots also exacerbate the consumption of content produced by users with their same political views, worsening the issue of political echo chambers. Furthermore, coordinated efforts carried out by Russia, China and other countries are hereby characterized. Finally, we draw a clear connection between bots, hyper-partisan media outlets, and conspiracy groups, suggesting the presence of systematic efforts to distort political narratives and propagate disinformation. Our findings may have impactful implications, shedding light on different forms of social media manipulation that may, altogether, ultimately pose a risk to the integrity of the election.","516":"Many people rely on online social networks as sources of news and information, and the spread of media content with ideologies across the political spectrum influences online discussions and impacts actions offline. To examine the impact of media in online social networks, we generalize bounded-confidence models of opinion dynamics by incorporating media accounts as influencers in a network. We quantify partisanship of content with a continuous parameter on an interval, and we formulate higher-dimensional generalizations to incorporate content quality and increasingly nuanced political positions. We simulate our model with one and two ideological dimensions, and we use the results of our simulations to quantify the \"entrainment\" of content from non-media accounts to the ideologies of media accounts in a network. We maximize media impact in a social network by tuning the number of media accounts that promote the content and the number of followers of the accounts. Using numerical computations, we find that the entrainment of the ideology of content spread by non-media accounts to media ideology depends on a network's structural features, including its size, the mean number of followers of its nodes, and the receptiveness of its nodes to different opinions. We then introduce content quality --- a key novel contribution of our work --- into our model. We incorporate multiple media sources with ideological biases and quality-level estimates that we draw from real media sources and demonstrate that our model can produce distinct communities (\"echo chambers\") that are polarized in both ideology and quality. Our model provides a step toward understanding content quality and ideology in spreading dynamics, with ramifications for how to mitigate the spread of undesired content and promote the spread of desired content.","517":"Theories of personal branding are built on the idea that each individual should be aware of the persona they present to the world. Nowadays, as social interactions are increasingly shifting to the online arena, users of social platforms are presented with many new opportunities and technology-enabled tools by which they can construct their online personas. A powerful type of tool that has emerged in this ecosystem is the ability to reiterate a friend\u2019s activity, that is, to redistribute an exact copy of the content that the friend has posted online (e.g., words, videos, or pictures) and to incorporate it into one\u2019s own online image. In this work, we examine how users employ reiteration tools when presenting themselves and shaping their online presence. We focus on retweeting behavior on Twitter and study the spectrum of topics that users choose to reiterate. We hypothesize that users\u2019 retweeting behavior will show patterns that are theorized to characterize effective personal branding strategies: Specifically, when reiterating content produced by others, a user will maintain a persona that is consistent with the persona portrayed in self-produced tweets. \nWe analyze data taken from Twitter over a period of 6 months in 2016, with regard to 3,388 nonexpert users and 464 expert users and the users whom they followed. We use LDA topic modeling to derive the topics in each user\u2019s self-produced tweets and retweets. We find that users\u2019 retweets tend to focus on the topics they address in their self-produced tweets, instead of adding new topics. Further, we find that a user\u2019s retweets do remarkably little to alter the distribution of topics discussed in self-produced tweets. Finally, we find that this tendency is more prominent among \u201cexpert\u201d users (i.e., professional bloggers who are particularly likely to use Twitter as a personal branding tool). A rigorous identification strategy lends support to the proposition that the observed effects are indeed driven by image-related considerations rather than by alternative factors known to influence retweeting behavior, such as exposure bias (a phenomenon associated with the formation of echo chambers), need for uniqueness, and social dynamics on the Twitter platform.","518":"In this work we look at opinion formation and the effects of two phenomena both of which promote consensus between agents connected by ties: influence, agents changing their opinions to match their neighbors; and selection, agents re-wiring to connect to new agents when the existing neighbor has a different opinion. In our agent-based model, we assume that only weak ties can be rewired and strong ties do not change. The network structure as well as the opinion landscape thus co-evolve with two important parameters: the probability of influence versus selection; and the fraction of strong ties versus weak ties. Using empirical and theoretical methodologies we discovered that on a two-dimensional spatial network: \\beginitemize \\item With no\/low selection the presence of weak ties enables fast consensus. This conforms with the classical theory that weak ties are helpful for quickly mixing and spreading information, and strong ties alone act much more slowly. \\item With high selection, too many weak ties inhibit any consensus at all---the graph partitions. The weak ties reinforce the differing opinions rather than mixing them. However, sufficiently many strong ties promote convergence, though at a slower pace. \\enditemize We additionally test the aforementioned results using a real network. Our study relates two theoretical ideas: the strength of weak ties---that weak ties are useful for spreading information; and the idea of echo chambers or filter bubbles, that people are typically bombarded by the opinions of like-minded individuals. The difference is in how (much) selection operates.","519":"False consensus effect (FCE) refers to a cognitive bias of relative overestimation of public support for one's own opinion. FCE has been linked to selective social interaction with like-minded people as well as to selective exposure to attitude-consistent information. Previous studies tested these links mostly in offline settings. However, it is assumed that FCE is also affected by the homogeneity of users' online contact network, the extent to which they use online social network (OSN), and their individual tendency to avoid ambiguous information. Two online studies with a total of 380 participants aged 18-35 years were conducted to test these hypotheses through a multilevel modeling approach. In Study 1, participants with a more homogeneous online network, longer daily OSN usage time, and lower ambiguity tolerance displayed significantly higher FCE. The effects of network homogeneity and ambiguity tolerance were replicated in Study 2. The implications of these findings are interpreted in the context of prior studies on FCE as well as the notion of OSN as \"echo chambers.\"","520":"This paper presents an ongoing process of examining and reinventing the Guqin, to forge a contemporary engagement with this unique traditional Chinese string instrument. The SlowQin (see figure 1) is both a hybrid resemblance of the Guqin and a fully functioning wireless interface to interact with computer software. It has been developed and performed with during the last eleven years. Instead of aiming for virtuosic perfection of playing the instrument, SlowQin emphasizes the openness for continuously rethinking and reinventing the Guqin\u2019s possibilities. Through a combination of conceptual work and practical production, Echo Ho\u2019s SlowQin project works as an experimental twist on Historically Informed Performance, with the motivation of conveying artistic gestures that tackle philosophical, ideological, and socio-political subjects embedded in our living environment in globalised conditions. In particular, this paper touches the history of the Guqin, gives an overview of the technical design concepts of the instrument, and discusses the aesthetical approaches of the SlowQin performances that have been realised so far.","521":"We propose a method for estimating argument diversity and interactivity in online discussion threads. Using a case study on the subject of Black Pete (\"Zwarte Piet\") in the Netherlands, the approach for automatic detection of echo chambers is presented. Dynamic thread scoring calculates the status of the discussion on the thread level, while individual messages receive a contribution score reflecting the extent to which the post contributed to the overall interactivity in the thread. We obtain platform-specific results. Gab hosts only echo chambers, while the majority of Reddit threads are balanced in terms of perspectives. Twitter threads cover the whole spectrum of interactivity. While the results based on the case study mirror previous research, this calculation is only the first step towards better understanding and automatic detection of echo effects in online discussions.","522":"Cardiovascular diseases (CVDs) are considered as the main reason of mortality around the world. Echocardiography is the most common imaging modality for diagnosis or treatment follow-up of CVDs. However, because of speckle-noise corruption and low resolution, segmentation of heart chambers in echo-images is a challenging endeavor. We previously proposed a probabilistic atlas as a prior model for the heart chambers in echo-images. In this paper, we propose a new active contour for the segmentation of cardiac chambers by using that digital atlas. Our deformable model effectively combines the global and local (patch-based) region-based energy functionals. Also, to extract all the cardiac chambers, we determine four active contours in every echo-image (one contour for each chamber in the four-chamber view). For simultaneously evolving all the curves, a coupling term is also added to the energy functional. Finally, the evolution equation of each active contour is computed through the Euler-Lagrange equation. Experimental results demonstrate that our method provides accurate solutions compared to expert delineations.","523":"Voat was a news aggregator website that shut down on December 25, 2020. The site had a troubled history and was known for hosting various banned subreddits. This paper presents a dataset with over 2.3M submissions and 16.2M comments posted from 113K users in 7.1K subverses (the equivalent of subreddit for Voat). Our dataset covers the whole lifetime of Voat, from its developing period starting on November 8, 2013, the day it was founded, April 2014, up until the day it shut down (December 25, 2020). This work presents the largest and most complete publicly available Voat dataset, to the best of our knowledge. We also present a preliminary analysis to cover posting activity and daily user and subverse registration on the platform so that researchers interested in our dataset can know what to expect. Our data may prove helpful to false news dissemination studies as we analyze the links users share on the platform, finding that many communities rely on alternative news press, like Breitbart and GatewayPundit, for their daily discussions. Last, we perform network analysis on user interactions finding that many users prefer not to interact with subverses outside their narrative interests, which could be helpful to researchers focusing on polarization and echo chambers. Also, since Voat was one of the platforms many Reddit users migrated to after a ban, we are confident that our dataset will motivate and assist researchers studying deplatforming. In addition, many hateful and conspiratorial communities seem to be very popular on Voat, which makes our work valuable for researchers focusing on toxicity, conspiracy theories, cross-platform studies of social networks, and natural language processing.","524":"Significance Differences in beliefs within a society are a prevalent human phenomenon. A standard explanation for polarized beliefs relies on \u201cecho chambers\u201d that expose people to different sources of information. However, there is ample evidence that people sustain different beliefs even when faced with the same information, and they interpret that information differently\u2014facts often attributed to a confirmatory bias. We suggest models of how humans form beliefs based on machine learning theory. These models show how stark differences in beliefs can arise and endure due to human limitations in interpreting complex information. Our framework illuminates inherent challenges and potential ways of overcoming polarization. We present two models of how people form beliefs that are based on machine learning theory. We illustrate how these models give insight into observed human phenomena by showing how polarized beliefs can arise even when people are exposed to almost identical sources of information. In our first model, people form beliefs that are deterministic functions that best fit their past data (training sets). In that model, their inability to form probabilistic beliefs can lead people to have opposing views even if their data are drawn from distributions that only slightly disagree. In the second model, people pay a cost that is increasing in the complexity of the function that represents their beliefs. In this second model, even with large training sets drawn from exactly the same distribution, agents can disagree substantially because they simplify the world along different dimensions. We discuss what these models of belief formation suggest for improving people\u2019s accuracy and agreement.","525":"Contrary to expectations that the increased connectivity offered by the internet and particularly Online Social Networks (OSNs) would result in broad consensus on contentious issues, we instead frequently observe the formation of polarised echo chambers, in which only one side of an argument is entertained. These can progress to filter bubbles, actively filtering contrasting opinions, resulting in vulnerability to misinformation and increased polarisation on social and political issues. These have real world effects when they spread offline, such as vaccine hesitation and violence. This work seeks to develop a better understanding of how echo chambers manifest in different discussions dealing with different issues over an extended period of time. We explore the activities of two groups of polarised accounts across three Twitter discussions in the Australian context. We found Australian Twitter accounts arguing against marriage equality in 2017 were more likely to support the notion that arsonists were the primary cause of the 2019\/2020 Australian bushfires, and those supporting marriage equality argued against that arson narrative. We also found strong evidence that the stance people took on marriage equality in 2017 did not predict their political stance in discussions around the Australian federal election two years later. Although mostly isolated from each other, we observe that in certain situations the polarised groups may interact with the broader community, which offers hope that the echo chambers may be reduced with concerted outreach to members.","526":"A model of opinion dynamics featuring disagreement and biased interactions, which reproduces the phenomenon of echo-chambers, is considered. An improvement of the model presenting open-minded agents, i.e. not acting in a biased way, and their ability to dismantle echo-chambers is also treated. In this setting, we devise a mechanism introducing open-mindedness in a self-consistent way. We also study how open-minded behavior can be enhanced through different mechanisms, leading to the disruption of the echo-chambers. In a second part, we consider a dataset consisting of six months of tweets on italian politics. We build a complete pipeline featuring machine learning and simple natural language processing tools in order to analyse the data. The goal is to empirically measure the observables of the model, in order to test it against empirical data but also to gain more insights on the users' opinion dynamics. We find that the model is only able to partially reproduce the properties of the dataset, even though some limitations of our methods prevent us from too strong conclusions. Still, the tools provided by the model are useful in determining some features of social bot users and their difference from human users, giving also some insights on the italian public political debate.","527":null,"528":"As polarised discussions is defined by spread of ideas within echo chambers, characterising what drives in-group spreading is essential for understanding the problem. We explore the characteristics of popular and viral content in a Twitter retweet network of climate change discussion around the 2019 announcement of the Nobel Peace Prize. The resulting network is polarised and we identify an activist and a skeptic group within it, with very little interaction between the two. We further disentangle tweet virality from tweet popularity using an independent cascade model, and find that popular features do not necessarily make the content more viral. Most importantly, our results reveal that the features most strongly related to virality are also ones that enhance intragroup ties while repulsing outgroup engagement. With this, our study sheds light, from an information spreading perspective, on the formation and upkeep of echo chambers of climate discussions.","529":"Echocardiography (echo) is a non-invasive, safe, widely available imaging modality that is frequently used to assess the heart structure and function. Accurate heart chamber segmentation is an essential step to quantify certain parameters, including heart chamber volumes. In clinical practice, this task is manually done by echo experts, where it consumes considerable time and is subjective to both errors as well as intra-operator variability. Artificial intelligence (AI) models have been used to automatically segment heart chambers. We conducted a scoping review to provide an overview of the AI models used for this task. Three bibliographic databases; PubMed, Embase, and Google Scholar were explored. Out of 640 initially retrieved studies, 36 studies were included. Multiple AI models used for echo images segmentation were identified, which can be broadly categorized into five methods: low-level image processing, deformable-based, statistical techniques, machine learning (ML), and deep learning-based (DL) techniques. The initial three categories were relatively simple and required less computational complexity compared to the ML and DL models. The convolutional neural network was the most widely used DL-based technique in most-recent publications. Generalizability of the models is a major concern that needs to be addressed in the future. Well-annotated larger 2D echo image datasets would be required to mitigate the challenges to some extent.","530":null,"531":null,"532":"A growing body of evidence points to critical vulnerabilities of social media, such as the emergence of partisan echo chambers and the viral spread of misinformation. We show that these vulnerabilities are amplified by abusive behaviors associated with so-called \u201cfollow trains\u201d on Twitter, in which long lists of like-minded accounts are mentioned for others to follow. We present the first systematic analysis of a large U.S. hyper-partisan train network. We observe an artificial inflation of influence: accounts heavily promoted by follow trains profit from a median six-fold increase in daily follower growth. This catalyzes the formation of highly clustered echo chambers, hierarchically organized around a dense core of active accounts. Train accounts also engage in other behaviors that violate platform policies: we find evidence of activity by inauthentic automated accounts and abnormal content deletion, as well as amplification of toxic content from lowcredibility and conspiratorial sources. Some train accounts have been active for years, suggesting that platforms need to pay greater attention to this kind of abuse.","533":"In online communication, it is often difficult to judge if an unknown person is competent, telling the truth or interested in honestly helping others. This leads to mistrust and social phenomena like echo chambers and misinformation campaigns. Creating transparency by introducing contributive social capital (CSC), a metric encompassing the competence, trustworthiness, and social responsibility of a user, could alleviate this problem. We investigate the utility of social capital market systems as information sources for the assessment of CSC.","534":"\n UNSTRUCTURED\n Social media radically changed how information is consumed and reported and elicited a disintermediated access to an unprecedented amount of content. The world health organization (WHO) coined the term infodemics to identify the information overabundance during an epidemic. Indeed, the spread of inaccurate and misleading information may alter behaviours and complicate crisis management and health responses. This paper addresses information diffusion during the COVID-19 pandemic period with a massive data analysis on YouTube. First, we analyze more than 2M users\u2019 engagement in 13000 videos released by 68 different YouTube channels, with different political bias and fact-checking indexes. We then investigate the relationship between each user\u2019s political preference and her\/his consumption of questionable\/reliable information. Our results, quantified using information theory measures, provide evidence for the existence of echo chambers across two dimensions represented by the political bias and by the trustworthiness of information channels. Finally, we observe that the echo chamber structure cannot be reproduced after properly randomizing the users\u2019 interaction patterns.\n","535":"Many real-world situations involve learning entirely or mostly based on the information provided by other people, which creates a thorny epistemological problem: how does one determine which of those people to trust? Previous work has shown that even populations of rational Bayesian agents, faced with this problem, polarise into \u201cecho chambers\u201d characterised by different beliefs and low levels of between-group trust. In this study we show that this general result holds even when the reasoners have a more complex meaning space and can communicate about their beliefs in a more nuanced way. However, even a tiny amount of exposure to a mutually trusted \u201cground truth\u201d is sufficient to eliminate polarisation. Societal and psychological implications are discussed.","536":"The echo chamber, a condition where people are only surrounded by similar opinions, in the social networking system (SNS) has become a topic of interest as of recently. There has been much research on the topic, but there are conflicting accounts on how prevalent they are. Some evidence shows that echo chambers are ubiquitous on the internet based on the prevalence of selective information sharing among SNS users. Other researchers argue that only a small segment of the population see themselves to be in an echo chamber based on survey results. We develop a model to explore the conditions that could connect the two counter-intuitive observations of the echo chamber. We use the reinterpretation of the Zaller model of public opinion using an agent-based model (ABM) framework to take into account how people convert political information into public opinion. We find that the two observations can coexist under the condition that the society has a balanced proportion of people's political predisposition among others. The findings also suggest that well-balanced media could play a role in moderating the echo chamber in society.","537":"On-line conflict can lead to and manifest itself in real-time emotional distress and radical behaviour. Whilst the topics are diverse, one of the most challenging and relatively under-explored topics is in real conflict landscapes. Many such places have high ethnolinguistic diversity with multiple principal and hybrid language groups. Here, we examine how on-line social network debates unfold for the recent Russian intervention in Ukraine. We use Natural Language Processing (NLP) to map the evolving Reddit social network, showing rich structural and sentiment signal evolution. Whilst relatively straightforward for well-resourced languages, NLP tasks for ethno-linguistic fictionalised areas with 22 languages including various lingua franca is challenging, and require proprietary methods. Yet, it is in this linguistic and real-world landscape that we uncover politically sensitive posts. We demonstrate how we can extract clear topic groups, echo chambers, and create the data that will enable us to track the sentiment of users and the role they play both within and between echo chambers.","538":"When individuals interact in a social network their opinions can change, at times quite significantly, as a result of social influence. In elections, for example, while they might initially support one candidate, what their friends say may lead them to support another. But how do opinions settle in a social network, as a result of social influence? A recently proposed graph-theoretic metric, the influence gap, has shown to be a reliable predictor of the effect of social influence in two-party elections, albeit only tested on regular and scale-free graphs. Here, we investigate whether the influence gap is able to predict the outcome of multi-party elections on networks exhibiting community structure, i.e., made of highly interconnected components, and therefore more resembling of real-world interaction. To encode communities we build on the classical model of caveman graphs, which we extend to a richer graph family that displays different levels of homophily, i.e., how much connections and opinions are intertwined. Our contribution is three-fold. First, we study the predictive power of the influence gap in the presence of communities. We show that when there is no clear initial majority the influence gap is not a good predictor of the election outcome. When we instead allow for varying majorities, although the influence gap improves as a predictor, counting the initial partisan majority does con\u2217Corresponding author Email address: p.turrini@warwick.ac.uk (Paolo Turrini) Preprint submitted to Elsevier February 9, 2022 ar X iv :2 20 2. 03 96 1v 1 [ cs .S I] 8 F eb 2 02 2 sistently better, across all levels of homophily. Second, we study the combined effect of the more predictive metrics, as function of the homophily levels. Using regression models, we demonstrate that the influence gap combined with the initial votes count does increase the overall predictive power for some levels of homophily. Third, we study elections with more than two parties. Specifically, we extend the definition of the influence gap to any number of parties, considering various generalisations, and show that the initial votes count has an even higher predictive power when compared to influence gap than it did in the two-party case.","539":null,"540":"The use of cognitive heuristics often leads to fast and effective decisions. However, they can also systematically and predictably lead to errors known as cognitive biases. Strategies for minimizing or mitigating these biases, however, remain largely non-technological (e.g., training courses). The growing use of visual analytic (VA) tools for analysis and decision making enables a new class of bias mitigation strategies. In this work, we explore the ways in which the design of visualizations (vis) may be used to mitigate cognitive biases. We derive a design space comprised of 8 dimensions that can be manipulated to impact a user\u2019s cognitive and analytic processes and describe them through an example hiring scenario. This design space can be used to guide and inform future vis systems that may integrate cognitive processes more closely.","541":"Information visualization designers strive to design data displays that allow for efficient exploration, analysis, and communication of patterns in data, leading to informed decisions. Unfortunately, human judgment and decision making are imperfect and often plagued by cognitive biases. There is limited empirical research documenting how these biases affect visual data analysis activities. Existing taxonomies are organized by cognitive theories that are hard to associate with visualization tasks. Based on a survey of the literature we propose a task-based taxonomy of 154 cognitive biases organized in 7 main categories. We hope the taxonomy will help visualization researchers relate their design to the corresponding possible biases, and lead to new research that detects and addresses biased judgment and decision making in data visualization.","542":"Ten years ago, Thaler and Sunstein introduced the notion of nudging to talk about how subtle changes in the 'choice architecture' can alter people's behaviors in predictable ways. This idea was eagerly adopted in HCI and applied in multiple contexts, including health, sustainability and privacy. Despite this, we still lack an understanding of how to design effective technology-mediated nudges. In this paper we present a systematic review of the use of nudging in HCI research with the goal of laying out the design space of technology-mediated nudging - the why (i.e., which cognitive biases do nudges combat) and the how (i.e., what exact mechanisms do nudges employ to incur behavior change). All in all, we found 23 distinct mechanisms of nudging, grouped in 6 categories, and leveraging 15 different cognitive biases. We present these as a framework for technology-mediated nudging, and discuss the factors shaping nudges' effectiveness and their ethical implications.","543":null,"544":"We examine how and why Asian American and Pacific Islander (AAPI) moderators on Reddit shape the norms of their online communities through the analytic lens of emotional labor. We conduct interviews with 21 moderators who facilitate identity work discourse in AAPI subreddits and present a thematic analysis of their moderation practices. We report on their challenges to sustaining moderation, which include burning out from volunteer work, navigating hierarchical structures, and balancing unfulfilled expectations. We then describe strategies that moderators employ to manage emotional labor, which involve distancing away from drama, building solidarity from shared struggles, and integrating an ecology of tools for self-organized moderation. We provide recommendations for improving moderation in online communities centered around identity work and discuss implications of emotional labor in the design of Reddit and similar platforms.","545":"Objective: Spectral power analysis plays a predominant role in electroencephalogram-based emotional recognition. It can reflect activity differences among multiple brain regions. In addition to activation difference, different emotions also involve different large-scale network during related information processing. In this paper, both information propagation patterns and activation difference in the brain were fused to improve the performance of emotional recognition. Methods: We constructed emotion-related brain networks with phase locking value and adopted a multiple feature fusion approach to combine the compensative activation and connection information for emotion recognition. Results: Recognition results on three public emotional databases demonstrated that the combined features are superior to either single feature based on power distribution or network character. Furthermore, the conducted feature fusion analysis revealed the common characters between activation and connection patterns involved in the positive, neutral, and negative emotions for information processing. Significance: The proposed feasible combination of both information propagation patterns and activation difference in the brain is meaningful for developing the effective human\u2013computer interaction systems by adapting to human emotions in the real world applications.","546":"Real-time data about various traffic events and conditions\u2014offences, accidents, dangerous driving, or dangerous road conditions\u2014is crucial for safe and efficient transportation. Unlike roadside infrastructure data which are often limited in scope and quantity, crowdsensing approaches promise much broader and comprehensive coverage of traffic events. However, to ensure safe and efficient traffic operation, assessing trustworthiness of crowdsourced data is of crucial importance; this also includes detection of intentional or unintentional manipulation, deception, and spamming. In this paper, we design and demonstrate a road traffic event detection and source reputation assessment system for unreliable data sources. Special care is taken to adapt the system for operation in decentralized mode, using smart contracts on a Turing-complete blockchain platform, eliminating single authority over such systems and increasing resilience to institutional data manipulation. The proposed solution was evaluated using both a synthetic traffic event dataset and a dataset gathered from real users, using a traffic event reporting mobile application in a professional driving simulator used for driver training. The results show the proposed system can accurately detect a range of manipulative and misreporting behaviors, and quickly converges to the final trust score even in a resource-constrained environment of a blockchain platform virtual machine.","547":"As a remedy against fake news on social media, we examine the effectiveness of three different mechanisms for source ratings that can be applied to articles when they are initially published: exper...","548":null,"549":"Open Source Software (OSS) has changed drastically over the last decade, with OSS projects now producing a large ecosystem of popular products, involving industry participation, and providing professional career opportunities. But our field's understanding of what motivates people to contribute to OSS is still fundamentally grounded in studies from the early 2000s. With the changed landscape of OSS, it is very likely that motivations to join OSS have also evolved. Through a survey of 242 OSS contributors, we investigate shifts in motivation from three perspectives: (1) the impact of the new OSS landscape, (2) the impact of individuals' personal growth as they become part of OSS communities, and (3) the impact of differences in individuals' demographics. Our results show that some motivations related to social aspects and reputation increased in frequency and that some intrinsic and internalized motivations, such as learning and intellectual stimulation, are still highly relevant. We also found that contributing to OSS often transforms extrinsic motivations to intrinsic, and that while experienced contributors often shift toward altruism, novices often shift toward career, fun, kinship, and learning. OSS projects can leverage our results to revisit current strategies to attract and retain contributors, and researchers and tool builders can better support the design of new studies and tools to engage and support OSS development.","550":"Trust and reputation are important terms whether the communication is Humans-to-Human (H2H), Human-Machine-Interaction (HMI) or Machine-to-Machine (M2M). As Cloud computing and the internet of things (IoT) bring new innovations, they also cause various security and privacy issues. As numerous devices are continuously integrating as a core part of IoT, it is necessarily important to consider various security issues such as the trustworthiness of a user or detection of a malicious user. Moreover, fog computing also known as edge computing is revolutionizing the Cloud-based IoT by providing the Cloud services at the edge of the network, which can provide aid in overcoming security, privacy and trust issues. In this work, we propose a context-aware trust evaluation model to evaluate the trustworthiness of a user in a Fog based IoT (FIoT). The proposed approach uses a context-aware multi-source trust and reputation based evaluation system which helps in evaluating the trustworthiness of a user effectively. Further, we use context-aware feedback and feedback crawler system which helps in making trust evaluation unbiased, effective and reliable. Furthermore, we introduce monitor mode for malicious\/untrustworthy users, which helps in monitoring the behavior and trustworthiness of a user. The proposed approach uses several tunable factors, which can be tuned based on the system\u2019s requirements. The simulations and results indicate that our approach is effective and reliable to evaluate the trustworthiness of a user.","551":"We study a new source of bias in online review platforms that originates from the popularity difference between the traveling reviewer\u2019s hometown and destination.","552":"In recent years, electronic word of mouth (e-WOM) has been widely used by consumers on different online platforms. The numerous studies have emphasized the growing importance of e-WOM for the consumer decision-making process, particularly in the tourist sector. There are various factors that will influence the adoption of e-WOM by the users but among all these factors, credibility is of paramount importance. Changes in the platform, new consumer trends, and possible fake information require a continuous update and analysis of the factors that can influence the e-WOM perceived credibility and e-WOM adoption on TripAdvisor and other social tourism platforms. In the present study, we analyzed the following five factors that can impact e-WOM perceived credibility and e-WOM adoption: 1) volume of e-WOM; 2) source credibility; 3) rate extremism; 4) consumer involvement, and; 5) perceived e-WOM credibility. For the analysis, the Elaboration Likelihood Model (ELM) and PLS-SEM were used. The sample consisted of a total of 221 participants who responded to the questionnaire. The results revealed that, with the exception rate extremism, the four remaining factors have a significant impact on e-WOM perceived credibility and adoption. Therefore, these factors are important drivers of the e-WOM perceived credibility resulting in the e-WOM adoption. The results of the present study provide meaningful practical implications for hotel or social tourism platforms managers in terms of possible strategies to improve their online reputation.","553":"Traditional public key infrastructure-based authentication schemes provide vehicular networks with identity authentication and conditional privacy protection, which are not sufficient for assessing the credibility of messages. Additionally, although the new generation of cellular networks (5G) can dramatically improve the transmission efficiency of the messages, many existing authentication schemes are based on complex bilinear pairing operations, and the calculation time is too long to be suitable for delay-sensitive 5G-enabled vehicular networks. To address these issues, we propose a reputation system-based lightweight message authentication framework and protocol for 5G-enabled vehicular networks. The trusted authority (TA) is in charge of reputation management. A vehicle with a reputation score below the given threshold cannot obtain a credit reference from the TA for participating in the communication; therefore, the number of untrusted messages in vehicular networks is reduced from the source. Security analysis shows that our scheme is secure against an adaptively chosen-message attack, and also satisfies a series of requirements of vehicular networks. The scheme is based on the elliptic curve cryptosystem and supports batch authentication; therefore, it shows better performance in terms of time consumption when compared with related schemes.","554":"Ransomware is a particular form of cyber-attack in which a victim loses access to either his electronic device or files unless he pays a ransom to criminals. A criminal\u2019s ability to make money from ransomware critically depends on victims believing that the criminal will honour ransom payments. In this paper we explore the extent to which a criminal can build trust through reputation. We demonstrate that there are situations in which it is optimal for the criminal to always return the files and situations in which it is not. We argue that the ability to build reputation will depend on how victims distinguish between different ransomware strands. If ransomware is to survive as a long term revenue source for criminals then they need to find ways of building a good reputation.","555":"Many interactional archetypes from outside of learning contexts are being adapted and widely used for online learning environments without consideration for some of the side effects relevant to learner outcomes. Of particular concern is the effectiveness of help exchange in these learning environments. To address this need, this article explores how the reputation system features of up\/downvoting, badges, and displayed expertise impact student helper selection in a peer help exchange system within a MOOC discussion forum. We draw from Expectancy Value Theory for Help Sources as a theoretical framework for positioning the work. Results from our field experiment show that up\/downvoting has a negative impact on help seeking which is mitigated by the positive effect of Help Giver badges. The mechanism behind these results are then explored in a survey experiment investigating reputation systems\u2019 impact on students\u2019 expectancies, values, and costs for a help source.","556":"Evidence shows that developer reputation is extremely important when accepting pull requests or resolving reported issues. It is particularly salient in Free\/Libre Open Source Software since the developers are distributed around the world, do not work for the same organization and, in most cases, never meet face to face. The existing solutions to expose developer reputation tend to be forge specific (GitHub), focus on activity instead of impact, do not leverage social or technical networks, and do not correct often misspelled developer identities. We aim to remedy this by amalgamating data from all public Git repositories, measuring the impact of developer work, expose developer's collaborators, and correct notoriously problematic developer identity data. We leverage World of Code (WoC), a collection of an almost complete (and continuously updated) set of Git repositories by first allowing developers to select which of the 34 million(M) Git commit author IDs belong to them and then generating their profiles by treating the selected collection of IDs as that single developer. As a side-effect, these selections serve as a training set for a supervised learning algorithm that merges multiple identity strings belonging to a single individual. As we evaluate the tool and the proposed impact measure, we expect to build on these findings to develop reputation badges that could be associated with pull requests and commits so developers could easier trust and prioritize them.","557":"Open source software communities have demonstrated that they can produce high quality results. The overall success of peer code review, commonly used in open source projects, has likely contributed strongly to this success. Code review is an emotionally loaded practice, with public exposure of reputation and ample opportunities for conflict. We set off to ask why code review works for open source communities, despite this inherent challenge. We interviewed 21 open source contributors from four communities and participated in meetings of ROS community devoted to implementation of the code review process. It appears that the hacker ethic is a key reason behind the success of code review in FOSS communities. It is built around the ethic of passion and the ethic of caring. Furthermore, we observed that tasks of code review are performed with strong intrinsic motivation, supported by many non-material extrinsic motivation mechanisms, such as desire to learn, to grow reputation, or to improve one's positioning on the job market. In the paper, we describe the study design, analyze the collected data and formulate 20 proposals for how what we know about hacker ethics and human and social aspects of code review, could be exploited to improve the effectiveness of the practice in software projects.","558":"This paper proposes a peer-to-peer energy market platform based on the new concept of multiclass energy management, to coordinate trading between prosumers with heterogeneous (i.e., beyond purely financial) preferences. Power networks are undergoing a fundamental transition, with traditionally passive distribution network consumers becoming \u201cprosumers\u201d; proactive consumers that actively manage their production and consumption of energy. The paper introduces the new concept of energy classes, allowing energy to be treated as a heterogeneous product, based on attributes of its source, which are perceived by prosumers to have value. Examples include generation technology, location in the network and owner's reputation. The proposed peer-to-peer energy market platform coordinates trading between subscribed prosumers and the wholesale electricity market, to minimize costs associated with losses and battery depreciation, while providing added value by accounting for the prosumers\u2019 individual preferences for the source\/destination of the energy they consume\/produce. The decomposable structure of the multiclass energy management problem is exploited to devise a distributed price-directed optimization mechanism, providing scalability and prosumer data privacy. Receding horizon model predictive control allows the prosumers to adjust their planned power flows based on the wholesale energy price, and up-to-date renewable generation and load predictions.","559":"Online marketplaces are increasingly adopting innovative business models such as using paid advertising as a major revenue source. We explore the two popular advertising tools, sponsored search and social media endorsement, in attracting web traffic from online sellers\u2019 perspective. We estimate an endogenous treatment model with latent variable to model online traffic given sellers\u2019 decisions on employing different advertising strategies. We find evidence that both sponsored search and social media endorsement are significant in attracting traffic, after we control for seller self-selection behavior in choosing their strategies. Sponsored search has a higher impact on low-reputation sellers in bringing more traffic, and sellers with more return customers have higher benefit in using sponsored search in generating traffic. The findings are consistent with informative view of the advertising theory, and they provide interesting and import implications for both the platform and market participants.","560":"Feedback systems associated with Internet markets are known to be subject to strategic manipulation that can create distortions in the reputation information provided to traders. The experiment we present suggests that distortions can emerge from sources that have heretofore been overlooked: the leniency and moral wiggle room that arise when there is uncertainty about the source of transaction problems. The control the laboratory affords permits us to separate the influence exerted by uncertainty per se from that implied by behavioral leniency. We observe that uncertainty about seller responsibility leads to leniency behaviors that reduce the informativeness of the feedback system, thereby diminishing the incentives for honest seller behavior. Under uncertainty, buyers pay about the same prices but get significantly less.","561":"A disruptive technology often used in finance, Internet of Things (IoT) and healthcare, blockchain can reach consensus within a decentralised network\u2014potentially composed of large amounts of unreliable nodes\u2014and to permanently and irreversibly store data in a tamper-proof manner. In this paper, we present a reputation system for Intelligent Transportation Systems (ITS). It considers the users interested in traffic information as the main actors of the architecture. They securely share their data which are collectively validated by other users. Users can choose to employ either such crowd-sourced validated data or data generated by the system to travel between two locations. The data saved is reliable, based on the providers\u2019 reputation and cannot be modified. We present results with a simulation for three cities: San Francisco, Rome and Beijing. We have demonstrated the impact of malicious attacks as the average speed decreased if erroneous information was stored in the blockchain as an implemented routing algorithm guides the honest cars on other free routes, and thus crowds other intersections.","562":"Cyber-physical social system (CPSS) has emerged as a new paradigm to help social users share and exchange data by the close association with the cyberspace and physical world. To further improve the performance of CPSS, the incentive computing scheme to provide efficient crowd sourcing in the CPPS becomes a challenge. Therefore, in this paper we propose a novel incentive scheme for CPSS based on the reputation of social users. First, we present a framework to provide crowd sourcing service in CPSS by dividing social users into three types, which are malicious users, speculative users and honest users, respectively. Second, based on the reputation of social users, an incentive scheme is proposed to encourage users to contribute sourcing data. Next, an auction game model is developed to help CPSS select the optimal social user to obtain the needed data. Finally, simulation results show that the proposal can obtain a lower cost and higher data accuracy than other conventional methods.","563":"Photons have been a flagship system for studying quantum mechanics, advancing quantum information science, and developing quantum technologies. Quantum entanglement, teleportation, quantum key distribution and early quantum computing demonstrations were pioneered in this technology because photons represent a naturally mobile and low-noise system with quantum-limited detection readily available. The quantum states of individual photons can be manipulated with very high precision using interferometry, an experimental staple that has been under continuous development since the 19th century. The complexity of photonic quantum computing device and protocol realizations has raced ahead as both underlying technologies and theoretical schemes have continued to develop. Today, photonic quantum computing represents an exciting path to medium- and large-scale processing. It promises to out aside its reputation for requiring excessive resource overheads due to inefficient two-qubit gates. Instead, the ability to generate large numbers of photons---and the development of integrated platforms, improved sources and detectors, novel noise-tolerant theoretical approaches, and more---have solidified it as a leading contender for both quantum information processing and quantum networking. Our concise review provides a flyover of some key aspects of the field, with a focus on experiment. Apart from being a short and accessible introduction, its many references to in-depth articles and longer specialist reviews serve as a launching point for deeper study of the field.","564":"The smart community (SC), as an important part of the Internet of Energy (IoE), can facilitate integration of distributed renewable energy sources and electric vehicles (EVs) in the smart grid. However, due to the potential security and privacy issues caused by untrusted and opaque energy markets, it becomes a great challenge to optimally schedule the charging behaviors of EVs with distinct energy consumption preferences in SC. In this paper, we propose a contract-based energy blockchain for secure EV charging in SC. First, a permissioned energy blockchain system is introduced to implement secure charging services for EVs with the execution of smart contracts. Second, a reputation-based delegated Byzantine fault tolerance consensus algorithm is proposed to efficiently achieve the consensus in the permissioned blockchain. Third, based on the contract theory, the optimal contracts are analyzed and designed to satisfy EVs\u2019 individual needs for energy sources while maximizing the operator\u2019s utility. Furthermore, a novel energy allocation mechanism is proposed to allocate the limited renewable energy for EVs. Finally, extensive numerical results are carried out to evaluate and demonstrate the effectiveness and efficiency of the proposed scheme through comparison with other conventional schemes.","565":"Problem definition: Although they enjoy low costs in sourcing from emerging economies, global brands also face serious brand and reputation risks from their suppliers\u2019 noncompliance with environmen...","566":"Crowdsourcing labeling systems provide an efficient way to generate multiple inaccurate labels for given observations. If the competence level or the \u201creputation,\u201d which can be explained as the probabilities of annotating the right label, for each crowdsourcing annotators is equal and biased to annotate the right label, majority voting (MV) is the optimal decision rule for merging the multiple labels into a single reliable one. However, in practice, the competence levels of annotators employed by the crowdsourcing labeling systems are often diverse very much. In these cases, weighted MV is more preferred. The weights should be determined by the competence levels. However, since the annotators are anonymous and the ground-truth labels are usually unknown, it is hard to compute the competence levels of the annotators directly. In this paper, we propose to learn the weights for weighted MV by exploiting the expertise of annotators. Specifically, we model the domain knowledge of different annotators with different distributions and treat the crowdsourcing problem as a domain adaptation problem. The annotators provide labels to the source domains and the target domain is assumed to be associated with the ground-truth labels. The weights are obtained by matching the source domains with the target domain. Although the target-domain labels are unknown, we prove that they could be estimated under mild conditions. Both theoretical and empirical analyses verify the effectiveness of the proposed method. Large performance gains are shown for specific data sets.","567":"The IoT (Internet of Things) connect systems, applications, data storage, and services that may be a new gateway for cyber-attacks as they continuously offer services in the organization. Currently, software piracy and malware attacks are high risks to compromise the security of IoT. These threats may steal important information that causes economic and reputational damages. In this paper, we have proposed a combined deep learning approach to detect the pirated software and malware-infected files across the IoT network. The TensorFlow deep neural network is proposed to identify pirated software using source code plagiarism. The tokenization and weighting feature methods are used to filter the noisy data and further, to zoom the importance of each token in terms of source code plagiarism. Then, the deep learning approach is used to detect source code plagiarism. The dataset is collected from Google Code Jam (GCJ) to investigate software piracy. Apart from this, the deep convolutional neural network is used to detect malicious infections in IoT network through color image visualization. The malware samples are obtained from Maling dataset for experimentation. The experimental results indicate that the classification performance of the proposed solution to measure the cybersecurity threats in IoT are better than the state of the art methods.","568":"Rapid spreading of misinformation is a growing worldwide concern as it has the capacity to greatly influence individual reputation and societal behavior. The consequences of unchecked spreading of misinformation can not only vary from political to financial but also effect global opinion for a long time. Thus, detecting fake news is important but challenging as the ability to accurately categorize certain information as true or fake is limited even in human. Moreover, fake news are a blend of correct news and false information making accurate classification even more confusing. In this paper, we propose a novel method of multilevel multiclass fake news detection based on relabeling of the dataset and learning iteratively. The proposed method outperforms the benchmark and our experiments indicate that profile of the source of information contributes the most in fake news detection.","569":"In the recent political climate, the topic of news quality has drawn attention both from the public and the academic communities. The growing distrust of traditional news media makes it harder to find a common base of accepted truth. In this work, we design and build MediaRank (urlwww.media-rank.com ), a fully automated system to rank over 50,000 online news sources around the world. MediaRank collects and analyzes one million news webpages and two million related tweets everyday. We base our algorithmic analysis on four properties journalists have established to be associated with reporting quality: peer reputation, reporting bias\/breadth, bottomline financial pressure, and popularity. Our major contributions of this paper include: (i) Open, interpretable quality rankings for over 50,000 of the world's major news sources. Our rankings are validated against 35 published news rankings, including French, German, Russian, and Spanish language sources. MediaRank scores correlate positively with 34 of 35 of these expert rankings. (ii) New computational methods for measuring influence and bottomline pressure. To the best of our knowledge, we are the first to study the large-scale news reporting citation graph in-depth. We also propose new ways to measure the aggressiveness of advertisements and identify social bots, establishing a connection between both types of bad behavior. (iii) Analyzing the effect of media source bias and significance. We prove that news sources cite others despite different political views in accord with quality measures. However, in four English-speaking countries (US, UK, Canada, and Australia), the highest ranking sources all disproportionately favor left-wing parties, even when the majority of news sources exhibited conservative slants.","570":"The rapid deployment of Electric Vehicles (EVs) and the integration of renewable energy sources have ameliorated the existing power systems and contributed to the development of greener smart communities. However, load balancing problems, security threats, privacy leakage issues, etc., remain unresolved. Many blockchain-based approaches have been used in literature to solve the aforementioned challenges. However, they are not sufficient to obtain satisfactory results because of the inefficient energy management methods and time-intensiveness of the primitive cryptographic executions on the network devices. In this paper, an efficient and secure blockchain-based Energy Trading (ET) model is proposed. It leverages the contract theory, incentive mechanism, and a reputation system for information asymmetry scenario. In order to motivate the ET entities to trade energy locally and EVs to participate in smart energy management, the proposed incentive provisioning mechanism plays a vital role. Besides, a reputation system improves the reliability and efficiency of the system and discourages the blockchain nodes from acting maliciously. A novel consensus algorithm, i.e., Proof of Work based on Reputation (PoWR), is proposed to reduce transaction confirmation latency and block creation time. Moreover, a shortest route algorithm, i.e., the Dijkstra algorithm, is implemented in order to reduce the traveling distance and energy consumption of the EVs during ET. The performance of the proposed model is evaluated using peak to average ratio, social welfare, utility of local aggregator, etc., as performance metrics. Moreover, privacy and security analyses of the system are also presented.","571":null,"572":"Open source software (OSS) has become an important organizational form of building software. Given the desire to understand drivers of OSS project success and the known importance of social structure for team functioning, we investigate the effects of the relative size of contribution-based subgroups on community size of OSS projects. Drawing on extant research on OSS and faultline-based subgrouping, we investigate the relation with project community size of the relative size of subgroups based on reputation, issue focus, contribution extent and contribution persistence. While in several instances non-significant, results suggest a differential relation in which a large share of core members with high reputation, issue focus and persistent contributions positively relate to community size, whereas a large share of extensively contributing members in the core team is negatively related. Our findings are of value to research and practice by furthering the understanding of work in OSS projects.","573":"Web content credibility implies finding credible and correct information on the web. Recent studies have shown there is an increasing trend of users turning towards the web for searching information related to a variety of topics including health, stocks, education, politics to name few. Information credibility is a critical factor in these domains for the decision makers. There is no limitation on the authorship of those articles and content. One criterion for evaluating credibility is to check the authority or source of information. However, there are situations when wrong information flows from credible sources. There are various approaches towards credibility assessment, broadly categorized into human-based and computational approaches. Computational approaches utilizing machine learning based techniques are computationally expensive. Reputation based approaches overcome this, however the latest work fails to take into account issue of negative referrals and utilizes simple summation as the calculation structure making it more resilient to attacks. This paper put forth verified hypothesis of direct relationship of credibility to the expertise of entity. Authors proposed a Bayesian based approach using feedback in the form of interaction among the entities to compute their expertise level, thereby showing improved results in terms of Precision, Correlation and Mean Average Error. The experiments are performed on two different datasets, one of the dataset is developed from a survey as the part of the research study. The results from the two experiments show that the reputation ranks are independent of the pattern of ratings and density of data, unlike previous techniques whose results were limited by these factors. The proposed technique gives 27% and 18% more precise results for the two experiments respectively compared to the baseline. The correlation results are also significant in both experiments for the proposed technique with significant values of 0.39 and 0.87 showing a linear relationship between predicted and original data. The paper also discusses the reputation attacks and proposes counter measures to tackle these attacks through simulation results.","574":"The Mobile Ad-Hoc Network (MANET) incorporates a collaborative networking scenario, where dynamic host movement results in frequent topology changes. In MANET, nodes cooperate during route establishment, and the data packet must travel from source to destination through multi-hop intermediate links. The nodes in a MANET can be localized in a restricted zone, where manual intervention to set-up fixed infrastructural support is practically infeasible. However, cooperative packet forwarding and data transmission is quite a common scenario in the context of MANET. Still, due to dynamic topological changes, weak, intermittent links appear within one-hop communication. This leads to a higher possibility of packet drop events and also increases the retransmission scenario, which affects the energy performance of the network. Addressing this issue, the study models a novel and intelligent packet forwarding approach based on the game theory, where trust evaluation in terms of node reputation factor also plays a very vital role. The approach also enforces an incentive modelling to stimulate the cooperation between mobile nodes during the MANET routing scenario. The system is designed and developed with evolutionary game perspectives to meet the Quality of Services (QoS) requirements. The experimental analysis supports the proposed modelling design aspects. Also, it exhibits that the reputation and trust-based game increases the utility of packet-forwarding strategy with high throughput and negligible network overhead.","575":null,"576":"One of the core issues in routing packets within Mobile Ad hoc Networks (MANETs) is the lack of trust and reputation of the participating nodes, which often leads to unreliable packet delivery. We use a fraction of nodes to validate routing actions taken by other nodes and leverage the distributed consensus mechanism in Blockchain networks to accrue the reputation of each node. Specifically, we employ heterogeneous difficulty for Proof of Work to represent the credibility of validation and design a scoring system to isolate malicious nodes via distributed consensus. The reputation of a node is then based on the combination of the difficulty level and the score. This reputation is incorporated in a novel routing metric to calculate the shortest, most reputed path between a source and destination node. The goal is to discourage malicious nodes by excluding those from participating in routing packets. A joint simulation of the Blockchain and routing algorithm reveal \u224812% improvement in overall packet delivery in the presence of routing attacks, compared to conventional routing algorithms in MANETs.","577":"The dissemination of fake news significantly affects personal reputation and public trust. Recently, fake news detection has attracted tremendous attention, and previous studies mainly focused on finding clues from news content or diffusion path. However, the required features of previous models are often unavailable or insufficient in early detection scenarios, resulting in poor performance. Thus, early fake news detection remains a tough challenge. Intuitively, the news from trusted and authoritative sources or shared by many users with a good reputation is more reliable than other news. Using the credibility of publishers and users as prior weakly supervised information, we can quickly locate fake news in massive news and detect them in the early stages of dissemination. In this paper, we propose a novel structure-aware multi-head attention network (SMAN), which combines the news content, publishing, and reposting relations of publishers and users, to jointly optimize the fake news detection and credibility prediction tasks. In this way, we can explicitly exploit the credibility of publishers and users for early fake news detection. We conducted experiments on three real-world datasets, and the results show that SMAN can detect fake news in 4 hours with an accuracy of over 91%, which is much faster than the state-of-the-art models.","578":"Open-source software (OSS) is a key aspect of software creation. However, little is known about programmers\u2019 decisions to trust software from OSS websites. The current study emulated OSS websites and manipulated reputation and performance factors in the stimuli according to the heuristic-systematic processing model. We sampled professional programmers\u2014with a minimum experience of three years\u2014from Amazon Mechanical Turk (N = 38). We used a 3 \u00d7 3 within-subjects design to investigate the relationship between OSS reputation and performance on users\u2019 time spent on code, the number of interface clicks, trustworthiness perceptions, and willingness to use OSS code. We found that participants spent more time on and clicked the interface more often for code that was high in reputation. Meta-information included with OSS tools was found to affect the degree to which computer programmers interact with and perceive online code repositories. Furthermore, participants reported higher levels of perceived trustworthiness in and trust toward highly reputable OSS code. Notably, we observed fewer significant main effects for the performance manipulation, which may correspond to participants considering performance attributes mainly within the context of reputation-relevant information. That is, the degree to which programmers investigate and then trust OSS code may depend on the initial reputation ratings.","579":"Despite the growing popularity of ride-sharing in China, our understanding regarding users' trust and behavioral intention toward this new type of hailing service is still limited. This study aims to examine the joint influences of institution-based, process-based and characteristic-based antecedents on customers' trust and continuance intention toward ride-sharing. Furthermore, the study aims to investigate if the relative influences of institution-based and process-based antecedents on trust are contingent upon customers' prior experience.,Drawing upon trust-building literature and the elaboration-likelihood model, we developed a research model and conducted an online survey to users of Didi, the largest ride-sharing platform in China. We used the structural equation modeling technique to analyze the collected data and examine the proposed research model.,Ther major research findings of the study suggest that structural assurance, government support, platform reputation and disposition to trust exhibit significant and different degrees of influences on customers' trust beliefs and continuance intention toward ride-sharing. A multi-group analysis further suggests that customers with less use experience focus more on government support and platform reputation, while customers with more use experience are more likely influenced by structural assurance.,The study contributes to the extant literature by identifying the joint influences of institutional-based, process-based and characteristic-based antecedents on users' continuance intention of ride-sharing service and uncovers the mediation mechanism of trust and perceived risk. Moreover, the study refines the boundary condition of the proposed research model by revealing the moderating effect of use experience.","580":"Algorithms are playing an increasingly important role in many areas of public policy. Yet, we know surprisingly little about the degree of trust individuals are willing to place in these algorithms. This article reports on a series of experiments on trust in algorithms for forecasting political events and criminal recidivism. Contrary to previous literature on algorithm aversion, we find that people show high levels of trust in algorithms relative to other sources of advice, even with minimal information about the algorithm. We also explore evaluation of combined human and algorithm advice. We find that, when experts make decisions in light of algorithm advice, the relative weight given to their judgments increases, but the algorithm\u2019s guidance is not disregarded. Finally, using a conjoint experiment, we evaluate the factors that influence people\u2019s preferences for algorithms, finding that risk aversion, data size, human in the loop, and developer reputation play an important role in engendering trust.","581":null,"582":"\nPurpose\nThe purpose of this paper is to propose visualization techniques as a new representation for privacy policies instead of traditional textual representation and to examine empirically their effects on users\u2019 information privacy awareness level.\n\n\nDesign\/methodology\/approach\nThe authors selected as a case the privacy policy of Instagram and conducted two empirical investigations, each one with three interventions and each representing a different version of the Instagram privacy policy to users. Through a pre- and a post-questionnaire, the authors examined the effects that each representation technique had on the users\u2019 privacy awareness level.\n\n\nFindings\nThe paper finds that visualized privacy policies lead to higher privacy awareness levels than conventional textual ones, especially when icons are included.\n\n\nResearch limitations\/implications\nThe authors implemented two new representation techniques offering beneficial guidelines for designing more attractive privacy policy representations. However, the samples are rather limited for generalization to the wide population; nonetheless, they are significant to demonstrate the effect of visualized techniques. The findings might also be subject to bias (e.g. brand bias), although the authors took necessary methodological actions to prevent bias.\n\n\nPractical implications\nThe results and the methodology of the paper could guide practitioners for the representation of a privacy policy, given that the authors provide systematic and concrete steps.\n\n\nOriginality\/value\nThis paper examines the value of privacy policy visualization as a new approach for enabling user privacy awareness, as well as implements two visualization techniques for a given privacy policy. The paper and its findings should be useful for researchers, as well as for practitioners.\n","583":"Human activities can be seen as sequences of events, which are crucial to understanding societies. Disproportional event distribution for different demographic groups can manifest and amplify social stereotypes, and potentially jeopardize the ability of members in some groups to pursue certain goals. In this paper, we present the first event-centric study of gender biases in a Wikipedia corpus. To facilitate the study, we curate a corpus of career and personal life descriptions with demographic information consisting of 7,854 fragments from 10,412 celebrities. Then we detect events with a state-of-the-art event detection model, calibrate the results using strategically generated templates, and extract events that have asymmetric associations with genders. Our study discovers that the Wikipedia pages tend to intermingle personal life events with professional events for females but not for males, which calls for the awareness of the Wikipedia community to formalize guidelines and train the editors to mind the implicit biases that contributors carry. Our work also lays the foundation for future works on quantifying and discovering event biases at the corpus level.","584":"Recently there has been a growing interest in fairness-aware recommender systems including fairness in providing consistent performance across different users or groups of users. A recommender system could be considered unfair if the recommendations do not fairly represent the tastes of a certain group of users while other groups receive recommendations that are consistent with their preferences. In this paper, we use a metric called miscalibration for measuring how a recommendation algorithm is responsive to users\u2019 true preferences and we consider how various algorithms may result in different degrees of miscalibration for different users. In particular, we conjecture that popularity bias which is a well-known phenomenon in recommendation is one important factor leading to miscalibration in recommendation. Our experimental results using two real-world datasets show that there is a connection between how different user groups are affected by algorithmic popularity bias and their level of interest in popular items. Moreover, we show that the more a group is affected by the algorithmic popularity bias, the more their recommendations are miscalibrated.","585":"Artificial intelligence (AI) systems can discriminate against protected classes \u2014 a fact that has sparked an extensive literature about bias in AI. Bias, as important as it is, is a special case of the overall problem of social justice. Beyond Bias focuses on the general problem. It incorporates contributions from the extensive discussion of AI and fairness in the computer science literature. In particular, it draws on Fairness Through Awareness, an influential article by the Harvard computer scientist Cynthia Dwork and her co-authors. Adapting Dwork\u2019s approach, Beyond Bias reexpresses intuitive, well-motivated fairness constraints in a more mathematical way that shows how to apply the constraints to mathematically and computationally complex AI systems. The mathematics nonetheless uses only elementary arithmetic (unlike Dwork et al.). \n \nBeyond Bias adapts the fairness constraints that it reexpresses from the Yale economist John Roemer. As Roemer notes in Equality of Opportunity, a conception of \u201cequality of opportunity . . . prevalent today in Western democracies . . . says that society should do what it can to \u2018level the playing field\u2019 among individuals who compete for positions.\u201d Beyond Bias shows that AI systems can unfairly tilt the playing field. The reason lies in the pervasive (and unavoidable) use of \u201cproxy variables\u201d \u2014 e. g., using credit ratings to predict driving safety (as many insurance companies do). The credit ratings are the substitute \u2014 the proxy \u2014 for details about individuals\u2019 driving practices. Beyond Bias is the first article to apply a level playing field concept of fairness to issues of fairness in AI systems. \n \nBeyond Bias briefly reviews the history of the use of proxy variables to evaluate consumers from the late Nineteenth Century to the present. It was already clear at the close of the Nineteenth Century that proxy-driven analysis could make seemingly unrelated aspects of one\u2019s life \u201chave a profound impact on [one\u2019s] future potential in matters economic or social,\u201d as Dan Bouk notes in HOW OUR DAYS BECAME NUMBERED: RISK AND THE RISE OF THE STATISTICAL INDIVIDUAL. The concern was that proxy-driven analysis would unfairly tilt the playing field, and that concern continues to this day. \n \nBeyond Bias outlines a regulatory approach that ensures level playing field fairness by incorporating its mathematical constraints on AI systems.","586":"News is a central source of information for individuals to inform themselves on current topics. Knowing a news article's slant and authenticity is of crucial importance in times of \"fake news,\" news bots, and centralization of media ownership. We introduce Newsalyze, a bias-aware news reader focusing on a subtle, yet powerful form of media bias, named bias by word choice and labeling (WCL). WCL bias can alter the assessment of entities reported in the news, e.g., \"freedom fighters\" vs. \"terrorists.\" At the core of the analysis is a neural model that uses a news-adapted BERT language model to determine target-dependent sentiment, a high-level effect of WCL bias. While the analysis currently focuses on only this form of bias, the visualizations already reveal patterns of bias when contrasting articles (overview) and in-text instances of bias (article view).","587":"We study the problem of learning conditional average treatment effects (CATE) from highdimensional, observational data with unobserved confounders. Unobserved confounders introduce ignorance\u2014a level of unidentifiability\u2014about an individual\u2019s response to treatment by inducing bias in CATE estimates. We present a new parametric interval estimator suited for highdimensional data, that estimates a range of possible CATE values when given a predefined bound on the level of hidden confounding. Further, previous interval estimators do not account for ignorance about the CATE associated with samples that may be underrepresented in the original study, or samples that violate the overlap assumption. Our interval estimator also incorporates model uncertainty so that practitioners can be made aware of such out-of-distribution data. We prove that our estimator converges to tight bounds on CATE when there may be unobserved confounding and assess it using semi-synthetic, high-dimensional datasets.","588":"ABSTRACT As we take advantage of new technologies that allow us to streamline the coding process of large qualitative datasets, we must consider whether human cognitive bias may introduce statistical bias in the process. Our research group analyzes large sets of student responses by developing computer models that are trained using human-coded responses and a suite of machine-learning techniques. Once a model is initially trained, it may be insufficiently accurate. Increasing the number of human-coded responses typically enhances these models to an acceptable level of accuracy. Alternatively, instead of human coding responses, we can rapidly increase the number of coded responses by verifying computer-predicted codes for each response. However, having access to this information may bias human coders. We designed the present study to test for differences in level of agreement with computer-predicted codes in terms of magnitude and direction during computer model calibration if information about computer-predicted codes is available. Our results indicate human coding bias despite being disciplinary experts who were aware of the possibility of cognitive bias creating statistical bias and that magnitude and direction of that bias varies across experts.","589":"The ground truth used for training image, video, or speech quality prediction models is based on the Mean Opinion Scores (MOS) obtained from subjective experiments. Usually, it is necessary to conduct multiple experiments, mostly with different test participants, to obtain enough data to train quality models based on machine learning. Each of these experiments is subject to an experiment-specific bias, where the rating of the same file may be substantially different in two experiments (e.g. depending on the overall quality distribution). These different ratings for the same distortion levels confuse neural networks during training and lead to lower performance. To overcome this problem, we propose a bias-aware loss function that estimates each dataset's biases during training with a linear function and considers it while optimising the network weights. We prove the efficiency of the proposed method by training and validating quality prediction models on synthetic and subjective image and speech quality datasets.","590":"Collecting large-scale human-annotated datasets via crowdsourcing to train and improve automated models is a prominent human-in-the-loop approach to integrate human and machine intelligence. However, together with their unique intelligence, humans also come with their biases and subjective beliefs, which may influence the quality of the annotated data and negatively impact the effectiveness of the human-in-the-loop systems. One of the most common types of cognitive biases that humans are subject to is the confirmation bias, which is people\u2019s tendency to favor information that confirms their existing beliefs and values. In this paper, we present an algorithmic approach to infer the correct answers of tasks by aggregating the annotations from multiple crowd workers, while taking workers\u2019 various levels of confirmation bias into consideration. Evaluations on real-world crowd annotations show that the proposed bias-aware label aggregation algorithm outperforms baseline methods in accurately inferring the ground-truth labels of different tasks when crowd workers indeed exhibit some degree of confirmation bias. Through simulations on synthetic data, we further identify the conditions when the proposed algorithm has the largest advantages over baseline methods.","591":null,"592":"Sentiment Analysis (SA) is an active research area for the last ten years. SA is the computational treatment of opinions, sentiments, and subjectivity of text. Twitter is one of the most widely used micro-blog and considered as an important source for computation of sentiment and of data analysis. Therefore, companies all over the world analyze Twitter data using SA and extract knowledge which has potential applications in diverse areas. Although SA is the successful way of finding the people\u2019s opinion, the bias in the tweets affects the results of the SA and reflects inaccurate analysis that may mislead users to take erroneous decisions. The biased tweets are shared by valid, but biased human users as well as the social bots to propagate the biased opinions on certain topics. To counter this, this research study proposes a statistical model to identify such users and social bots who share the biased content in the form of tweets in the Twitter social media. For experiment purpose, we use annotated twitter dataset and argue the results of SA with and without the biased tweets and explored the effects of biased users at micro-level and macro level. The empirical results show that the proposed approach is effective and properly identifies the biased users and bots from other authentic users using sentiment analysis.","593":"Recently there has been a growing interest in fairness-aware recommender systems, including fairness in providing consistent performance across different users or groups of users. A recommender system could be considered unfair if the recommendations do not fairly represent the tastes of a certain group of users while other groups receive recommendations that are consistent with their preferences. In this paper, we use a metric called miscalibration for measuring how a recommendation algorithm is responsive to users' true preferences and we consider how various algorithms may result in different degrees of miscalibration. A well-known type of bias in recommendation is popularity bias where few popular items are over-represented in recommendations, while the majority of other items do not get significant exposure. We conjecture that popularity bias is one important factor leading to miscalibration in recommendation. Our experimental results using two real-world datasets show that there is a strong correlation between how different user groups are affected by algorithmic popularity bias and their level of interest in popular items. Moreover, we show algorithms with greater popularity bias amplification tend to have greater miscalibration.","594":"Variability is one of the major challenges for CMOS in the nano era. Manufacturers test each circuit sample to ensure that samples that do not meet the desired specification are discarded. However, testing is only effective for variability, which is observable right after manufacturing, such as geometric variations, work function, and random dopant fluctuation. This is in contrast to time-dependent variability (TDV), i.e., differences in the defects of transistors, which is not macroscopically observable immediately after manufacturing. In fact, defects are electrically neutral until they capture a carrier [with mechanisms called bias temperature instability (BTI) and random telegraph noise (RTN)] and thus become observable through their induced degradation. Therefore, transistors which are characterized identically after manufacturing will drift apart during their lifetime, as their susceptibility to effects such as BTI and RTN is different. In this paper, we model for the first time TDV from a defect-centric physical perspective all the way to the circuit level. Our novel defect-centric transistor reliability specification provides a fast, yet accurate method to estimate an upper bound for TDV on the transistor level, while our novel worst cell (WCL) and worst value (WVL) libraries allow for fast evaluation of the impact of TDV on the timing of circuits. Our approach is fully compatible with existing EDA tool flows, allowing us to model and optimize complex circuits like full microprocessors. By evaluating the impact of TDV with our reliability specification and variability-aware cell libraries, we are able to model TDV, which allowed us to reduce the required defect variability guardband by 46%. In addition, we provide design optimization strategies on each abstraction level such as limiting continuous stress, transistor hardening, and implement a novel variability-aware synthesis to achieve up to 57% additional guardband reduction.","595":"There has been growing attention on fairness considerations recently, especially in the context of intelligent decision making systems. For example, explainable recommendation systems may suffer from both explanation bias and performance disparity. We show that inactive users may be more susceptible to receiving unsatisfactory recommendations due to their insufficient training data, and that their recommendations may be biased by the training records of active users due to the nature of collaborative filtering, which leads to unfair treatment by the system. In this paper, we analyze different groups of users according to their level of activity, and find that bias exists in recommendation performance between different groups. Empirically, we find that such performance gap is caused by the disparity of data distribution, specifically the knowledge graph path distribution in this work. We propose a fairness constrained approach via heuristic re-ranking to mitigate this unfairness problem in the context of explainable recommendation over knowledge graphs. We experiment on several real-world datasets with state-of-the-art knowledge graph-based explainable recommendation algorithms. The promising results show that our algorithm is not only able to provide high-quality explainable recommendations, but also reduces the recommendation unfairness in several aspects.","596":"Surfacing and mitigating bias in ML pipelines is a complex topic, with a dire need to provide system-level support to data scientists. Humans should be empowered to debug these pipelines, in order to control for bias and to improve data quality and representativeness. We propose fair-DAGs, an open-source library that extracts directed acyclic graph (DAG) representations of the data flow in preprocessing pipelines for ML. The library subsequently instruments the pipelines with tracing and visualization code to capture changes in data distributions and identify distortions with respect to protected group membership as the data travels through the pipeline. We illustrate the utility of fair-DAGs with experiments on publicly available ML pipelines. ACM Reference Format: Ke Yang, Biao Huang, Julia Stoyanovich, Sebastian Schelter. 2020. Fairness-Aware Instrumentation of Preprocessing Pipelines for Machine Learning. In Workshop on Human-In-the-Loop Data Analytics (HILDA\u201920), June 14\u201319, 2020, Portland, OR, USA. ACM, New York, NY, USA, 4 pages. https:\/\/doi.org\/10.1145\/3398730.3399194","597":"It is often observed that the probabilistic predictions given by a machine learning model can disagree with averaged actual outcomes on specific subsets of data, which is also known as the issue of miscalibration. It is responsible for the unreliability of practical machine learning systems. For example, in online advertising, an ad can receive a click-through rate prediction of 0.1 over some population of users where its actual click rate is 0.15. In such cases, the probabilistic predictions have to be fixed before the system can be deployed. In this paper, we first introduce a new evaluation metric named field-level calibration error that measures the bias in predictions over the sensitive input field that the decision-maker concerns. We show that existing post-hoc calibration methods have limited improvements in the new field-level metric and other non-calibration metrics such as the AUC score. To this end, we propose Neural Calibration, a simple yet powerful post-hoc calibration method that learns to calibrate by making full use of the field-aware information over the validation set. We present extensive experiments on five large-scale datasets. The results showed that Neural Calibration significantly improves against uncalibrated predictions in common metrics such as the negative log-likelihood, Brier score and AUC, as well as the proposed field-level calibration error.","598":"Learning to rank with implicit feedback is one of the most important tasks in many real-world information systems where the objective is some specific utility, e.g., clicks and revenue. However, we point out that existing methods based on probabilistic ranking principle do not necessarily achieve the highest utility. To this end, we propose a novel ranking framework called U-rank that directly optimizes the expected utility of the ranking list. With a position-aware deep click-through rate prediction model, we address the attention bias considering both query-level and item-level features. Due to the item-specific attention bias modeling, the optimization for expected utility corresponds to a maximum weight matching on the item-position bipartite graph. We base the optimization of this objective in an efficient Lambdaloss framework, which is supported by both theoretical and empirical analysis. We conduct extensive experiments for both web search and recommender systems over three benchmark datasets and two proprietary datasets, where the performance gain of U-rank over state-of-the-arts is demonstrated. Moreover, our proposed U-rank has been deployed on a large-scale commercial recommender and a large improvement over the production baseline has been observed in an online A\/B testing.","599":"Abstract reasoning refers to the ability to analyze information, discover rules at an intangible level, and solve problems in innovative ways. Raven\u2019s Progressive Matrices (RPM) test is typically used to examine the capability of abstract reasoning. The subject is asked to identify the correct choice from the answer set to fill the missing panel at the bottom right of RPM (e.g., a 3\u00d73 matrix), following the underlying rules inside the matrix. Recent studies, taking advantage of Convolutional Neural Networks (CNNs), have achieved encouraging progress to accomplish the RPM test. However, they partly ignore necessary inductive biases of RPM solver, such as order sensitivity within each row\/column and incremental rule induction. To address this problem, in this paper we propose a Stratified Rule-Aware Network (SRAN) to generate the rule embeddings for two input sequences. Our SRAN learns multiple granularity rule embeddings at different levels, and incrementally integrates the stratified embedding flows through a gated fusion module. With the help of embeddings, a rule similarity metric is applied to guarantee that SRAN can not only be trained using a tuplet loss but also infer the best answer efficiently. We further point out the severe defects existing in the popular RAVEN dataset for RPM test, which prevent from the fair evaluation of the abstract reasoning ability. To fix the defects, we propose an answer set generation algorithm called Attribute Bisection Tree (ABT), forming an improved dataset named Impartial-RAVEN (I-RAVEN for short). Extensive experiments are conducted on both PGM and I-RAVEN datasets, showing that our SRAN outperforms the state-of-the-art models by a considerable margin.reasoning refers to the ability to analyze information, discover rules at an intangible level, and solve problems in innovative ways. Raven\u2019s Progressive Matrices (RPM) test is typically used to examine the capability of abstract reasoning. The subject is asked to identify the correct choice from the answer set to fill the missing panel at the bottom right of RPM (e.g., a 3\u00d73 matrix), following the underlying rules inside the matrix. Recent studies, taking advantage of Convolutional Neural Networks (CNNs), have achieved encouraging progress to accomplish the RPM test. However, they partly ignore necessary inductive biases of RPM solver, such as order sensitivity within each row\/column and incremental rule induction. To address this problem, in this paper we propose a Stratified Rule-Aware Network (SRAN) to generate the rule embeddings for two input sequences. Our SRAN learns multiple granularity rule embeddings at different levels, and incrementally integrates the stratified embedding flows through a gated fusion module. With the help of embeddings, a rule similarity metric is applied to guarantee that SRAN can not only be trained using a tuplet loss but also infer the best answer efficiently. We further point out the severe defects existing in the popular RAVEN dataset for RPM test, which prevent from the fair evaluation of the abstract reasoning ability. To fix the defects, we propose an answer set generation algorithm called Attribute Bisection Tree (ABT), forming an improved dataset named Impartial-RAVEN (I-RAVEN for short). Extensive experiments are conducted on both PGM and I-RAVEN datasets, showing that our SRAN outperforms the state-of-the-art models by a considerable margin.","600":"This paper describes a unified static\/dynamic entropy generator based on a 512-b common entropy source (ES) array fabricated in 14-nm tri-gate CMOS with reconfigurable and adaptive post-processing circuits implemented on Arria 10 FPGA, targeted for flexible and secure privacy preserving mutual authentication on compact trusted mote platforms at the edge of internet of things. Several conditioning techniques that include temporal majority voting (TMV)-assisted ES array segregation with integrated bias tracking, three-way in-line self-calibration for tolerance to process\u2013voltage\u2013temperature variation, tri-level hierarchical Von Neumann (VN) extraction to maximize entropy harvesting, soft-dark bit masking for improving physically unclonable function (PUF) stability, and selective stress hardening to co-optimize the ES array for static-dynamic entropy with bias aware device aging enable simultaneous PUF and true random number generator (TRNG) operation with 1.48 and 0.56 Gb\/s throughput, respectively, measured at 650 mV, 70 \u00b0C. The all-digital design with a compact layout footprint of 2114 <inline-formula> <tex-math notation=\"LaTeX\">$\\mu \\text{m}^{2}$ <\/tex-math><\/inline-formula> facilitates seamless integration in area constrained system-on-chips while achieving: 1) 25% area savings over conventional separate PUF and TRNG implementations; 2) cryptographic quality TRNG stream that passes all NIST randomness tests with 0.38 average p-value; 3) <inline-formula> <tex-math notation=\"LaTeX\">$1.6\\times $ <\/tex-math><\/inline-formula> higher extractor performance at <inline-formula> <tex-math notation=\"LaTeX\">$9\\times $ <\/tex-math><\/inline-formula> lower area with 750-gate hierarchical VN circuit over conventional light-weight entropy extractors; 4) 0.9996\/0.99997 static\/dynamic Shannon entropy indicating unbiased PUF\/TRNG streams; 5) ultra-low energy consumption of 2.5 and 0.46 pJ\/bit measured at 650 mV, 70 \u00b0C in TRNG and PUF modes; 6) 40% higher TRNG throughput with three-way self-calibration featuring coarse-grain column swap, fine-grain incremental ES substitution, and residual entropy recycling; 7) resistance to power injection attacks as measured by 64% higher performance over un-calibrated design in the presence 200-mV supply noise; 8) 2.8% PUF bit-error measured at 0.55\u20130.75 V, 25 \u00b0C\u2013110 \u00b0C with 15-way TMV and soft dark-bit masking over a window of 100 cycles; 9) <inline-formula> <tex-math notation=\"LaTeX\">$14.8\\times $ <\/tex-math><\/inline-formula> inter and intra-PUF hamming distance separation; and 10) 56% reduction in discarded ES cells with selective stress hardening to opportunistically reinforce\/nullify pre-existing bias in PUF\/TRNG candidate cells. To our knowledge, this is the first reported unified PUF-TRNG implementation enabling simultaneous generation of high-entropy chip-ID and encryption keys in real time.","601":"Several neural-based metrics have been recently proposed to evaluate machine translation quality. However, all of them resort to point estimates, which provide limited information at segment level. This is made worse as they are trained on noisy, biased and scarce human judgements, often resulting in unreliable quality predictions. In this paper, we introduce uncertainty-aware MT evaluation and analyze the trustworthiness of the predicted quality. We combine the C OMET framework with two uncertainty estimation methods, Monte Carlo dropout and deep ensembles, to obtain quality scores along with con\ufb01dence intervals. We compare the performance of our uncertainty-aware MT evaluation methods across multiple language pairs from the QT21 dataset and the WMT20 metrics task, augmented with MQM annotations. We experiment with varying numbers of references and further discuss the use-fulness of uncertainty-aware quality estimation (without references) to \ufb02ag possibly critical translation mistakes.","602":"Despite the recent success in face recognition and object classification, in the field of human gaze prediction, computer models are still struggling to accurately mimic human attention. One main reason is that visual attention is a complex human behavior influenced by multiple factors, ranging from low-level features (e.g., color, contrast) to high-level human perception (e.g., objects interactions, object sentiment), making it difficult to model computationally. In this work, we investigate the relation between object sentiment and human attention. We first introduce a new evaluation metric (AttI) for measuring human attention that focuses on human fixation consensus. A series of empirical data analyses with AttI indicate that emotion-evoking objects receive attention favor, especially when they co-occur with emotionally-neutral objects, and this favor varies with different image complexity. Based on the empirical analyses, we design a deep neural network for human attention prediction which allows the attention bias on emotion-evoking objects to be encoded in its feature space. Experiments on two benchmark datasets demonstrate its superior performance, especially on metrics that evaluate relative importance of salient regions. This research provides the clearest picture to date on how object sentiments influence human attention, and it makes one of the first attempts to model this phenomenon computationally.","603":"Visual relationship detection has been motivated by the \u201cinsufficiency of objects to describe rich visual knowledge\u201d. However, we find that training and testing on current popular datasets may not support such statements; most approaches can be outperformed by a naive image-agnostic baseline that fuses language and spatial features. We visualize the errors of numerous existing detectors, to discover that most of them are caused by the coexistence and penalization of antagonizing predicates that could describe the same interaction. Such annotations hurt the dataset\u2019s causality and models tend to overfit the dataset biases, resulting in a saturation of accuracy to artificially low levels. We construct a simple architecture and explore the effect of using language on generalization. Then, we introduce adaptive local-context-aware classifiers, that are built on-the-fly based on the objects\u2019 categories. To improve context awareness, we mine and learn predicate synonyms, i.e. different predicates that could equivalently hold, and apply a distillation-like loss that forces synonyms to have similar classifiers and scores. The last also serves as a regularizer that mitigates the dominance of the most frequent classes, enabling zero-shot generalization. We evaluate predicate accuracy on existing and novel test scenarios to display state-of-the-art results over prior biased baselines.","604":"Effective flood risk management requires a realistic estimation of flood losses. However, available flood damage estimates are still characterized by significant levels of uncertainty, questioning the capacity of flood damage models to depict real damages. With a joint effort of eight international research groups, the objective of this study was to compare, in a blind-validation test, the performances of different models for the assessment of the direct flood damage to the residential sector at the building level (i.e. microscale). The test consisted of a common flood case study characterized by high availability of hazard and building data but with undisclosed information on observed losses in the implementation stage of the models. The nine selected models were chosen in order to guarantee a good mastery of the models by the research teams, variety of the modelling approaches, and heterogeneity of the original calibration context in relation to both hazard and vulnerability features. By avoiding possible biases in model implementation, this blind comparison provided more objective insights on the transferability of the models and on the reliability of their estimations, especially regarding the potentials of local and multivariable models. From another perspective, the exercise allowed us to increase awareness of strengths and limits of flood damage modelling, which are summarized in the paper in the form of take-home messages from a modeller's perspective.","605":"Circuit aging has become the major reliability concern in current and upcoming technology nodes. For instance, Bias Temperature Instability (BTI) leads to an increase in the threshold voltage of a transistor. That, in turn, may prolong the critical path delay of the processor and eventually may lead to timing errors. In order to avoid aging-induced timing errors, designers employ guardbands either with respect to voltage or frequency. State-of-the-art techniques determine a guardband type at the circuit level at design time irrespective from the running workload at the system level. Our investigation revealed that generated temperatures by a running workload have the potential to play a key role in determining the appropriate guardband type with respect to\u00a0system performance. Therefore, we propose a paradigm shift in designing guardbands: to select the guardband types on-the-fly with respect to the workload-induced temperatures aiming at optimizing for performance under temperature and reliability constraints. Moreover, different guardband types for different cores can be selected simultaneously when multiple applications with diverse properties suggest this to be useful. Our dynamic guardband selection allows for a higher performance compared to techniques that employ a fixed (at design time) guardband type throughout.","606":"The potential for learned models to amplify existing societal biases has been broadly recognized. Fairness-aware classifier constraints, which apply equality metrics of performance across subgroups defined on sensitive attributes such as race and gender, seek to rectify inequity but can yield non-uniform degradation in performance for skewed datasets. In certain domains, imbalanced degradation of performance can yield another form of unintentional bias. In the spirit of constructing fairness-aware algorithms as societal imperative, we explore an alternative: Pareto-Efficient Fairness (PEF). Theoretically, we prove that PEF identifies the operating point on the Pareto curve of subgroup performances closest to the fairness hyperplane, maximizing multiple subgroup accuracy. Empirically we demonstrate that PEF outperforms by achieving Pareto levels in accuracy for all subgroups compared to strict fairness constraints in several UCI datasets.","607":"The topic of this brief is a single-stage amplifier biased by a doublet of voltage-combiners in a folded configuration, in order to be supplied by a power source of 1.2 V, maintaining proper dc biasing and avoiding the need of any device stacking. The topology has been automatically designed, optimized, and laid out, from sizing to layout level, using a layout-aware approach provided by the AIDA framework, a state-of-the-art analog IC design optimization framework. Experimental results prove that a gain of approximately 44 dB, together with a figure-of-merit higher than 1300 MHz $\\times $ pF\/mW are achievable using the proposed topology, with standard UMC 130 nm technology devices and a 1.2-V supply source. Finally, an extension to supply sources below nominal is explored, showing exciting results toward a future of high energy-efficiency amplifiers.","608":"Temperature effect inversion (TEI) phenomenon in ultralow power (ULP) very large scale integration circuits has been identified as an important effect by both academia and industry. Although a number of ULP methods that attempt to exploit the TEI phenomenon have been proposed, the small size of the design exploration space when applying these methods to ULP circuits hinders them from achieving their full potential. This is mainly due to the limited granularity of the supply voltage level control. Starting with an intuition that the body biasing (BB) technique is a key to overcome this limitation, this paper exploits the BB technique along with the TEI-aware voltage scaling (TEI-VS) method and TEI-aware frequency scaling (TEI-FS) method, so as to substantially increase the design spaces of these methods. Techniques for optimally combining the BB technique with TEI-VS and TEI-FS are introduced. Simulation results with the latest commercial CMOS process technologies for ULP designs demonstrate the effectiveness of the proposed methodology.","609":"Emerging transportation modes, including car-sharing, bike-sharing, and ride-hailing, are transforming urban mobility yet have been shown to reinforce socioeconomic inequity. These services rely on accurate demand prediction, but the demand data on which these models are trained reflect biases around demographics, socioeconomic conditions, and entrenched geographic patterns. To address these biases and improve fairness, we present FairST, a fairness-aware demand prediction model for spatiotemporal urban applications, with emphasis on new mobility. We use 1D (time-varying, space-constant), 2D (space-varying, time-constant) and 3D (both time- and space-varying) convolutional branches to integrate heterogeneous features, while including fairness metrics as a form of regularization to improve equity across demographic groups. We propose two spatiotemporal fairness metrics, region-based fairness gap (RFG), applicable when demographic information is provided as a constant for a region, and individual-based fairness gap (IFG), applicable when a continuous distribution of demographic information is available. Experimental results on bike share and ride share datasets show that FairST can reduce inequity in demand prediction for multiple sensitive attributes (i.e. race, age, and education level), while achieving better accuracy than even state-of-the-art fairness-oblivious methods.","610":"Recommender Systems (RSs) are widely used to help online users discover products, books, news, music, movies, courses, restaurants, etc. Because a traditional recommendation strategy always shows the most relevant items (thus with highest predicted rating), traditional RS\u2019s are expected to make popular items become even more popular and non-popular items become even less popular which in turn further divides the haves (popular) from the have-nots (unpopular). Therefore, a major problem with RSs is that they may introduce biases affecting the exposure of items, thus creating a popularity divide of items during the feedback loop that occurs with users, and this may lead the RS to make increasingly biased recommendations over time. In this paper, we view the RS environment as a chain of events that are the result of interactions between users and the RS. Based on that, we propose several debiasing algorithms during this chain of events, and evaluate how these algorithms impact the predictive behavior of the RS, as well as trends in the popularity distribution of items over time. We also propose a novel blind-spot-aware matrix factorization (MF) algorithm to debias the RS. Results show that propensity matrix factorization achieved a certain level of debiasing of the RS while active learning combined with the propensity MF achieved a higher debiasing effect on recommendations.","611":"Network function virtualization (NFV) decouples the traditional network functions from specific or proprietary hardware, such that virtualized network functions (VNFs) can run in software form. By exploring NFV, a consecutive set of VNFs can constitute a service function chain (SFC) to provide the network service. From the perspective of network service providers, how to maximize the network utility is always one of the major concerns. To this end, there are two main issues need to be considered at runtime: 1) how to handle the unpredictable network traffic burst? and 2) how to fairly allocate resources among various flows to satisfy different traffic demands? In this paper, we investigate a fairness-aware flow scheduling problem for network utility maximization, with joint consideration of resource allocation and rate control. Based on a discrete-time queuing model, we propose a low-complexity online-distributed algorithm using the Lyapunov optimization framework, which can achieve arbitrary optimal utility with different fairness levels by tuning the fairness bias parameter. We theoretically analyze the optimality of the algorithm and evaluate its efficiency by both simulation and testbed-based experiments.","612":"In complex dynamic tasks such as driving it is essential to be aware of potentially important targets in peripheral vision. While eye tracking methods in various driving tasks have provided much information about drivers\u2019 gaze strategies, these methods only inform about overt attention and provide limited grounds to assess hypotheses concerning covert attention. We adapted the Posner cue paradigm to a dynamic steering task in a driving simulator. The participants were instructed to report the presence of peripheral targets while their gaze was fixed to the road. We aimed to see whether and how the active steering task and complex visual stimulus might affect directing covert attention to the visual periphery. In a control condition, the detection task was performed without a visual scene and active steering. Detection performance in bends was better in the control task compared to corresponding performance in the steering task, indicating that active steering and the complex visual scene affected the ability to distribute covert attention. Lower targets were discriminated slower than targets at the level of the fixation circle in both conditions. We did not observe higher discriminability for on-road targets. The results may be accounted for by either bottom-up optic flow biasing of attention, or top-down saccade planning.","613":"Using the barometer for height estimation often requires the use of external reference to correct biases in measurement. These biases are often caused by the change of the ambient pressure environment. The barometric height estimation is especially challenging in tactical and rescue applications where high temperatures or sudden large pressure shocks can change the pressure rapidly. We assess the suitability of barometers for infrastructure-free navigation in tactical applications. First, this paper investigates the effect of transition in seamless indoor\/outdoor navigation. Second, we measure the effects of pressure shocks, caused by explosions or firearms, on low-cost and lightweight micro-electromechanical barometers to ensure that the sensors are capable of operating under these conditions. Finally, we investigate the use of sonar measurement to estimate the vertical speed as an alternative to the reference barometer for infrastructure-free navigation. The fusion of barometer and sonar achieved on average 0.46-m root-mean-square error (RMSE) while simple barometric height estimation had a RMSE of 0.65 m. The fusion method had no errors over 1.5 m during the test. This accuracy is generally sufficient to find the correct floor level which is crucial for tactical situational awareness. The goal of this paper is to develop the methods for seamless indoor\/outdoor navigation, and therefore the most important result of this paper is that the error caused when transitioning between outdoor and indoor environments is visibly reduced.","614":"Human face image is a large category of visual information utilized by various human facial data services (e.g., face recognition, face generation, face attribute prediction). However, the quality of data services (QoDS) on human face datasets is usually biased towards the majority demographic group due to the data imbalance issue. In this paper, we focus on a fair human face dataset sampling problem where the goal is to sample a sub-dataset from the original dataset to reduce its bias by leveraging crowd intelligence to infer the demographic labels of face images (e.g., male or female, old or young). Our problem is motivated by the limitations of current fair data sampling solutions that require pre-annotated demographic labels to sample a fair dataset. Two important challenges exist in solving our problem: 1) it is extremely time-consuming and expensive to assign crowd workers to annotate demographic labels of all images in a large-scale facial dataset; 2) it is not a trivial task to improve the fairness of the sampled sub-dataset (with fewer data samples) without sacrificing the accuracy performance of data services on such dataset. To address the above challenges, we develop FairCrowd, a fair crowdsourcing-based data sampling framework that leverages an efficient batch-level demographic label inference model and a joint fair-accuracy-aware data shuffling method. We evaluate the performance of FairCrowd through a large-scale real-world face image dataset that consists of celebrity faces from a diversified set of demographic groups. The results show that FairCrowd not only reduces demographic bias but also improves the accuracy of data services trained on the sub-dataset generated by FairCrowd, leading to a more desirable QoDS of the application.","615":"\nPurpose\nThe purpose of this paper was to investigate antecedents and results of strategic choices of multinational corporation (MNC) subsidiaries in Croatia economy. Hence, the authors examined knowledge management and its association with performance. Additionally, they explored which of the strategies will be most likely chosen by subsidiaries in transitional economies that are characterized by market volatility and uncertainty.\n\n\nDesign\/methodology\/approach\nData were collected from a survey of 131 MNC subsidiaries operating in Croatia. To test the theoretical correlation between knowledge management capabilities and strategic orientation, the authors used the ANCOVA method and controlled for industry, years in international business and firm size.\n\n\nFindings\nThe results pointed out the recognized necessities for a specific alignment between environment, strategy and knowledge management capabilities. The findings also suggest that there is a positive relationship between knowledge management and performance.\n\n\nResearch limitations\/implications\nAs with most of the research, this paper has limitations. First, all data were collected using self-report surveys raising the possibility of response set biases. Additionally, all data were collected at one point in one country specifically in Croatia.\n\n\nPractical implications\nClearly, there is substantial interaction between the MNC subsidiary\u2019s environment and the MNC subsidiary\u2019s strategic orientation. Most notably, the environment studied here was at the competitive and consumer market level. Firms need to develop a strategic plan for knowledge management based upon the local environmental influences.\n\n\nSocial implications\nOther firms from Central and Eastern European and developed countries may compare their own environment, strategy and knowledge management practices in MNCs with findings from Croatia to be aware of similarities and market differences.\n\n\nOriginality\/value\nThe strategic employment of knowledge acquisition, conversion and application are examined across firms using the Prospector, Analyzer, Defender and Reactor strategic orientations.\n","616":"Recent works have shown that a rich set of semantic directions exist in the latent space of Generative Adversarial Networks (GANs), which enables various facial attribute editing applications. However, existing methods may suffer poor attribute variation disentanglement, leading to unwanted change of other attributes when altering the desired one. The semantic directions used by existing methods are at attribute level, which are difficult to model complex attribute correlations, especially in the presence of attribute distribution bias in GAN\u2019s training set. In this paper, we propose a novel framework (IALS) that performs InstanceAware Latent-Space Search to find semantic directions for disentangled attribute editing. The instance information is injected by leveraging the supervision from a set of attribute classifiers evaluated on the input images. We further propose a Disentanglement-Transformation (DT ) metric to quantify the attribute transformation and disentanglement efficacy and find the optimal control factor between attribute-level and instance-specific directions based on it. Experimental results on both GAN-generated and real-world images collectively show that our method outperforms state-of-the-art methods proposed recently by a wide margin. Code is available at https:\/\/github.com\/yxuhan\/IALS.","617":"Virtual environments for gaming and simulation provide dynamic and adaptive experiences, but, despite advances in multisensory interfaces, these are still primarily visual experiences. To support real-time dynamic adaptation, interactive virtual environments could implement techniques to predict and manipulate human visual attention. One promising way of developing such techniques is to base them on psychophysical observations, an approach that requires a sound understanding of visual attention allocation. Understanding how this allocation of visual attention changes depending on a user\u2019s task offers clear benefits in developing these techniques and improving virtual environment design. With this aim, we investigated the effect of task on visual attention in interactive virtual environments. We recorded fixation data from participants completing freeview, search, and navigation tasks in three different virtual environments. We quantified visual attention differences between conditions by identifying the predictiveness of a low-level saliency model and its corresponding color, intensity, and orientation feature-conspicuity maps, as well as measuring fixation center bias, depth, duration, and saccade amplitude. Our results show that task does affect visual attention in virtual environments. Navigation relies more than search or freeview on intensity conspicuity to allocate visual attention. Navigation also produces fixations that are more central, longer, and deeper into the scenes. Further, our results suggest that it is difficult to distinguish between freeview and search tasks. These results provide important guidance for designing virtual environments for human interaction, as well as identifying future avenues of research for developing \u201cattention-aware\u201d virtual worlds.","618":"As the SARS-CoV-2 pandemic continues its rapid global spread, quantification of local transmission patterns has been, and will continue to be, critical for guiding pandemic response. Understanding the accuracy and limitations of statistical methods to estimate the reproduction number, R0, in the context of emerging epidemics is therefore vital to ensure appropriate interpretation of results and the subsequent implications for control efforts. Using simulated epidemic data we assess the performance of 6 commonly-used statistical methods to estimate R0 as they would be applied in a real-time outbreak analysis scenario - fitting to an increasing number of data points over time and with varying levels of random noise in the data. Method comparison was also conducted on empirical outbreak data, using Zika surveillance data from the 2015-2016 epidemic in Latin America and the Caribbean. We find that all methods considered here frequently over-estimate R0 in the early stages of epidemic growth on simulated data, the magnitude of which decreases when fitted to an increasing number of time points. This trend of decreasing bias over time can easily lead to incorrect conclusions about the course of the epidemic or the need for control efforts. We show that true changes in pathogen transmissibility can be difficult to disentangle from changes in methodological accuracy and precision, particularly for data with significant over-dispersion. As localised epidemics of SARS-CoV-2 take hold around the globe, awareness of this trend will be important for appropriately cautious interpretation of results and subsequent guidance for control efforts.","619":null,"620":"Driver profiling is an emerging scheme that has a wide range of applications in the field of Intelligent Transportation Systems (ITS). Driver profiling is the real-time process of detecting driving behaviors and computing a driver's competence level based on detected behaviors. In this paper, a novel driver profiling framework is presented. A risk prediction model is hosted in the cloud to determine the risk associated with detected behaviors in specific driving environments. Risk values along with a driver's compliance to warnings are both utilized to compute a driver's risk profile. Using SHRP2 large-scale Naturalistic Driving (ND) dataset, the development of the risk prediction model is presented herein with the underlying sub-processes of data preprocessing, error analysis, and model selection. Validation results show that a developed randomized trees supervised learning model is proven to have a good tradeoff between bias and variance with evidently high performance results.","621":"Abstractive text summarization aims at compressing the information of a long source document into a rephrased, condensed summary. Despite advances in modeling techniques, abstractive summarization models still suffer from several key challenges: (i) layout bias: they overfit to the style of training corpora; (ii) limited abstractiveness: they are optimized to copying n-grams from the source rather than generating novel abstractive summaries; (iii) lack of transparency: they are not interpretable. In this work, we propose a framework based on document-level structure induction for summarization to address these challenges. To this end, we propose incorporating latent and explicit dependencies across sentences in the source document into end-to-end single-document summarization models. Our framework complements standard encoder-decoder summarization models by augmenting them with rich structure-aware document representations based on implicitly learned (latent) structures and externally-derived linguistic (explicit) structures. We show that our summarization framework, trained on the CNN\/DM dataset, improves the coverage of content in the source documents, generates more abstractive summaries by generating more novel n-grams, and incorporates interpretable sentence-level structures, while performing on par with standard baselines.","622":"To solve the data sparseness and cold start problems in collaborative filtering (CF) based recommender systems (RS), various complex algorithms are proposed to extract and integrate explicit or implicit information of data for the recommendation. In this paper, we propose to aggregate and transmit the rich semantic information with the help of knowledge graph (KG) that is regarded as one of the main sources of auxiliary information. Specifically, we first propose a Neural Graph Collaborative Filtering to construct and aggregate information. And then we build a scalable and end-to-end knowledge-aware graph collaborative filtering model named KGCF. In KGCF, neighbourhood information in KG is encoded to construct information in a complex new way. And the information from neighbours are merged with a personalized bias calculated by attention mechanism based on KG. In order to extend the interacted items and capture the high-level semantic information of KG, multiple KGCF layers stacked is used in KGCF. Experimental results on three real data sets indicate that the KGCF model proposed in this paper is superior to the existing models in terms of accuracy and can also effectively solve the data sparsity problem of RS.","623":"The aim of the work described in this paper is to detect trees in eye level view images. Unlike previous work that universally considers highly constrained environments, such as natural parks and wooded areas, or simple scenes with little clutter and clear tree separation, our focus is on much more challenging suburban scenes, which are rich in clutter and highly variable in type and appearance (houses, falls, shrubs, cars, bicycles, pedestrians, hydrants, lamp posts, etc.). Thus, we motivate and introduce three different approaches: (i) a conventional computer vision based approach, employing manually engineered steps and making use of explicit human knowledge of the application domain, (ii) a more machine learning oriented approach, which learns from densely extracted local features in the form of scale invariant features (SIFT), and (iii) a machine learning based approach, which employs both colour and appearance models as a means of making the most of available discriminative information. We also make a significant contribution in regards to the collection of training and evaluation data. In contrast to the existing work, which relies on manual data collection (thus risking unintended bias) or corpora constrained in variability and limited in size (thus not allowing for reliable generalisation inferences to be made), we show how large amounts of representative data can be collected automatically using freely available tools, such as Google\u2019s Street View, and equally automatically processed to produce a large corpus of minimally biased imagery. Using a large data set collected in the manner and comprising tens of thousands of images, we confirm our theoretical arguments that motivated our machine learning based and colour-aware histograms of oriented gradients based method, which achieved a recall of 95% and precision of 97%.","624":"Handling classification uncertainty is crucial for supporting efficient and ethical classification systems. This thesis addresses uncertainty issues from the perspective of end-users with limited expertise in machine learning. We investigate uncertainties that pertain to estimating class sizes, i.e., numbers of objects per class. We aim at enabling non-expert end-users to conduct uncertainty-aware and scientifically-valid analysis of class sizes. We research the means to support end-users' understanding of class size uncertainty. After investigating the specific use case of in-situ video monitoring of animal populations, where classes represent animal species, we derive generalizable methods for: -Assessing the uncertainty factors and the uncertainty propagation that result in high-level errors and biases in class size estimates. -Estimating the magnitude of classification errors in class size estimates. -Visualizing classification uncertainty when evaluating classification systems, and interpreting class size estimates. We first study the high-level information needs that can or cannot be addressed by computer vision techniques for monitoring animal populations. The uncertainty issues inherent to each data collection technique, and high-level requirements for uncertainty assessment are identified. We further investigate the information that support end-users in developing informed uncertainty assessments. We explore how information about classification errors impacts users' understanding, trust and acceptance of the computer vision system. We highlight unfulfilled information needs requiring additional uncertainty assessments. From these insights, we identify key uncertainty factors to address for enabling scientifically valid analyses of classification results. Our scope includes uncertainty factors from computer vision systems, and from the conditions in which systems are deployed. We identify the interactions between uncertainty factors, how uncertainties propagates to high-level information, and the uncertainty assessment methods that are applicable or missing. We then investigate uncertainty assessment methods for estimating the numbers of errors in classification end-results. We highlight the unaddressed case of disjoint test and target sets, which impacts the variance of error estimation results. We introduce 3 new methods: -The Sample-to-Sample method estimates the variance of error estimation results for disjoint test and target sets. -The Maximum Determinant method uses the determinant of error rate matrices as a predictor of the variance of error estimation results. -The Ratio-to-TP method uses atypical error rates that have properties of interest for predicting the variance of error estimation results. We then investigate the means to communicate uncertainty to non-expert end-users. We introduce a simplified design for visualizing classification errors. We present a user study that compares our simplified visualization to well-established visualizations. We identify the main difficulties that users encountered with the visualizations and with understanding classification errors. Finally, we introduce a visualization tool that enables end-users to explore class size estimate, and the uncertainties in specific subsets of the data. We present a user study that investigates how the interface design supports user awareness of uncertainty. We highlight the factors that facilitated or complicated the exploration of the data and its uncertainties. Our results contribute to a broader range of applications dealing with uncertain computer vision and classification data. They inform the design of comprehensive uncertainty assessment methods and tools.","625":"Heterogeneous wireless sensor networks (WSNs) consist of resource\u2010starving nodes that face a challenging task of handling various issues such as data redundancy, data fusion, congestion control, and energy efficiency. In these networks, data fusion algorithms process the raw data generated by a sensor node in an energy\u2010efficient manner to reduce redundancy, improve accuracy, and enhance the network lifetime. In literature, these issues are addressed individually, and most of the proposed solutions are either application\u2010specific or too complex that make their implementation unrealistic, specifically, in a resource\u2010constrained environment. In this paper, we propose a novel node\u2010level data fusion algorithm for heterogeneous WSNs to detect noisy data and replace them with highly refined data. To minimize the amount of transmitted data, a hybrid data aggregation algorithm is proposed that performs in\u2010network processing while preserving the reliability of gathered data. This combination of data fusion and data aggregation algorithms effectively handle the aforementioned issues by ensuring an efficient utilization of the available resources. Apart from fusion and aggregation, a biased traffic distribution algorithm is introduced that considerably increases the overall lifetime of heterogeneous WSNs. The proposed algorithm performs the tedious task of traffic distribution according to the network's statistics, ie, the residual energy of neighboring nodes and their importance from a network's connectivity perspective. All our proposed algorithms were tested on a real\u2010time dataset obtained through our deployed heterogeneous WSN in an orange orchard and also on publicly available benchmark datasets. Experimental results verify that our proposed algorithms outperform the existing approaches in terms of various performance metrics such as throughput, lifetime, data accuracy, computational time, and delay.","626":"In everyday life, games begin inconspicuously, leaving an individual to stumble upon their assessment of a situation. An unaware individual is unlikely to exhibit strategic behavior in a given situation, which highlights the importance of awareness examination. The purpose of this exploratory analysis is to examine awareness and assessment of a game\u2019s existence at the individual level. That requires examination of respondents\u2019 detection (as an indication of their awareness) and identification (as an indication of their assessment) of game elements in game-like situations and their relation to awareness of the game existence. The empirical data is collected using a scenario technique and is statistically analyzed. The results show that the respondents are, on average, at least partially aware of possibility for strategic interaction (even in vague situations). The revealed regularities point out to the relation of the game elements to game existence belief, but also indicate the presence of psychological biases and information utilization issues. For example, the respondents assign different levels of belief to game existence regarding possible losses or gains. Research limitations involve the use of a small convenience sample and lead to suggestions for results validation in future research. Possible implications of the results are discussed.","627":"Diversity and fairness are increasingly linked in the field of personalized recommendations. For instance, the diversification of items (\u201ditem diversity\u201d) is considered key to fairness. Less attention has been paid to \u201duser diversity\u201d and its implications for fairness. In this paper, I problematize the conceptualization and application of user diversity in recommender systems. I argue that the widespread understanding of user diversity as natural, value-neutral, and individual-level categories may accidentally compound historical injustice. To mitigate emerging biases, diversity dimensions need to be contextualized by mapping structural inequalities between users. The paper thus stresses the importance of paying attention to the structural context of diversity, whereas the context refers to political and social circumstances surrounding the user\u2019s life. The paper makes three contributions: 1) It connects fairness to diversity literature in the field of recommender system, 2) it specifies the tension between item-side and user-side fairness by revealing a bias in the treatment of user diversity, 3) it proposes solutions to mitigate the bias by drawing on Black feminist and critical race theory.","628":"Public policy programs are set to manage the natural hazards\u2019 risk and raise public awareness and preparedness. The advance in information technologies lets the disaster-handling bodies design and develop platforms and tools (e.g., visual questionnaires or serious games) to raise endangered people\u2019s preparedness level. One primordial element which impacts human behavior and decision making during an incident is emotion. It seems to influence the preparedness level and risk perception towards an adaptation in behavior. So both research and industry communities can be interested in improving their emergency preparedness systems by considering real human behavior and emotions. This paper aims at better understanding the current state of the research on emotion-based disaster preparedness methods, channels, and tools and their mechanisms to adapt preparedness platforms and tools to emotions. It presents a targeted literature review which reinforced or revealed the following main findings: i) There are various individual (e.g., emotions) and contextual (e.g., communication channels) factors which affect citizens risk perception, ii) Humans\u2019 future emotions are exposed to different biases. Moderating such biases can positively impact the risk perception, iii) The emotions lead to specific body signals that can be captured and used in disaster communication channels for preparedness, iv) Adapting the channels (e.g., preparedness platforms) can improve both systems\u2019 usability and humans\u2019 learning objectives. This study leads us to the idea of the need to use of emotions within the disaster preparedness platforms and tools.","629":"Abstract Sequencing technologies has provided the basis of most modern genome sequencing studies due to its high base-level accuracy and relatively low cost. One of the most demanding step is mapping reads to the human reference genome. The reliance on a single reference human genome could introduce substantial biases in downstream analyses. Pangenomic graph reference representations offer an attractive approach for storing genetic variations. Moreover, it is possible to include known variants in the reference in order to make read mapping, variant calling, and genotyping variant-aware. Only recently a framework for variation graphs, vg [Garrison E, Adam MN, Siren J, et al. Variation graph toolkit improves read mapping by representing genetic variation in the reference. Nat Biotechnol 2018;36:875\u20139], have improved variation-aware alignment and variant calling in general. The major bottleneck of vg is its high cost of reads mapping to a variation graph. In this paper we study the problem of SNP calling on a variation graph and we present a fast reads alignment tool, named VG SNP-Aware. VG SNP-Aware is able align reads exactly to a variation graph and detect SNPs based on these aligned reads. The results show that VG SNP-Aware can efficiently map reads to a variation graph with a speedup of 40\u00d7 with respect to vg and similar accuracy on SNPs detection.","630":"Highly regulated domains such as finance have long favoured the use of machine learning algorithms that are scalable, transparent, robust and yield better performance. One of the most prominent examples of such an algorithm is XGBoost. Meanwhile, there is also a growing interest in building fair and unbiased models in these regulated domains and numerous bias-mitigation algorithms have been proposed to this end. However, most of these bias-mitigation methods are restricted to specific model families such as logistic regression or support vector machine models, thus leaving modelers with a difficult decision of choosing between fairness from the bias-mitigation algorithms and scalability, transparency, performance from algorithms such as XGBoost. We aim to leverage the best of both worlds by proposing a fair variant of XGBoost that enjoys all the advantages of XGBoost, while also matching the levels of fairness from the state-of-the-art bias-mitigation algorithms. Furthermore, the proposed solution requires very little in terms of changes to the original XGBoost library, thus making it easy for adoption. We provide an empirical analysis of our proposed method on standard benchmark datasets used in the fairness community.","631":"A model for estimating the dispersion in the output of a MOS-only, constant inversion level, current reference is presented. Based on such model, a design method is introduced that allows to optimize how area is spent in order to minimize the dispersion for a given layout complexity. The model was successfully compared with the measurements of a current source fabricated on a 130-nm CMOS technology and with the simulations of six other designs. The fabricated, ultralow power, current source has an area of 0.032 mm2 and produces 11.4 nA on average, while all eight measured devices were inside \u00b12.1% of the average.","632":"Simultaneous localization and mapping (SLAM) during communication is emerging. This technology promises to provide information on propagation environments and transceivers\u2019 location, thus creating several new services and applications for the Internet of Things and environment-aware communication. Using crowdsourcing data collected by multiple agents appears to be much potential for enhancing SLAM performance. However, the measurement uncertainties in practice and biased estimations from multiple agents may result in serious errors. This study develops a robust SLAM method with measurement plug-and-play and crowdsourcing mechanisms to address the above problems. First, we divide measurements into different categories according to their unknown biases and realize a measurement plug-and-play mechanism by extending the classic belief propagation (BP)-based SLAM method. The proposed mechanism can obtain the time-varying agent location, radio features, and corresponding measurement biases (such as clock bias, orientation bias, and received signal strength model parameters), with high accuracy and robustness in challenging scenarios without any prior information on anchors and agents. Next, we establish a probabilistic crowdsourcing-based SLAM mechanism, in which multiple agents cooperate to construct and refine the radio map in a decentralized manner. Our study presents the first BP-based crowdsourcing that resolves the \u201cdouble count\u201d and \u201cdata reliability\u201d problems through the flexible application of probabilistic data association methods. Numerical results reveal that the crowdsourcing mechanism can further improve the accuracy of the mapping result, which, in turn, ensures the decimeter-level localization accuracy of each agent in a challenging propagation environment.","633":null,"634":"Abstract Modeling human cognition is challenging because there are infinitely many mechanisms that can generate any given observation. Some researchers address this by constraining the hypothesis space through assumptions about what the human mind can and cannot do, while others constrain it through principles of rationality and adaptation. Recent work in economics, psychology, neuroscience, and linguistics has begun to integrate both approaches by augmenting rational models with cognitive constraints, incorporating rational principles into cognitive architectures, and applying optimality principles to understanding neural representations. We identify the rational use of limited resources as a unifying principle underlying these diverse approaches, expressing it in a new cognitive modeling paradigm called resource-rational analysis. The integration of rational principles with realistic cognitive constraints makes resource-rational analysis a promising framework for reverse-engineering cognitive mechanisms and representations. It has already shed new light on the debate about human rationality and can be leveraged to revisit classic questions of cognitive psychology within a principled computational framework. We demonstrate that resource-rational models can reconcile the mind's most impressive cognitive skills with people's ostensive irrationality. Resource-rational analysis also provides a new way to connect psychological theory more deeply with artificial intelligence, economics, neuroscience, and linguistics.","635":"In this paper, we consider a cognitive radio system with some of secondary users (SUs) equipped with multiple antenna full-duplex transceivers. We design a hybrid system to sense and access the spectrum opportunistically such that the SU operates on both underlay and interweave hybrid methods while the primary user (PU) may be active or inactive, respectively, to perform the sensing as agile as possible. Moreover, we maximize the throughput by allocating the spectral resources assuming limited available energy during each time frame with constraints on the interference to the primary user. We show that this problem is convex and propose a simple solution algorithm for it. Our simulations confirm the accuracy of our analytical and theoretical results and illustrate that the total achieved throughput of full-duplex cognitive radio even by considering self-interference is maximized under the assumed conditions.","636":"In classroom, student learning is affected by multiple factors that influence information processing. Working memory with its limited capacity and duration plays a key role in learner ability to process information and, therefore, is critical for student performance. Cognitive load theory, based on human cognitive architecture, focuses on the instructional implications of relations between working memory and learner knowledge base in long-term memory. The ultimate goal of this theory is to generate effective instructional methods that allow managing students' working memory load to optimize their learning, indicating the relations between the form of instructional design and the function of instructional design. This chapter considers recent additions to the theory based on working memory resources depletion that occurs after exerting significant cognitive effort and reverses after a rest period. The discussed implications for instructional design include optimal sequencing of learning and assessment tasks using spaced and massed practice tasks, immediate and delayed tests.","637":"The development of Industrial Internet of Things (IIoT) has been limited due to the shortage of spectrum resources. Based on cognitive radio, the cognitive IIoT (CIIoT) has been proposed to improve spectrum utilization via sensing and accessing the idle spectrum. To improve sensing and transmission performance of the CIIoT, a cluster-based CIIoT is proposed, in this article, wherein the cluster heads perform cooperative spectrum sensing to get available spectrum, and the nodes transmit via nonorthogonal multiple access (NOMA). The frame structure of the CIIoT is designed, and the spectrum access probability and average total throughput of the CIIoT are deduced. A joint resource optimization for sensing time, node powers, and the number of clusters is formulated to maximize the average total throughput. The optimal solution is obtained via sensing and power optimization. The clustering algorithm and cluster head alternation are proposed to improve transmission performance and ensure energy balance, respectively. The simulations have indicated that the NOMA for the cluster-based CIIoT can better guarantee the transmission performance of each node, especially the node decoded first, than the traditional NOMA and orthogonal multiple access.","638":"Sixth generation (6G)-enabled Internet of Things (IoT) needs sufficient spectrum resources to provide spectrum access for massive IoT\u2019s terminals. However, traditional orthogonal multiple access restricts the full use of limited spectrum resources. In this article, a nonorthogonal multiple access (NOMA)-based hybrid spectrum access scheme is proposed for 6G-enabled cognitive IoT (CIoT), where the CIoT may access both the idle and busy spectrum via NOMA regardless of the primary user\u2019s (PU) state. The uplink resource allocations for the CIoT are optimized in the decoding-PU-last and decoding-PU-first schemes, respectively, which seek to maximize the average total transmission rate of CIoT while ensuring the minimum transmission rates for PU and each CIoT node. Then, a clustering NOMA-based CIoT is presented to decrease the interuser interference, where the nodes in each cluster use NOMA to transmit in the allocated subchannel. The simulation results have shown the performance advantages for the NOMA-based hybrid spectrum access and better rate guarantee for the clustering NOMA-based CIoT.","639":null,"640":"The Internet of Things (IoT) platform has played a significant role in improving road transport safety and efficiency by ubiquitously connecting intelligent vehicles through wireless communications. Such an IoT paradigm however, brings in considerable strain on limited spectrum resources due to the need of continuous communication and monitoring. Cognitive radio (CR) is a potential approach to alleviate the spectrum scarcity problem through opportunistic exploitation of the underutilized spectrum. However, highly dynamic topology and time-varying spectrum states in CR-based vehicular networks introduce quite a few challenges to be addressed. Moreover, a variety of vehicular communication modes, such as vehicle-to-infrastructure and vehicle-to-vehicle, as well as data QoS requirements pose critical issues on efficient transmission scheduling. Based on this motivation, in this paper, we adopt a deep ${Q}$ -learning approach for designing an optimal data transmission scheduling scheme in cognitive vehicular networks to minimize transmission costs while also fully utilizing various communication modes and resources. Furthermore, we investigate the characteristics of communication modes and spectrum resources chosen by vehicles in different network states, and propose an efficient learning algorithm for obtaining the optimal scheduling strategies. Numerical results are presented to illustrate the performance of the proposed scheduling schemes.","641":"In a conventional cognitive radio (CR) network, only when the primary user\u2019s (PU) frequency bands are sensed to be free, secondary users (SUs) can utilize these frequency band resources. Therefore, spectrum sensing (SS) can improve spectrum utilization. Spectrum sharing means that the SUs are allowed to utilize the licensed spectrum bands belonging to the PU to transmit information with PU simultaneously. Spectrum sharing performs well under the conditions that the interference to the PU is assured to be less than a certain threshold. Non-orthogonal multiple access (NOMA) has attracted considerable interests in recent years, which is seen as an important wireless access scheme for the coming 5G wireless communication system. Simultaneous wireless information and power transfer (SWIPT) is proposed as a popular technique to extend the operation duration of power-supply-limited wireless networks. The CR-NOMA is seen as a special form of the power-domain NOMA, wherein the requirements of the SU and PU are strictly met so that excellent system performance can be achieved. In this paper, a joint frame structure is described, wherein SUs first perform SWIPT for spectrum sensing and then transmit information via an overlay and underlay mode. Moreover, the optimization problem to maximize the achievable throughput for the CR network is presented to obtain the optimal sensing slot, while the total transmission power and the minimum rate requirements of the SUs are both constrained. A joint power allocation and sensing time optimizing algorithm based on dichotomy method are proposed to achieve the optimal solution. The simulation results show that there is a maximal throughput via setting an optimal sensing time for the secondary network.","642":"In this paper, we study resource allocation problems for a two-tier cognitive heterogeneous network in interweave spectrum sharing mode. Secondary users (SUs) in small cells (SCs) opportunistically access the licensed spectrum resources. Non-orthogonal multiple access (NOMA) is used to boost the number of accessible SUs sharing the limited and dynamic licensed spectrum holes. Practically, there exists a tradeoff: an SC can increase its instantaneous sum throughput by accessing more idle bandwidth, which creates higher liability due to the dynamics of licensed spectrum and contention among the multiple SCs. Aiming to maximize the sum throughput of second-tier SCs network, we formulate a mixed integer non-linear programming problem with the constraints of the available idle bandwidth, the successive interference cancellation complexity, the transmission power budget, and the minimum data requirements. To efficiently solve this problem, we decompose the original optimization problem into bandwidth resource allocation subproblem, SUs clustering subproblem, and power allocation subproblem. Based on the scale of SCs network and the activities of licensed spectrum, we introduce an optimal bandwidth configuration to maximize the average sum throughput of SCs. By analyzing the derivation of the achievable rate expression of a NOMA-enabled SU, we develop a novel SUs clustering algorithm which can improve the throughput of a cluster by grouping SUs with more distinctive channel conditions. With the results of SUs clustering, we propose power allocation within a NOMA cluster by using Karush-Kuhn-Tucker optimality conditions. Furthermore, we perform power allocation across NOMA clusters by using the difference of convex programming. The simulation results validate the performance of the proposed resource allocation algorithms.","643":"Traditional mobile edge computing (MEC) methods always assume that the wireless devices (WDs) can offload their data to the base stations (BSs) or the access points (APs) at any time, which are not practical due to the tension between a large number of the WDs and the limited spectrum resources. In this paper, a framework for MEC-enabled cognitive radio (CR) networks is proposed, which integrates three technologies: MEC, CR, and wireless power transfer (WPT). To obtain the spectrum for offloading, cooperative relaying is considered. Optimization problems are formulated to study the upper bound of the energy efficiency (EE) of the WD and to maximize the practical EE in both partial offloading and local computing scenarios, which are non-convex and intractable. In order to tackle these problems, a two-phase method is proposed. The transmit power, the time for energy harvesting (EH) and MEC, and the central processing unit (CPU) frequency of the WD are jointly optimized. Semi-closed-form solutions are obtained in partial offloading scenario by using fractional programming theory, Lagrangian dual decomposition, and successive pseudo-convex approximation (SPCA) methods. Closed-form solutions are obtained for local computing scenarios. The simulation results show the effects of the different parameters on the system performance.","644":"Algorithms for spectrum sharing over resource\u2010limited cognitive radio networks are often designed to solve specific problems. This means that a certain algorithm deals specifically with a certain limited resource, and is not suitable for other resources. This limitation violates the software\u2010defined networking philosophy, where a scheme has to be reprogrammable to cope with different limited resources that can dynamically arise depending on network conditions. In this work, we investigate the problem of spectrum sharing in resource\u2010limited cognitive radio networks. Specifically, we introduce a novel spectrum sharing algorithm that is compatible with software\u2010defined networks, in the sense that it can be reprogrammed to support multiple constraints on resources of different types. A main feature of the proposed scheme is that computations could be distributed across multiple processing units to reduce computational complexity on each unit. In addition, the proposed algorithm is equipped with a fairness scheme. Simulation results demonstrate the efficacy of the proposed scheme.","645":"Visual working memory is a brief, capacity-limited store of visual information that is involved in a large number of cognitive functions. To guide one\u2019s behavior effectively, one must efficiently allocate these limited memory resources across memory items. Previous research has suggested that items are either stored in memory or completely blocked from memory access. However, recent behavioral work proposes that memory resources can be flexibly split across items based on their level of task importance. Here, we investigated the electrophysiological correlates of flexible resource allocation by manipulating the distribution of resources amongst systematically lateralized memory items. We examined the contralateral delay activity (CDA), a waveform typically associated with the number of items held in memory. Across three experiments, we found that, in addition to memory load, the CDA flexibly tracks memory resource allocation. This allocation occurred as early as attentional selection, as indicated by the N2pc. Additionally, CDA amplitude was better-described when fit with a continuous model predicted by load and resources together than when fit with either alone. Our findings show that electrophysiological markers of attentional selection and memory maintenance not only track memory load, but also the proportion of memory resources those items receive.","646":"Utilization of Wireless sensor network is growing with the development in modern technologies. On other side electromagnetic spectrum is limited resources. Application of wireless communication is expanding day by day which directly threaten electromagnetic spectrum band to become congested. Cognitive Radio solves this issue by implementation of unused frequency bands as \"White Space\". There is another important factor that gets attention in cognitive model i.e: Wireless Security. One of the famous causes of security threat is malicious node in cognitive radio wireless sensor networks (CRWSN). The goal of this paper is to focus on security issues which are related to CRWSN as Fusion techniques, Co-operative Spectrum sensing along with two dangerous attacks in CR: Primary User Emulation (PUE) and Spectrum Sensing Data Falsification (SSDF).","647":null,"648":"The active inference framework, and in particular its recent formulation as a partially observable Markov decision process (POMDP), has gained increasing popularity in recent years as a useful approach for modelling neurocognitive processes. This framework is highly general and flexible in its ability to be customized to model any cognitive process, as well as simulate predicted neuronal responses based on its accompanying neural process theory. It also affords both simulation experiments for proof of principle and behavioral modelling for empirical studies. However, there are limited resources that explain how to build and run these models in practice, which limits their widespread use. Most introductions assume a technical background in programming, mathematics, and machine learning. In this paper we offer a step-by-step tutorial on how to build POMDPs, run simulations using standard MATLAB routines, and fit these models to empirical data. We assume a minimal background in programming and mathematics, thoroughly explain all equations, and provide exemplar scripts that can be customized for both theoretical and empirical studies. Our goal is to provide the reader with the requisite background knowledge and practical tools to apply active inference to their own research. We also provide optional technical sections and several appendices, which offer the interested reader additional technical details. This tutorial should provide the reader with all the tools necessary to use these models and to follow emerging advances in active inference research.","649":"Mental disorders are widespread in countries all over the world. Nevertheless, there is a global shortage in human resources delivering mental health services. Leaving people with mental disorders untreated may increase suicide attempts and mortality. To address this matter of limited resources, conversational agents have gained momentum in the last years. In this work, we introduce SERMO, a mobile application with integrated chatbot that implements methods from cognitive behaviour therapy (CBT) to support mentally ill people in regulating emotions and dealing with thoughts and feelings. SERMO asks the user on a daily basis on events that occurred and on emotions. It determines automatically the basic emotion of a user from the natural language input using natural language processing and a lexicon-based approach. Depending on the emotion, an appropriate measurement such as activities or mindfulness exercises are suggested by SERMO. Additional functionalities are an emotion diary, a list of pleasant activities, mindfulness exercises and information on emotions and CBT in general. User experience was studied with 21 participants using the User Experience Questionnaire (UEQ). Findings show that efficiency, perspicuity and attractiveness are considered as good. The scales describing hedonic quality (stimulation and novelty), i.e., fun of use, show neutral evaluations.","650":"Non-orthogonal multiple access (NOMA) is considered as one of the most promising technologies to handle the issue of spectrum scarcity in beyond fifth-generation (5G) networks. Integrating NOMA in cognitive radio (CR) network is expected to usher a new era of reliable, seamless, and massive connectivity. In this regard, this work explores the relay selection problem in CR networks when operating in the spectrum sharing model. Specifically, the secondary users (SUs) in the CR-NOMA network opportunistically access the licensed spectrum resources to boost the number of accessible SUs sharing the limited and dynamic spectrum resources. Moreover, to improve the performance of far users, partial relay selection architecture is exploited at full-duplex (FD) and half duplex (HD) relays for both uplink and downlink communications. For in-depth performance evaluation, we provide closed-form expressions of the outage probabilities of the users in FD and HD relay-aided CR-NOMA networks. In addition to this, the analytical expressions of asymptotic outage probabilities and ergodic capacity are also provided which unveils the critical factors affecting the performance of CR-NOMA networks. To validate the derived expressions, extensive simulations are performed that demonstrate the accuracy of analytical expressions for FD and HD relay-aided CR-NOMA networks.","651":"Planning is useful. It lets people take actions that have desirable long-term consequences. But, planning is hard. It requires thinking about consequences, which consumes limited computational and cognitive resources. Thus, people should plan their actions, but they should also be smart about how they deploy resources used for planning their actions. Put another way, people should also \"plan their plans\". Here, we formulate this aspect of planning as a meta-reasoning problem and formalize it in terms of a recursive Bellman objective that incorporates both task rewards and information-theoretic planning costs. Our account makes quantitative predictions about how people should plan and meta-plan as a function of the overall structure of a task, which we test in two experiments with human participants. We find that people's reaction times reflect a planned use of information processing, consistent with our account. This formulation of planning to plan provides new insight into the function of hierarchical planning, state abstraction, and cognitive control in both humans and machines.","652":null,"653":"An average medium-sized organisation logs approx. 10 to 500 mln events per day on the system. Only less than 5% of threat alerts are being investigated by the specialised staff, leaving the security hole open for potential attacks. Insufficient information in alert message produced in machine-friendly rather than human-friendly format causes cognitive overload on currently limited cybersecurity resources. In this paper, the model that generates the report in natural language by means of applying novel storytelling techniques from security logs is proposed. The solution caters for different levels of reader expertise and preference by providing adjustable templates, filled from both local and global knowledge base. The validation is performed on case study from Security Operations Centre (SOC) at educational institution. The report generated proves superior to existing approach in terms of comprehension (increased cognition) and completeness (enriched context). The evaluation demonstrates power of storytelling in potential threats interpretation in cybersecurity context.","654":"The IoT network allows IoT devices to communicate with other devices, applications, and services by exploiting existing network infrastructure. Recently, a promising paradigm, MEC, emerging for alleviating high latency data services in cloud computing framework plays an important role in the IoT network. Network performance and intelligence can be improved by integrating cognitive and cooperative mechanisms in the MEC framework. However, the QoS of computation-intensive tasks may degrade because of the limited available computational resources in MEC servers. Moreover, the characteristics of resources belonging to MEC servers and cloud servers are commonly different. In order to optimize the strategy of resource assignment, the tasks of assigning the limited computational resources in MEC servers and resolving the high latency problem in cloud servers have attracted growing interest from researchers. In this article, we propose a joint optimization paradigm for task-driven resource assignment based on evolutionary computation considering the power consumption and computation\/communication delay simultaneously. The MEC framework consists of MEC servers, mobile devices, and cloud servers, and offloads the computational resources to the edge of end users. Additionally, we introduce and analyze three typical task-driven cases, which are the server-determined condition, server-flexible condition, and server-uncertain condition, respectively. Finally, we present the existing technical challenges and discuss the open research issues.","655":"Multimedia learning theory describes how the designers of instructional messages, systems, and learning environments can optimize learning. The principles and heuristics of multimedia learning theory have application in traditional and online environments, with young and adult learners, in K-12, higher education, military, corporate, government, and informal learning environments. This diversity of application is based on the foundational premise that all learners can independently process auditory and visual information, have limited working memory resources, and require cognitive resources to process new information and to learn. This chapter describes the basic tenets of multimedia learning theory, best practices that can improve our message design Key Points: \u2022 Multimedia learning theory describes the use of multiple simultaneous techniques in instructional message design, such as combining narration and visuals in a presentation. \u2022 1) Dual coding, 2) limited working memory capacity, and 3) the need to maximize cognitive resources for learning are fundamental principles. \u2022 The key to effective multimedia design is to minimize extraneous processing, manage essential processing, and maximizing working memory resources available for generative","656":"Dynamic spectrum access (DSA)\/cognitive radio (CR) systems can benefit from the knowledge of the activity statistics of primary channels, which can use this information to intelligently adapt their spectrum use to the operating environment. Particularly relevant statistics are the minimum, mean and variance of the on\/off period durations, the channel duty cycle and the governing distribution. However, most DSA\/CR systems have limited resources (power consumption, memory capacity, computational capability) and an important question arises of how many on\/off period observations are required (i.e., the number of observed on\/off periods, referred to as observation sample size in this paper) to estimate the statistics of the primary channel to a certain desired level of accuracy. In this paper, closed-form expressions to link such sample size with the accuracy of the observed primary activity statistics are proposed. A comprehensive theoretical analysis is performed on the required number of observed on\/off periods to obtain a specific estimation accuracy. The accuracy of the obtained analytical results is validated and corroborated with both simulation and experimental results, showing a perfect agreement. The analytical results derived in this paper can be used in the design and dimensioning of DSA\/CR systems in which the spectrum awareness function relies on spectrum sensing.","657":"It has been 20 years since the concept of cognitive radio (CR) was proposed, which is an efficient approach to provide more access opportunities to connect massive wireless devices. To improve the spectrum efficiency, CR enables unlicensed usage of licensed spectrum resources. It has been regarded as the key enabler for intelligent communications. In this article, we will provide an overview on the intelligent communication in the past two decades to illustrate the revolution of its capability from cognition to artificial intelligence (AI). Particularly, this article starts from a comprehensive review of typical spectrum sensing and sharing, followed by the recent achievements on the AI-enabled intelligent radio. Moreover, research challenges in the future intelligent communications will be discussed to show a path to the real deployment of intelligent radio. After witnessing the glorious developments of CR in the past 20 years, we try to provide readers a clear picture on how intelligent radio could be further developed to smartly utilize the limited spectrum resources as well as to optimally configure wireless devices in the future communication systems.","658":"One of the most fundamental and striking limitations of human cognition appears to be a constraint in the number of control-dependent processes that can be executed at one time. This constraint motivates one of the most influential tenets of cognitive psychology: that cognitive control relies on a central, limited capacity processing mechanism that imposes a seriality constraint on processing. Here we provide a formally explicit challenge to this view. We argue that the causality is reversed: the constraints on control-dependent behavior reflect a rational bound that control mechanisms impose on processing, to prevent processing interference that arises if two or more tasks engage the same resource to be executed. We use both mathematical and numerical analyses of shared representations in neural network architectures to articulate the theory, and demonstrate its ability to explain a wide range of phenomena associated with control-dependent behavior. Furthermore, we argue that the need for control, arising from the shared use of the same resources by different tasks, reflects the optimization of a fundamental tradeoff intrinsic to network architectures: the increase in learning efficacy associated with the use of shared representations, versus the efficiency of parallel processing (i.e., multitasking) associated with task-dedicated representations. The theory helps frame a formally rigorous, normative approach to the tradeoff between control-dependent processing versus automaticity, and relates to a number of other fundamental principles and phenomena concerning cognitive function, and computation more generally.","659":"The multicomponent model aims to provide a broad theoretical framework enabling both more detailed fractionation and analysis of its components, and a capacity for it be used fruitfully beyond the laboratory. In its current form it comprises four interacting components. Two of these are modality-specific memory storage systems, one verbal-acoustic, the phonological loop, and one visuospatial, the sketchpad. Information in both these stores can be temporarily maintained via focused attention termed \u2018refreshing\u2019, while the phonological loop can also maintain familiar verbalizable material by subvocal or overt rehearsal. Both subsystems are controlled by a third component, the central executive, a supervisory system with limited resources. The central executive is principally concerned with internally directed attentional control processes but also has a role in the attentional selection of perceptual information. Information from these three components is coordinated with information from perception and long-term memory through the fourth component, a multidimensional, multimodal episodic buffer. This component is capable of holding up to around four episodic chunks, and is a valuable but essentially passive storage system, controlled by the central executive and accessible to conscious awareness. The multicomponent model has been systematically developed using a number of experimental tools. These include, principally, similarity effects to identify the type of coding involved, concurrent task methods to assess the contributions of the various subsystems to complex tasks, and neuropsychological evidence, in particular from the study of single cases with very specific deficits. The model continues to evolve and has proved successful both in accounting for a broad range of data on memory and related cognitive areas and in its application to the understanding of a wide range of cognitive activities and populations.","660":"Social isolation is likely to be recommended for older adults due to COVID-19, with ongoing reduced clinical contact suggested for this population. This has increased the need for remote memory clinics, we therefore review the literature, current practices and guidelines on organizing such remote memory clinics, focusing on assessment of cognition, function and other relevant measurements, proposing a novel pathway based on three levels of complexity: simple telephone or video-based interviews and testing using available tests (Level 1), digitized and validated methods based on standard pen-and-paper tests and scales (Level 2), and finally fully digitized cognitive batteries and remote measurement technologies (RMTs, Level 3). Pros and cons of these strategies are discussed. Remotely collected data negates the need for frail patients or carers to commute to clinic and offers valuable insights into progression over time, as well as treatment responses to therapeutic interventions, providing a more realistic and contextualized environment for data-collection. Notwithstanding several challenges related to internet access, computer skills, limited evidence base and regulatory and data protection issues, digital biomarkers collected remotely have significant potential for diagnosis and symptom management in older adults and we propose a framework and pathway for how technologies can be implemented to support remote memory clinics. These platforms are also well-placed for administration of digital cognitive training and other interventions. The individual, societal and public\/private costs of COVID-19 are high and will continue to rise for some time but the challenges the pandemic has placed on memory services also provides an opportunity to embrace novel approaches. Remote memory clinics\u2019 financial, logistical, clinical and practical benefits have been highlighted by COVID-19, supporting their use to not only be maintained when social distancing legislation is lifted but to be devoted extra resources and attention to fully potentiate this valuable arm of clinical assessment and care.","661":"Training deep reinforcement learning agents complex behaviors in 3D virtual environments requires significant computational resources. This is especially true in environments with high degrees of aliasing, where many states share nearly identical visual features. Minecraft is an exemplar of such an environment. We hypothesize that interactive machine learning IML, wherein human teachers play a direct role in training through demonstrations, critique, or action advice, may alleviate agent susceptibility to aliasing. However, interactive machine learning is only practical when the number of human interactions is limited, requiring a balance between human teacher effort and agent performance. We conduct experiments with two reinforcement learning algorithms which enable human teachers to give action advice, Feedback Arbitration and Newtonian Action Advice, under visual aliasing conditions. To assess potential cognitive load per advice type, we vary the accuracy and frequency of various human action advice techniques. Training efficiency, robustness against infrequent and inaccurate advisor input, and sensitivity to aliasing are examined.","662":"Attention and self-attention mechanisms, inspired by cognitive processes, are now central to state-of-the-art deep learning on sequential tasks. However, most recent progress hinges on heuristic approaches with limited understanding of attention's role in model optimization and computation, and rely on considerable memory and computational resources that scale poorly. In this work, we present a formal analysis of how self-attention affects gradient propagation in recurrent networks, and prove that it mitigates the problem of vanishing gradients when trying to capture long-term dependencies. Building on these results, we propose a relevancy screening mechanism, inspired by the cognitive process of memory consolidation, that allows for a scalable use of sparse self-attention with recurrence. While providing guarantees to avoid vanishing gradients, we use simple numerical experiments to demonstrate the tradeoffs in performance and computational resources by efficiently balancing attention and recurrence. Based on our results, we propose a concrete direction of research to improve scalability of attentive networks.","663":"Postural control research suggests a non-linear, n-shaped relationship between dual-tasking and postural stability. Nevertheless, the extent of this relationship remains unclear. Since kinematic principal component analysis has offered novel approaches to study the control of movement components (PM) and n-shapes have been found in measures of sway irregularity, we hypothesized (H1) that the irregularity of PMs and their respective control, and the control tightness will display the n-shape. Furthermore, according to the minimal intervention principle (H2) different PMs should be affected differently. Finally, (H3) we expected stronger dual-tasking effects in the older population, due to limited cognitive resources. We measured the kinematics of forty-one healthy volunteers (23 aged 26 \u00b1 3; 18 aged 59 \u00b1 4) performing 80 s tandem stances in five conditions (single-task and auditory n-back task; n = 1\u20134), and computed sample entropies on PM time-series and two novel measures of control tightness. In the PM most critical for stability, the control tightness decreased steadily, and in contrast to H3, decreased further for the younger group. Nevertheless, we found n-shapes in most variables with differing magnitudes, supporting H1 and H2. These results suggest that the control tightness might deteriorate steadily with increased cognitive load in critical movements despite the otherwise eminent n-shaped relationship.","664":"The development of 5G-satellite integrated networks suffers from limited spectrum resources. In this paper, we investigate how to assign spectrum intelligently based on dynamical cooperation among primary users (PUs) and cognitive users (CUs) for 5G-satellite integrated networks. Firstly, we propose the cooperative transmission ability model. The effective time for users to communicate with satellites is formally measured. Based on this model, then, we formulate the intelligent spectrum assignment problem. Next, we propose the spectrum assignment mechanism PU4CU to maximize the throughput of CUs, including our random-based and greedy-based algorithms. Finally, we propose the stable matching-based cooperative spectrum assignment algorithm with the aim of maximizing the overall throughput, where CUs not only request spectrum from PUs but also transmit a part of the traffic of PUs. Extensive simulation results demonstrate that our three algorithms significantly improve spectrum utilization ratio and system performance.","665":"Problem solving is one of the most important 21st century skills. However, effectively coaching young students in problem solving is challenging because teachers must continuously monitor their cognitive and affective states, and make real-time pedagogical interventions to maximize their learning outcomes. It is an even more challenging task in social environments with limited human coaching resources. To lessen the cognitive load on a teacher and enable affect-sensitive intelligent tutoring, many researchers have investigated automated cognitive and affective detection methods. However, most of the studies use culturally-sensitive indices of affect that are prone to social editing such as facial expressions, and only few studies have explored involuntary dynamic behavioral signals such as gross body movements. In addition, most current methods rely on expensive labelled data from trained annotators for supervised learning. In this paper, we explore a semi-supervised learning framework that can learn low-dimensional representations of involuntary dynamic behavioral signals (mainly gross-body movements) from a modest number of short time series segments. Experiments on a real-world dataset reveal a significant advantage of these representations in discriminating cognitive disequilibrium and flow, as compared to traditional complexity measures from dynamical systems literature, and demonstrate their potential in transferring learned models to previously unseen subjects.","666":null,"667":"Abstract We agree with the authors regarding the utility of viewing cognition as resulting from an optimal use of limited resources. Here, we advocate for extending this approach to the study of cognitive development, which we feel provides particularly powerful insight into the debate between bounded optimality and true sub-optimality, precisely because young children have limited computational and cognitive resources.","668":"Work in AI-based explanation systems has uncovered an interesting contradiction: people prefer and learn best from why explanations but expert esports commentators primarily answer what questions when explaining complex behavior in real-time strategy games. Three possible explanations for this contradiction are: 1.) broadcast audiences are well-informed and do not need why explanations; 2.) consuming why explanations in real-time is too cognitively demanding for audiences; or 3.) producing live why explanations is too difficult for commentators. We answer this open question by investigating the effects of explanation types and presentation modalities on audience recall and cognitive load in the context of an esports broadcast. We recruit 111 Dota 2 players and split them into three groups: the first group views a Dota 2 broadcast, the second group has the addition of an interactive map that provides what explanations, and the final group receives the interactive map with detailed why explanations. We find that participants who receive short interactive text prompts that provide what explanations outperform the no explanation group on a multiple-choice recall task. We also find that participants who receive detailed why explanations submit reports of cognitive load that are higher than the no explanation group. Our evidence supports the conclusion that informed audiences benefit from explanations but do not have the cognitive resources to process why answers in real-time. It also supports the conclusion that stacked explanation interventions across different modalities, like audio, interactivity, and text, can aid real-time comprehension when attention resources are limited. Together, our results indicate that interactive multimedia interfaces can be leveraged to quickly guide attention and provide low-cost explanations to improve intelligibility when time is too scarce for cognitively demanding why explanations.","669":null,"670":null,"671":"Human rationality is predominantly evaluated by the extent to which the mind respects the tenets of normative formalisms like logic and probability theory, and is often invoked by appealing to the notion of optimality. Drawing mainly on Simon\u2019s bounded rationality principle, there has been a surge in the understanding of human rationality with respect to the limited computational and cognitive resources the mind is faced with. In this work, we focus on another fairly underappreciated yet crucial facet of rationality, robustness: insensitivity of a model\u2019s performance to miscalculations of its parameters. We argue that an integrative pursuit of three facets (optimality, efficient use of limited resources, and robustness) would be a fruitful approach to understanding the extent of human rationality. We present several novel formalizations of robustness and discuss a recently proposed metacognitively-rational model of risky choice which is surprisingly robust to underand over-estimation of its focal parameter, nicely accounting for well-known framing effects in human decision-making under risk. We close by highlighting the ubiquitous presence of robustness in natural as well as artificial realms, and the implications of our work for rationalistic approaches to understanding human cognition at the algorithmic level of analysis.","672":"Significance From choosing among the many courses offered in graduate school to dividing budget into research programs, the breadth\u2013depth is a commonplace dilemma that arises when finite resources (e.g., time, money, cognitive capabilities) need to be allocated among a large range of alternatives. For such problems, decision makers need to trade off breadth\u2014allocating little capacity to each of many alternatives\u2014and depth\u2014focusing capacity on a few options. We found that little available capacity (less than 10 samples for search) promotes allocating resources broadly, and thus breadth search is favored. Increased capacity results in an abrupt transition toward favoring a balance between breadth and depth. We finally describe a rich casuistic and heuristics for metareasoning with finite resources. In multialternative risky choice, we are often faced with the opportunity to allocate our limited information-gathering capacity between several options before receiving feedback. In such cases, we face a natural trade-off between breadth\u2014spreading our capacity across many options\u2014and depth\u2014gaining more information about a smaller number of options. Despite its broad relevance to daily life, including in many naturalistic foraging situations, the optimal strategy in the breadth\u2013depth trade-off has not been delineated. Here, we formalize the breadth\u2013depth dilemma through a finite-sample capacity model. We find that, if capacity is small (\u223c10 samples), it is optimal to draw one sample per alternative, favoring breadth. However, for larger capacities, a sharp transition is observed, and it becomes best to deeply sample a very small fraction of alternatives, which roughly decreases with the square root of capacity. Thus, ignoring most options, even when capacity is large enough to shallowly sample all of them, is a signature of optimal behavior. Our results also provide a rich casuistic for metareasoning in multialternative decisions with bounded capacity using close-to-optimal heuristics.","673":"Automatic service composition in mobile and pervasive computing faces many challenges due to the complex nature of the environment. Common approaches address service composition from optimization perspectives which are not feasible in practice due to the intractability of the problem, limited computational resources of smart devices, service host's mobility, and time constraints. Our main contribution is the development of a cognitively-inspired agent-based service composition model focused on bounded rationality rather than optimality, which allows the system to compensate for limited resources by selectively filtering out continuous streams of data. The evaluation of our approach shows promising results when compared against state-of-the-art service composition models.","674":"Cognitive Radars (CRs) have the capability to adapt to their environment and accumulate knowledge from their interactions with the environment. This paper deals with the Radar Resource Management (RRM) problem where the radar assigns limited time resources to a set of tasks. The problem is modeled as an optimization problem where the aim is to minimize the number of delayed and dropped tasks which is an NP-hard problem. We propose a modified Monte Carlo Tree Search (MCTS) approach to find an effective solution. We further develop a Reinforcement Learning (RL) solution that uses a Neural Network (NN) to guide the modified MCTS. This produces a stable RL algorithm that learns on its own, requires no external training data, and can adapt to a varying environment. The results show the proposed RL algorithm outperforms other techniques including commonly used heuristics and produces close to optimal results.","675":"Deception plays a crucial role in adversarial or strategic interactions for self-defense and survival. This paper introduces a general framework and solution to address the deception of adversaries with bounded rationality. Such a problem is commonly encountered in many applications especially involving human adversaries. Leveraging the cognitive bias of humans in reward evaluation under stochastic outcomes, we introduce a framework to optimally assign resources of a limited quantity to optimally defend against human adversaries. Then we formulate the resource allocation problem as a signomial program to minimize the defender\u2019s cost in an environment modeled as a Markov decision process. We use police patrol hour assignment as an illustrative example and provide detailed simulation results based on real-world data.","676":null,"677":"Wireless networks are very significant in the present world owing to their widespread use and its application in domains like disaster management, smart cities, IoT etc. A wireless network is made up of a group of wireless nodes that communicate with each other without using any formal infrastructure. The topology of the wireless network is not fixed and it can vary. The huge increase in the number of wireless devices is a challenge owing to the limited availability of wireless spectrum. Opportunistic spectrum access by Cognitive radio enables the efficient usage of limited spectrum resources. The unused channels assigned to the primary users may go waste in idle time. Cognitive radio systems will sense the unused channel space and assigns it temporarily for secondary users. This paper discusses about the recent trends in the two most important aspects of Cognitive radio namely spectrum sensing and security.","678":"This article examines the causes of dual-task interference in a time pressured dynamic environment. Resource sharing theories are often used as a theoretical framework to understand dual-task interference. These frameworks propose that resources from a limited pool of information-processing capacity are reallocated toward the primary task as task load increases and, as a result, secondary-task performance declines if the total demand exceeds capacity limit. However, tests of resource models have relied on behavioral results that could be because of a number of different cognitive processes, including changes in response caution, rate of information processing, nondecision processes, and response biases. We applied evidence-accumulation models to quantify the cognitive processes underlying performance in a dual-task paradigm to examine the causes underlying dual-task interference. We fit performance in time-pressured environment on both a primary classification task and a secondary detection task using evidence-accumulation models. Under greater time pressure, the rate of information processing increased for the primary task while response caution decreased, whereas the rate of information processing for the secondary task declined with greater time pressure. Assuming the rate of evidence accumulation is proportional to available capacity these results are consistent with resource theory and highlight the value of evidence-accumulation models for understanding the complex set of processes underlying dual-task interference. (PsycINFO Database Record (c) 2019 APA, all rights reserved).","679":"Within computational neuroscience, the algorithmic and neural basis of structure learning remains poorly understood. Concept learning is one primary example, which requires both a type of internal model expansion process (adding novel hidden states that explain new observations), and a model reduction process (merging different states into one underlying cause and thus reducing model complexity via meta-learning). Although various algorithmic models of concept learning have been proposed within machine learning and cognitive science, many are limited to various degrees by an inability to generalize, the need for very large amounts of training data, and\/or insufficiently established biological plausibility. Using concept learning as an example case, we introduce a novel approach for modeling structure learning\u2014and specifically state-space expansion and reduction\u2014within the active inference framework and its accompanying neural process theory. Our aim is to demonstrate its potential to facilitate a novel line of active inference research in this area. The approach we lay out is based on the idea that a generative model can be equipped with extra (hidden state or cause) \u201cslots\u201d that can be engaged when an agent learns about novel concepts. This can be combined with a Bayesian model reduction process, in which any concept learning\u2014associated with these slots\u2014can be reset in favor of a simpler model with higher model evidence. We use simulations to illustrate this model's ability to add new concepts to its state space (with relatively few observations) and increase the granularity of the concepts it currently possesses. We also simulate the predicted neural basis of these processes. We further show that it can accomplish a simple form of \u201cone-shot\u201d generalization to new stimuli. Although deliberately simple, these simulation results highlight ways in which active inference could offer useful resources in developing neurocomputational models of structure learning. They provide a template for how future active inference research could apply this approach to real-world structure learning problems and assess the added utility it may offer.","680":"Within computational neuroscience, the algorithmic and neural basis of structure learning remains poorly understood. Concept learning is one primary example, which requires both a type of internal model expansion process (adding novel hidden states that explain new observations), and a model reduction process (merging different states into one underlying cause and thus reducing model complexity via meta-learning). Although various algorithmic models of concept learning have been proposed within machine learning and cognitive science, many are limited to various degrees by an inability to generalize, the need for very large amounts of training data, and\/or insufficiently established biological plausibility. Using concept learning as an example case, we introduce a novel approach for modeling structure learning within the active inference framework and its accompanying neural process theory. This approach is based on the idea that a generative model can be equipped with extra (hidden state or cause) \u2018slots\u2019 that can be engaged when an agent learns about novel concepts. This can be combined with a Bayesian model reduction process, in which any concept learning \u2013 associated with these slots \u2013 can be reset in favor of a simpler model with higher model evidence. We use simulations to illustrate this model\u2019s ability to add new concepts to its state space (with relatively few observations) and increase the granularity of the concepts it currently possesses. We also simulate the predicted neural basis of these processes. We further show that it accomplishes a simple form of \u2018one-shot\u2019 generalization to new stimuli. Although deliberately simple, these results suggest that this general approach to modeling concept learning within active inference research may also offer useful resources in developing neurocomputational models of structure learning more generally.","681":"People often plan hierarchically. That is, rather than planning over a monolithic representation of a task, they decompose the task into simpler subtasks and then plan to accomplish those. Although much work explores how people decompose tasks, there is less analysis of why people decompose tasks in the way they do. Here, we address this question by formalizing task decomposition as a resource-rational representation problem. Specifically, we propose that people decompose tasks in a manner that facilitates efficient use of limited cognitive resources given the structure of the environment and their own planning algorithms. Using this model, we replicate several existing findings. Our account provides a normative explanation for how people identify subtasks as well as a framework for studying how people reason, plan, and act using resource-rational representations.","682":"Mental workload or cognitive load is the total amount of mental resources required while doing a task. Apart from qualitative measures, various physiological signals are being used for assessment of mental workload. However, very limited research has been done on assessment of cognitive load from respiratory signals. In the present study, we have tried to analyze the cognitive load mainly based on respiratory features. n-back memory test has been modified to impart low and high cognitive load. The peripheral blood volume signal (PPG) collected while executing the task is used to reconstruct the breathing pattern signal. A number of morphological as well as statistical features are calculated from this reconstructed signal. Finally a classifier is used for classifying the low and high cognitive load. Results show that a classification accuracy of 76.8% is obtained while using respiratory features only. A maximum accuracy of 81.80% is obtained if we combine time domain PPG features with respiratory features. The features finally selected can also be used to study the habituation effect.","683":"Today\u2019s applications are using machine learning algorithms to analyze the data collected from a swarm of devices on the Internet of Things (IoT). However, most existing learning algorithms are overcomplex to enable real-time learning on IoT devices with limited resources and computing power. Recently, Hyperdimensional computing (HDC) is introduced as an alternative computing paradigm for enabling efficient and robust learning. HDC emulates the cognitive task by representing the values as patterns of neural activity in high-dimensional space. HDC first encodes all data points to high-dimensional vectors. It then efficiently performs the learning task using a well-defined set of operations. Existing HDC solutions have two main issues that hinder their deployments on low-power embedded devices: (i) the encoding module is costly, dominating 80% of the entire training performance, (ii) the HDC model size and the computation cost grow significantly with the number of classes in online inference.In this paper, we proposed a novel architecture, LookHD, which enables real-time HDC learning on low-power edge devices. LookHD exploits computation reuse to memorize the encoding module and simplify its computation with single memory access. LookHD also address the inference scalability by exploiting HDC governing mathematics that compresses the HDC trained model into a single hypervector. We present how the proposed architecture can be implemented on the existing low power architectures: ARM processor and FPGA design. We evaluate the efficiency of the proposed approach on a wide range of practical classification problems such as activity recognition, face recognition, and speech recognition. Our evaluations show that LookHD can achieve, on average, $ 28.3\\times$ faster and $ 97.4\\times$ more energy-efficient training as compared to the state-of-the-art HDC implemented on the FPGA. Similarly, in the inference, LookHD is $ 2.2\\times$ faster, $ 4.1\\times$ more energy-efficient, and has $ 6.3\\times$ smaller model size than the same state-of-the-art algorithms.","684":"Various emergencies are happening frequently in recent years, causing great loss of life and property. Therefore, it has become imperative to improve emergency management. Considering that the performance of emergency management could be affected by many different factors, it is hard to improve all the factors under the condition of limited resources. One approach that works well is to optimize the key factors that affect emergency management. To this end, an integrated method based on fuzzy cognitive map (FCM) and Pearson\u2019s product-moment correlation coefficient is presented in this article to determine the critical risk factors in emergency management. First, the causal relationships between the risk factors influencing emergency management are determined according to expert opinions. To verify if the survey results from experts are reliable, an item-average correlation test based on Pearson\u2019s product-moment correlation coefficient is performed. Then, two scenarios are designed and the FCM method is utilized to identifying the critical risk factors of emergency management. Finally, five critical factors are figured out, and the efficiency of emergency management could be enhanced by optimizing these five factors. In addition, a comparative analysis is also conducted to validate the advantages of the proposed method.","685":"The growing number of radio communication devices and limited spectrum resources are drivers for the development of new techniques of dynamic spectrum access and spectrum sharing. In order to make use of the spectrum opportunistically, the concept of cognitive radio was proposed, where intelligent decisions on transmission opportunities are based on spectrum sensing. In this paper, two Machine Learning (ML) algorithms, namely k-Nearest Neighbours and Random Forest, have been proposed to increase spectrum sensing performance. These algorithms have been applied to Energy Detection (ED) and Energy Vector-based data (EV) to detect the presence of a Fourth Generation (4G) Long-Term Evolution (LTE) signal for the purpose of utilizing the available resource blocks by a 5G new radio system. The algorithms capitalize on time, frequency and spatial dependencies in daily communication traffic. Research results show that the ML methods used can significantly improve the spectrum sensing performance if the input training data set is carefully chosen. The input data sets with ED decisions and energy values have been examined, and advantages and disadvantages of their real-life application have been analyzed.","686":"To date, the application of semantic network methodologies to study cognitive processes in psychological phenomena has been limited in scope. One barrier to broader application is the lack of resources for researchers unfamiliar with the approach. Another barrier, for both the unfamiliar and knowledgeable researcher, is the tedious and laborious preprocessing of semantic data. In this article, we aim to minimize these barriers by offering a comprehensive semantic network analysis pipeline (preprocessing, estimating, and analyzing networks), and an associated R tutorial that uses a suite of R packages to accommodate this pipeline. Two of these packages, SemNetDictionaries and SemNetCleaner, promote an efficient, reproducible, and transparent approach to preprocessing verbal fluency data. The third package, SemNeT, provides methods and measures for analyzing and statistically comparing semantic networks via a point-and-click graphical user interface. Using real-world data, we present a startto-finish pipeline from raw data to semantic network analysis results. This article aims to provide resources for researchers, both the unfamiliar and knowledgeable, that reduce some of the barriers for conducting semantic network analysis.","687":"Algorithms for approximate Bayesian inference, such as those based on sampling (i.e., Monte Carlo methods), provide a natural source of models of how people may deal with uncertainty with limited cognitive resources. Here, we consider the idea that individual differences in working memory capacity (WMC) may be usefully modeled in terms of the number of samples, or \"particles,\" available to perform inference. To test this idea, we focus on two recent experiments that report positive associations between WMC and two distinct aspects of categorization performance: the ability to learn novel categories, and the ability to switch between different categorization strategies (\"knowledge restructuring\"). In favor of the idea of modeling WMC as a number of particles, we show that a single model can reproduce both experimental results by varying the number of particles-increasing the number of particles leads to both faster category learning and improved strategy-switching. Furthermore, when we fit the model to individual participants, we found a positive association between WMC and best-fit number of particles for strategy switching. However, no association between WMC and best-fit number of particles was found for category learning. These results are discussed in the context of the general challenge of disentangling the contributions of different potential sources of behavioral variability.","688":"Mental illness is a global health problem, but access to mental healthcare resources remain poor worldwide. Online peer-to-peer support platforms attempt to alleviate this fundamental gap by enabling those who struggle with mental illness to provide and receive social support from their peers. However, successful social support requires users to engage with each other and failures may have serious consequences for users in need. Our understanding of engagement patterns on mental health platforms is limited but critical to inform the role, limitations, and design of these platforms. Here, we present a large-scale analysis of engagement patterns of 35 million posts on two popular online mental health platforms, TalkLife and Reddit. Leveraging communication models in human-computer interaction and communication theory, we operationalize a set of four engagement indicators based on attention and interaction. We then propose a generative model to jointly model these indicators of engagement, the output of which is synthesized into a novel set of eleven distinct, interpretable patterns. We demonstrate that this framework of engagement patterns enables informative evaluations and analysis of online support platforms. Specifically, we find that mutual back-and-forth interactions are associated with significantly higher user retention rates on TalkLife. Such back-and-forth interactions, in turn, are associated with early response times and the sentiment of posts.","689":"E-learning is the most promising venture in the entire world During the COVID-19 lockdown, e-learning issuccessfully providing potential information to the students and researchers In developing nations like India, with limited resources, e-learning tools and platforms provide a chance to make education available to middle and low income households This paper gives insights about three different online services, namely Google Classroom, Zoom, and Microsoft Teams being used by three different educational institutions We aim to analyze the efficiency and acceptability of e-learning tools among Indian students during the COVID-19 lockdown The paper also aims to evaluate the impact of e-learning on the environment and public health during COVID-19 lockdown It is found that e-learning has potential to reduce carbon emissions, which has beneficial impact on the environment However, the mental health is impacted as e-learning may lead to self-isolation and reduction in academic achievements that may lead to anxiety and mental depression Due to usage of electronic devices for learning, the eyes and neck muscles may be put in strain, having deleterious effects on physical health \u00a9 2018 Tsinghua University Press","690":"Mobile social networks (MSNs) provide real-time information services to individuals in social communities through mobile devices. However, due to their high openness and autonomy, MSNs have been suffering from rampant rumors, fraudulent activities, and other types of misuses. To mitigate such threats, it is urgent to control the spread of fraud information. The research challenge is: how to design control strategies to efficiently utilize limited resources and meanwhile minimize individuals\u2019 losses caused by fraud information? To this end, we model the fraud information control issue as an optimal control problem, in which the control resources consumption for implementing control strategies and the losses of individuals are jointly taken as a constraint called total cost, and the minimum total cost becomes the objective function. Based on the optimal control theory, we devise the optimal dynamic allocation of control strategies. Besides, a dynamics model for fraud information diffusion is established by considering the uncertain mental state of individuals, we investigate the trend of fraud information diffusion and the stability of the dynamics model. Our simulation study shows that the proposed optimal control strategies can effectively inhibit the diffusion of fraud information while incurring the smallest total cost. Compared with other control strategies, the control effect of the proposed optimal control strategies is about 10% higher.","691":null,"692":"In a situation where life becomes more stressful and challenging, people feel compelled to be more concerned about their mental situation. Different emotional statuses are external reactions to different mental states. Therefore, researchers always identify people\u2019s mental situation by monitoring their real-time emotions. At the same time, due to the availability of built-in sensors in a smartphone, applications that can identify real-time emotions of mobile users are constantly emerging. However, compared to most emotion recognition algorithms, computing resources and battery life in mobile phones are always limited. This makes accuracy and latency of these applications are unsatisfactory. In this paper, we propose a micro-service platform for mobile emotion recognition application developers (MSPMERAD) which can supply high performance. First, a classifier fusion emotion recognition algorithm is proposed by using a dynamic adaptive fusion strategy. Second, this new algorithm is encapsulated into a micro-service. With other affiliated micro-services such as data uploading, preprocessing, etc., developers can ignore the implementation of the emotion recognition algorithm and just focus on how to collect sensor data and interact with users. The accuracy and latency of one application based on the MSPMERAD are compared with another application that is implemented using a locale emotion recognition algorithm. Experiments based on the daily behavior data of 50 student volunteers show that the application based on our platform has higher recognition accuracy with a more reasonable time.","693":"Developing a clinical practice guideline (CPG) is expensive and time-consuming and therefore often unrealistic in settings with limited funding or resources. Although CPGs form the cornerstone of providing synthesised, systematic, evidence-based guidance to patients, healthcare practitioners and managers, there is no added benefit in developing new CPGs when there are accessible, good-quality, up-to-date CPGs available that can be adapted to fit local needs. Different approaches to CPG development have been proposed, including adopting, adapting or contextualising existing high-quality CPGs to make recommendations relevant to local contexts. These approaches are attractive where technical and financial resources are limited and high-quality guidance already exists. However, few examples exist to showcase such alternative approaches to CPG development. The South African Guidelines Excellence project held a workshop in 2017 to provide an opportunity for dialogue regarding different approaches to guideline development with key examples and case studies from the South African setting. Four CPGs represented the topics: mental health, health promotion, chronic musculoskeletal pain and prehospital emergency care. Each CPG used a different approach, however, using transparent, reportable methods. They included advisory groups with representation from content experts, CPG users and methodologists. They assessed CPGs and systematic reviews for adopting or adapting. Each team considered local context issues through qualitative research or stakeholder engagement. Lessons learnt include that South Africa needs fit-for-purpose guidelines and that existing appropriate, high-quality guidelines must be taken into account. Approaches for adapting guidelines are not clear globally and there are lessons to be learnt from existing descriptions of approaches from South Africa.","694":"Strategies to mitigate the spread of COVID-19, namely quarantine and social distancing protocols, have exposed a troubling paradox: mandated isolation meant to preserve well-being has inadvertently contributed to its decline. Prolonged isolation has been associated with widespread loneliness and diminished mental health, with effects compounded by limited face-to-face access to clinical and social support systems. While remote communication technologies (e.g., video chat) can connect individuals with healthcare providers and social networks, remote technologies might have limited effectiveness in clinical and social contexts. In this review, we articulate the promise of Virtual Reality as a conduit to clinical resources and social connection. Furthermore, we outline various social and economic factors limiting the virtual reality industry\u2019s ability to maximize its potential to address mental health issues brought upon by the pandemic. These barriers are delineated across five dimensions: sociocultural, content, affordability, supply chain, and equitable design. After examining potential short- and long-term solutions to these hurdles, we outline potential avenues for applied and theoretical research seeking to validate these solutions. Through this evaluation we seek to (a) emphasize virtual reality\u2019s capacity to improve mental health by connecting communities to clinical and social support systems, (b) identify socioeconomic barriers preventing users from accessing these systems through virtual reality, and (c) discuss solutions that ensure these systems can be equitably accessed via changes to existing and future virtual reality infrastructures.","695":null,"696":"We study the problem of few-sample fine-tuning of BERT contextual representations, and identify three sub-optimal choices in current, broadly adopted practices. First, we observe that the omission of the gradient bias correction in the BERTAdam optimizer results in fine-tuning instability. We also find that parts of the BERT network provide a detrimental starting point for fine-tuning, and simply re-initializing these layers speeds up learning and improves performance. Finally, we study the effect of training time, and observe that commonly used recipes often do not allocate sufficient time for training. In light of these findings, we re-visit recently proposed methods to improve few-sample fine-tuning with BERT and re-evaluate their effectiveness. Generally, we observe a decrease in their relative impact when modifying the fine-tuning process based on our findings.","697":"Abstract Respondent attrition is a common problem in national longitudinal panel surveys. To make full use of the data, weights are provided to account for attrition. Weight adjustments are based on sampling design information and data from the base year; information from subsequent waves is typically not utilized. Alternative methods to address bias from nonresponse are full information maximum likelihood (FIML) or multiple imputation (MI). The effects on bias of growth parameter estimates from using these methods are compared via a simulation study. The results indicate that caution needs to be taken when utilizing panel weights when there is missing data, and to consider methods like FIML and MI, which are not as susceptible to the omission of important auxiliary variables.","698":"Although fixed-effects models for panel data are now widely recognized as powerful tools for longitudinal data analysis, the limitations of these models are not well known. We provide a critical discussion of 12 limitations, including a culture of omission, low statistical power, limited external validity, restricted time periods, measurement error, time invariance, undefined variables, unobserved heterogeneity, erroneous causal inferences, imprecise interpretations of coefficients, imprudent comparisons with cross-sectional models, and questionable contributions vis-\u00e0-vis previous work. Instead of discouraging the use of fixed-effects models, we encourage more critical applications of this rigorous and promising methodology. The most important deficiencies\u2014Type II errors, biased coefficients and imprecise standard errors, misleading p values, misguided causal claims, and various theoretical concerns\u2014should be weighed against the likely presence of unobserved heterogeneity in other regression models. Ultimately, we must do a better job of communicating the pitfalls of fixed-effects models to our colleagues and students.","699":"Approaches for dealing with item omission include incorrect scoring, ignoring missing values, and approaches for nonignorable missing values and have only been evaluated for certain forms of nonignorability. In this paper we investigate the performance of these approaches for various conditions of nonignorability, that is, when the missing response depends on i) the item response, ii) a latent missing propensity, or iii) both. No approach results in unbiased parameter estimates of the Rasch model under all missing data mechanisms. Incorrect scoring only results in unbiased estimates under very specific data constellations of missing mechanisms i) and iii). The approach for nonignorable missing values only results in unbiased estimates under condition ii). Ignoring results in slightly more biased estimates than the approach for nonignorable missing values, while the latter also indicates the presence of nonignorablity under all simulated conditions. We illustrate the results in an empirical example on PISA data.","700":"Over the last decades, climate change has triggered an increase in the frequency of spruce bark beetle (Ips typographus L.) in Central Europe. More than 50% of forests in the Czech Republic are seriously threatened by this pest, leading to high ecological and economic losses. The exponential increase of bark beetle infestation hinders the implementation of costly field campaigns to prevent and mitigate its effects. Remote sensing may help to overcome such limitations as it provides frequent and spatially continuous data on vegetation condition. Using Sentinel-2 images as main input, two models have been developed to test the ability of this data source to map bark beetle damage and severity. All models were based on a change detection approach, and required the generation of previous forest mask and dominant species maps. The first damage mapping model was developed for 2019 and 2020, and it was based on bi-temporal regressions in spruce areas to estimate forest vitality and bark beetle damage. A second model was developed for 2020 considering all forest area, but excluding clear-cuts and completely dead areas, in order to map only changes in stands dominated by alive trees. The three products were validated with in situ data. All the maps showed high accuracies (acc > 0.80). Accuracy was higher than 0.95 and F1-score was higher than 0.88 for areas with high severity, with omission errors under 0.09 in all cases. This confirmed the ability of all the models to detect bark beetle attack at the last phases. Areas with no damage or low severity showed more complex results. The no damage category yielded greater commission errors and relative bias (CEs = 0.30\u20130.42, relB = 0.42\u20130.51). The similar results obtained for 2020 leaving out clear-cuts and dead trees proved that the proposed methods could be used to help forest managers fight bark beetle pests. These biotic damage products based on Sentinel-2 can be set up for any location to derive regular forest vitality maps and inform of early damage.","701":null,"702":"Text based games are simulations in which an agent interacts with the world purely through natural language. They typically consist of a number of puzzles interspersed with interactions with common everyday objects and locations. Deep reinforcement learning agents can learn to solve these puzzles. However, the everyday interactions with the environment, while trivial for human players, present as additional puzzles to agents. We explore two techniques for incorporating commonsense knowledge into agents. Inferring possibly hidden aspects of the world state with either a commonsense inference model COMET, or a language model BERT. Biasing an agents exploration according to common patterns recognized by a language model. We test our technique in the 9to05 game, which is an extreme version of a text based game that requires numerous interactions with common, everyday objects in common, everyday scenarios. We conclude that agents that augment their beliefs about the world state with commonsense inferences are more robust to observational errors and omissions of common elements from text descriptions.","703":"ABSTRACT Risk methods are powerful and versatile, but they have limitations and subtle traps. The paper explores the nature of risk. There are three main difficulties. First, there is a problem with quality and completeness of information. Lack of precise information means that likelihood and consequences have to be estimated, so the information is vulnerable to biases: some are explored. Secondly, there is a serious problem of completeness in risk models, where omissions can lead to serious consequences. Unexpected events, sometimes called \u2018black swans\u2019, abound. Thirdly, the conjunction of very small probabilities and major consequences can lead to unreliable and dubious results. Applications areas considered are structural engineering, project management and risk management generally. There are situations where a resilience approach is preferable to risk.","704":"We applied a supervised individual-tree segmentation algorithm to ultra-high-density drone lidar in a temperate mountain forest in the southern Czech Republic. We compared the number of trees correctly segmented, stem diameter at breast height (DBH), and tree height from drone-lidar segmentations to field-inventory measurements and segmentations from terrestrial laser scanning (TLS) data acquired within two days of the drone-lidar acquisition. Our analysis detected 51% of the stems >15 cm DBH, and 87% of stems >50 cm DBH. Errors of omission were much more common for smaller trees than for larger ones, and were caused by removal of points prior to segmentation using a low-intensity and morphological filter. Analysis of segmented trees indicates a strong linear relationship between DBH from drone-lidar segmentations and TLS data. The slope of this relationship is 0.93, the intercept is 4.28 cm, and the r2 is 0.98. However, drone lidar and TLS segmentations overestimated DBH for the smallest trees and underestimated DBH for the largest trees in comparison to field data. We evaluate the impact of random error in point locations and variation in footprint size, and demonstrate that random error in point locations is likely to cause an overestimation bias for small-DBH trees. A Random Forest classifier correctly identified broadleaf and needleleaf trees using stem and crown geometric properties with overall accuracy of 85.9%. We used these classifications and DBH estimates from drone-lidar segmentations to apply allometric scaling equations to segmented individual trees. The stand-level aboveground biomass (AGB) estimate using these data is 76% of the value obtained using a traditional field inventory. We demonstrate that 71% of the omitted AGB is due to segmentation errors of omission, and the remaining 29% is due to DBH estimation errors. Our analysis indicates that high-density measurements from low-altitude drone flight can produce DBH estimates for individual trees that are comparable to TLS. These data can be collected rapidly throughout areas large enough to produce landscape-scale estimates. With additional refinement, these estimates could augment or replace manual field inventories, and could support the calibration and validation of current and forthcoming space missions.","705":"In two studies, we investigated the relation between information structure and argument omission in German child language in order to quantify to what extent the subject\u2013object hypothesis (i.e., subjects are omitted more often than objects) is influenced by discourse pragmatics. Twenty four children took part in an elicited production study in which they produced transitive subject\u2013verb\u2013object and object\u2013verb\u2013subject sentences. Both constructions are instances of a topic-comment information structure. The results showed that 3;6 year-old children omitted subjects and objects alike when the arguments assumed topics status and were placed in utterance-initial position. In a second study, we then assessed whether a model of language learning implemented with a recency bias (resulting in learning from the end of utterances) would produce similar omission rates of initial arguments. The model was found to be sensitive to the frequency with which both word orders occurred in the input: initial objects were omitted more often than initial subjects, the pattern found in German caregiver speech. The results suggest that argument omission is heavily influenced by information structure and that a subject\u2013object asymmetry per se does not exist.","706":"We characterize optimal oversight of algorithms in a world where an agent designs a complex prediction function but a principal is limited in the amount of information she can learn about the prediction function. We show that limiting agents to prediction functions that are simple enough to be fully transparent is inefficient as long as the bias induced by misalignment between principal\u2019s and agent\u2019s preferences is small relative to the uncertainty about the true state of the world. Algorithmic audits can improve welfare, but the gains depend on the design of the audit tools. Tools that focus on minimizing overall information loss, the focus of many post-hoc explainer tools, will generally be inefficient since they focus on explaining the average behavior of the prediction function rather than sources of mis-prediction, which matter for welfare-relevant outcomes. Targeted tools that focus on the source of incentive misalignment, e.g., excess false positives or racial disparities, can provide first-best solutions. We provide empirical support for our theoretical findings using an application in consumer lending. We thank Mario Curiki and Ruying Gao for outstanding research assistance. We thank Susan Athey, Simon Freyaldenhoven, Talia Gillis, Danielle Li, Amit Seru, Ken Singleton, PR Stark, Chenzi Xu, the FinRegLab team and seminar and conference participants at Stanford University, the NBER Summer Institute, Stanford SITE, the New Perspectives on Consumer Behavior in Credit and Payments Markets Conference, and the OCC for helpful discussions and comments. We thank the Stanford Institute for HumanCentered Artificial Intelligence (HAI) and Amazon Web Services for generous support. Any errors or omissions are the responsibility of the authors.","707":"We investigate the discounting mismatch in actor-critic algorithm implementations from a representation learning perspective. Theoretically, actor-critic algorithms usually have discounting for both actor and critic, i.e., there is a $\\gamma^t$ term in the actor update for the transition observed at time $t$ in a trajectory and the critic is a discounted value function. Practitioners, however, usually ignore the discounting ($\\gamma^t$) for the actor while using a discounted critic. We investigate this mismatch in two scenarios. In the first scenario, we consider optimizing an undiscounted objective $(\\gamma = 1)$ where $\\gamma^t$ disappears naturally $(1^t = 1)$. We then propose to interpret the discounting in critic in terms of a bias-variance-representation trade-off and provide supporting empirical results. In the second scenario, we consider optimizing a discounted objective ($\\gamma < 1$) and propose to interpret the omission of the discounting in the actor update from an auxiliary task perspective and provide supporting empirical results.","708":"Multiple imputation by chained equations (MICE) is the most common method for imputing missing data. In the MICE algorithm, imputation can be performed using a variety of parametric and nonparametric methods. The default setting in the implementation of MICE is for imputation models to include variables as linear terms only with no interactions, but omission of interaction terms may lead to biased results. It is investigated, using simulated and real datasets, whether recursive partitioning creates appropriate variability between imputations and unbiased parameter estimates with appropriate confidence intervals. We compared four multiple imputation (MI) methods on a real and a simulated dataset. MI methods included using predictive mean matching with an interaction term in the imputation model in MICE (MICE-interaction), classification and regression tree (CART) for specifying the imputation model in MICE (MICE-CART), the implementation of random forest (RF) in MICE (MICE-RF), and MICE-Stratified method. We first selected secondary data and devised an experimental design that consisted of 40 scenarios (2\u2009\u00d7\u20095\u2009\u00d7\u20094), which differed by the rate of simulated missing data (10%, 20%, 30%, 40%, and 50%), the missing mechanism (MAR and MCAR), and imputation method (MICE-Interaction, MICE-CART, MICE-RF, and MICE-Stratified). First, we randomly drew 700 observations with replacement 300 times, and then the missing data were created. The evaluation was based on raw bias (RB) as well as five other measurements that were averaged over the repetitions. Next, in a simulation study, we generated data 1000 times with a sample size of 700. Then, we created missing data for each dataset once. For all scenarios, the same criteria were used as for real data to evaluate the performance of methods in the simulation study. It is concluded that, when there is an interaction effect between a dummy and a continuous predictor, substantial gains are possible by using recursive partitioning for imputation compared to parametric methods, and also, the MICE-Interaction method is always more efficient and convenient to preserve interaction effects than the other methods.","709":"In this comparative study, a jury instruction scenario was used to test the translating capabilities of multiple machine translation tools and a human translator with extensive court experience. Three certified translators\/interpreters subjectively evaluated the target texts generated using adequacy and fluency as the evaluation metrics. This subjective evaluation found that the machine generated results had much poorer adequacy and fluency compared with results produced by their human counterpart. Human translators can use strategic omission and explicitation strategies such as addition, paraphrasing, substitution, and repetition to remove ambiguity, and achieve a natural flow in the target language. We also investigate instances where human evaluators have major disagreements and found that human experts could have very biased views. On the other hand, a word2vec based algorithm, if given a good reference translation, can serve as a robust and reliable similarity reference to quantify human evalutors\u2019 biases beacuse it was trained on a large corpus using neural network models. Even though the machine generated versions had better fluency performance compared to their adequacy \u00a9 2019 The authors. This article is licensed under a Creative Commons 4.0 license, no derivative works, attribution, CCBY-ND. performance, the human translator\u2019s fluency performance was still far superior. The lack of understanding by machine translators led to inaccurate and improper word\/phrase selections, which led to bad fluency.","710":"Transportation analysts are inundated with requests to apply popular machine learning modeling techniques to datasets to uncover never-before-seen relationships that could potentially revolutionize safety, congestion, and mobility. However, the results from such models can be influenced not just by biases in underlying data, but also through practitioner-induced biases. To demonstrate the significant number of subjective judgments made in the development and interpretation of machine learning models, we developed Logistic Regression and Neural Network models for transportation-focused datasets including those looking at driving injury\/fatalities and pedestrian fatalities. We then developed five different representations of feature importance for each dataset, including different feature interpretations commonly used in the machine learning community. Twelve distinct judgments were highlighted in the development and interpretation of these models, which produced inconsistent results. Such inconsistencies can lead to very different interpretations of the results, which can lead to errors of commission and omission, with significant cost and safety implications if policies are erroneously adapted from such outcomes.","711":"Unification of the global vertical datum has been a key problem to be solved for geodesy over a long period, and the main challenge for a unified vertical datum system is to determine the vertical offset between the local vertical datum and the global vertical datum. For this purpose, the geodetic boundary value problem (GBVP) approach based on the remove-compute-restore (RCR) technique is used to determine the vertical datum parameters in this paper. In the RCR technique, a global geopotential model (GGM) is required to remove and restore the long wavelengths of the gravity field. The satellite missions of the GRACE (Gravity Recovery and Climate Experiment) and GOCE (Gravity field and steady-state Ocean Circulation Exploration) offer high accuracy medium\u2013long gravity filed information, but GRACE\/GOCE-based GGMs are restricted to medium\u2013long wavelengths because the maximum degree of their spherical harmonic representation is limited, which is known as an omission error. To compensate for the omission error of GRACE\/GOCE-based GGM, a weighting method is used to determine the combined GGM by combining the high-resolution EGM2008 model (Earth Gravitational Model 2008) and GRACE\/GOCE-based GGM to effectively bridge the spectral gap between satellite and terrestrial data. An additional consideration for the high-frequency gravity signals is induced by the topography, and the residual terrain model (RTM) is used to recover the omission errors effect of the combined GGM. In addition, to facilitate practical implementation of the GBVP approach, the effects of the indirect bias term, the spectral accuracy of the GGM, and the systematic levelling errors and distortions in estimations of the vertical datum parameters are investigated in this study. Finally, as a result of the GBVP solution based on the combined DIR_R6\/EGM2008 model, RTM, and residual gravity, the geopotential values of the North American Vertical Datum of 1988 (NAVD88), the Australian Height Datum (AHD), and the Hong Kong Principal Datum (HKPD) are estimated to be equal to 62636861.31 \u00b1 0.96, 62653852.60 \u00b1 0.95 and 62636860.55 \u00b1 0.29 m2s\u22122, respectively. The vertical offsets of NAVD88, AHD, and HKPD with respect to the global geoid are estimated as \u22120.809 \u00b1 0.090, 0.082 \u00b1 0.093, and \u22120.731 \u00b1 0.030 m, respectively.","712":"Functional connectivity (FC) maps from brain fMRI data can be derived with dual regression, a proposed alternative to traditional seed\u2010based FC (SFC) methods that detect temporal correlation between a predefined region (seed) and other regions in the brain. As with SFC, incorporating nuisance regressors (NR) into the dual regression must be done carefully, to prevent potential bias and insensitivity of FC estimates. Here, we explore the potentially untoward effects on dual regression that may occur when NR correlate highly with the signal of interest, using both synthetic and real fMRI data to elucidate mechanisms responsible for loss of accuracy in FC maps. Our tests suggest significantly improved accuracy in FC maps derived with dual regression when highly correlated temporal NR were omitted. Single\u2010map dual regression, a simplified form of dual regression that uses neither spatial nor temporal NR, offers a viable alternative whose FC maps may be more easily interpreted, and in some cases be more accurate than those derived with standard dual regression.","713":"The problem of inferring unrealistically high prices from choice-based conjoint optimization exercises is widely known among market research practitioners and applied marketing researchers. The literature suggests two approaches to alleviate this problem. One focuses on making the hypothetical choice situation more realistic ('incentive-aligned conjoint analysis'). The other approach seeks to discard respondents from the sample that appear not to provide usable information, or simply answer randomly ('data cleaning'). This paper highlights a different reason for inferring abnormally high prices - the omission of budget constraints in the standard single-unit demand discrete-choice framework - and proposes a methodology to estimate heterogeneous budget constraints to correct for the bias. We review the theory of utility separation that motivates category specific budgets, discuss identification, and show how to derive equilibrium prices when category budgets matter. The proposed methodology substantially increases the face validity of implied competitive prices in an industry-grade discrete-choice experiment and improves targeting decisions by disentangling price-sensitivity within a budget from the budget constraint itself. Finally, we illustrate how inferred category budgets relate to a rich set of observed consumer characteristics and that ignoring budgets may obfuscate systematic relations between consumer characteristics and choice behavior.","714":"Rapid generation of synthetic aperture radar (SAR) based flood extent and flood depth maps provide valuable data in disaster response efforts. We present a simple but powerful method using dual-polarimetric SAR imagery. A RGB false-color map is generated using pre- and post-flooding imagery, allowing operators to distinguish between existing standing water in pre-flooding data and recently flooded areas. This method works very well in areas of standing water, while large omission errors can be seen in urban areas due to the double-bounce effect. A flood depth map is also estimated by using an external DEM. Compared with FEMA flood product, flood water depth from the proposed method showed low bias with small dispersion. This automatic flood mapping system will contribute to the rapid assessment for disaster relief efforts.","715":"This paper reports on efforts to design a social matching system that instigates collaborative research across multiple fields of practice, in this instance: researchers from academia and organizations in their local geographic community. A qualitative study is presented about university researchers and the design of their profile pages for the system. Findings show that university researchers prefer profile page designs that enable them to demonstrate a willingness to adapt to non-academic partners, such as by de-emphasizing esoteric markers of expertise like scholarly publications and clarifying their resources and goals. Some also wish to circumvent potential bias by omitting information about their name, physical appearance, and academic department. However, these desired omissions raise questions about how to design for sufficient distinction between profile pages and the presentation of a unique professional identity. Implications are discussed for the design of social marching systems for collaboration.","716":"Approaches for dealing with item omission include incorrect scoring, ignoring missing values, and approaches for nonignorable missing values and have only been evaluated for certain forms of nonignorability. In this paper we investigate the performance of these approaches for various conditions of nonignorability, that is, when the missing response depends on i) the item response, ii) a latent missing propensity, or iii) both. No approach results in unbiased parameter estimates of the Rasch model under all missing data mechanisms. Incorrect scoring only results in unbiased estimates under very specific data constellations of missing mechanisms i) and iii). The approach for nonignorable missing values only results in unbiased estimates under condition ii). Ignoring results in slightly more biased estimates than the approach for nonignorable missing values, while the latter also indicates the presence of nonignorablity under all simulated conditions. We illustrate the results in an empirical example on PISA data.","717":"Informational bias is bias conveyed through sentences or clauses that provide tangential, speculative or background information that can sway readers\u2019 opinions towards entities. By nature, informational bias is context-dependent, but previous work on informational bias detection has not explored the role of context beyond the sentence. In this paper, we explore four kinds of context for informational bias in English news articles: neighboring sentences, the full article, articles on the same event from other news publishers, and articles from the same domain (but potentially different events). We find that integrating event context improves classification performance over a very strong baseline. In addition, we perform the first error analysis of models on this task. We find that the best-performing context-inclusive model outperforms the baseline on longer sentences, and sentences from politically centrist articles.","718":"In this paper, we quantify, analyze and mitigate gender bias exhibited in ELMo\u2019s contextualized word vectors. First, we conduct several intrinsic analyses and find that (1) training data for ELMo contains significantly more male than female entities, (2) the trained ELMo embeddings systematically encode gender information and (3) ELMo unequally encodes gender information about male and female entities. Then, we show that a state-of-the-art coreference system that depends on ELMo inherits its bias and demonstrates significant bias on the WinoBias probing corpus. Finally, we explore two methods to mitigate such gender bias and show that the bias demonstrated on WinoBias can be eliminated.","719":"Many recent methods for unsupervised or self-supervised representation learning train feature extractors by maximizing an estimate of the mutual information (MI) between different views of the data. This comes with several immediate problems: For example, MI is notoriously hard to estimate, and using it as an objective for representation learning may lead to highly entangled representations due to its invariance under arbitrary invertible transformations. Nevertheless, these methods have been repeatedly shown to excel in practice. In this paper we argue, and provide empirical evidence, that the success of these methods cannot be attributed to the properties of MI alone, and that they strongly depend on the inductive bias in both the choice of feature extractor architectures and the parametrization of the employed MI estimators. Finally, we establish a connection to deep metric learning and argue that this interpretation may be a plausible explanation for the success of the recently introduced methods.","720":"Variational approaches based on neural networks are showing promise for estimating mutual information (MI) between high dimensional variables. However, they can be difficult to use in practice due to poorly understood bias\/variance tradeoffs. We theoretically show that, under some conditions, estimators such as MINE exhibit variance that could grow exponentially with the true amount of underlying MI. We also empirically demonstrate that existing estimators fail to satisfy basic self-consistency properties of MI, such as data processing and additivity under independence. Based on a unified perspective of variational approaches, we develop a new estimator that focuses on variance reduction. Empirical results on standard benchmark tasks demonstrate that our proposed estimator exhibits improved bias-variance trade-offs on standard benchmark tasks.","721":"Estimating and optimizing Mutual Information (MI) is core to many problems in machine learning; however, bounding MI in high dimensions is challenging. To establish tractable and scalable objectives, recent work has turned to variational bounds parameterized by neural networks, but the relationships and tradeoffs between these bounds remains unclear. In this work, we unify these recent developments in a single framework. We find that the existing variational lower bounds degrade when the MI is large, exhibiting either high bias or high variance. To address this problem, we introduce a continuum of lower bounds that encompasses previous bounds and flexibly trades off bias and variance. On high-dimensional, controlled problems, we empirically characterize the bias and variance of the bounds and their gradients and demonstrate the effectiveness of our new bounds for estimation and representation learning.","722":"Word embeddings are widely used in NLP for a vast range of tasks. It was shown that word embeddings derived from text corpora reflect gender biases in society, causing serious concern. Several recent works tackle this problem, and propose methods for significantly reducing this gender bias in word embeddings, demonstrating convincing results. However, we argue that this removal is superficial. While the bias is indeed substantially reduced according to the provided bias definition, the actual effect is mostly hiding the bias, not removing it. The gender bias information is still reflected in the distances between \u201cgender-neutralized\u201d words in the debiased embeddings, and can be recovered from them. We present a series of experiments to support this claim, for two debiasing methods. We conclude that existing bias removal techniques are insufficient, and should not be trusted for providing gender-neutral modeling.","723":"Abstract Background Missing data are unavoidable in epidemiological research, potentially leading to bias and loss of precision. Multiple imputation (MI) is widely advocated as an improvement over complete case analysis (CCA). However, contrary to widespread belief, CCA is preferable to MI in some situations. Methods We provide guidance on choice of analysis when data are incomplete. Using causal diagrams to depict missingness mechanisms, we describe when CCA will not be biased by missing data and compare MI and CCA, with respect to bias and efficiency, in a range of missing data situations. We illustrate selection of an appropriate method in practice. Results For most regression models, CCA gives unbiased results when the chance of being a complete case does not depend on the outcome after taking the covariates into consideration, which includes situations where data are missing not at random. Consequently, there are situations in which CCA analyses are unbiased while MI analyses, assuming missing at random (MAR), are biased. By contrast MI, unlike CCA, is valid for all MAR situations and has the potential to use information contained in the incomplete cases and auxiliary variables to reduce bias and\/or improve precision. For this reason, MI was preferred over CCA in our real data example. Conclusions Choice of method for dealing with missing data is crucial for validity of conclusions, and should be based on careful consideration of the reasons for the missing data, missing data patterns and the availability of auxiliary information.","724":"Visual Question Answering (VQA) is the task of answering questions about an image. Some VQA models often exploit unimodal biases to provide the correct answer without using the image information. As a result, they suffer from a huge drop in performance when evaluated on data outside their training set distribution. This critical issue makes them unsuitable for real-world settings. \nWe propose RUBi, a new learning strategy to reduce biases in any VQA model. It reduces the importance of the most biased examples, i.e. examples that can be correctly classified without looking at the image. It implicitly forces the VQA model to use the two input modalities instead of relying on statistical regularities between the question and the answer. We leverage a question-only model that captures the language biases by identifying when these unwanted regularities are used. It prevents the base VQA model from learning them by influencing its predictions. This leads to dynamically adjusting the loss in order to compensate for biases. We validate our contributions by surpassing the current state-of-the-art results on VQA-CP v2. This dataset is specifically designed to assess the robustness of VQA models when exposed to different question biases at test time than what was seen during training. \nOur code is available: this http URL","725":"Many interpretation methods for neural models in natural language processing investigate how information is encoded inside hidden representations. However, these methods can only measure whether the information exists, not whether it is actually used by the model. We propose a methodology grounded in the theory of causal mediation analysis for interpreting which parts of a model are causally implicated in its behavior. The approach enables us to analyze the mechanisms that facilitate the flow of information from input to output through various model components, known as mediators. As a case study, we apply this methodology to analyzing gender bias in pre-trained Transformer language models. We study the role of individual neurons and attention heads in mediating gender bias across three datasets designed to gauge a model\u2019s sensitivity to gender bias. Our mediation analysis reveals that gender bias effects are concentrated in specific components of the model that may exhibit highly specialized behavior.","726":"Supplemental digital content is available in the text. Summary Statement As virtual simulation is burgeoning, faculty and administrators are asking for evidence of its effectiveness. The objective of this systematic review was to identify how virtual simulation impacts nursing student learning outcomes. Applying the Preferred Reporting Items for Systematic Reviews and Meta-analyses guidelines, 80 studies were reviewed. Results indicate that most research (n = 69, 86%) supported virtual simulation as an effective pedagogy to support learning outcomes while highlighting gaps and areas of bias. Adding search terms could have expanded the findings. The body of evidence supports virtual simulation as an effective pedagogy. Future studies should use more robust research designs, prioritize curricular integration of virtual simulation, and determine best practices in virtual simulation methodology.","727":"The computer science research community and the broader public have become increasingly aware of negative consequences of algorithmic systems. In response, the top-tier Neural Information Processing Systems (NeurIPS) conference for machine learning and artificial intelligence research required that authors include a statement of broader impact to reflect on potential positive and negative consequences of their work. We present the results of a qualitative thematic analysis of a sample of statements written for the 2020 conference. The themes we identify broadly fall into categories related to how consequences are expressed (e.g., valence, specificity, uncertainty), areas of impacts expressed (e.g., bias, the environment, labor, privacy), and researchers' recommendations for mitigating negative consequences in the future. In light of our results, we offer perspectives on how the broader impact statement can be implemented in future iterations to better align with potential goals.","728":"We survey 146 papers analyzing \u201cbias\u201d in NLP systems, finding that their motivations are often vague, inconsistent, and lacking in normative reasoning, despite the fact that analyzing \u201cbias\u201d is an inherently normative process. We further find that these papers\u2019 proposed quantitative techniques for measuring or mitigating \u201cbias\u201d are poorly matched to their motivations and do not engage with the relevant literature outside of NLP. Based on these findings, we describe the beginnings of a path forward by proposing three recommendations that should guide work analyzing \u201cbias\u201d in NLP systems. These recommendations rest on a greater recognition of the relationships between language and social hierarchies, encouraging researchers and practitioners to articulate their conceptualizations of \u201cbias\u201d---i.e., what kinds of system behaviors are harmful, in what ways, to whom, and why, as well as the normative reasoning underlying these statements\u2014and to center work around the lived experiences of members of communities affected by NLP systems, while interrogating and reimagining the power relations between technologists and such communities.","729":"Many people consider news articles to be a reliable source of information on current events. However, due to the range of factors influencing news agencies, such coverage may not always be impartial. Media bias, or slanted news coverage, can have a substantial impact on public perception of events, and, accordingly, can potentially alter the beliefs and views of the public. The main data gap in current research on media bias detection is a robust, representative, and diverse dataset containing annotations of biased words and sentences. In particular, existing datasets do not control for the individual background of annotators, which may affect their assessment and, thus, represents critical information for contextualizing their annotations. In this poster, we present a matrix-based methodology to crowdsource such data using a self-developed annotation platform. We also present MBIC (Media Bias Including Characteristics) the first sample of 1,700 statements representing various media bias instances. The statements were reviewed by ten annotators each and contain labels for media bias identification both on the word and sentence level. MBIC is the first available dataset about media bias reporting detailed information on annotator characteristics and their individual background. The current dataset already significantly extends existing data in this domain providing unique and more reliable insights into the perception of bias. In future, we will further extend it both with respect to the number of articles and annotators per article.","730":"Face recognition (FR) systems have a growing effect on critical decision-making processes. Recent works have shown that FR solutions show strong performance differences based on the user\u2019s demographics. However, to enable a trustworthy FR technology, it is essential to know the influence of an extended range of facial attributes on FR beyond demographics. Therefore, in this work, we analyze FR bias over a wide range of attributes. We investigate the influence of 47 attributes on the verification performance of two popular FR models. The experiments were performed on the publicly available MAAD-Face attribute database with over 120M high-quality attribute annotations. To prevent misleading statements about biased performances, we introduced control group-based validity values to decide if unbalanced test data causes the performance differences. The results demonstrate that also many nondemographic attributes strongly affect recognition performance, such as accessories, hairstyles and colors, face shapes, or facial anomalies. The observations of this work show the strong need for further advances in making the FR system more robust, explainable, and fair. Moreover, our findings might help to a better understanding of how FR networks work, enhance the robustness of these networks, and develop more generalized bias-mitigating FR solutions.","731":"The task of item recommendation requires ranking a large catalogue of items given a context. Item recommendation algorithms are evaluated using ranking metrics that depend on the positions of relevant items. To speed up the computation of metrics, recent work often uses sampled metrics where only a smaller set of random items and the relevant items are ranked. This paper investigates sampled metrics in more detail and shows that they are inconsistent with their exact version, in the sense that they do not persist relative statements, e.g., recommender A is better than B, not even in expectation. Moreover, the smaller the sampling size, the less difference there is between metrics, and for very small sampling size, all metrics collapse to the AUC metric. We show that it is possible to improve the quality of the sampled metrics by applying a correction, obtained by minimizing different criteria such as bias or mean squared error. We conclude with an empirical evaluation of the naive sampled metrics and their corrected variants. To summarize, our work suggests that sampling should be avoided for metric calculation, however if an experimental study needs to sample, the proposed corrections can improve the quality of the estimate.","732":"Recent work has shown that some common machine learning classifiers can be compiled into Boolean circuits that have the same input-output behavior. We present a theory for unveiling the reasons behind the decisions made by Boolean classifiers and study some of its theoretical and practical implications. We define notions such as sufficient, necessary and complete reasons behind decisions, in addition to classifier and decision bias. We show how these notions can be used to evaluate counterfactual statements such as \"a decision will stick even if ... because ... .\" We present efficient algorithms for computing these notions, which are based on new advances on tractable Boolean circuits, and illustrate them using a case study.","733":"Truthfulness judgments are a fundamental step in the process of fighting misinformation, as they are crucial to train and evaluate classifiers that automatically distinguish true and false statements. Usually such judgments are made by experts, like journalists for political statements or medical doctors for medical statements. In this paper, we follow a different approach and rely on (non-expert) crowd workers. This of course leads to the following research question: Can crowdsourcing be reliably used to assess the truthfulness of information and to create large-scale labeled collections for information credibility systems? To address this issue, we present the results of an extensive study based on crowdsourcing: we collect thousands of truthfulness assessments over two datasets, and we compare expert judgments with crowd judgments, expressed on scales with various granularity levels. We also measure the political bias and the cognitive background of the workers, and quantify their effect on the reliability of the data provided by the crowd.","734":"A central concern in Computational Social Sciences (CSS) is fairness: where the role of NLP is to scale up text analysis to large corpora, the quality of automatic analyses should be as independent as possible of textual properties. We analyze the performance of a state-of-the-art neural model on the task of political claims detection (i.e., the identification of forward-looking statements made by political actors) and identify a strong frequency bias: claims made by frequent actors are recognized better. We propose two simple debiasing methods which mask proper names and pronouns during training of the model, thus removing personal information bias. We find that (a) these methods significantly decrease frequency bias while keeping the overall performance stable; and (b) the resulting models improve when evaluated in an out-of-domain setting.","735":"As machine learning increasingly affects people and society, it is important that we strive for a comprehensive and unified understanding of potential sources of unwanted consequences. For instance, downstream harms to particular groups are often blamed on \"biased data,\" but this concept encompass too many issues to be useful in developing solutions. In this paper, we provide a framework that partitions sources of downstream harm in machine learning into six distinct categories spanning the data generation and machine learning pipeline. We describe how these issues arise, how they are relevant to particular applications, and how they motivate different solutions. In doing so, we aim to facilitate the development of solutions that stem from an understanding of application-specific populations and data generation processes, rather than relying on general statements about what may or may not be \"fair.\"","736":"We investigate gradient descent training of wide neural networks and the corresponding implicit bias in function space. Focusing on 1D regression, we show that the solution of training a width-$n$ shallow ReLU network is within $n^{- 1\/2}$ of the function which fits the training data and whose difference from initialization has smallest 2-norm of the second derivative weighted by $1\/\\zeta$. The curvature penalty function $1\/\\zeta$ is expressed in terms of the probability distribution that is utilized to initialize the network parameters, and we compute it explicitly for various common initialization procedures. For instance, asymmetric initialization with a uniform distribution yields a constant curvature penalty, and thence the solution function is the natural cubic spline interpolation of the training data. The statement generalizes to the training trajectories, which in turn are captured by trajectories of spatially adaptive smoothing splines with decreasing regularization strength.","737":"Temporal orienting improves sensory processing, akin to other top\u2013down biases. However, it is unknown whether these improvements reflect increased neural gain to any stimuli presented at expected time points, or specific tuning to task-relevant stimulus aspects. Furthermore, while other top\u2013down biases are selective, the extent of trade-offs across time is less well characterized. Temporal orienting improves sensory processing, akin to other top\u2013down biases. However, it is unknown whether these improvements reflect increased neural gain to any stimuli presented at expected time points, or specific tuning to task-relevant stimulus aspects. Furthermore, while other top\u2013down biases are selective, the extent of trade-offs across time is less well characterized. Here, we tested whether gain and\/or tuning of auditory frequency processing in humans is modulated by rhythmic temporal expectations, and whether these modulations are specific to time points relevant for task performance. Healthy participants (N = 23) of either sex performed an auditory discrimination task while their brain activity was measured using magnetoencephalography\/electroencephalography (M\/EEG). Acoustic stimulation consisted of sequences of brief distractors interspersed with targets, presented in a rhythmic or jittered way. Target rhythmicity not only improved behavioral discrimination accuracy and M\/EEG-based decoding of targets, but also of irrelevant distractors preceding these targets. To explain this finding in terms of increased sensitivity and\/or sharpened tuning to auditory frequency, we estimated tuning curves based on M\/EEG decoding results, with separate parameters describing gain and sharpness. The effect of rhythmic expectation on distractor decoding was linked to gain increase only, suggesting increased neural sensitivity to any stimuli presented at relevant time points. SIGNIFICANCE STATEMENT Being able to predict when an event may happen can improve perception and action related to this event, likely due to the alignment of neural activity to the temporal structure of stimulus streams. However, it is unclear whether rhythmic increases in neural sensitivity are specific to task-relevant targets, and whether they competitively impair stimulus processing at unexpected time points. By combining magnetoencephalography and encephalographic recordings, neural decoding of auditory stimulus features, and modeling, we found that rhythmic expectation improved neural decoding of both relevant targets and irrelevant distractors presented and expected time points, but did not competitively impair stimulus processing at unexpected time points. Using a quantitative model, these results were linked to nonspecific neural gain increases due to rhythmic expectation.","738":"Media plays an important role in shaping public opinion. Biased media can influence people in undesirable directions and hence should be unmasked as such. We observe that feature-based and neural text classification approaches which rely only on the distribution of low-level lexical information fail to detect media bias. This weakness becomes most noticeable for articles on new events, where words appear in new contexts and hence their \u201cbias predictiveness\u201d is unclear. In this paper, we therefore study how second-order information about biased statements in an article helps to improve detection effectiveness. In particular, we utilize the probability distributions of the frequency, positions, and sequential order of lexical and informational sentence-level bias in a Gaussian Mixture Model. On an existing media bias dataset, we find that the frequency and positions of biased statements strongly impact article-level bias, whereas their exact sequential order is secondary. Using a standard model for sentence-level bias detection, we provide empirical evidence that article-level bias detectors that use second-order information clearly outperform those without.","739":null,"740":"Imbalanced data refers to a problem in machine learning where there exists unequal distribution of instances for each classes. Performing a classification task on such data can often turn bias in favour of the majority class. The bias gets multiplied in cases of high dimensional data. To settle this problem, there exists many real-world data mining techniques like over-sampling and under-sampling, which can reduce the Data Imbalance. Synthetic Minority Oversampling Technique (SMOTe) provided one such state-of-the-art and popular solution to tackle class imbalancing, even on high-dimensional data platform. In this work, a novel and consistent oversampling algorithm has been proposed that can further enhance the performance of classification, especially on binary imbalanced datasets. It has been named as NMOTe (Navo Minority Oversampling Technique), an upgraded and superior alternative to the existing techniques. A critical analysis and comprehensive overview on the literature has been done to get a deeper insight into the problem statements and nurturing the need to obtain the most optimal solution. The performance of NMOTe on some standard datasets has been established in this work to get a statistical understanding on why it has edged the existing state-of-the-art to become the most robust technique for solving the two-class data imbalance problem.","741":null,"742":"Dialogue systems in the form of chatbots and personal as- sistants are being increasingly integrated into people\u2019s lives. Modern dialogue systems may consider adopting anthropo- morphic personas, mimicking societal demographic groups to appear more approachable and trustworthy to users. However, the adoption of a persona can result in the adoption of biases. In this paper, we present the \ufb01rst large-scale study on persona biases in dialogue systems and conduct analyses on personas of different social classes, sexual orientations, races, and gen- ders. We de\ufb01ne persona biases as harmful differences in responses (e.g., varying levels of offensiveness, agreement with harmful statements) generated from adopting different demographic personas. Furthermore, we introduce an open-source framework, U NIT P ERSONA B IAS , to explore and aggregate persona biases in dialogue systems. By analyzing the Blender and DialoGPT dialogue systems, we observe that adopting personas can actually decrease harmful responses, compared to not using any personas. Additionally, we \ufb01nd that persona choices can affect the degree of harms in generated responses and thus should be systematically evaluated before deploy-ment. We also analyze how personas can result in different amounts of harm towards speci\ufb01c demographics.","743":"Recent studies showed agreement between how the human brain and neural networks represent objects, suggesting that we might start to understand the underlying computations. However, we know that the human brain is prone to biases at many perceptual and cognitive levels, often shaped by learning history and evolutionary constraints. Here, we explore one such perceptual phenomenon, perceiving animacy, and use the performance of neural networks as a benchmark. We performed an fMRI study that dissociated object appearance (what an object looks like) from object category (animate or inanimate) by constructing a stimulus set that includes animate objects (e.g., a cow), typical inanimate objects (e.g., a mug), and, crucially, inanimate objects that look like the animate objects (e.g., a cow mug). Behavioral judgments and deep neural networks categorized images mainly by animacy, setting all objects (lookalike and inanimate) apart from the animate ones. In contrast, activity patterns in ventral occipitotemporal cortex (VTC) were better explained by object appearance: animals and lookalikes were similarly represented and separated from the inanimate objects. Furthermore, the appearance of an object interfered with proper object identification, such as failing to signal that a cow mug is a mug. The preference in VTC to represent a lookalike as animate was even present when participants performed a task requiring them to report the lookalikes as inanimate. In conclusion, VTC representations, in contrast to neural networks, fail to represent objects when visual appearance is dissociated from animacy, probably due to a preferred processing of visual features typical of animate objects. SIGNIFICANCE STATEMENT How does the brain represent objects that we perceive around us? Recent advances in artificial intelligence have suggested that object categorization and its neural correlates have now been approximated by neural networks. Here, we show that neural networks can predict animacy according to human behavior but do not explain visual cortex representations. In ventral occipitotemporal cortex, neural activity patterns were strongly biased toward object appearance, to the extent that objects with visual features resembling animals were represented closely to real animals and separated from other objects from the same category. This organization that privileges animals and their features over objects might be the result of learning history and evolutionary constraints.","744":"Getting an overview over the legal domain has become challenging, especially in a broad, international context. Legal question answering systems have the potential to alleviate this task by automatically retrieving relevant legal texts for a specific statement and checking whether the meaning of the statement can be inferred from the found documents. We investigate a combination of the BM25 scoring method of Elasticsearch with word embeddings trained on English translations of the German and Japanese civil law. For this, we define criteria which select a dynamic number of relevant documents according to threshold scores. Exploiting two deep learning classifiers and their respective prediction bias with a threshold-based answer inclusion criterion has shown to be beneficial for the textual entailment task, when compared to the baseline.","745":"In an empirical Bayes analysis, we use data from repeated sampling to imitate inferences made by an oracle Bayesian with extensive knowledge of the data-generating distribution. Existing results provide a comprehensive characterization of when and why empirical Bayes point estimates accurately recover oracle Bayes behavior. In this paper, we develop confidence intervals that provide asymptotic frequentist coverage of empirical Bayes estimands. Our intervals include an honest assessment of bias even in situations where empirical Bayes point estimates may converge very slowly. Applied to multiple testing situations, our approach provides flexible and practical confidence statements about the local false sign rate. As an intermediate step in our approach, we develop methods for inference about linear functionals of the effect size distribution in the Bayes deconvolution problem that may be of independent interest.","746":"Pre-trained language models (PTLMs) have achieved impressive performance on commonsense inference benchmarks, but their ability to employ commonsense to make robust inferences, which is crucial for effective communications with humans, is debated. In the pursuit of advancing fluid human-AI communication, we propose a new challenge, RICA: Robust Inference using Commonsense Axioms, that evaluates robust commonsense inference despite textual perturbations. To generate data for this challenge, we develop a systematic and scalable procedure using commonsense knowledge bases and probe PTLMs across two different evaluation settings. Extensive experiments on our generated probe sets with more than 10k statements show that PTLMs perform no better than random guessing on the zero-shot setting, are heavily impacted by statistical biases, and are not robust to perturbation attacks. We also find that fine-tuning on similar statements offer limited gains, as PTLMs still fail to generalize to unseen inferences. Our new large-scale benchmark exposes a significant gap between PTLMs and human-level language understanding and offers a new challenge for PTLMs to demonstrate commonsense.","747":"Beam search is an effective and widely used decoding algorithm in many sequence-to-sequence (seq2seq) text generation tasks. However, in open-ended text generation, beam search is often found to produce repetitive and generic texts, sampling-based decoding algorithms like top-k sampling and nucleus sampling are more preferred. Standard seq2seq models suffer from label bias due to its locally normalized probability formulation. This paper provides a series of empirical evidence that label bias is a major reason for such degenerate behaviors of beam search. By combining locally normalized maximum likelihood estimation and globally normalized sequence-level training, label bias can be reduced with almost no sacrifice in perplexity. To quantitatively measure label bias, we test the model's ability to discriminate the groundtruth text and a set of context-agnostic distractors. We conduct experiments on large-scale response generation datasets. Results show that beam search can produce more diverse and meaningful texts with our approach, in terms of both automatic and human evaluation metrics. Our analysis also suggests several future working directions towards the grand challenge of open-ended text generation.","748":"Abstract Word-level language identification is an essential prerequisite for extracting useful information from code-mixed social media content. Previous studies in word-level language identification show two important observations. First, the local context is an important indicator of the language of a word when a word is valid in multiple languages. Second, considering the word in isolation from its context leads to more effective language classification when a word is borrowed or embedded into sentences of other languages. In this paper, we propose a framework for language identification that makes use of a dynamic switching mechanism for effective language classification of both words that are borrowed or embedded from other languages as well as words that are valid in multiple languages. For a given input, the proposed switching mechanism makes a dynamic decision to bias its prediction either towards the prediction obtained by the contextual information or that obtained by the word in isolation. In contrast to existing studies that rely upon large amounts of annotated data for robust performance in a multilingual environment, the proposed approach uses minimal annotated resources and no external resources, making it easily extendible to newer languages. Evaluation over a corpus of transliterated Facebook comments shows that the proposed approach outperforms its baseline counterparts: classification based on the contextual information, classification based on the word in isolation, as well as an ensemble of the two classifiers.","749":"Existing word-embeddings have performed well in various downstream tasks, but there may be a bias towards the text domain because they are learned from a text corpus. When word-embeddings are used in the Zero-Shot Recognition(ZSR) task, the task becomes a mapping problem between two completely different heterogeneous domains, a low-level visual feature domain, and a word embedding domain, and due to the bias of word-embeddings, it was not easy to learn this mapping function. However, if the context of the visual domain can be learned and embedded, the mapping function of ZSR will be much easier to converge because it only needs to learn the mapping between domains that are more correlated to each other. Therefore, in this paper, we propose a new methodology for embedding the context contained in the visual domain using the annotation information collected from the image dataset. In addition, to utilize the annotations collected from the image dataset for embedding, we proposed a new distance formula to measure the contextual distance between the bounding boxes of objects. Finally, it was verified through various experiments on two datasets that the embeddings learned by our new methodology performed well when applied to ZSR.","750":"Language is gendered if the context surrounding a mention is suggestive of a particular binary gender for that mention. Detecting the different ways in which language is gendered is an important task since gendered language can bias NLP models (such as for coreference resolution). This task is challenging since genderedness is often expressed in subtle ways. Existing approaches need considerable annotation efforts for each language, domain, and author, and often require handcrafted lexicons and features. Additionally, these approaches do not provide a quantifiable measure of how gendered the text is, nor are they applicable at the fine-grained mention level. In this paper, we use existing NLP pipelines to automatically annotate gender of mentions in the text. On corpora labeled using this method, we train a supervised classifier to predict the gender of any mention from its context and evaluate it on unseen text. The model confidence for a mention\u2019s gender can be used as a proxy to indicate the level of genderedness of the context. We test this gendered language detector on movie summaries, movie reviews, news articles, and fiction novels, achieving an AUC-ROC of up to 0.71, and observe that the model predictions agree with human judgments collected for this task. We also provide examples of detected gendered sentences from aforementioned domains.","751":"Recent literature focuses on utilizing the entity information in the sentence-level relation extraction (RE), but this risks leaking super\ufb01cial and spurious clues of relations. As a result, RE still suffers from unintended entity bias , i.e., the spurious correlation between entity mentions (names) and relations. Entity bias can mislead the RE models to extract the relations that do not exist in the text. To combat this issue, some previous work masks the entity mentions to prevent the RE models from over-\ufb01tting entity mentions. However, this strategy degrades the RE performance because it loses the semantic information of entities. In this pa-per, we propose the C O RE ( Counterfactual Analysis based Relation Extraction ) debiasing method that guides the RE models to focus on the main effects of textual context without losing the entity information. We \ufb01rst construct a causal graph for RE, which models the dependencies between variables in RE models. Then, we propose to conduct counterfactual analysis on our causal graph to distill and mitigate the entity bias, that captures the causal effects of speci\ufb01c entity mentions in each instance. Note that our C O RE method is model-agnostic to debias existing RE systems during inference without changing their training processes. Extensive experimental results demonstrate that our C O RE yields signif-icant gains on both effectiveness and generalization for RE. The source code is provided at: https:\/\/github.com\/vanoracai\/CoRE","752":"Mining and analyzing online travel reviews and travel information is playing an increasingly important role in the tourism industry. Accurately capturing the uniqueness and attractiveness of the tourist destinations recorded in the travel notes is the key to tourism analysis and application. The current way to obtain the attraction of tourism is easy to cause bias due to the use of simple statistical methods. This paper proposes a model based on deep learning, which uses Bert pre-training method, based on Transformer, and mines travel notes through Attention to find the attraction point. The model can understand the chapter-level semantics of travel notes based on the context, so much so that the extracted features are closer to the meaning of the text. It also exhibits good performance in generating unique labels of tourist destinations and similar tourism clusters. The experimental results are consistent with the facts, the validity of the model is also proved.","753":"Individual electronic health records (EHRs) and clinical reports are often part of a larger sequence\u2014for example, a single patient may generate multiple reports over the trajectory of a disease. In applications such as cancer pathology reports, it is necessary not only to extract information from individual reports, but also to capture aggregate information regarding the entire cancer case based off case-level context from all reports in the sequence. In this paper, we introduce a simple modular add-on for capturing case-level context that is designed to be compatible with most existing deep learning architectures for text classification on individual reports. We test our approach on a corpus of 431,433 cancer pathology reports, and we show that incorporating case-level context significantly boosts classification accuracy across six classification tasks\u2014site, subsite, laterality, histology, behavior, and grade. We expect that with minimal modifications, our add-on can be applied towards a wide range of other clinical text-based tasks.","754":"Many text corpora exhibit socially problematic biases, which can be propagated or amplified in the models trained on such data. For example, doctor cooccurs more frequently with male pronouns than female pronouns. In this study we (i) propose a metric to measure gender bias; (ii) measure bias in a text corpus and the text generated from a recurrent neural network language model trained on the text corpus; (iii) propose a regularization loss term for the language model that minimizes the projection of encoder-trained embeddings onto an embedding subspace that encodes gender; (iv) finally, evaluate efficacy of our proposed method on reducing gender bias. We find this regularization method to be effective in reducing gender bias up to an optimal weight assigned to the loss term, beyond which the model becomes unstable as the perplexity increases. We replicate this study on three training corpora\u2014Penn Treebank, WikiText-2, and CNN\/Daily Mail\u2014resulting in similar conclusions.","755":"Gender bias exists in natural language datasets, which neural language models tend to learn, resulting in biased text generation. In this research, we propose a debiasing approach based on the loss function modification. We introduce a new term to the loss function which attempts to equalize the probabilities of male and female words in the output. Using an array of bias evaluation metrics, we provide empirical evidence that our approach successfully mitigates gender bias in language models without increasing perplexity. In comparison to existing debiasing strategies, data augmentation, and word embedding debiasing, our method performs better in several aspects, especially in reducing gender bias in occupation words. Finally, we introduce a combination of data augmentation and our approach and show that it outperforms existing strategies in all bias evaluation metrics.","756":"Despite their prevalence in society, social biases are difficult to define and identify, primarily because human judgements in this domain can be unreliable. Therefore, we take an unsupervised approach to identifying gender bias at a comment or sentence level, and present a model that can surface text likely to contain bias. The main challenge in this approach is forcing the model to focus on signs of implicit bias, rather than other artifacts in the data. Thus, the core of our methodology relies on reducing the influence of confounds through propensity score matching and adversarial learning. Our analysis shows how biased comments directed towards female politicians contain mixed criticisms and references to their spouses, while comments directed towards other female public figures focus on appearance and sexualization. Ultimately, our work offers a way to capture subtle biases in various domains without relying on subjective human judgements.","757":"Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc\/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.","758":"Recent advances in Named Entity Recognition (NER) show that document-level contexts can significantly improve model performance. In many application scenarios, however, such contexts are not available. In this paper, we propose to find external contexts of a sentence by retrieving and selecting a set of semantically relevant texts through a search engine, with the original sentence as the query. We find empirically that the contextual representations computed on the retrieval-based input view, constructed through the concatenation of a sentence and its external contexts, can achieve significantly improved performance compared to the original input view based only on the sentence. Furthermore, we can improve the model performance of both input views by Cooperative Learning, a training method that encourages the two input views to produce similar contextual representations or output label distributions. Experiments show that our approach can achieve new state-of-the-art performance on 8 NER data sets across 5 domains.","759":"Warning users about misinformation on social media is not a simple usability task. Soft moderation has to balance between debunking falsehoods and avoiding moderation bias while preserving the social media consumption flow. Platforms thus employ minimally distinguishable warning tags with generic text under a suspected misinformation content. This approach resulted in an unfavorable outcome where the warnings \u201cbackfired\u201d and users believed the misinformation more, not less. In response, we developed enhancements to the misinformation warnings where users are advised on the context of the information hazard and exposed to standard warning iconography. We ran an A\/B evaluation with the Twitter\u2019s original warning tags in a 337 participant usability study. The majority of the participants preferred the enhancements as a nudge toward recognizing and avoiding misinformation. The enhanced warning tags were most favored by the politically left-leaning and to a lesser degree moderate participants, but they also appealed to roughly a third of the right-leaning participants. The education level was the only demographic factor shaping participants\u2019 preferences. We use our findings to propose user-tailored improvements in the soft moderation of misinformation on social media.","760":"The study of free-living populations is important to generate knowledge related to the epidemiology of disease and other health outcomes. These studies are unable to provide the same level of control as is possible in laboratory studies and thus are susceptible to certain errors. The primary categories of study errors are random and systematic. Random errors cause imprecision and can be quantified using statistical methods including the calculation of confidence intervals. Systematic errors cause bias, which is typically difficult to quantify within the context of an individual study. The three main categories of systematic errors are selection, information, and confounding bias. Selection bias occurs when enrolled animals are not representative of the target population of interest in respect to characteristics important to the primary study objective. Information bias occurs when data collected from enrolled animals deviates from the true value. Information bias is most damaging when errors vary among comparison groups. Both selection and information bias are prevented through the application of good study design procedures. Researchers should select study animals after careful consideration of the primary study objective and desired target population. Investigators can reduce information bias through standardised data collection procedures and the use of blinding. Confounding bias occurs when the measured association between a predictor and an outcome ignores the influential effect of an additional variable. Confounding is common and analysts must implement the appropriate statistical adjustments to reduce the associated bias. All studies will have some errors and biased data with high precision are the most damaging to the validity of study conclusions. Authors can facilitate the critical evaluation of their research by providing text related to the limitations and potential sources of bias within the discussion section of their manuscripts.","761":"Usage of presuppositions in social media and news discourse can be a powerful way to influence the readers as they usually tend to not examine the truth value of the hidden or indirectly expressed information. Fairclough and Wodak (1997) discuss presupposition at a discourse level where some implicit claims are taken for granted in the explicit meaning of a text or utterance. From the Gricean perspective, the presuppositions of a sentence determine the class of contexts in which the sentence could be felicitously uttered. This paper aims to correlate the type of knowledge presupposed in a news article to the bias present in it. We propose a set of guidelines to identify various kinds of presuppositions in news articles and present a dataset consisting of 1050 articles which are annotated for bias (positive, negative or neutral) and the magnitude of presupposition. We introduce a supervised classification approach for detecting bias in political news which significantly outperforms the existing systems.","762":"We focus on the cross-domain context-dependent text-to-SQL generation task. Based on the observation that adjacent natural language questions are often linguistically dependent and their corresponding SQL queries tend to overlap, we utilize the interaction history by editing the previous predicted query to improve the generation quality. Our editing mechanism views SQL as sequences and reuses generation results at the token level in a simple manner. It is flexible to change individual tokens and robust to error propagation. Furthermore, to deal with complex table structures in different domains, we employ an utterance-table encoder and a table-aware decoder to incorporate the context of the user utterance and the table schema. We evaluate our approach on the SParC dataset and demonstrate the benefit of editing compared with the state-of-the-art baselines which generate SQL from scratch. Our code is available at https:\/\/github.com\/ryanzhumich\/sparc_atis_pytorch.","763":"Current image captioning systems perform at a merely descriptive level, essentially enumerating the objects in the scene and their relations. Humans, on the contrary, interpret images by integrating several sources of prior knowledge of the world. In this work, we aim to take a step closer to producing captions that offer a plausible interpretation of the scene, by integrating such contextual information into the captioning pipeline. For this we focus on the captioning of images used to illustrate news articles. We propose a novel captioning method that is able to leverage contextual information provided by the text of news articles associated with an image. Our model is able to selectively draw information from the article guided by visual cues, and to dynamically extend the output dictionary to out-of-vocabulary named entities that appear in the context source. Furthermore we introduce ``GoodNews'', the largest news image captioning dataset in the literature and demonstrate state-of-the-art results.","764":"Text normalization (TN) is an important step in conversational systems. It converts written text to its spoken form to facilitate speech recognition, natural language understanding and text-to-speech synthesis. Finite state transducers (FSTs) are commonly used to build grammars that handle text normalization. However, translating linguistic knowledge into grammars requires extensive effort. In this paper, we frame TN as a machine translation task and tackle it with sequence-to-sequence (seq2seq) models. Previous research focuses on normalizing a word (or phrase) with the help of limited word-level context, while our approach directly normalizes full sentences. We find subword models with additional linguistic features yield the best performance (with a word error rate of 0.17%).","765":null,"766":"Network-enabled devices and the consecutive surge of internet users created a significant impact on the knowledge society. In the era of Social Media, the final user is the new reporter that embraces these tools to spread novelty and breaking news about specific subjects. Sometimes, this type of reporting is biased due to the level of the user's knowledge of the matter or to intentionally achieve a goal. The ability to share other users' post magnify this phenomenon and create a domino effect that can lead to the diffusion of biased information. Therefore, the reliability of the shared novelty about an event is becoming fundamental more than ever. The proposed method tries to deal with this drawback by cross-relating text streams with corresponding heterogeneous levels of reliability, for instance, Twitter and Google News. As Text Stream Mining technique, the method adopts the Fuzzy Formal Concept Analysis to incrementally carry out a fuzzy lattice for each text stream. These two fuzzy lattices are compared in time and context-aware manner to derive the trustworthiness of the relations among entities that are mentioned together in the same tweet content. Preliminary experimental results made on a real dataset show that the proposed credibility assessment system provides good performance depending on some parameters, like similarity threshold T (empirically fixed at 0.8) and time window, set at 1 hour.","767":"ABSTRACT Background and Context: The use of block-based programming environments is purported to be a good way to gently introduce novice computer programmers to computer programming. A small, but growing body of research examines the differences between block-based and text-based programming environments. Objective: Thus, the purpose of this study was to examine the overall effect of block-based versus text-based programming environments on both cognitive and affective student learning outcomes. Method: Five academic databases were searched to identify literature meeting our inclusion criteria and resulted in 13 publications with 52 effect size comparisons on both cognitive and affective outcomes. Findings: We found small effect size (g = 0.245; p = .137; with a 95% confidence interval of \u22120.078 to 0.567) in favor of block-based programming environments on cognitive outcomes, and a trivial effect size (g = 0.195, p = .429; with a 95% confidence interval of \u22120.289 to 0.678) on affective outcomes. Both effect size calculations were statistically insignificant using random effects models. The effect sizes were examined for moderating effects by education level, learning environment, and study duration. Some evidence of publication bias was detected in these data. Implications: More research is needed to examine the utility and efficacy of block-based programming environments for novice programmers. Future studies should account for hybrid programming environments using novel research methods.","768":"Recent advances in deep learning techniques have enabled machines to generate cohesive open-ended text when prompted with a sequence of words as context. While these models now empower many downstream applications from conversation bots to automatic storytelling, they have been shown to generate texts that exhibit social biases. To systematically study and benchmark social biases in open-ended language generation, we introduce the Bias in Open-Ended Language Generation Dataset (BOLD), a large-scale dataset that consists of 23,679 English text generation prompts for bias benchmarking across five domains: profession, gender, race, religion, and political ideology. We also propose new automated metrics for toxicity, psycholinguistic norms, and text gender polarity to measure social biases in open-ended text generation from multiple angles. An examination of text generated from three popular language models reveals that the majority of these models exhibit a larger social bias than human-written Wikipedia text across all domains. With these results we highlight the need to benchmark biases in open-ended language generation and caution users of language generation models on downstream tasks to be cognizant of these embedded prejudices.","769":"Word embeddings are becoming popular for political science research, yet we know little about their properties and performance. To help scholars seeking to use these techniques, we explore the effects of key parameter choices\u2014including context window length, embedding vector dimensions, and pretrained versus locally fit variants\u2014on the efficiency and quality of inferences possible with these models. Reassuringly we show that results are generally robust to such choices for political corpora of various sizes and in various languages. Beyond reporting extensive technical findings, we provide a novel crowdsourced \u201cTuring test\u201d\u2013style method for examining the relative performance of any two models that produce substantive, text-based outputs. Our results are encouraging: popular, easily available pretrained embeddings perform at a level close to\u2014or surpassing\u2014both human coders and more complicated locally fit models. For completeness, we provide best practice advice for cases where local fitting is required.","770":"State-of-the-art models in natural language processing rely on separate rigid subword tokenization algorithms, which limit their generalization ability and adap-tation to new settings. In this paper, we propose a new model inductive bias that learns a subword tokenization end-to-end as part of the model. To this end, we introduce a soft gradient-based subword tokenization module (GBST) that automatically learns latent subword representations from characters in a data-driven fashion. Concretely, GBST enumerates candidate subword blocks and learns to score them in a position-wise fashion using a block scoring network. We additionally introduce C HARFORMER , a deep Transformer model that integrates GBST and operates on the byte level. Via extensive experiments on English GLUE, multilingual, and noisy text datasets, we show that C HARFORMER outperforms a series of competitive byte-level baselines while generally performing on par and sometimes outperforming subword-based models. Additionally, C HARFORMER is fast, improving the speed of both vanilla byte-level and subword-level Transformers by 28-100% while maintaining competitive quality. We believe this work paves the way for highly performant token-free models that are trained completely end-to-end.","771":"Social biases with respect to demographics (e.g., gender, age, race) in datasets are often encoded in the large pre-trained language models trained on them. Prior works have largely focused on mitigating biases in context-free representations, with recent shift to contextual ones. While this is useful for several word and sentence-level classification tasks, mitigating biases in only the representations may not suffice to use these models for language generation tasks, such as auto-completion, summarization, or dialogue generation. In this paper, we propose an approach to mitigate social biases in BERT, a large pre-trained contextual language model, and show its effectiveness in fill-in-the-blank sentence completion and summarization tasks. In addition to mitigating biases in BERT, which in general acts as an encoder, we propose lexical co-occurrence-based bias penalization in the decoder units in generation frameworks, and show bias mitigation in summarization. Finally, our approach results in better debiasing of BERT-based representations compared to post training bias mitigation, thus illustrating the efficacy of our approach to not just mitigate biases in representations, but also generate text with reduced biases.","772":"Abstract Persuasive argumentation depends on multiple aspects, which include not only the content of the individual arguments, but also the way they are presented. The presentation of arguments is crucial \u2013 in particular in the context of dialogical argumentation. However, the effects of different discussion styles on the listener are hard to isolate in human dialogues. In order to demonstrate and investigate various styles of argumentation, we propose a multi-agent system in which different aspects of persuasion can be modelled and investigated separately. Our system utilizes argument structures extracted from text-based reviews for which a minimal bias of the user can be assumed. The persuasive dialogue is modelled as a dialogue game for argumentation that was motivated by the objective to enable both natural and flexible interactions between the agents. In order to support a comparison of factual against affective persuasion approaches, we implemented two fundamentally different strategies for both agents: The logical policy utilizes deep Reinforcement Learning in a multi-agent setup to optimize the strategy with respect to the game formalism and the available argument. In contrast, the emotional policy selects the next move in compliance with an agent emotion that is adapted to user feedback to persuade on an emotional level. The resulting interaction is presented to the user via virtual avatars and can be rated through an intuitive interface.","773":"We present a text-based framework for investigating moral sentiment change of the public via longitudinal corpora. Our framework is based on the premise that language use can inform people\u2019s moral perception toward right or wrong, and we build our methodology by exploring moral biases learned from diachronic word embeddings. We demonstrate how a parameter-free model supports inference of historical shifts in moral sentiment toward concepts such as slavery and democracy over centuries at three incremental levels: moral relevance, moral polarity, and fine-grained moral dimensions. We apply this methodology to visualizing moral time courses of individual concepts and analyzing the relations between psycholinguistic variables and rates of moral sentiment change at scale. Our work offers opportunities for applying natural language processing toward characterizing moral sentiment change in society.","774":"State-of-the-art solutions for Natural Language Processing (NLP) are able to capture a broad range of contexts, like the sentence-level context or document-level context for short documents. But these solutions are still struggling when it comes to longer, real-world documents with the information encoded in the spatial structure of the document, such as page elements like tables, forms, headers, openings or footers; complex page layout or presence of multiple pages. \nTo encourage progress on deeper and more complex Information Extraction (IE) we introduce a new task (named Kleister) with two new datasets. Utilizing both textual and structural layout features, an NLP system must find the most important information, about various types of entities, in long formal documents. We propose Pipeline method as a text-only baseline with different Named Entity Recognition architectures (Flair, BERT, RoBERTa). Moreover, we checked the most popular PDF processing tools for text extraction (pdf2djvu, Tesseract and Textract) in order to analyze behavior of IE system in presence of errors introduced by these tools.","775":"In this paper, we study Multimodal Named Entity Recognition (MNER) for social media posts. Existing approaches for MNER mainly suffer from two drawbacks: (1) despite generating word-aware visual representations, their word representations are insensitive to the visual context; (2) most of them ignore the bias brought by the visual context. To tackle the first issue, we propose a multimodal interaction module to obtain both image-aware word representations and word-aware visual representations. To alleviate the visual bias, we further propose to leverage purely text-based entity span detection as an auxiliary module, and design a Unified Multimodal Transformer to guide the final predictions with the entity span predictions. Experiments show that our unified approach achieves the new state-of-the-art performance on two benchmark datasets.","776":"With the starting point that implicit human biases are reflected in the statistical regularities of language, it is possible to measure biases in English static word embeddings. State-of-the-art neural language models generate dynamic word embeddings dependent on the context in which the word appears. Current methods measure pre-defined social and intersectional biases that occur in contexts defined by sentence templates. Dispensing with templates, we introduce the Contextualized Embedding Association Test (CEAT), that can summarize the magnitude of overall bias in neural language models by incorporating a random-effects model. Experiments on social and intersectional biases show that CEAT finds evidence of all tested biases and provides comprehensive information on the variance of effect magnitudes of the same bias in different contexts. All the models trained on English corpora that we study contain biased representations. GPT-2 contains the smallest magnitude of overall bias followed by GPT, BERT, and then ELMo, negatively correlating with the contextualization levels of the models. Furthermore, we develop two methods, Intersectional Bias Detection (IBD) and Emergent Intersectional Bias Detection (EIBD), to automatically identify the intersectional biases and emergent intersectional biases from static word embeddings in addition to measuring them in contextualized word embeddings. We present the first algorithmic bias detection findings on how intersectional group members are strongly associated with unique emergent biases that do not overlap with the biases of their constituent minority identities. IBD achieves an accuracy of 81.6% and 82.7%, respectively, when detecting the intersectional biases of African American females and Mexican American females, where the random correct identification rates are 14.3% and 13.3%. EIBD reaches an accuracy of 84.7% and 65.3%, respectively, when detecting the emergent intersectional biases unique to African American females and Mexican American females, where the random correct identification rates are 9.2% and 6.1%. Our results indicate that intersectional biases associated with members of multiple minority groups, such as African American females and Mexican American females, have the highest magnitude across all neural language models.","777":"Dense neural text retrieval has achieved promising results on open-domain Question Answering (QA), where latent representations of questions and passages are exploited for maximum inner product search in the retrieval process. However, current dense retrievers require splitting documents into short passages that usually contain local, partial and sometimes biased context, and highly depend on the splitting process. As a consequence, it may yield inaccurate and misleading hidden representations, thus deteriorating the final retrieval result. In this work, we propose Dense Hierarchical Retrieval (DHR), a hierarchical framework which can generate accurate dense representations of passages by utilizing both macroscopic semantics in the document and microscopic semantics specific to each passage. Specifically, a document-level retriever first identifies relevant documents, among which relevant passages are then retrieved by a passage-level retriever. The ranking of the retrieved passages will be further calibrated by examining the document-level relevance. In addition, hierarchical title structure and two negative sampling strategies (i.e., InDoc and In-Sec negatives) are investigated. We apply DHR to large-scale open-domain QA datasets. DHR significantly outperforms the original dense passage retriever, and helps an end-to-end QA system outperform the strong baselines on multiple open-domain QA benchmarks.","778":"Embeddings of textual data containing location names (e.g., social media posts) have essential applications in various contexts such as marketing and disaster management. In these downstream implementations, social biases behind location names are highly prone to introduce unfair results through their embeddings; for example, emergent text messages with swapped location names might result in varied rescue responses. Hence, it is critical to address social biases encoded in location names and to seek its mitigation. Prevalent works addressing biases in embeddings mainly focus on individual attributes like gender or ethnicity. Yet, a large number of social attributes behind location names (e.g., income level and population density) makes it challenging to originate the source of biases. Existing mitigation methods based on finding attribute subspaces cannot be simply applied to address social biases. Moreover, bias mitigation tends to simultaneously remove necessary semantics from embeddings, making it difficult to achieve a balance between mitigation performance and semantics retention. In this article, we first employ the concept of counterfactual fairness to investigate the social biases encoded in training data. Then, we quantify the biases in the contextual embeddings (BERT and ELMo). We report a high correlation between biases in the training data and embeddings. Next, we introduce a novel bias mitigation algorithm that customizes bias representations for any location names. The method yields debiased location name vectors for various social attributes simultaneously. The proposed algorithm achieves a better mitigation performance on overall attributes compared with a prevalent postprocessing method, while maintaining correctness by retaining semantic information.","779":"The Word Embedding Association Test shows that GloVe and word2vec word embeddings exhibit human-like implicit biases based on gender, race, and other social constructs (Caliskan et al., 2017). Meanwhile, research on learning reusable text representations has begun to explore sentence-level texts, with some sentence encoders seeing enthusiastic adoption. Accordingly, we extend the Word Embedding Association Test to measure bias in sentence encoders. We then test several sentence encoders, including state-of-the-art methods such as ELMo and BERT, for the social biases studied in prior work and two important biases that are difficult or impossible to test at the word level. We observe mixed results including suspicious patterns of sensitivity that suggest the test\u2019s assumptions may not hold in general. We conclude by proposing directions for future work on measuring bias in sentence encoders.","780":"Contextual string embeddings are a recent type of contextualized word embedding that were shown to yield state-of-the-art results when utilized in a range of sequence labeling tasks. They are based on character-level language models which treat text as distributions over characters and are capable of generating embeddings for any string of characters within any textual context. However, such purely character-based approaches struggle to produce meaningful embeddings if a rare string is used in a underspecified context. To address this drawback, we propose a method in which we dynamically aggregate contextualized embeddings of each unique string that we encounter. We then use a pooling operation to distill a \u201dglobal\u201d word representation from all contextualized instances. We evaluate these \u201dpooled contextualized embeddings\u201d on common named entity recognition (NER) tasks such as CoNLL-03 and WNUT and show that our approach significantly improves the state-of-the-art for NER. We make all code and pre-trained models available to the research community for use and reproduction.","781":"Masked Language Models (MLMs) have shown superior performances in numerous downstream NLP tasks when used as text encoders. Unfortunately, MLMs also demonstrate significantly worrying levels of social biases. We show that the previously proposed evaluation metrics for quantifying the social biases in MLMs are problematic due to following reasons: (1) prediction accuracy of the masked tokens itself tend to be low in some MLMs, which raises questions regarding the reliability of the evaluation metrics that use the (pseudo) likelihood of the predicted tokens, and (2) the correlation between the prediction accuracy of the mask and the performance in downstream NLP tasks is not taken into consideration, and (3) high frequency words in the training data are masked more often, introducing noise due to this selection bias in the test cases. To overcome the abovementioned disfluencies, we propose All Unmasked Likelihood (AUL), a bias evaluation measure that predicts all tokens in a test case given the MLM embedding of the unmasked input. We find that AUL accurately detects different types of biases in MLMs. We also propose AUL with Attention weights (AULA) to evaluate tokens based on their importance in a sentence. However, unlike AUL and AULA, previously proposed bias evaluation measures for MLMs systematically overestimate the measured biases, and are heavily influenced by the unmasked tokens in the context.","782":null,"783":"Social bias in machine learning has drawn significant attention, with work ranging from demonstrations of bias in a multitude of applications, curating definitions of fairness for different contexts, to developing algorithms to mitigate bias. In natural language processing, gender bias has been shown to exist in context-free word embeddings. Recently, contextual word representations have outperformed word embeddings in several downstream NLP tasks. These word representations are conditioned on their context within a sentence, and can also be used to encode the entire sentence. In this paper, we analyze the extent to which state-of-the-art models for contextual word representations, such as BERT and GPT-2, encode biases with respect to gender, race, and intersectional identities. Towards this, we propose assessing bias at the contextual word level. This novel approach captures the contextual effects of bias missing in context-free word embeddings, yet avoids confounding effects that underestimate bias at the sentence encoding level. We demonstrate evidence of bias at the corpus level, find varying evidence of bias in embedding association tests, show in particular that racial bias is strongly encoded in contextual word models, and observe that bias effects for intersectional minorities are exacerbated beyond their constituent minority identities. Further, evaluating bias effects at the contextual word level captures biases that are not captured at the sentence level, confirming the need for our novel approach.","784":"In multi-turn dialogue generation, response is usually related with only a few contexts. Therefore, an ideal model should be able to detect these relevant contexts and produce a suitable response accordingly. However, the widely used hierarchical recurrent encoder-decoder models just treat all the contexts indiscriminately, which may hurt the following response generation process. Some researchers try to use the cosine similarity or the traditional attention mechanism to find the relevant contexts, but they suffer from either insufficient relevance assumption or position bias problem. In this paper, we propose a new model, named ReCoSa, to tackle this problem. Firstly, a word level LSTM encoder is conducted to obtain the initial representation of each context. Then, the self-attention mechanism is utilized to update both the context and masked response representation. Finally, the attention weights between each context and response representations are computed and used in the further decoding process. Experimental results on both Chinese customer services dataset and English Ubuntu dialogue dataset show that ReCoSa significantly outperforms baseline models, in terms of both metric-based and human evaluations. Further analysis on attention shows that the detected relevant contexts by ReCoSa are highly coherent with human\u2019s understanding, validating the correctness and interpretability of ReCoSa.","785":"In recent years, pangenomes received increasing attention from the scienti\ufb01c community for their ability to incorporate population variation information and alleviate reference genome bias. Maximal Exact Matches ( MEMs ) and Maximal Unique Matches ( MUMs ) have proven themselves to be useful in multiple bioinformatic contexts, for example short-read alignment and multiple-genome alignment. However, standard techniques using su\ufb03x trees and FM-indexes do not scale to a pangenomic level. Recently, Gagie et al. [JACM 20] introduced the r -index that is a Burrows-Wheeler Transform ( BWT )-based index able to handle hundreds of human genomes. Later, Rossi et al. [JCB 22] enabled the computation of MEMs using the r -index, and Boucher et al. [DCC 21] showed how to compute them in a streaming fashion. In this paper, we show how to augment Boucher et al.\u2019s approach to enable the computation of MUMs on the r -index, while preserving the space and time bounds. We add additional O ( r ) samples of the longest common pre\ufb01x ( LCP ) array, where r is the number of equal-letter runs of the BWT , that permits the computation of the second longest match of the pattern su\ufb03x with respect to the input text, which in turn allows the computation of candidate MUMs . We implemented a proof-of-concept of our approach, that we call mum-phinder , and tested on real-world datasets. We compared our approach with competing methods that are able to compute MUMs . We observe that our method is up to 8 times smaller, while up to 19 times slower when the dataset is not highly repetitive, while on highly repetitive data, our method is up to 6.5 times slower and uses up to 25 times less memory. their insightful","786":"Existing machine reading comprehension (MRC) models do not scale effectively to real-world applications like web-level information retrieval and question answering (QA). We argue that this stems from the nature of MRC datasets: most of these are static environments wherein the supporting documents and all necessary information are fully observed. In this paper, we propose a simple method that reframes existing MRC datasets as interactive, partially observable environments. Specifically, we \u201cocclude\u201d the majority of a document\u2019s text and add context-sensitive commands that reveal \u201cglimpses\u201d of the hidden text to a model. We repurpose SQuAD and NewsQA as an initial case study, and then show how the interactive corpora can be used to train a model that seeks relevant information through sequential decision making. We believe that this setting can contribute in scaling models to web-level QA scenarios.","787":"Contextualized representations trained over large raw text data have given remarkable improvements for NLP tasks including question answering and reading comprehension. There have been works showing that syntactic, semantic and word sense knowledge are contained in such representations, which explains why they benefit such tasks. However, relatively little work has been done investigating commonsense knowledge contained in contextualized representations, which is crucial for human question answering and reading comprehension. We study the commonsense ability of GPT, BERT, XLNet, and RoBERTa by testing them on seven challenging benchmarks, finding that language modeling and its variants are effective objectives for promoting models' commonsense ability while bi-directional context and larger training set are bonuses. We additionally find that current models do poorly on tasks require more necessary inference steps. Finally, we test the robustness of models by making dual test cases, which are correlated so that the correct prediction of one sample should lead to correct prediction of the other. Interestingly, the models show confusion on these test cases, which suggests that they learn commonsense at the surface rather than the deep level. We release a test set, named CATs publicly, for future research.","788":"End-to-End (E2E) automatic speech recognition (ASR) systems learn word spellings directly from text-audio pairs, in contrast to traditional ASR systems which incorporate a separate pronunciation lexicon. The lexicon allows a traditional system to correctly spell rare words observed only in LM training, if their phonetic pronunciation is known during inference. E2E systems, however, are more likely to misspell rare words.We propose an E2E model which benefits from the best of both worlds: it outputs graphemes, and thus learns to spell words directly, while leveraging pronunciations for words which might be likely in a given context. Our model is based on the recently proposed Contextual Listen, Attend, and Spell (CLAS) model. As in CLAS, our model accepts a set of bias phrases, which are first converted into fixed length embeddings which are provided as additional inputs to the model. Unlike CLAS, which accepts only the textual form of the bias phrases, the proposed model also has access to the corresponding phonetic pronunciations, which improves performance on challenging sets which include words unseen in training. The proposed model provides a 16% relative word-error-rate reduction over CLAS when both the phonetic and written representation of the context bias phrases are used.","789":"We present a systematic study of biases in natural language generation (NLG) by analyzing text generated from prompts that contain mentions of different demographic groups. In this work, we introduce the notion of the regard towards a demographic, use the varying levels of regard towards different demographics as a defining metric for bias in NLG, and analyze the extent to which sentiment scores are a relevant proxy metric for regard. To this end, we collect strategically-generated text from language models and manually annotate the text with both sentiment and regard scores. Additionally, we build an automatic regard classifier through transfer learning, so that we can analyze biases in unseen text. Together, these methods reveal the extent of the biased nature of language model generations. Our analysis provides a study of biases in NLG, bias metrics and correlated human judgments, and empirical evidence on the usefulness of our annotated dataset.","790":"Allowing machines to choose whether to kill humans would be devastating for world peace and security. But how do we equip machines with the ability to learn ethical or even moral choices? In this study, we show that applying machine learning to human texts can extract deontological ethical reasoning about \u201cright\u201d and \u201cwrong\u201d conduct. We create a template list of prompts and responses, such as \u201cShould I [action]?\u201d, \u201cIs it okay to [action]?\u201d, etc. with corresponding answers of \u201cYes\/no, I should (not).\u201d and \"Yes\/no, it is (not).\" The model's bias score is the difference between the model's score of the positive response (\u201cYes, I should\u201d) and that of the negative response (\u201cNo, I should not\u201d). For a given choice, the model's overall bias score is the mean of the bias scores of all question\/answer templates paired with that choice. Specifically, the resulting model, called the Moral Choice Machine (MCM), calculates the bias score on a sentence level using embeddings of the Universal Sentence Encoder since the moral value of an action to be taken depends on its context. It is objectionable to kill living beings, but it is fine to kill time. It is essential to eat, yet one might not eat dirt. It is important to spread information, yet one should not spread misinformation. Our results indicate that text corpora contain recoverable and accurate imprints of our social, ethical and moral choices, even with context information. Actually, training the Moral Choice Machine on different temporal news and book corpora from the year 1510 to 2008\/2009 demonstrate the evolution of moral and ethical choices over different time periods for both atomic actions and actions with context information. By training it on different cultural sources such as the Bible and the constitution of different countries, the dynamics of moral choices in culture, including technology are revealed. That is the fact that moral biases can be extracted, quantified, tracked, and compared across cultures and over time.","791":"Astounding results from Transformer models on natural language tasks have intrigued the vision community to study their application to computer vision problems. Among their salient benefits, Transformers enable modeling long dependencies between input sequence elements and support parallel processing of sequence as compared to recurrent networks e.g., Long short-term memory (LSTM). Different from convolutional networks, Transformers require minimal inductive biases for their design and are naturally suited as set-functions. Furthermore, the straightforward design of Transformers allows processing multiple modalities (e.g., images, videos, text and speech) using similar processing blocks and demonstrates excellent scalability to very large capacity networks and huge datasets. These strengths have led to exciting progress on a number of vision tasks using Transformer networks. This survey aims to provide a comprehensive overview of the Transformer models in the computer vision discipline. We start with an introduction to fundamental concepts behind the success of Transformers i.e., self-attention, large-scale pre-training, and bidirectional feature encoding. We then cover extensive applications of transformers in vision including popular recognition tasks (e.g., image classification, object detection, action recognition, and segmentation), generative modeling, multi-modal tasks (e.g., visual-question answering, visual reasoning, and visual grounding), video processing (e.g., activity recognition, video forecasting), low-level vision (e.g., image super-resolution, image enhancement, and colorization) and 3D analysis (e.g., point cloud classification and segmentation). We compare the respective advantages and limitations of popular techniques both in terms of architectural design and their experimental value. Finally, we provide an analysis on open research directions and possible future works. We hope this effort will ignite further interest in the community to solve current challenges towards the application of transformer models in computer vision.","792":"Lip-reading aims to infer the speech content from the lip movement sequence and can be seen as a typical sequence-to-sequence (seq2seq) problem which translates the input image sequence of lip movements to the text sequence of the speech content. However, the traditional learning process of seq2seq models always suffers from two problems: the exposure bias resulted from the strategy of \u201cteacher-forcing\u201d, and the inconsistency between the discriminative optimization target (usually the cross-entropy loss) and the final evaluation metric (usually the character\/word error rate). In this paper, we propose a novel pseudo-convolutional policy gradient (PCPG) based method to address these two problems. On the one hand, we introduce the evaluation metric (refers to the character error rate in this paper) as a form of reward to optimize the model together with the original discriminative target. On the other hand, inspired by the local perception property of convolutional operation, we perform a pseudo-convolutional operation on the reward and loss dimension, so as to take more context around each time step into account to generate a robust reward and loss for the whole optimization. Finally, we perform a thorough comparison and evaluation on both the word-level and sentence-level benchmarks. The results show a significant improvement over other related methods, and report either a new state-of-the-art performance or a competitive accuracy on all these challenging benchmarks, which clearly proves the advantages of our approach.","793":"Discussing things you care about can be difficult, especially via online platforms, where sharing your opinion leaves you open to the real and immediate threats of abuse and harassment. Due to these threats, people stop expressing themselves and give up on seeking different opinions. Recent research efforts focus on examining the strengths and weaknesses (e.g. potential unintended biases) of using machine learning as a support tool to facilitate safe space for online discussions; for example, through detecting various types of negative online behaviors such as hate speech, online harassment, or cyberbullying. Typically, these efforts build upon sentiment analysis or spam detection in text. However, the toxicity of the language could be a strong indicator for the intensity of the negative behavior. In this paper, we study the topic of toxicity in online conversations by addressing the problems of subjectivity, bias, and ambiguity inherent in this task. We start with an analysis of the characteristics of subjective assessment tasks (e.g. relevance judgment, toxicity judgment, sentiment assessment, etc). Whether we perceive something as relevant or as toxic can be influenced by almost infinite amounts of prior or current context, e.g. culture, background, experiences, education, etc. We survey recent work that tries to understand this phenomenon, and we outline a number of open questions and challenges which shape the research perspectives in this multi-disciplinary field.","794":"State-of-the-art Neural Machine Translation (NMT) models struggle with generating low-frequency tokens, tackling which remains a major challenge. The analysis of long-tailed phenomena in the context of structured prediction tasks is further hindered by the added complexities of search during inference. In this work, we quantitatively characterize such long-tailed phenomena at two levels of abstraction, namely, token classification and sequence generation. We propose a new loss function, the Anti-Focal loss, to better adapt model training to the structural dependencies of conditional text generation by incorporating the inductive biases of beam search in the training process. We show the efficacy of the proposed technique on a number of Machine Translation (MT) datasets, demonstrating that it leads to significant gains over cross-entropy across different language pairs, especially on the generation of low-frequency words. We have released the code to reproduce our results.","795":"Recent advancements in sensing techniques for mHealth applications have led to successful development and deployments of several mHealth intervention designs, including Just-In-Time Adaptive Interventions (JITAI). JITAIs show great potential because they aim to provide the right type and amount of support, at the right time. Timing the delivery of a JITAI such as the user is receptive and available to engage with the intervention is crucial for a JITAI to succeed. Although previous research has extensively explored the role of context in users' responsiveness towards generic phone notifications, it has not been thoroughly explored for actual mHealth interventions. In this work, we explore the factors affecting users' receptivity towards JITAIs. To this end, we conducted a study with 189 participants, over a period of 6 weeks, where participants received interventions to improve their physical activity levels. The interventions were delivered by a chatbot-based digital coach -Ally - which was available on Android and iOS platforms. We define several metrics to gauge receptivity towards the interventions, and found that (1) several participant-specific characteristics (age, personality, and device type) show significant associations with the overall participant receptivity over the course of the study, and that (2) several contextual factors (day\/time, phone battery, phone interaction, physical activity, and location), show significant associations with the participant receptivity, in-the-moment. Further, we explore the relationship between the effectiveness of the intervention and receptivity towards those interventions; based on our analyses, we speculate that being receptive to interventions helped participants achieve physical activity goals, which in turn motivated participants to be more receptive to future interventions. Finally, we build machine-learning models to detect receptivity, with up to a 77% increase in F1 score over a biased random classifier.","796":null,"797":null,"798":"The recommendations of the Text Encoding Initiative (TEI) seem to have become a defining feature of the methodological framework of the Digital Humanities, despite recurrent concerns that the system they define is at the same time both too rigorous for the manifold variability of humanistic text, and not precise enough to guarantee interoperability of resources defined using it. In this paper I question the utility of standardization in a scholarly context, proposing however that documentation of formal encoding practice is an essential part of scholarship. After discussing the range of information such documentation entails, I explore the notion of conformance proposed by the TEI Guidelines, suggesting that this must operate at both a technical syntactic level, and a less easily verifiable semantic level. One of the more noticeable features of the Guidelines is their desire to have (as the French say) both the butter and the money for the butter; I will suggest that this polymorphous multiplicity is an essential component of the system, and has been a key factor in determining the TEI\u2019s continued relevance.","799":"Abstract Objective To investigate how the general public trades off explainability versus accuracy of artificial intelligence (AI) systems and whether this differs between healthcare and non-healthcare scenarios. Materials and Methods Citizens\u2019 juries are a form of deliberative democracy eliciting informed judgment from a representative sample of the general public around policy questions. We organized two 5-day citizens\u2019 juries in the UK with 18 jurors each. Jurors considered 3 AI systems with different levels of accuracy and explainability in 2 healthcare and 2 non-healthcare scenarios. Per scenario, jurors voted for their preferred system; votes were analyzed descriptively. Qualitative data on considerations behind their preferences included transcribed audio-recordings of plenary sessions, observational field notes, outputs from small group work and free-text comments accompanying jurors\u2019 votes; qualitative data were analyzed thematically by scenario, per and across AI systems. Results In healthcare scenarios, jurors favored accuracy over explainability, whereas in non-healthcare contexts they either valued explainability equally to, or more than, accuracy. Jurors\u2019 considerations in favor of accuracy regarded the impact of decisions on individuals and society, and the potential to increase efficiency of services. Reasons for emphasizing explainability included increased opportunities for individuals and society to learn and improve future prospects and enhanced ability for humans to identify and resolve system biases. Conclusion Citizens may value explainability of AI systems in healthcare less than in non-healthcare domains and less than often assumed by professionals, especially when weighed against system accuracy. The public should therefore be actively consulted when developing policy on AI explainability.","800":"In this paper, we present Hierarchical Graph Network (HGN) for multi-hop question answering. To aggregate clues from scattered texts across multiple paragraphs, a hierarchical graph is created by constructing nodes from different levels of granularity (questions, paragraphs, sentences, and entities), the representations of which are initialized with RoBERTa-based context encoders. Given this hierarchical graph, the initial node representations are updated through graph propagation, and multi-hop reasoning is performed via traversing through the graph edges for each subsequent sub-task (e.g., paragraph selection, supporting facts extraction, answer prediction). By weaving heterogeneous nodes into an integral unified graph, this characteristic hierarchical differentiation of node granularity enables HGN to support different question answering sub-tasks simultaneously. Experiments on the HotpotQA benchmark demonstrate that the proposed model achieves new state of the art in both the Distractor and Fullwiki settings.","801":"Recent progress in natural language generation has raised dual-use concerns. While applications like summarization and translation are positive, the underlying technology also might enable adversaries to generate neural fake news: targeted propaganda that closely mimics the style of real news. \nModern computer security relies on careful threat modeling: identifying potential threats and vulnerabilities from an adversary's point of view, and exploring potential mitigations to these threats. Likewise, developing robust defenses against neural fake news requires us first to carefully investigate and characterize the risks of these models. We thus present a model for controllable text generation called Grover. Given a headline like `Link Found Between Vaccines and Autism,' Grover can generate the rest of the article; humans find these generations to be more trustworthy than human-written disinformation. \nDeveloping robust verification techniques against generators like Grover is critical. We find that best current discriminators can classify neural fake news from real, human-written, news with 73% accuracy, assuming access to a moderate level of training data. Counterintuitively, the best defense against Grover turns out to be Grover itself, with 92% accuracy, demonstrating the importance of public release of strong generators. We investigate these results further, showing that exposure bias -- and sampling strategies that alleviate its effects -- both leave artifacts that similar discriminators can pick up on. We conclude by discussing ethical issues regarding the technology, and plan to release Grover publicly, helping pave the way for better detection of neural fake news.","802":"This paper describes the ongoing development of a TEI-conformant model for the encoding of hybrid primary sources containing text and graphical components on a similar level of semantic meaning. The subsequent considerations are part of the digital scholarly edition project representing the notebooks of the Austrian conceptual artist Hartmut Skerbisch (1945\u20132009), a handwritten corpus created over a period of almost 40 years. Besides text, drawings were an important visual means of expression for the artist. In the context of digitally representing the numerous graphics embedded in the notes with equivalent depth to the text, a three-step model is proposed. This model takes into account the (1) graphical components characterizing the composition, (2) textual functions describing and directing the execution of artworks, and (3) interpretation of the graphics and their contextualization with connected material and information. The paper discusses the existing methods of representing graphics in TEI, presents the combination of these methods in the actual scholarly edition project, and introduces the semantic enrichment of the TEI sources through formal descriptions in RDF\/XML taxonomies using linked open data. Thus, the genealogy of artistic concepts and artworks documented in the notebooks will become traceable.","803":"I was recently invited to give a research seminar at an academic institution and so I did what most academics do in such cases: I made a PowerPoint (PPT) presentation. I had recently updated the PPT software on my computer, and as I worked my way through the design of the slide deck, I started to receive automatically generated design suggestions for my slides. These suggestions were different from the standard template slides already available in PPT; they were dynamic and based on the elements I had already placed on the slides. The program took my text and images and moved them around, put them in boxes, drew an outline around them, and, in some cases, added fancy borders. Not all \u201cdesign ideas,\u201d as the software calls them, were good or even useful. The software also made what I thought were some egregious errors. For instance, it would \u201cun-crop\u201d an image I had cropped. Yet, over time, I found myself making increased use of the suggestions, and as I did so, the range of suggestions I received changed. I got a wider variety of suggestions. This whole process would have gone unnoticed except that in this instance I was preparing a talk on the potential impact of artificial intelligence (AI) on engineering education. In the context of that topic, it was hard for me to ignore a real-life example of AI in action. My work practice was being shaped by AI. From a technical perspective, this is an unremarkable example. Yet, it portends a future where increasingly in some manner AI will touch most activities in which engineering educators engage. Like the early and often clumsy incarnations of search engines and voice-recognition systems before they become ordinary, an increasing range of AI-based activities that now seem inconsequential will be embedded in engineering education practices with possible profound implications for how we teach, conduct research, and otherwise engage with our profession. Engineering as a profession is located centrally in the material context of our world. This material context shapes our quality of life, both physically and socially, and by designing and changing this materiality\u2014whether through physical material or digital designs\u2014engineers play a critical role in the world (Johri, 2014). And this materiality is where AI lives. It is only through the engineering of systems employing algorithms that AI finds its way into the world. AI, then, often embeds ideas of how engineers, among others, see the world; these embedded ideas in turn shape the world in which they live. This is not an insignificant burden for the profession and for those who train the future professionals\u2014 engineering educators. Once we tease out the hyperbole of AI from its reality, advances in AI present both significant opportunities and risks. Most AI experts agree that although artificial general intelligence, the kind of AI that is just like humans, is a long way off, artificial narrow intelligence (ANI), which is programmed to perform a single task, is making rapid progress. Driverless cars, drone deliveries, and conversations with Alexa are all applications of ANI that, just a few years back, were unfathomable except as science fiction. Although ANI applications have limitations, and often serious biases, they have slowly started to augment, if not replace, human practices across a range of activities. Augmentation is not new. Humans have augmented their practices for centuries through different tools and technologies (Ong, 2013). Whether it was the development of language and oral culture or the symbolic system of writing, we have always found ways to augment cognition to make us more \u201cintelligent.\u201d By offloading our thinking and exchange of ideas to an external representational system, we have been able to make remarkable progress at a societal level (Johri, Roth, & Olds, 2013). From a situated learning perspective, and especially from the distributed cognition lens, by distributing some of our thinking to other artifacts, we have been able to handle complexity that might not have otherwise been tackled (Johri & Olds, 2011). In the past few decades, introduction of computation to this process has taken our ability to be intelligent to another level (Engelbart, 1962). We have not just amplified what we can do but rearranged how we do what we do\u2014calculators have not just offloaded day-to-day calculations but have allowed us to undertake tasks that require computation that was previously untenable (Pea, 1985). AI-based augmentation, though, is different. AI gives technology agency the power to initiate interaction and the ability to be a communicator on par with humans. Machines, like the PPT slide example, are now the ones giving ideas without being asked or prompted, and even though humans will retain some control, increasingly they will become comfortable with even more actions being initiated by a machine. It is through DOI: 10.1002\/jee.20326","804":null,"805":"Community question answering (CQA) sites have grown to be useful platforms where users search for highly specific information to resolve a problem. However, the significant increase in the number of user-generated content with high variance in quality on these sites not only presents challenges for user navigation but also outgrow the community\u2019s peer reviewing capacity. This necessitates ways to automatically assess the quality of new questions so as to maintain quality of content served to its users. While existing methods commonly employ social network indicators as features, our model aims to avoid social influence biases arising from these indicators by predicting the quality from semantic evaluation of the question text. Formulation of the proposed model is non-trivial as it requires the extraction of meaningful features from the noisy question text at different granularities while filtering redundant information. In this work, a neural architecture is proposed to address this problem by aggregating the textual features extracted at word- and sentence-level in a hierarchical manner. In addition, a unique attention mechanism that focuses on sentence segments for interpreting a question is developed. This new mechanism employs the global topical information from common problem contexts. The proposed approach is verified on the Stack Overflow question dataset and is shown to outperform existing neural models.","806":"As video game press (\"experts\") and casual gamers (\"amateurs\") have different motivations when writing video game reviews, discrepancies in their reviews may arise. To study such potential discrepancies, we conduct a large-scale investigation of more than 1 million reviews on the Metacritic review platform. In particular, we assess the existence and nature of discrepancies in video game appraisal by experts and amateurs, and how they manifest in ratings, over time, and in review language. Leveraging these insights, we explore the predictive power of early expert vs. amateur reviews in forecasting video game reputation in the short- and long-term. We find that amateurs, in contrast to experts, give more polarized ratings of video games, rate games surprisingly long after game release, and are positively biased towards older games. On a textual level, we observe that experts write rather complex, less readable texts than amateurs, whose reviews are more emotionally charged. While in the short-term amateur reviews are remarkably predictive of game reputation among other amateurs (achieving 91% ROC AUC in a binary classification), both expert and amateur reviews are equally well suited for long-term predictions. Overall, our work is the first large-scale comparative study of video game reviewing behavior, with practical implications for amateurs when deciding which games to play, and for game developers when planning which games to design, develop, or continuously support. More broadly, our work contributes to the discussion of wisdom of the few vs. wisdom of the crowds, as we uncover the limits of experts in capturing the views of amateurs in the particular context of video game reviews.","807":null,"808":"In all goal-oriented selection activities, an existence of certain level of bias is unavoidable and may be desired for efficient artificial intelligence based decision support systems. However, a fair independent comparison of all eligible entities is essential to alleviate explicit bias in competitive marketplace. For example, searching online for a good or service, it is expected that the underlying algorithm will provide fair results by searching all available entities in the category mentioned. However, a biased search can make a narrow or collaborative query, ignoring competitive outcomes, resulting customers in costing more or getting lower quality products or services for the money they spend. This paper describes algorithmic bias in different contexts with examples and scenarios, best practices to detect bias, and two case studies to identify algorithmic bias.","809":"Word segmentation is an essential and challenging task in natural language processing, especially for the Chinese language due to its high linguistic complexity. Existing methods for Chinese word segmentation, including statistical machine learning methods and neural network methods, usually have good performance in specific knowledge domains. Given the increasing importance of interdisciplinary and cross-domain studies, one of the challenges in cross-domain word segmentation is to handle the out-of-vocabulary (OOV) words. Existing methods show unsatisfactory performance to meet the practical standard. To this end, we propose a document-level context-aware model that can automatically perceive and identify OOV words from different domains. Our method jointly implements a word-based and a character-based model and then processes the results with a newly proposed reconstruction model. We evaluate the new method by designing and conducting comprehensive experiments on two real-world datasets (e.g., news from different domains). The results demonstrate the superiority of our method over the state-of-the-art models in handling texts from different domains. Importantly, when doing the word segmentation under the cross-domain scenario, our proposed method can improve the performance of OOV words recognition.","810":null,"811":"Abstract Motivation Information extraction by mining the scientific literature is key to uncovering relations between biomedical entities. Most existing approaches based on natural language processing extract relations from single sentence-level co-mentions, ignoring co-occurrence statistics over the whole corpus. Existing approaches counting entity co-occurrences ignore the textual context of each co-occurrence. Results We propose a novel corpus-wide co-occurrence scoring approach to relation extraction that takes the textual context of each co-mention into account. Our method, called CoCoScore, scores the certainty of stating an association for each sentence that co-mentions two entities. CoCoScore is trained using distant supervision based on a gold-standard set of associations between entities of interest. Instead of requiring a manually annotated training corpus, co-mentions are labeled as positives\/negatives according to their presence\/absence in the gold standard. We show that CoCoScore outperforms previous approaches in identifying human disease\u2013gene and tissue\u2013gene associations as well as in identifying physical and functional protein\u2013protein associations in different species. CoCoScore is a versatile text mining tool to uncover pairwise associations via co-occurrence mining, within and beyond biomedical applications. Availability and implementation CoCoScore is available at: https:\/\/github.com\/JungeAlexander\/cocoscore. Supplementary information Supplementary data are available at Bioinformatics online.","812":"Arti\ufb01cial writing is permeating our lives due to recent advances in large-scale, transformer-based language models (LMs) such as BERT, its variants, GPT-2\/3, and others. Using them as pre-trained models and \ufb01ne-tuning them for speci\ufb01c tasks, researchers have extended state of the art for many NLP tasks and shown that they capture not only linguistic knowledge but also retain general knowledge implicitly present in the data. Unfortunately, LMs trained on un\ufb01ltered text corpora su\ufb00er from degenerated and biased behaviour. While this is well established, we show that recent improvements of LMs also store ethical and moral norms of the society and actually bring a \u201cmoral direction\u201d to surface. In this study, we show that these norms can be captured geometrically by a direction, which can be computed, e.g., by a PCA, in the embedding space, re\ufb02ecting well the agreement of phrases to social norms implicitly expressed in the training texts. Furthermore, this provides a path for attenuating or even preventing toxic degeneration in LMs. Being able to rate the (non-)normativity of arbitrary phrases without explicitly training the LM for this task, we demonstrate the capabilities of the moral direction for guiding (even other) LMs towards producing normative text and showcase it on RealToxicityPrompts testbed, preventing the neural toxic degeneration in GPT-2. We used a signi\ufb01cance level of 5% in the analysis. Samples with missing values, i.e. where the participants failed to respond within \ufb01ve seconds, were","813":"Deep CNN networks have shown great success in various tasks for text-independent speaker recognition. In this paper, we explore two approaches for modeling long temporal contexts to improve the performance of the ResNet networks. The first approach is simply integrating the utterance-level mean and variance normalization into the ResNet architecture. Secondly, we combine the BLSTM and ResNet into one unified architecture. The BLSTM layers model long range, supposedly phonetically aware, context information, which could facilitate the ResNet to learn the optimal attention weight and suppress the environmental variations. The BLSTM outputs are projected into multiple-channel feature maps and fed into the ResNet network. Experiments on the VoxCeleb1 and the internal MS-SV tasks show that with attentive pooling, the proposed approaches achieve up to 23-28% relative improvement in EER over a well-trained ResNet.","814":"Natural language inference (NLI) is a fundamental NLP task, investigating the entailment relationship between two texts. Popular NLI datasets present the task at sentence-level. While adequate for testing semantic representations, they fall short for testing contextual reasoning over long texts, which is a natural part of the human inference process. We introduce ConTRoL, a new dataset for ConTextual Reasoning over Long texts. Consisting of 8,325 expert-designed \"context-hypothesis\" pairs with gold labels, ConTRoL is a passage-level NLI dataset with a focus on complex contextual reasoning types such as logical reasoning. It is derived from competitive selection and recruitment test (verbal reasoning test) for police recruitment, with expert level quality. Compared with previous NLI benchmarks, the materials in ConTRoL are much more challenging, involving a range of reasoning types. Empirical results show that state-of-the-art language models perform by far worse than educated humans. Our dataset can also serve as a testing-set for downstream tasks like Checking Factual Correctness of Summaries.","815":"Document classification requires to extract high-level features from low-level word vectors. Typically, feature extraction by deep neural networks makes use of all words in a document, which cannot scale well for a long document. In this paper, we propose to tackle the long document classification task by incorporating the recurrent attention learning framework, which can produce the discriminative features with significantly less words. Specifically, the core work is to train a recurrent neural network (RNN)-based controller, which can focus its attention on the discriminative parts. Then, the glimpsed feature is extracted by a typical short text level convolutional neural network (CNN) from the focused group of words. The controller locates its attention according to the context information, which consists of the coarse representation of the original document and the memorized glimpsed features. By glimpsing a few groups, the document can be classified by aggregating these glimpsed features and the coarse representation. For our collected 11-class 10 000-word arXiv paper data set, the proposed method outperforms two subsampled deep CNN baseline models by a large margin given much less observed words.","816":"Training generative models that can generate high-quality text with sufficient diversity is an important open problem for Natural Language Generation (NLG) community. Recently, generative adversarial models have been applied extensively on text generation tasks, where the adversarially trained generators alleviate the exposure bias experienced by conventional maximum likelihood approaches and result in promising generation quality. However, due to the notorious defect of mode collapse for adversarial training, the adversarially trained generators face a quality-diversity trade-off, i.e., the generator models tend to sacrifice generation diversity severely for increasing generation quality. In this paper, we propose a novel approach which aims to improve the performance of adversarial text generation via efficiently decelerating mode collapse of the adversarial training. To this end, we introduce a cooperative training paradigm, where a language model is cooperatively trained with the generator and we utilize the language model to efficiently shape the data distribution of the generator against mode collapse. Moreover, instead of engaging the cooperative update for the generator in a principled way, we formulate a meta learning mechanism, where the cooperative update to the generator serves as a high level meta task, with an intuition of ensuring the parameters of the generator after the adversarial update would stay resistant against mode collapse. In the experiment, we demonstrate our proposed approach can efficiently slow down the pace of mode collapse for the adversarial text generators. Overall, our proposed method is able to outperform the baseline approaches with significant margins in terms of both generation quality and diversity in the testified domains.","817":"The Chinese text classification task is challenging compared to tasks based on other languages such as English due to the characteristics of the Chinese text itself. In recent years, some popular methods based on deep learning have been used for text classification, such as the convolutional neural network (CNN) and the long short-term memory (LSTM) network. However, some problems are still encountered when classifying Chinese text. For example, important but obscure context information in Chinese text is not easily extracted. To improve the effect of Chinese text classification, we propose a novel classification model in this paper named the hierarchical comprehensive context modeling network (HCCMN) that can extract more comprehensive context. Our approach aims to extract contextual information and integrate it with the original input and then extract hierarchically more context, spatial information and high-weight local features from the integrated results. In addition, our method can remember long-term historical obscure information. Since Chinese radiology texts are complicated and difficult to obtain, we collected a Chinese radiology medical text dataset (CIRTEXT) containing more than 56,000 real-world data samples to verify the effect of this work. We conducted experiments on four datasets and showed that our HCCMN performs at state-of-the-art levels on three selected evaluation metrics compared to baselines. We present promising results showing that our hierarchical context modeling network extracts useful context from Chinese text more effectively and comprehensively.","818":"This paper presents a novel technique for single slope analog to digital converter (SSADC) to suppress the row-wise noise in CMOS image sensor. A sample switch is used in the current-steering DAC to reduce the noise introduced by bias circuits, which will deteriorate the characteristic of uniformity in the row direction. The sample switch can fix the voltage which biases the current source in the current-steering DAC when generating a ramp to avoid the ramp fluctuation in the time domain. The digital correlated double sampling is used to reduce the non-uniformity in column-level ADCs. The CMOS image sensor prototype is fabricated in 110nm 1P3M process. The 10-bit SSADC achieves DNL of \u22120.20 \/ +0.15 LSB and INL of \u22121.35 \/ +0.91 LSB at a sampling frequency of 29.2 KHz. It is proved that the row-wise noise is reduced from <inline-formula> <tex-math notation=\"LaTeX\">$764~\\mu {\\mathrm {V}}_{\\text {rms}}$ <\/tex-math><\/inline-formula> to 163 <inline-formula> <tex-math notation=\"LaTeX\">$\\mu {\\mathrm {V}}_{\\text {rms}}$ <\/tex-math><\/inline-formula>at a frame rate of 228 fps using the proposed sample switch structure. The prototype photos taken by the sensor show that the row-wise noise is reduced under the low-illumination circumstance effectively.","819":"Recognizing text in images has been a hot research topic in computer vision for decades due to its various application. However, the variations in text appearance in term of perspective distortion, text line curvature, text styles, etc., cause great trouble in text recognition. Inspired by the Transformer structure [1] that achieved outstanding performance in many natural language processing related applications, we propose a new Transformer-like structure for text recognition in images, which is referred to as the Hierarchical Attention Transformer Network (HATN). The entire network can be trained end-to-end by using only images and sentence-level annotations. A new hierarchical attention mechanism is proposed to lean the character-level, word-level and sentence-level contexts more efficiently and sufficiently. Extensive experiments on seven public datasets with regular and irregular text arrangements have demonstrated that the proposed HATN can achieve accurate recognition results with high efficiency.","820":"Informational bias is widely present in news articles. It refers to providing one-sided, selective or suggestive information of specific aspects of certain entity to guide a specific interpretation, thereby biasing the reader\u2019s opinion. Sentence-level informational bias detection is a very challenging task in a way that such bias can only be revealed together with the context, examples include collecting information from various sources or analyzing the entire article in combination with the background. In this paper, we integrate three levels of context to detect the sentence-level informational bias in English news articles: adjacent sentences, whole article, and articles from other news outlets describing the same event. Our model, MultiCTX (Multi-level ConTeXt), uses contrastive learning and sentence graphs together with Graph Attention Network (GAT) to encode these three degrees of context at different stages by tactically composing contrastive triplets and constructing sentence graphs within events. Our experiments proved that contrastive learning together with sentence graphs effectively incorporates context in varying degrees and significantly outperforms the current SOTA model sentencewise in informational bias detection.","821":null,"822":"Despite progress toward gender equality in the labor market over the past few decades, gender segregation in labor force composition and labor market outcomes persists. Evidence has shown that job advertisements may express gender preferences, which may selectively attract potential job candidates to apply for a given post and thus reinforce gendered labor force composition and outcomes. Removing gender-explicit words from job advertisements does not fully solve the problem as certain implicit traits are more closely associated with men, such as ambitiousness, while others are more closely associated with women, such as considerateness. However, it is not always possible to find neutral alternatives for these traits, making it hard to search for candidates with desired characteristics without entailing gender discrimination. Existing algorithms mainly focus on the detection of the presence of gender biases in job advertisements without providing a solution to how the text should be (re)worded. To address this problem, we propose an algorithm that evaluates gender bias in the input text and provides guidance on how the text should be debiased by offering alternative wording that is closely related to the original input. Our proposed method promises broad application in the human resources process, ranging from the development of job advertisements to algorithm-assisted screening of job applications.","823":"A new method for Text-to-SQL parsing, Grammar Pre-training (GP), is proposed to decode deep relations between question and database. Firstly, to better utilize the information of databases, a random value is added behind a question word which is recognized as a column, and the new sentence serves as the model input. Secondly, initialization of vectors for decoder part is optimized, with reference to the former encoding so that question information can be concerned. Finally, a new approach called flooding level is adopted to get the non-zero training loss which can generalize better results. By encoding the sentence with GRAPPA and RAT-SQL model, we achieve better performance on spider, a crossDB Text-to-SQL dataset (72.8 dev, 69.8 test). Experiments show that our method is easier to converge during training and has excellent robustness.","824":"A new source driving circuit to compensate characteristics variations of thin-film transistors for AMOLED displays with high resolution is presented in this brief. The second-generation current conveyor is implemented for rapid current sensing of the feedback line, which is biased with a constant reference-voltage (<inline-formula> <tex-math notation=\"LaTeX\">$V_{{\\mathrm{ REF}}}$ <\/tex-math><\/inline-formula>). Further, the current difference between the current of the driving transistor (<inline-formula> <tex-math notation=\"LaTeX\">${I}_{ {D}}$ <\/tex-math><\/inline-formula>) and the programming current, i.e., <inline-formula> <tex-math notation=\"LaTeX\">${I}_{{\\mathrm{ DATA}}}$ <\/tex-math><\/inline-formula>, is converted into switching voltage through an amplifier with a shorted resistor, to control the input of a ramp voltage (<inline-formula> <tex-math notation=\"LaTeX\">${V}_{{\\mathrm{ RAMP}}}$ <\/tex-math><\/inline-formula>). Thus, the degradations in electrical characteristics of the driving transistor can be compensated in real time, and both the influence of threshold voltage (<inline-formula> <tex-math notation=\"LaTeX\">${V}_{{\\mathrm{ TH}}}$ <\/tex-math><\/inline-formula>) shift and mobility (<inline-formula> <tex-math notation=\"LaTeX\">${ {\\mu }}$ <\/tex-math><\/inline-formula>) variation are effectively suppressed. The current-error rate of the proposed circuit is less than 3% with <inline-formula> <tex-math notation=\"LaTeX\">${V}_{{\\mathrm{ TH}}}$ <\/tex-math><\/inline-formula> shift of \u00b10.5 V or <inline-formula> <tex-math notation=\"LaTeX\">${ {\\mu } }$ <\/tex-math><\/inline-formula> variation of \u00b115%. In addition, the settling time is less than <inline-formula> <tex-math notation=\"LaTeX\">$4~{ {\\mu } }{\\text s}$ <\/tex-math><\/inline-formula> with the panel loading of 1.5 <inline-formula> <tex-math notation=\"LaTeX\">$\\text{K}{ {\\Omega }}$ <\/tex-math><\/inline-formula> and 100 pF at the OLED current (<inline-formula> <tex-math notation=\"LaTeX\">${I}_{{\\mathrm{ OLED}}}$ <\/tex-math><\/inline-formula>) levels ranging from 3 <inline-formula> <tex-math notation=\"LaTeX\">${ {\\mu }}\\text{A}$ <\/tex-math><\/inline-formula> to 200 nA.","825":"This article introduces a compact NMOS-only voltage reference that is able to operate down to a 0.25-V supply voltage and 5.4-pW power consumption. This allows reliable generation of a stable output voltage even in harvested systems under highly uncertain environmental conditions. At the system level, pW-power, 0.25\u20131.8-V operation, and a competitive power supply rejection ratio (PSRR) relax or eliminate the need for intermediate power conversion and supply regulation for additional power and cost reductions. The proposed voltage reference is based on a body biasing scheme assisted by replica well biasing to compensate voltage and temperature fluctuations. A 180-nm test chip shows that the proposed reference occupies an area of <inline-formula> <tex-math notation=\"LaTeX\">$2200~\\mu \\text{m}^{2}$ <\/tex-math><\/inline-formula>, while providing 91.4-mV output voltage with 0.51-mV (0.56%) standard deviation, <inline-formula> <tex-math notation=\"LaTeX\">$24.2~\\mu \\text{V}\/^{\\circ }\\text{C}$ <\/tex-math><\/inline-formula> (265 ppm\/\u00b0C) temperature coefficient, and <inline-formula> <tex-math notation=\"LaTeX\">$144.5~\\mu \\text{V}$ <\/tex-math><\/inline-formula>\/V (0.16%\/V) line sensitivity across 30 dice from the same manufacturing lot. The resulting absolute output voltage accuracy without any trimming is 2.8 mV at 3-<inline-formula> <tex-math notation=\"LaTeX\">$\\sigma $ <\/tex-math><\/inline-formula> variations, 0.3-V fluctuation, and temperature change by 50 \u00b0C, improving on prior art by 1.4\u2013<inline-formula> <tex-math notation=\"LaTeX\">$19.7\\times $ <\/tex-math><\/inline-formula>. Overall, the capability of reliable operating down to ultralow voltages, pW-power, and the inherently small footprint make the proposed reference well suited for low-cost tightly constrained systems.","826":"In this paper, an ensemble-based system (EBS) for estimating chlorophyll-a concentrations (Chl-a) in inland water bodies using downscaled MODIS images was developed. Seeking additional opinions before making a decision is part of human nature, particularly for decisions involving health issues. The general concept behind EBS algorithms is based on this principle. Forty-six Chl-a measurements, collected over four water bodies between 2000 and 2008, were used to calibrate the EBS. Measurements ranged from 2.7 (oligotrophic waters) to 91 000 mg Chl-a <inline-formula> <tex-math notation=\"LaTeX\">$\\text{m}^{{-3}}$ <\/tex-math><\/inline-formula> (hypertrophic waters). The EBS performance was evaluated by cross validation, and also using an independent database (Chl-a ranging from 1 to 14 mg <inline-formula> <tex-math notation=\"LaTeX\">$\\text{m}^{{-3}}$ <\/tex-math><\/inline-formula>). Cross-validation results were satisfactory both under high-blooming conditions (<inline-formula> <tex-math notation=\"LaTeX\">$\\text{R}^{2} = 0.98$ <\/tex-math><\/inline-formula>, relative RMSE (RMSEr) = 15%, relative Bias (BIASr) = \u22122%, and relative Nash (NASHr) = 0.95) and at the initialization of blooms (<inline-formula> <tex-math notation=\"LaTeX\">$\\text{R}^{2} = 0.77$ <\/tex-math><\/inline-formula>, RMSEr = 37%, BIASr = \u22128%, and NASHr = 0.70). The EBS also performed well on the independent database (<inline-formula> <tex-math notation=\"LaTeX\">$\\text{R}^{2} =0.93$ <\/tex-math><\/inline-formula>, RMSEr = 50%, BIASr = \u221227%, and NASHr = 0.70). A visual comparison mapping Chl-a on the Missisquoi Bay of Lake Champlain additionally illustrates the potential of the EBS to detect early phases of algal growth contrary to other models (adaptive model, Kharu, and APProach by Elimination). This approach is a proof of concept for a more efficient way to quantify algal biomass from remote sensing and could be exported to any types of satellite imagery in a context of water quality monitoring.","827":null,"828":null,"829":"Citation context analysis (CCA) is an important task in natural language processing that studies how and why scholars discuss each others\u2019 work. Despite being studied for decades, traditional frameworks for CCA have largely relied on overlysimplistic assumptions of how authors cite, which ignore several important phenomena. For instance, scholarly papers often contain rich discussions of cited work that span multiple sentences and express multiple intents concurrently. Yet, CCA is typically approached as a single-sentence, single-label classification task, and thus existing datasets fail to capture this interesting discourse. In our work, we address this research gap by proposing a novel framework for CCA as a document-level context extraction and labeling task. We release MULTICITE, a new dataset of 12,653 citation contexts from over 1,200 computational linguistics papers. Not only is it the largest collection of expert-annotated citation contexts to-date, MULTICITE contains multi-sentence, multi-label citation contexts within full paper texts. Finally, we demonstrate how our dataset, while still usable for training classic CCA models, also supports the development of new types of models for CCA beyond fixed-width text classification. We release our code and dataset at https:\/\/github.com\/allenai\/multicite.","830":"In this study, we try to address the problem of leveraging visual signals to improve Automatic Speech Recognition (ASR), also known as visual context-aware ASR (VC-ASR). We explore novel VC-ASR approaches to leverage video and text representations extracted by a self-supervised pre-trained text-video embedding model. Firstly, we propose a multi-stream attention architecture to leverage signals from both audio and video modalities. This architecture consists of separate encoders for the two modalities and a single decoder that at-tends over them. We show that this architecture is better than fusing modalities at the signal level. Additionally, we also explore lever-aging the visual information in a second pass model, which has also been referred to as a \u2018deliberation model\u2019. The deliberation model accepts audio representations and text hypotheses from the first pass ASR and combines them with a visual stream for an improved visual context-aware recognition. The proposed deliberation scheme can work on top of any well trained ASR and also enabled us to leverage the pre-trained text model to ground the hypotheses with the visual features. Our experiments on HOW2 dataset show that multi-stream and deliberation architectures are very effective at the VC-ASR task. We evaluate the proposed models for two scenarios; clean audio stream and distorted audio in which we mask out some specific words in the audio. The deliberation model outperforms the multi-stream model and achieves a relative WER improvement of 6% and 8.7% for the clean and masked data, respectively, compared to an audio-only model. The deliberation model also improves re-covering the masked words by 59% relative.","831":"Emotion awareness research in SE context has been growing in recent years. Currently, researchers often rely on textual communication records to extract emotion states using natural language processing techniques. However, how well these extracted emotion states reflect people's real emotions has not been thoroughly investigated. In this paper, we report a multi-level, longitudinal empirical study with 82 individual members in 27 project teams. We collected their self-reported retrospective emotion states on a weekly basis during their year-long projects and also extracted corresponding emotions from the textual communication records. We then model and compare the dynamics of these two types of emotions using multiple statistical and time series analysis methods. Our analyses yield a rich set of findings. The most important one is that the dynamics of emotions extracted using text-based algorithms often do not well reflect the dynamics of self-reported retrospective emotions. Besides, the extracted emotions match self-reported retrospective emotions better at the team-level. Our results also suggest that individual personalities and the team's emotion display norms significantly impact the match\/mismatch. Our results should warn the research community about the limitations and challenges of applying text-based emotion recognition tools in SE research.","832":null,"833":"We present our Charles-UPF submission for the Shared Task on Evaluating Accuracy in Generated Texts at INLG 2021. Our system can detect the errors automatically using a combination of a rule-based natural language generation (NLG) system and pretrained language models (LMs). We first utilize a rule-based NLG system to generate sentences with facts that can be derived from the input. For each sentence we evaluate, we select a subset of facts which are relevant by measuring semantic similarity to the sentence in question. Finally, we finetune a pretrained language model on annotated data along with the relevant facts for fine-grained error detection. On the test set, we achieve 69% recall and 75% precision with a model trained on a mixture of human-annotated and synthetic data.","834":"Scene text recognition (STR), with various applications, has become a popular research. With deep learning, many sequence to sequence (seq2seq) models have been proposed. However, the Teacher-Forcing training method used in the seq2seq models gave rise to the problem of exposure bias. Moreover, the autoregressive decoding manner limits seq2seq models ability of utilizing future semantic information. To solve these problems, a new Transformer-based network is proposed in this paper. A Re-Embedding Layer with sampling module is introduced to overcome the problem of exposure bias and a context fusion module (CFM) is designed to model global context information. Experiment results on several benchmarks have demonstrated the effectiveness of the proposed method in scene text recognition.","835":"With the rapid development of the Internet, the number of Internet users has grown rapidly, and the Internet has become more and more influential on people\u2019s lives. As a result, the amount of network text is increasing rapidly, and it is difficult to extract interested event information from it only by manual reading. Therefore, event extraction technique automatically extracting useful information from a large amount of unstructured texts becomes increasingly important. Event detection is the first step of event extraction task and plays a vital role in it. However, current event detection research lacks comprehensive consideration of the context of the trigger words. A Chinese event detection method based on multi-feature fusion and BiLSTM is proposed in this paper. The contextual information of word is divided into sentence-level and document-level in the method. The contextual information is captured based on BiLSTM model. At the same time, a word representation method suitable for trigger word classification tasks is proposed in this paper. The word representation incorporates semantic information, grammar information, and document-level context information of word. The word vectors in the sentence are sequentially inputted into BiLSTM model to obtain output vectors containing sentence-level contextual information. Finally, output vectors of BiLSTM are inputted into the Softmax classifier to realize the identification of the trigger words. The experimental results show that Chinese Event Detection Based on Multi-feature Fusion and BiLSTM method proposed in this paper has high accuracy.","836":"We tackle the problem of classifying news articles pertaining to disinformation vs mainstream news by solely inspecting their diffusion mechanisms on Twitter. Our technique is inherently simple compared to existing text-based approaches, as it allows to by-pass the multiple levels of complexity which are found in news content (e.g. grammar, syntax, style). We employ a multi-layer representation of Twitter diffusion networks, and we compute for each layer a set of global network features which quantify different aspects of the sharing process. Experimental results with two large-scale datasets, corresponding to diffusion cascades of news shared respectively in the United States and Italy, show that a simple Logistic Regression model is able to classify disinformation vs mainstream networks with high accuracy (AUROC up to 94%), also when considering the political bias of different sources in the classification task. We also highlight differences in the sharing patterns of the two news domains which appear to be country-independent. We believe that our network-based approach provides useful insights which pave the way to the future development of a system to detect misleading and harmful information spreading on social media.","837":"Scene text detection is one of the most challenging problems in computer vision and has attracted great interest. In general, scene text detection methods are divided into two categories: detection-based and segmentation-based methods. Recently, the segmentation-based methods are more and more popular due to their superior performances and the advantages of detecting arbitrary-shape texts. However, there still exist the following problems: (a) the misclassfication of the unexpected texts, (b) the split of long text lines, (c) the failure of separating very close text instances. In this paper, we propose an accurate segmentation-based detector, which is equipped with context attention and repulsive text border. The context attention incorporates global channel attention, non-local self-attention and spatial attention to better exploit the global and local context, which can greatly increase the discriminative ability for pixels. Due to the enhancement of pixel-level features, false positives and the misdetections of long texts are reduced. Besides, for the purpose of solving very close text instance, a repulsive pixel link, which focuses on the relationships between pixels at the border, is proposed. Experiments on several standard benchmarks, including MSRA-TD500, ICDAR2015, ICDAR2017-MLT and CTW1500, validate the superiority of the proposed method.","838":"Many existing approaches for interpreting text classification models focus on providing importance scores for parts of the input text, such as words, but without a way to test or improve the interpretation method itself. This has the effect of compounding the problem of understanding or building trust in the model, with the interpretation method itself adding to the opacity of the model. Further, importance scores on individual examples are usually not enough to provide a sufficient picture of model behavior. To address these concerns, we propose MOXIE (MOdeling conteXt-sensitive InfluencE of words) with an aim to enable a richer interface for a user to interact with the model being interpreted and to produce testable predictions. In particular, we aim to make predictions for importance scores, counterfactuals and learned biases with MOXIE. In addition, with a global learning objective, MOXIE provides a clear path for testing and improving itself. We evaluate the reliability and efficiency of MOXIE on the task of sentiment analysis.","839":"In this paper, we propose methods for improving the modeling performance of a Transformer-based non-autoregressive textto-speech (TNA-TTS) model. Although the text encoder and audio decoder handle different types and lengths of data (i.e., text and audio), the TNA-TTS models are not designed considering these variations. Therefore, to improve the modeling performance of the TNA-TTS model we propose a hierarchical Transformer structure-based text encoder and audio decoder that are designed to accommodate the characteristics of each module. For the text encoder, we constrain each self-attention layer so the encoder focuses on a text sequence from the local to the global scope. Conversely, the audio decoder constrains its self-attention layers to focus in the reverse direction, i.e., from global to local scope. Additionally, we further improve the pitch modeling accuracy of the audio decoder by providing sentence and word-level pitch as conditions. Various objective and subjective evaluations verified that the proposed method outperformed the baseline TNA-TTS.","840":"Transformer-based language models have taken many fields in NLP by storm. BERT and its derivatives dominate most of the existing evaluation benchmarks, including those for Word Sense Disambiguation (WSD), thanks to their ability in capturing context-sensitive semantic nuances. However, there is still little knowledge about their capabilities and potential limitations for encoding and recovering word senses. In this article, we provide an in-depth quantitative and qualitative analysis of the celebrated BERT model with respect to lexical ambiguity. One of the main conclusions of our analysis is that BERT performs a decent job in capturing high-level sense distinctions, even when a limited number of examples is available for each word sense. Our analysis also reveals that in some cases language models come close to solving coarse-grained noun disambiguation under ideal conditions in terms of availability of training data and computing resources. However, this scenario rarely occurs in real-world settings and, hence, many practical challenges remain even in the coarse-grained setting. We also perform an in-depth comparison of the two main language model based WSD strategies, i.e., fine-tuning and feature extraction, finding that the latter approach is more robust with respect to sense bias and it can better exploit limited available training data.","841":"Text-level discourse rhetorical structure (DRS) parsing is known to be challenging due to the notorious lack of training data. Although recent top-down DRS parsers can better leverage global document context and have achieved certain success, the performance is still far from perfect. To our knowledge, all previous DRS parsers make local decisions for either bottom-up node composition or top-down split point ranking at each time step, and largely ignore DRS parsing from the global view point. Obviously, it is not sufficient to build an entire DRS tree only through these local decisions. In this work, we present our insight on evaluating the pros and cons of the entire DRS tree for global optimization. Specifically, based on recent well-performing top-down frameworks, we introduce a novel method to transform both gold standard and predicted constituency trees into tree diagrams with two color channels. After that, we learn an adversarial bot between gold and fake tree diagrams to estimate the generated DRS trees from a global perspective. We perform experiments on both RST-DT and CDTB corpora and use the original Parseval for performance evaluation. The experimental results show that our parser can substantially improve the performance when compared with previous state-of-the-art parsers.","842":"Video-text retrieval is an important yet challenging task in vision-language understanding, which aims to learn a joint embedding space where related video and text instances are close to each other. Most current works simply measure the video-text similarity based on video-level and text-level embeddings. However, the neglect of more fine-grained or local information causes the problem of insufficient representation. Some works exploit the local details by disentangling sentences, but overlook the corresponding videos, causing the asymmetry of video-text representation. To address the above limitations, we propose a Hierarchical Alignment Network (HANet) to align different level representations for video-text matching. Specifically, we first decompose video and text into three semantic levels, namely event (video and text), action (motion and verb), and entity (appearance and noun). Based on these, we naturally construct hierarchical representations in the individual-local-global manner, where the individual level focuses on the alignment between frame and word, local level focuses on the alignment between video clip and textual context, and global level focuses on the alignment between the whole video and text. Different level alignments capture fine-to-coarse correlations between video and text, as well as take the advantage of the complementary information among three semantic levels. Besides, our HANet is also richly interpretable by explicitly learning key semantic concepts. Extensive experiments on two public datasets, namely MSR-VTT and VATEX, show the proposed HANet outperforms other state-of-the-art methods, which demonstrates the effectiveness of hierarchical representation and alignment. Our code is publicly available at https:\/\/github.com\/Roc-Ng\/HANet.","843":"Cultural evolutionary theory has identified a range of cognitive biases that guide human social learning. Naturalistic and experimental studies indicate transmission biases favoring negative and positive information. To address these conflicting findings, the present study takes a socially situated view of information transmission, which predicts that bias expression will depend on the social context. We report a large-scale experiment (N = 425) that manipulated the social context and examined its effect on the transmission of the positive and negative information contained in a narrative text. In each social context, information was progressively lost as it was transmitted from person to person, but negative information survived better than positive information, supporting a negative transmission bias. Importantly, the negative transmission bias was moderated by the social context: Higher social connectivity weakened the bias to transmit negative information, supporting a socially situated account of information transmission. Our findings indicate that our evolved cognitive preferences can be moderated by our social goals.","844":"In recent years there has been an increasing use of satellite Earth observation (EO) data in dengue research, in particular the identification of landscape factors affecting dengue transmission. Summarizing landscape factors and satellite EO data sources, and making the information public are helpful for guiding future research and improving health decision-making. In this case, a review of the literature would appear to be an appropriate tool. However, this is not an easy-to-use tool. The review process mainly includes defining the topic, searching, screening at both title\/abstract and full-text levels and data extraction that needs consistent knowledge from experts and is time-consuming and labor intensive. In this context, this study integrates the review process, text scoring, active learning (AL) mechanism, and bidirectional long short-term memory (BiLSTM) networks, and proposes a semi-supervised text classification framework that enables the efficient and accurate selection of the relevant articles. Specifically, text scoring and BiLSTM-based active learning were used to replace the title\/abstract screening and full-text screening, respectively, which greatly reduces the human workload. In this study, 101 relevant articles were selected from 4 bibliographic databases, and a catalogue of essential dengue landscape factors was identified and divided into four categories: land use (LU), land cover (LC), topography and continuous land surface features. Moreover, various satellite EO sensors and products used for identifying landscape factors were tabulated. Finally, possible future directions of applying satellite EO data in dengue research in terms of landscape patterns, satellite sensors and deep learning were proposed. The proposed semi-supervised text classification framework was successfully applied in research evidence synthesis that could be easily applied to other topics, particularly in an interdisciplinary context.","845":"This study analyses the problems associated with bilingual teaching mathematics in nationalRussian schools of the Russian Federation. In particular, problems associated with the Russian and Yakut language interference and the mixing of language codes that negatively affect the acquisition of subject knowledge are indicated. Based on the analysis of the speech corpus of bilingual students, the paper revealed the need for the purposeful development of mathematical speech in a primary school. The role of the principle of relying on the native language of schoolchildren in the conditions of bilingual teaching mathematics is determined and the inadmissibility of mixing language codes is justified. The main characteristics of the basic 1 Kazan Federal University 2 Kazan Federal University, Tel. .: +7 (950) 316-01-08.Email: A.V.Danilov@kpfu.ru . 3 Institute of National Schools in the Republic of Sakha (Yakutia). 4 Nottingham Trent University (Great Britain). communicative qualities of mathematical speech and the criteria for assessing their level of formation are given. A system of mathematical problems has been developed and presented in the form of parallel textual bodies in two languages (bi-texts) with an indication of the basic communicative qualities of mathematical speech, the development of which they are aimed at. This paper is useful for familiarizing with the potential of bi-texts in a bilingual learning environment. The work shows the process of developing special mathematical problems presented in the form of bi-texts; the presented experience can be applied in the training of other subjects in the conditions of national-Russian bilingualism. Peri\u00f3dico do N\u00facleo de Estudos e Pesquisas sobre G\u00eanero e Direito Centro de Ci\u00eancias Jur\u00eddicas Universidade Federal da Para\u00edba V. 8 No 07 Ano 2019 \u2013 Special Edition ISSN | 2179-7137 | http:\/\/periodicos.ufpb.br\/ojs2\/index.php\/ged\/index 327","846":"This article introduces an approach that learns segment-level context for sequence labeling in natural language processing (NLP). Previous approaches limit their basic unit to a word for feature extraction because sequence labeling is a token-level task in which labels are annotated word-by-word. However, the text segment is an ultimate unit for labeling, and we are easily able to obtain segment information from annotated labels in a IOB\/IOBES format. Most neural sequence labeling models expand their learning capacity by employing additional layers, such as a character-level layer, or jointly training NLP tasks with common knowledge. The architecture of our model is based on the charLSTM-BiLSTM-CRF model, and we extend the model with an additional segment-level layer called segLSTM. We therefore suggest a sequence labeling algorithm called charLSTM-BiLSTM-CRF-segLSTM$^{sLM}$ which employs an additional segment-level long short-term memory (LSTM) that trains features by learning adjacent context in a segment. We demonstrate the performance of our model on four sequence labeling datasets, namely, Peen Tree Bank, CoNLL 2000, CoNLL 2003, and OntoNotes 5.0. Experimental results show that our model performs better than state-of-the-art variants of BiLSTM-CRF. In particular, the proposed model enhances the performance of tasks for finding appropriate labels of multiple token segments.","847":null,"848":null,"849":"Abstract Decomposing variables into between and within components are often required in multilevel analysis. This method of decomposition should not ignore possible unreliability of an observed group mean (i.e., arithmetic mean) that is due to small cluster sizes and can lead to substantially biased estimates. Adjustment procedures that allow unbiased estimation have been defined and implemented in software for a two-level model. This study shows how to implement a two-stage adjustment procedure in a three-level design. A simulation study showed that the adjustment procedure provides unbiased estimates. To demonstrate how the adjustment procedure can change results in a real data context, an illustration is provided using a set up in which 355 Level-1 units are nested in 93 Level-2 and 19 Level-3 units.","850":null,"851":"Aspect-level sentiment classification aims to distinguish the sentiment polarity of each aspect in a given sentence. It is more complex than text-level sentiment classification in that it is a finegrained task. Existing methods, which formulate this task as predicting the sentiment polarity of a provided (sentence, aspect) pair, tend to ignore the relationship between the sentiment polarity of aspects. In this paper, we propose a sequence prediction model with a sentiment polarity fusion module which sequentially predicts the sentiment polarity of each aspect within sentence. Besides, we use the temporal attention mechanism to keep track of what has been focused on, which discourages repeated attention to the context words with strong sentiment polarity when predicting the sentiment polarity of different aspects. Experimental results on five benchmarking collections illustrate that our proposed model outperforms a range of baseline models by a substantial margin, and further demonstrate that the relationship between the sentiment polarity of aspects is helpful to solve the aspect-level sentiment classification.","852":"With the rapid development of Internet social platforms, buyer shows (such as comment text) have become an important basis for consumers to understand products and purchase decisions. The early sentiment analysis methods were mainly text-level and sentence-level, which believed that a text had only one sentiment. This phenomenon will cover up the details, and it is difficult to reflect people\u2019s fine-grained and comprehensive sentiments fully, leading to people\u2019s wrong decisions. Obviously, aspect-level sentiment analysis can obtain a more comprehensive sentiment classification by mining the sentiment tendencies of different aspects in the comment text. However, the existing aspect-level sentiment analysis methods mainly focus on attention mechanism and recurrent neural network. They lack emotional sensitivity to the position of aspect words and tend to ignore long-term dependencies. In order to solve this problem, on the basis of Bidirectional Encoder Representations from Transformers (BERT), this paper proposes an effective aspect-level sentiment analysis approach (ALM-BERT) by constructing an aspect feature location model. Specifically, we use the pretrained BERT model first to mine more aspect-level auxiliary information from the comment context. Secondly, for the sake of learning the expression features of aspect words and the interactive information of aspect words\u2019 context, we construct an aspect-based sentiment feature extraction method. Finally, we construct evaluation experiments on three benchmark datasets. The experimental results show that the aspect-level sentiment analysis performance of the ALM-BERT approach proposed in this paper is significantly better than other comparison methods.","853":"In TTS-based audiobook production, multi-role dubbing and emotional expressions can significantly improve the naturalness of audiobooks. However, it requires manual annotation of original novels with explicit speaker and emotion tags in sentence level, which is extremely time-consuming and costly. In this paper, we propose a chapter-wise understanding system for Chinese novels, to predict speaker and emotion tags automatically based on the chapter-level context. Compared with baselines of each component, our models obtain higher performance. Audiobooks produced by our proposed system along with a multi-speaker emotional TTS system, are proved to achieve comparable quality score to audiobooks made by individual producers. Demos are demonstrated in https:\/\/jeffpan.net\/icassp\/2021\/main.html.","854":"Background: The existing literature in software engineering reports adverse effects of confirmation bias on software testing. Confirmation bias among software testers leads to confirmatory behavior, which is designing or executing relatively more specification consistent test cases (confirmatory behavior) than specification inconsistent test cases (disconfirmatory behavior). Objective: We aim to explore the antecedents to confirmatory and disconfirmatory behavior of software testers. Furthermore, we aim to understand why and how those antecedents lead to (dis)confirmatory behavior. Method: We follow grounded theory method for the analyses of the data collected through semi-structured interviews with twelve software testers. Results: We identified twenty antecedents to (dis)confirmatory behavior, and classified them in nine categories. Experience and Time are the two major categories. Experience is a disconfirmatory category, which also determines which behavior (confirmatory or disconfirmatory) occurs first among software testers, as an effect of other antecedents. Time Pressure is a confirmatory antecedent of the Time category. It also contributes to the confirmatory effects of antecedents of other categories. Conclusion: The disconfirmatory antecedents, especially that belong to the testing process, e.g., test suite reviews by project team members, may help circumvent the deleterious effects of confirmation bias in software testing. If a team\u2019s resources permit, the designing and execution of a test suite could be divided among the test team members, as different perspectives of testers may help to detect more errors. The results of our study are based on a single context where dedicated testing teams focus on higher levels of testing. The study\u2019s scope does not account for the testing performed by developers. Future work includes exploring other contexts to extend our results.","855":"Gender bias is a frequent occurrence in NLP-based applications, especially pronounced in gender-inflected languages. Bias can appear through associations of certain adjectives and animate nouns with the natural gender of referents, but also due to unbalanced grammatical gender frequencies of inflected words. This type of bias becomes more evident in generating conversational utterances where gender is not specified within the sentence, because most current NLP applications still work on a sentence-level context. As a step towards more inclusive NLP, this paper proposes an automatic and generalisable re-writing approach for short conversational sentences. The rewriting method can be applied to sentences that, without extra-sentential context, have multiple equivalent alternatives in terms of gender. The method can be applied both for creating gender balanced outputs as well as for creating gender balanced training data. The proposed approach is based on a neural machine translation system trained to \u2018translate\u2019 from one gender alternative to another. Both the automatic and manual analysis of the approach show promising results with respect to the automatic generation of gender alternatives for conversational sentences in Spanish.","856":"PurposeFull text of a document is a rich source of information that can be used to provide meaningful topics. The purpose of this paper is to demonstrate how to use citation context (CC) in the full text to identify the cited topics and citing topics efficiently and effectively by employing automatic text analysis algorithms.Design\/methodology\/approachThe authors present two novel topic models, Citation-Context-LDA (CC-LDA) and Citation-Context-Reference-LDA (CCRef-LDA). CC is leveraged to extract the citing text from the full text, which makes it possible to discover topics with accuracy. CC-LDA incorporates CC, citing text, and their latent relationship, while CCRef-LDA incorporates CC, citing text, their latent relationship and reference information in CC. Collapsed Gibbs sampling is used to achieve an approximate estimation. The capacity of CC-LDA to simultaneously learn cited topics and citing topics together with their links is investigated. Moreover, a topic influence measure method based on CC-LDA is proposed and applied to create links between the two-level topics. In addition, the capacity of CCRef-LDA to discover topic influential references is also investigated.FindingsThe results indicate CC-LDA and CCRef-LDA achieve improved or comparable performance in terms of both perplexity and symmetric Kullback\u2013Leibler (sKL) divergence. Moreover, CC-LDA is effective in discovering the cited topics and citing topics with topic influence, and CCRef-LDA is able to find the cited topic influential references.Originality\/valueThe automatic method provides novel knowledge for cited topics and citing topics discovery. Topic influence learnt by our model can link two-level topics and create a semantic topic network. The method can also use topic specificity as a feature to rank references.","857":"This protocol outlines the methods for our systematic review on commercial text-matching software (TMS). We propose to use Joanna Briggs Institute\u2019s (JBI) Methodology for Mixed Methods Systematic Reviews. This systematic review will provide insights into how TMS is used in post-secondary contexts, highlighting evidence relating to how well such software reduces incidences of plagiarism, and also how it can be used for educational purposes to support student learning at the undergraduate and graduate levels.","858":"The text-based speech editor allows the editing of speech through intuitive cutting, copying, and pasting operations to speed up the process of editing speech. However, the major drawback of current systems is that edited speech often sounds unnatural due to cut-copy-paste operation. In addition, it is not obvious how to synthesize records according to a new word not appearing in the transcript, which often needs the help of text-to-speech (TTS) and voice conversion (VC) technology at the same time. This paper first proposes a novel end-toend text-based speech editing method called context-aware mask prediction network (CampNet). The model can simulate the text-based speech editing process by randomly masking part of speech and then predicting the masked region by sensing the speech context. It can solve unnatural prosody in the edited region and synthesize the speech corresponding to the unseen words in the transcript. Secondly, for the possible operation of text-based speech editing, we design three text-based operations based on CampNet: deletion, insertion, and replacement. These operations can cover various situations of speech editing. Thirdly, to synthesize the speech corresponding to long text in insertion and replacement operations, a word-level autoregressive generation method is proposed, which can synthesize the speech of arbitrary length text. Fourthly, we propose a speaker adaptation method using only one sentence for CampNet and explore the ability of few-shot learning based on CampNet, which provides a new idea for speech forgery tasks. The subjective and objective experiments on VCTK and LibriTTS datasets show that the speech editing results based on CampNet are better than TTS technology, manual editing, and VoCo method (the combination of TTS and VC). We also conduct detailed ablation experiments to explore the effect of the CampNet structure on its performance. Finally, the experiment shows that speaker adaptation with only one sentence can further improve the naturalness of speech editing for one-shot learning.","859":"We propose a novel context-free grammar to represent text embeddings in conjunction with their various transformations. We show how this grammar can serve as a unification layer on top of different featurization techniques, and their hybridization thereof. The approach is embodied in an opensource library, called TEXTWISER, with a high-level user interface to serve researchers and practitioners. The goal of TEXTWISER is to enable rapid experimentation with various featurization methods and to serve as a building block within AI applications consuming unstructured data. We highlight several key benefits that are desirable especially in industrial settings where rapid experimentation, reusability, reproducibility, and time to market are of great interest. Finally, we showcase a deployed service powered by TEXTWISER as a proof-of-concept enterprise application.","860":"The cross-database context-dependent Text-to-SQL (XDTS) problem has attracted considerable attention in recent years due to its wide range of potential applications. However, we identify two biases in existing datasets for XDTS: (1) a high proportion of context-independent questions and (2) a high proportion of easy SQL queries. These biases conceal the major challenges in XDTS to some extent. In this work, we present Chase, a large-scale and pragmatic Chinese dataset for XDTS. It consists of 5,459 coherent question sequences (17,940 questions with their SQL queries annotated) over 280 databases, in which only 35% of questions are context-independent, and 28% of SQL queries are easy. We experiment on Chase with three state-of-the-art XDTS approaches. The best approach only achieves an exact match accuracy of 40% over all questions and 16% over all question sequences, indicating that Chase highlights the challenging problems of XDTS. We believe that XDTS can provide fertile soil for addressing the problems.","861":"Approaches to computational argumentation tasks such as stance detection and aspect detection have largely focused on the text of independent claims, losing out on potentially valuable context provided by the rest of the collection. We introduce a general approach to these tasks motivated by syntopical reading, a reading process that emphasizes comparing and contrasting viewpoints in order to improve topic understanding. To capture collection-level context, we introduce the syntopical graph, a data structure for linking claims within a collection. A syntopical graph is a typed multi-graph where nodes represent claims and edges represent different possible pairwise relationships, such as entailment, paraphrase, or support. Experiments applying syntopical graphs to the problems of detecting stance and aspects demonstrate state-of-the-art performance in each domain, significantly outperforming approaches that do not utilize collection-level information.","862":"Understanding the stance and bias reflected in the text is an essential part of achieving machine intelligence. Successful detection of them will not only provide us with a huge amount of insights about public opinion and sentiment but also lay the foundation for serving the most reliable and accurate information to meet people's needs. Traditionally, this problem is often modeled merely as a text classification task. However, it is highly challenging due to the huge variation involved in opinion expressions as well as the need for background knowledge and commonsense reasoning. Meanwhile, just as we want to understand a word based on its context, we also have social contexts for a piece of text, including its author, its sharing pattern online, and its narrative about notable entities and events. These important factors have been largely ignored in previous work. In this dissertation, we tackle this problem by proposing three novel neural network models. Each of them capturing one important social context that can provide rich signals for the detection of stance and bias. The first model aims at predicting the stance of posts from online debate forums. We proposed a structured representation learning model that can make use of the authorship relation and conversational structure in debates. It takes advantage of both collective relational classification methods and distributed representation learning. The performance boost after the inference that is defined over the embedding space. The second model focuses on bias detection in news articles. We identify the social context available for many news articles, which is the engagement pattern over social media. We construct the social information graph involving news articles and apply GCN to aggregate local neighborhood information when generating graph representations. A joint text and graph model is then used to propagate information from both directions. Experimental results show even little social signals can lead to significant improvement. Last but not least, we explore the situation where we cannot obtain context information for test articles. In this case, we designed pre-training strategies that can inject external knowledge about entities, frames, and sharing users into the text model so that it can better identify relevant text spans for bias classification. We also show larger performance gains can be achieved when the supervision is limited, demonstrating the advantage of our model in such cases. Empirical results demonstrate that our models significantly outperform competitive baseline methods, by more accurately regularize the text representation given additional signals available in the social context and by identifying the portion of the text where stance and bias are most readily perceptible.","863":"Is bias amplified when neural machine translation (NMT) models are optimized for speed and evaluated on generic test sets using BLEU? We investigate architectures and techniques commonly used to speed up decoding in Transformer-based models, such as greedy search, quantization, average attention networks (AANs) and shallow decoder models and show their effect on gendered noun translation. We construct a new gender bias test set, SimpleGEN, based on gendered noun phrases in which there is a single, unambiguous, correct answer. While we find minimal overall BLEU degradation as we apply speed optimizations, we observe that gendered noun translation performance degrades at a much faster rate.","864":"Fake news causes significant damage to society. To deal with these fake news, several studies on building detection models and arranging datasets have been conducted. Most of the fake news datasets depend on a specific time period. Consequently, the detection models trained on such a dataset have difficulty detecting novel fake news generated by political changes and social changes; they may possibly result in biased output from the input, including specific person names and organizational names. We refer to this problem as Diachronic Bias because it is caused by the creation date of news in each dataset. In this study, we confirm the bias, especially proper nouns including person names, from the deviation of phrase appearances in each dataset. Based on these findings, we propose masking methods using Wikidata to mitigate the influence of person names and validate whether they make fake news detection models robust through experiments with in-domain and out-of-domain data.","865":"Subjective bias detection is critical for applications like propaganda detection, content recommendation, sentiment analysis, and bias neutralization. This bias is introduced in natural language via inflammatory words and phrases, casting doubt over facts, and presupposing the truth. In this work, we perform comprehensive experiments for detecting subjective bias using BERT-based models on the Wiki Neutrality Corpus(WNC). The dataset consists of 360k labeled instances, from Wikipedia edits that remove various instances of the bias. We further propose BERT-based ensembles that outperform state-of-the-art methods like BERTlarge by a margin of 5.6 F1 score.","866":"Many recent studies have shown that for models trained on datasets for natural language inference (NLI), it is possible to make correct predictions by merely looking at the hypothesis while completely ignoring the premise. In this work, we manage to derive adversarial examples in terms of the hypothesis-only bias and explore eligible ways to mitigate such bias. Specifically, we extract various phrases from the hypotheses (artificial patterns) in the training sets, and show that they have been strong indicators to the specific labels. We then figure out \u2018hard\u2019 and \u2018easy\u2019 instances from the original test sets whose labels are opposite to or consistent with those indications. We also set up baselines including both pretrained models (BERT, RoBerta, XLNet) and competitive non-pretrained models (InferSent, DAM, ESIM). Apart from the benchmark and baselines, we also investigate two debiasing approaches which exploit the artificial pattern modeling to mitigate such hypothesis-only bias: down-sampling and adversarial training. We believe those methods can be treated as competitive baselines in NLI debiasing tasks.","867":null,"868":"We provide a computational account of the integration of various constraints proposed to be involved in the resolution of the direct object\/sentence complement ambiguity. In the first part, competition-integration simulations show that a constraint-based model accounts for the results of Garnsey, Pearlmutter, Myers, and Lotocky (1997) at least as well as the garden-path model. In the second part, we compare the efficacy of norming techniques for capturing plausibility effects. Simulations show that norms designed to tap people's conceptual knowledge of events better capture plausibility effects than do norms that are biased toward tapping linguistic knowledge. We conclude that local information concerning event plausibility is an important constraint for understanding ambiguity resolution. Part 1: Distinguishing Between Theories of Sentence Processing The human language comprehension system is impressive in its ability to integrate multiple sources of information when comprehending sentences (Marslen-Wilson, 1975). Most theories of sentence comprehension include the idea that understanding sentences involves the rapid integration of general syntactic information (Frazier & Rayner, 1982), lexically-specific syntactic information (MacDonald, Pearlmutter, & Seidenberg, 1994; Garnsey et al., 1997), discourse information (Spivey & Tanenhaus, 1998), and knowledge of thematic roles (McRae, Ferretti, & Amyote, 1997; Trueswell, Tanenhaus, & Garnsey, 1994). They differ, however, in their claims about precisely when the comprehension system exploits various types of information. Two prominent theories of sentence processing have emerged in this debate. The garden-path model (Frazier, 1987; Frazier & Rayner, 1982) claims the comprehension system naively constrains initial interpretation by using a limited subset of the relevant information, reserving other information sources for evaluating and, if necessary, revising the initial interpretation. The first stage of comprehension uses only the major syntactic category of each word (noun, verb, etc.), phrase-structure rules, and a small set of syntactic decision principles. One of these principles, minimal attachment, states that the initial interpretation always corresponds to the simplest structure that can be built. The second stage of comprehension temporally lags behind the first, with all potentially relevant sources of knowledge being used to evaluate, and if necessary, revise the initial structure. In contrast, the constraint-based approach views syntactic ambiguity resolution as a continuous process in which the most likely syntactic alternatives are evaluated with respect to all available evidence (MacDonald et al., 1994; McRae, Spivey-Knowlton, & Tanenhaus, 1998). Thus, the distinguishing features of this model are that multiple constraints are combined to compute alternative interpretations in parallel, and that these alternatives compete with one another during processing. Unlike the garden-path model, lexically-specific knowledge and relevant discourse information is available to guide initial interpretations rather than solely to revise the initial interpretation if it is incorrect. The Direct Object\/Sentence Complement Ambiguity The direct object\/sentence complement ambiguity occurs when a noun phrase (NP) following a main verb is temporarily ambiguous with respect to its relationship to the verb. Consider the following examples: 1a) The gossipy neighbor heard (that) the story had never actually been true. 1b) The gossipy neighbor heard (that) the house would never be flooded again. In (1), the NPs \"the story\" and \"the house\" are ambiguous as to whether they are the direct object of the verb (i.e., something that someone has heard), or the subject of a sentence complement (something that someone has heard about). In (1a), for example, when the complementizer \"that\" is removed from these sentences, readers receive confirmation that the gossipy neighbor has not directly heard the story when they read the auxiliary verb \"had\" or \"would\". Readers' use of verb-bias and plausibility information to constrain resolution of the direct object\/sentence complement ambiguity has recently been investigated by Garnsey et al. (1997). They manipulated the plausibility of the post-verbal noun as a direct object. For example, in (1a) \u201cthe story\u201d is a plausible direct object of the verb \u201cheard\u201d (i.e., people tend to hear stories directly), whereas \u201cthe house\u201d is not as plausible (people do not commonly hear houses directly). Of particular interest to Garnsey et al. was how this type of plausibility 3 0 2 0 1 0 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 the story had never EQ Implausible DO EQ Plausible DO","869":"Verbal probabilistic expressions (verbal probabilities) contain a communicative function called directionality and can be categorized as positive (e.g., likely or probable) or negative (e.g., unlikely or doubtful) on the ba-sis of their directionality. Previous studies have demonstrated that the directionality of phrases affects decisions. In particular, people tend to be more risk seeking when presented with positive phrases and risk averse when presented with negative phrases. The rationality (i.e., maximizing utility) of such seemingly biased decisions is examined in this study. We hypothesize that because a speaker tends to choose a positive or negative expression on the basis of context, the selected phrase works as an adaptive cue for understanding the situational change, and that decision biases based on differences in expressions will lead to more rational decision making. Computer simulations were conducted regarding decisions with uncertainty based on verbal probabilities. We found that despite speaker biases in probability judgments, miscommunication generated by the vagueness of verbal expressions, and individual differences in subjective values, biased deci-sion makers who changed their risk attitude on the basis of the directionality of verbal probabilities could make more decisions that were rational than could those who did not show such decision biases. 3510 \u00a92020 The Author(s). This work is licensed under a Creative Commons Attribution 4.0 International License (CC BY).","870":"Voice-based assistants are becoming increasingly widespread all over the world. However, the performance of these assistants in the interaction with users of languages and accents of developing countries is not clear yet. Eventual bias against specific language or accent of different groups of people in developing countries is maybe a factor to increase the digital gap in these countries. Our research aims at analysing the presence of bias in the interaction via audio. We carried out experiments to verify the quality of the recognition of phrases spoken by different groups of people. We evaluated the behaviour of Google Assistant and Siri for groups of people formed according to gender and regions that have different accents. Preliminary results indicate that accent and mispronunciation due to regional differences are not being properly considered by the assistants we have analyzed.","871":null,"872":"Opinion mining techniques, investigating if text is expressing a positive or negative opinion, continuously gain in popularity, attracting the attention of many scientists from different disciplines. Specific use cases, however, where the expressed opinion is indisputably positive or negative, render such solutions obsolete and emphasize the need for a more in-depth analysis of the available text. Emotion analysis is a solution to this problem, but the multi-dimensional elements of the expressed emotions in text along with the complexity of the features that allow their identification pose a significant challenge. Machine learning solutions fail to achieve a high accuracy, mainly due to the limited availability of annotated training datasets, and the bias introduced to the annotations by the personal interpretations of emotions from individuals. A hybrid rule-based algorithm that allows the acquisition of a dataset that is annotated with regard to the Plutchik\u2019s eight basic emotions is proposed in this paper. Emoji, keywords and semantic relationships are used in order to identify in an objective and unbiased way the emotion expressed in a short phrase or text. The acquired datasets are used to train machine learning classification models. The accuracy of the models and the parameters that affect it are presented in length through an experimental analysis. The most accurate model is selected and offered through an API to tackle the emotion detection in social media posts.","873":"Recent research has demonstrated how racial biases against users who write African American English exists in popular toxic language datasets. While previous work has focused on a single fairness criteria, we propose to use additional descriptive fairness metrics to better understand the source of these biases. We demonstrate that different benchmark classifiers, as well as two in-process bias-remediation techniques, propagate racial biases even in a larger corpus. We then propose a novel ensemble-framework that uses a specialized classifier that is fine-tuned to the African American English dialect. We show that our proposed framework substantially reduces the racial biases that the model learns from these datasets. We demonstrate how the ensemble framework improves fairness metrics across all sample datasets with minimal impact on the classification performance, and provide empirical evidence for its ability to unlearn the annotation biases towards authors who use African American English. ** Please note that this work may contain examples of offensive words and phrases.","874":"Sarcasm is one of the main challenges for sentiment analysis systems. Its complexity comes from the expression of opinion using implicit indirect phrasing. In this paper, we present ArSarcasm, an Arabic sarcasm detection dataset, which was created through the reannotation of available Arabic sentiment analysis datasets. The dataset contains 10,547 tweets, 16% of which are sarcastic. In addition to sarcasm the data was annotated for sentiment and dialects. Our analysis shows the highly subjective nature of these tasks, which is demonstrated by the shift in sentiment labels based on annotators\u2019 biases. Experiments show the degradation of state-of-the-art sentiment analysers when faced with sarcastic content. Finally, we train a deep learning model for sarcasm detection using BiLSTM. The model achieves an F1 score of 0.46, which shows the challenging nature of the task, and should act as a basic baseline for future research on our dataset.","875":"The predominant challenge in weakly supervised semantic parsing is that of spurious programs that evaluate to correct answers for the wrong reasons. Prior work uses elaborate search strategies to mitigate the prevalence of spurious programs; however, they typically consider only one input at a time. In this work we explore the use of consistency between the output programs for related inputs to reduce the impact of spurious programs. We bias the program search (and thus the model\u2019s training signal) towards programs that map the same phrase in related inputs to the same sub-parts in their respective programs. Additionally, we study the importance of designing logical formalisms that facilitate this kind of consistency-based training. We find that a more consistent formalism leads to improved model performance even without consistency-based training. When combined together, these two insights lead to a 10% absolute improvement over the best prior result on the Natural Language Visual Reasoning dataset.","876":"End-to-end (E2E) speech recognition architectures assemble all components of traditional speech recognition system into a single model. Although it simplifies ASR system, it introduces contextual ASR drawback: the E2E model has worse performance on utterances containing infrequent proper nouns. In this work, we propose to add a contextual bias attention (CBA) module to attention based encoder decoder (AED) model to improve its ability of recognizing the contextual phrases. Specifically, CBA utilizes the context vector of source attention in decoder to attend to a specific bias embedding. Jointly learned with the basic AED parameters, CBA can tell the model when and where to bias its output probability distribution. At inference stage, a list of bias phrases is preloaded and we adapt the posterior distributions of both CTC and attention decoder according to the attended bias phrase of CBA. We evaluate the proposed method on GigaSpeech and achieve a consistent relative improvement on recall rate of bias phrases ranging from 15% to 28% compared to the baseline model. Meanwhile, our method shows a strong anti-bias ability as the performance on general tests only degrades 1.7% even 2,000 bias phrases are present.","877":"Nowadays, most methods for end-to-end contextual speech recognition bias the recognition process towards contextual knowledge. Since all-neural contextual biasing methods rely on phrase-level contextual modeling and attention-based relevance modeling, they may suffer from the confusion between similar context-specific phrases, which hurts predictions at the token level. In this work, we focus on mitigating confusion problems with fine-grained contextual knowledge selection (FineCoS). In FineCoS, we introduce fine-grained knowledge to reduce the uncertainty of token predictions. Specifically, we first apply phrase selection to narrow the range of phrase candidates, and then conduct token attention on the tokens in the selected phrase candidates. Moreover, we re-normalize the attention weights of most relevant phrases in inference to obtain more focused phrase-level contextual representations, and inject position information to help model better discriminate phrases or tokens. On LibriSpeech and an in-house 160,000-hour dataset, we explore the proposed methods based on an all-neural biasing method, collaborative decoding (ColDec). The proposed methods further bring at most 6.1% relative word error rate reduction on LibriSpeech and 16.4% relative character error rate reduction on the in-house dataset.","878":"Phrase grounding (PG) is a multimodal task that grounds language in images. PG systems are evaluated on well-known benchmarks, using Intersection over Union (IoU) as evaluation metric. This work highlights a disconcerting bias in the evaluation of grounded plural phrases, which arises from representing sets of objects as a union box covering all component bounding boxes, in conjunction with the IoU metric. We detect, analyze and quantify an evaluation bias in the grounding of plural phrases and define a novel metric, c-IoU, based on a union box\u2019s component boxes. We experimentally show that our new metric greatly alleviates this bias and recommend using it for fairer evaluation of plural phrases in PG tasks.","879":"Scene graph generation has received growing attention with the advancements in image understanding tasks such as object detection, attributes and relationship prediction, etc. However, existing datasets are biased in terms of object and relationship labels, or often come with noisy and missing annotations, which makes the development of a reliable scene graph prediction model very challenging. In this paper, we propose a novel scene graph generation algorithm with external knowledge and image reconstruction loss to overcome these dataset issues. In particular, we extract commonsense knowledge from the external knowledge base to refine object and phrase features for improving generalizability in scene graph generation. To address the bias of noisy object annotations, we introduce an auxiliary image reconstruction path to regularize the scene graph generation network. Extensive experiments show that our framework can generate better scene graphs, achieving the state-of-the-art performance on two benchmark datasets: Visual Relationship Detection and Visual Genome datasets.","880":"Search engines, by ranking a few links ahead of million others based on opaque rules, open themselves up to criticism of bias. Previous research has focused on measuring political bias of search engine algorithms to detect possible search engine manipulation effects on voters or unbalanced ideological representation in search results. Insofar that these concerns are related to the principle of fairness, this notion of fairness can be seen as explicitly oriented toward election candidates or political processes and only implicitly oriented toward the public at large. Thus, we ask the following research question: how should an auditing framework that is explicitly centered on the principle of ensuring and maximizing fairness for the public (i.e., voters) operate? To answer this question, we qualitatively explore four datasets about elections and politics in the United States: 1) a survey of eligible U.S. voters about their information needs ahead of the 2018 U.S. elections, 2) a dataset of biased political phrases used in a large-scale Google audit ahead of the 2018 U.S. election, 3) Google's \"related searches\" phrases for two groups of political candidates in the 2018 U.S. election (one group is composed entirely of women), and 4) autocomplete suggestions and result pages for a set of searches on the day of a statewide election in the U.S. state of Virginia in 2019. We find that voters have much broader information needs than the search engine audit literature has accounted for in the past, and that relying on political science theories of voter modeling provides a good starting point for informing the design of voter-centered audits.","881":"Systematic review, meta\u2010analysis and other forms of evidence synthesis are critical to strengthen the evidence base concerning conservation issues and to answer ecological and evolutionary questions. Synthesis lags behind the pace of scientific publishing, however, due to time and resource costs which partial automation of evidence synthesis tasks could reduce. Additionally, current methods of retrieving evidence for synthesis are susceptible to bias towards studies with which researchers are familiar. In fields that lack standardized terminology encoded in an ontology, including ecology and evolution, research teams can unintentionally exclude articles from the review by omitting synonymous phrases in their search terms. To combat these problems, we developed a quick, objective, reproducible method for generating search strategies that uses text mining and keyword co\u2010occurrence networks to identify the most important terms for a review. The method reduces bias in search strategy development because it does not rely on a predetermined set of articles and can improve search recall by identifying synonymous terms that research teams might otherwise omit. When tested against the search strategies used in published environmental systematic reviews, our method performs as well as the published searches and retrieves gold\u2010standard hits that replicated versions of the original searches do not. Because the method is quasi\u2010automated, the amount of time required to develop a search strategy, conduct searches, and assemble results is reduced from approximately 17\u201334 hr to under 2 hr. To facilitate use of the method for environmental evidence synthesis, we implemented the method in the R package litsearchr, which also contains a suite of functions to improve efficiency of systematic reviews by automatically deduplicating and assembling results from separate databases.","882":"ABSTRACT Verb bias facilitates parsing of temporarily ambiguous sentences, but it is unclear when and how comprehenders use probabilistic knowledge about the combinatorial properties of verbs in context. In a self-paced reading experiment, participants read direct object\/sentential complement sentences. Reading time in the critical region was investigated as a function of three forms of bias: structural bias (the frequency with which a verb appears in direct object\/sentential complement sentences), lexical bias (the simple co-occurrence of verbs and other lexical items), and global bias (obtained from norming data about the use of verbs with specific noun phrases). For reading times at the critical word, structural bias was the only reliable predictor. However, global bias was superior to structural and lexical bias at the post-critical word and for offline acceptability ratings. The results suggest that structural information about verbs is available immediately, but that context-specific, semantic information becomes increasingly informative as processing proceeds.","883":"A series of recent papers has used a parsing algorithm due to Shen et al. (2018) to recover phrase-structure trees based on proxies for \"syntactic depth.\" These proxy depths are obtained from the representations learned by recurrent language models augmented with mechanisms that encourage the (unsupervised) discovery of hierarchical structure latent in natural language sentences. Using the same parser, we show that proxies derived from a conventional LSTM language model produce trees comparably well to the specialized architectures used in previous work. However, we also provide a detailed analysis of the parsing algorithm, showing (1) that it is incomplete---that is, it can recover only a fraction of possible trees---and (2) that it has a marked bias for right-branching structures which results in inflated performance in right-branching languages like English. Our analysis shows that evaluating with biased parsing algorithms can inflate the apparent structural competence of language models.","884":"The goal of event detection (ED) is to detect the occurrences of events and categorize them. Previous work solved this task by recognizing and classifying event triggers, which is defined as the word or phrase that most clearly expresses an event occurrence. As a consequence, existing approaches required both annotated triggers and event types in training data. However, triggers are nonessential to event detection, and it is time-consuming for annotators to pick out the \u201cmost clearly\u201d word from a given sentence, especially from a long sentence. The expensive annotation of training corpus limits the application of existing approaches. To reduce manual effort, we explore detecting events without triggers. In this work, we propose a novel framework dubbed as Type-aware Bias Neural Network with Attention Mechanisms (TBNNAM), which encodes the representation of a sentence based on target event types. Experimental results demonstrate the effectiveness. Remarkably, the proposed approach even achieves competitive performances compared with state-of-the-arts that used annotated triggers.","885":"Linking authors of short-text contents has important usages in many applications, including Named Entity Recognition (NER) and human community detection. However, certain challenges lie ahead. First, the input short-text contents are noisy, ambiguous, and do not follow the grammatical rules. Second, traditional text mining methods fail to effectively extract concepts through words and phrases. Third, the textual contents are temporally skewed, which can affect the semantic understanding by multiple time facets. Finally, using knowledge-bases can make the results biased to the content of the external database and deviate the meaning from the input short text corpus. To overcome these challenges, we devise a neural network-based temporal-textual framework that generates the subgraphs with highly correlated authors from short-text contents. Our approach, on the one hand, computes the relevance score (edge weight) between the authors through considering a portmanteau of contents and concepts, and on the other hand, employs a stack-wise graph cutting algorithm to extract the communities of the related authors. Experimental results show that compared to other knowledge-centered competitors, our multi-aspect vector space model can achieve a higher performance in linking short-text authors. In addition, given the author linking task, the more comprehensive the dataset is, the higher the significance of the extracted concepts will be.","886":"\nPurpose\nRecent tourism research has adopted social media analytics (SMA) to examine tourism destination image (TDI) and gain timely insights for marketing purposes. Comparing the methodologies of SMA and intercept surveys would provide a more in-depth understanding of both methodologies and a more holistic understanding of TDI than each method on their own. This study aims to investigate the unique merits and biases of SMA and a traditional visitor intercept survey.\n\n\nDesign\/methodology\/approach\nThis study collected and compared data for the same tourism destination from two sources: responses from a visitor intercept survey (n = 1,336) and Flickr social media photos and metadata (n = 11,775). Content analysis, machine learning and text analysis techniques were used to analyze and compare the destination image represented from both methods.\n\n\nFindings\nThe results indicated that the survey data and social media data shared major similarities in the identified key image phrases. Social media data revealed more diverse and more specific aspects of the destination, whereas survey data provided more insights in specific local landmarks. Survey data also included additional subjective judgment and attachment towards the destination. Together, the data suggested that social media data should serve as an additional and complementary source of information to traditional survey data.\n\n\nOriginality\/value\nThis study fills a research gap by comparing two methodologies in obtaining TDI: SMA and a traditional visitor intercept survey. Furthermore, within SMA, photo and metadata are compared to offer additional awareness of social media data\u2019s underlying complexity. The results showed the limitations of text-based image questions in surveys. The findings provide meaningful insights for tourism marketers by having a more holistic understanding of TDI through multiple data sources.\n","887":"Language models trained on large-scale unfiltered datasets curated from the open web acquire systemic biases, prejudices, and harmful views from their training data. We present a methodology for programmatically identifying and removing harmful text from web-scale datasets. A pretrained language model is used to assess the loglikelihood of researcher-written trigger phrases conditioned on a specific document, which is used to identify and filter documents from the dataset. We demonstrate that models trained on this filtered dataset exhibit lower propensity to generate harmful text, with a marginal decrease in performance on standard language modeling benchmarks compared to unfiltered baselines. We provide a partial explanation for this performance gap by surfacing examples of hate speech and other undesirable content from standard language modeling benchmarks. Finally, we discuss the generalization of this method and how trigger phrases reflecting specific values can be used by researchers to build language models which are more closely aligned with their values.","888":null,"889":"Rapid progress in text-to-image generation has been often measured by Fre\u0107het Inception Distance (FID) to capture how realistic the generated images are, or by R-Precision to assess if they are well conditioned on the given textual descriptions. However, a systematic study on how well the text-to-image synthesis models generalize to novel word compositions is missing. In this work, we focus on assessing how true the generated images are to the input texts in this particularly challenging scenario of novel compositions. We present the first systematic study of text-to-image generation on zero-shot compositional splits targeting two scenarios, unseen object-color (e.g. \u201cblue petal\u201d) and object-shape (e.g. \u201clong beak\u201d) phrases. We create new benchmarks building on the existing CUB and Oxford Flowers datasets. We also propose a new metric, based on a powerful vision-and-language CLIP model, which we leverage to compute R-Precision. This is in contrast to the common approach where the same retrieval model is used during training and evaluation, potentially leading to biased behavior. We experiment with several recent text-to-image generation methods. Our automatic and human evaluation confirm that there is indeed a gap in performance when encountering previously unseen phrases. We show that the image correctness rather than purely perceptual quality is especially impacted. Finally, our CLIP-R-Precision metric demonstrates better correlation with human judgments than the commonly used metric. Dataset and evaluation code at: https:\/\/github.com\/Seth-Park\/comp-t2i-dataset.","890":"Text categorization is an essential task in Web content analysis. Considering the ever-evolving Web data and new emerging categories, instead of the laborious supervised setting, in this paper, we focus on the minimally-supervised setting that aims to categorize documents effectively, with a couple of seed documents annotated per category. We recognize that texts collected from the Web are often structure-rich, i.e., accompanied by various metadata. One can easily organize the corpus into a text-rich network, joining raw text documents with document attributes, high-quality phrases, label surface names as nodes, and their associations as edges. Such a network provides a holistic view of the corpus\u2019 heterogeneous data sources and enables a joint optimization for network-based analysis and deep textual model training. We therefore propose a novel framework for minimally supervised categorization by learning from the text-rich network. Specifically, we jointly train two modules with different inductive biases \u2013 a text analysis module for text understanding and a network learning module for class-discriminative, scalable network learning. Each module generates pseudo training labels from the unlabeled document set, and both modules mutually enhance each other by co-training using pooled pseudo labels. We test our model on two real-world datasets. On the challenging e-commerce product categorization dataset with 683 categories, our experiments show that given only three seed documents per category, our framework can achieve an accuracy of about 92%, significantly outperforming all compared methods; our accuracy is only less than 2% away from the supervised BERT model trained on about 50K labeled documents.","891":"Natural language processing (NLP) models trained on people-generated data can be unreliable because, without any constraints, they can learn from spurious correlations that are not relevant to the task. We hypothesize that enriching models with speaker information in a controlled, educated way can guide them to pick up on relevant inductive biases. For the speaker-driven task of predicting code-switching points in English\u2013Spanish bilingual dialogues, we show that adding sociolinguistically-grounded speaker features as prepended prompts significantly improves accuracy. We find that by adding influential phrases to the input, speaker-informed models learn useful and explainable linguistic information. To our knowledge, we are the first to incorporate speaker characteristics in a neural model for code-switching, and more generally, take a step towards developing transparent, personalized models that use speaker information in a controlled way.","892":"This paper presents Semantic SentenceRank (SSR), an unsupervised scheme for automatically ranking sentences in a single document according to their relative importance. In particular, SSR extracts essential words and phrases from a text document, and uses semantic measures to construct, respectively, a semantic phrase graph over phrases and words, and a semantic sentence graph over sentences. It applies two variants of article-structure-biased PageRank to score phrases and words on the first graph and sentences on the second graph. It then combines these scores to generate the final score for each sentence. Finally, SSR solves a multi-objective optimization problem for ranking sentences based on their final scores and topic diversity through semantic subtopic clustering. An implementation of SSR that runs in quadratic time is presented, and it outperforms, on the SummBank benchmarks, each individual judge\u2019s ranking and compares favorably with the combined ranking of all judges.","893":"Monolingual word alignment is important for studying fine-grained editing operations (i.e., deletion, addition, and substitution) in text-to-text generation tasks, such as paraphrase generation, text simplification, neutralizing biased language, etc. In this paper, we present a novel neural semi-Markov CRF alignment model, which unifies word and phrase alignments through variable-length spans. We also create a new benchmark with human annotations that cover four different text genres to evaluate monolingual word alignment models in more realistic settings. Experimental results show that our proposed model outperforms all previous approaches for monolingual word alignment as well as a competitive QA-based baseline, which was previously only applied to bilingual data. Our model demonstrates good generalizability to three out-of-domain datasets and shows great utility in two downstream applications: automatic text simplification and sentence pair classification tasks.","894":"Query-biased Summarization (QBS) aims to produce a query-dependent summary of a retrieved document to reduce the human effort for inspecting the full-text content. Typical summarization approaches extract document snippets that overlap with the query and show them to searchers. Such QBS methods show relevant information in a document but do not inform searchers what is missing. Our study focuses on reducing user effort in finding relevant documents by exposing the information in the query that is missing in the retrieved results. We use a classical approach, DSPApprox, to find terms or phrases relevant to a query. Then, we identify which terms or phrases are missing in a document, present them in a search interface, and ask crowd workers to judge document relevance based on snippets and missing information. Experimental results show both benefits and limitations of our method compared with traditional ones that only show relevant snippets.","895":"Keyphrase extraction is a fundamental task in Natural Language Processing, which usually contains two main parts: candidate keyphrase extraction and keyphrase importance estimation. From the view of human understanding documents, we typically measure the importance of phrase according to its syntactic accuracy, information saliency, and concept consistency simultaneously. However, most existing keyphrase extraction approaches only focus on the part of them, which leads to biased results. In this paper, we propose a new approach to estimate the importance of keyphrase from multiple perspectives (called as KIEMP) and further improve the performance of keyphrase extraction. Specifically, KIEMP estimates the importance of phrase with three modules: a chunking module to measure its syntactic accuracy, a ranking module to check its information saliency, and a matching module to judge the concept (i.e., topic) consistency between phrase and the whole document. These three modules are seamlessly jointed together via an end-to-end multi-task learning model, which is helpful for three parts to enhance each other and balance the effects of three perspectives. Experimental results on six benchmark datasets show that KIEMP outperforms the existing state-of-the-art keyphrase extraction approaches in most cases.","896":"An abstractive snippet is an originally created piece of text to summarize a web page on a search engine results page. Compared to the conventional extractive snippets, which are generated by extracting phrases and sentences verbatim from a web page, abstractive snippets circumvent copyright issues; even more interesting is the fact that they open the door for personalization. Abstractive snippets have been evaluated as equally powerful in terms of user acceptance and expressiveness\u2014but the key question remains: Can abstractive snippets be automatically generated with sufficient quality? This paper introduces a new approach to abstractive snippet generation: We identify the first two large-scale sources for distant supervision, namely anchor contexts and web directories. By mining the entire ClueWeb09 and ClueWeb12 for anchor contexts and by utilizing the DMOZ Open Directory Project, we compile the Webis Abstractive Snippet Corpus 2020, comprising more than 3.5 million triples of the form \u27e8query, snippet, document\u27e9 as training examples, where the snippet is either an anchor context or a web directory description in lieu of a genuine query-biased abstractive snippet of the web document. We propose a bidirectional abstractive snippet generation model and assess the quality of both our corpus and the generated abstractive snippets with standard measures, crowdsourcing, and in comparison to the state of the art. The evaluation shows that our novel data sources along with the proposed model allow for producing usable query-biased abstractive snippets while minimizing text reuse. Code, data, and slides: https:\/\/webis.de\/publications.html#?q=WWW+2020","897":"Contextual biasing to a specific domain, including a user\u2019s song names, app names and contact names, is an important component of any production-level automatic speech recognition (ASR) system. Contextual biasing is particularly challenging in end-toend models because these models keep a small list of candidates during beam search, and also do poorly on proper nouns, which is the main source of biasing phrases. In this paper, we present various algorithmic and training improvements to shallow-fusionbased biasing for end-to-end models. We will show that the proposed approach obtains better performance than a state-ofthe-art conventional model across a variety of tasks, the first time this has been demonstrated.","898":"hierarchical representations, encoding relations among linguistic sub-units, are a key feature of many theories of syntax and semantics. In the noun phrase, such representations have been argued to have a universal form, in which Adjectives are structurally closest to the Noun, then Numerals, then Demonstratives (Cinque 2005; Abels & Neeleman 2012). This hierarchy can explain (among other things) a striking asymmetry in the frequency of noun phrase word order patterns among the world\u2019s languages: in the vast majority, Adjectives are linearly closer to the Noun, and Demonstratives farthest away (e.g., N-Adj-Num-Dem or Dem-Num-Adj-N). In other words, there appears to be a transparent mapping between the hypothesised structure and linear order in most languages. Building on previous research using artificial language learning experiments, here we aimed to provide robust experimental evidence that human learners are biased in favour of such transparent mappings. We showed that English speakers taught a new language in which modifiers were postnominal (unlike English), used their knowledge of the underlying structure to infer linear order. For example, they assumed that the language would have N-AdjDem order rather than N-Dem-Adj order. The latter is more similar to the surface order of English, but the former transparently reflects an underlying structure in which Adj is structurally closer to the Noun than Dem. Importantly, these findings provide stronger evidence than those reported in previous research (e.g., Culbertson & Adger 2014), in which a potential confound\u2014use of a metalinguistic flipping strategy\u2014could have explained learners\u2019 preferences. We also found that the strength of the preferences we found in our experiments correlated with structural distance; learners\u2019 preferences for the relative order of Adj and Dem were very strong, while for Adj and Num and Num and Dem they were relatively weaker. These results show that, when learning a new language, learners are sensitive to the detailed hierarchical structure of the noun phrase rather than the linear order of their native language. Our results also point to the need for future work exploring whether this structure is learned from experience with a particular language, or reflects a universal underlying representation that shapes noun phrase word order typology.","899":"Business email compromise (BEC) and employee impersonation have become one of the most costly cyber-security threats, causing over $12 billion in reported losses. Impersonation emails take several forms: for example, some ask for a wire transfer to the attacker\u2019s account, while others lead the recipient to following a link, which compromises their credentials. Email security systems are not effective in detecting these attacks, because the attacks do not contain a clearly malicious payload, and are personalized to the recipient. We present BEC-Guard, a detector used at Barracuda Networks that prevents business email compromise attacks in real-time using supervised learning. BEC-Guard has been in production since July 2017, and is part of the Barracuda Sentinel email security product. BEC-Guard detects attacks by relying on statistics about the historical email patterns that can be accessed via cloud email provider APIs. The two main challenges when designing BEC-Guard are the need to label millions of emails to train its classifiers, and to properly train the classifiers when the occurrence of employee impersonation emails is very rare, which can bias the classification. Our key insight is to split the classification problem into two parts, one analyzing the header of the email, and the second applying natural language processing to detect phrases associated with BEC or suspicious links in the email body. BEC-Guard utilizes the public APIs of cloud email providers both to automatically learn the historical communication patterns of each organization, and to quarantine emails in real-time. We evaluated BEC-Guard on a commercial dataset containing more than 4,000 attacks, and show it achieves a precision of 98.2% and a false positive rate of less than one in five million emails.","900":"Current models of Human Sentence Processing fall into two broad categories: Constraint Satisfaction accounts, which emphasise the immediate access of the comprehension processes to detailed linguistic information as parsing progresses (e.g., MacDonald et al., 1994), and Syntax First accounts, which hold that parsing is essentially a two-stage process, with initial decisions being made on the basis of a subset of available information (see, e.g., Frazier, 1995). In this paper, we examine evidence from Mitchell (1987) which seems strongly to favour a syntax \u00a3rst position, suggesting that basic lexical information about verbs may have little in\u00a4uence on the early stages of sentence processing. We provide experimental evidence to show (a) that detailed linguistic information is available early, but (b) that bare NP adverbs (a type of modi\u00a3er) are read surprisingly fast, a \u00a3nding which appears dif\u00a3cult to reconcile with many current accounts of sentence processing. Constraint Satisfaction models of Human Sentence Processing rely heavily on detailed information about the combinatorial possibilities and probabilities associated with each word of a sentence. For example, MacDonald et al. (1994) suggest that the reading of a sentence such as (1a) is affected by lexico-syntactic factors including the frequencies with which the word raced is used in each of its senses (for example, as a past participle or as a past tense verb), as well as thematic factors such as how good an agent or patient horse is of raced. (1a) The horse raced past the barn fell.1 (1b) The landmine buried in the sand exploded. This type of account can be contrasted with Syntax First positions, according to which initial parsing decisions are made on the basis of a subset of available linguistic information (generally comprising category information and phrase structure rules, e.g., Frazier, 1979). These decisions may later be revised in the light of further (syntactic, thematic or pragmatic) evidence, but these revisions have an associated processing cost. According to such accounts, (1b) should be as hard to understand as (1a), since they are syntactic homomorphs. The constraint satisfaction view, on the other hand, predicts the intuitively observable difference between the two, by pointing out that (thematically) landmine makes a poor agent (but a good patient) of buried, as well as (syntactically) the statistical facts that buried is typically used as a passive past participle (in comparison to raced which is typically used as an active past tense verb). However, evidence from a study by Mitchell (1987) appears highly incompatible with constraint-based accounts. According to Mitchell, the most basic form of information associated with a verb\u2014that of whether a verb is transitive or intransitive, or in other words the verb\u2019s subcategorisation information\u2014may not be available during the initial stages of sentence comprehension. Using materials like those in (2), he found that readers of (2a) were typically slow (relative to a control with a disambiguating adverbial phrase such as during surgery after visited or sneezed) at reading the word wrote. This is to be expected within almost any framework, since it is syntactically permissible (as well as thematically acceptable) for the doctor to be initially interpreted as the direct object of visited. (2a) After the child visited the doctor wrote him a prescription. (2b) After the child sneezed the doctor wrote him a prescription. Crucially, Mitchell also showed that readers were slow to read the doctor in (2b). Since sneezed is a (typically) intransitive verb,2 Mitchell interpreted these \u00a3ndings as suggesting that information about the subcategorisation of sneezed was not initially available to the parsing process (but was made available as soon as later processes could check the plausibility of the doctor as an object of sneezed). Mitchell\u2019s \u00a3ndings are clearly problematic for constraintbased accounts of sentence processing. If the differences between (1a) and (1b) are to be accounted for in terms of information about the (probabilistic) \u2018goodness of \u00a3t\u2019 between a verb and its arguments (including the relative frequencies with which particular subcategorisation frames of a given verb are used), an account must be made of the apparent insensitivity of the human parser to the fact that sneezed is rarely, if ever, used as a transitive verb. Less often remarked upon is the dif\u00a3culty that Mitchell\u2019s results may pose for many syntax \u00a3rst theories. Although the 1Regions of example sentences where more than one interpretation is (potentially) available are typeset in italics, and disambiguating regions are set in bold. 2Almost every \u2018intransitive\u2019 verb, as Adams et al. (1998) note, can be used in some transitive senses, if only in highly stylised phrases such as He sneezed a tiny sneeze, She yawned a big yawn, etc. details of models differ, a number of current positions converge on the importance of (potential) argumenthood, with incoming constituents being preferentially attached to the current phrase marker as arguments rather than as modi\u00a3ers or adjuncts (e.g., Crocker, 1992; Frazier & Clifton, 1996). In order to adjudicate between the attachment of a constituent as a modi\u00a3er or as an argument, the human parser must be aware that a potential site for argument attachment exists. If this information is unavailable at the time a verb is encountered, then an argument attachment strategy would provide a poor account, at least at the explanatory level, of the parser\u2019s behaviour. Interpretations of Mitchell\u2019s \u00a3ndings tend to assume that detailed information about the verb is initially available, but that either linguistic or experimental factors give rise to the results obtained. For example, Tanenhaus and Trueswell (1995) observe that there may be a residual bias to interpret a noun phrase following a verb as its object, lexical biases notwithstanding. This has the advantage of providing a straightforward account of Mitchell\u2019s \u00a3ndings within a constraint satisfaction framework, but the disadvantage that it damages the predictive power of the theory (if dif\u00a3culty in reading (1a) is accounted for in terms of information associated with a particular verb, but Mitchell\u2019s \u00a3ndings are interpreted in the light of the behaviour of verbs in general, how are we to know which factors are likely to in\u00a4uence the interpretations of hitherto untested sentences?). Critics of Mitchell\u2019s experimental design have noted that he used a self-paced reading paradigm in his initial study. Due to the way that the materials were segmented (such that participants saw the words . . . sneezed the doctor in a single display before pressing a key to view the matrix verb of which the doctor was the subject), participants may have been misled into \u2018strategically\u2019 attempting to interpret the doctor as the object of sneezed. This criticism (effectively of the ecological validity of the self-paced reading paradigm) was addressed by Adams, Clifton, and Mitchell (1998), who replicated Mitchell\u2019s experiment using an eyetracker, so that materials did not have to be arti\u00a3cially segmented. Although their \u00a3ndings contradict Mitchell\u2019s, they remain unconvinced that subcategorisation information is initially available. One argument that they make is that Mitchell\u2019s \u00a3ndings must still be accounted for: even if segmentation affects the way in which subjects read Mitchell\u2019s materials, it is clear that it does not cause subjects to violate phrase-structure rules (when attaching adverbials in control materials), whereas subcategorisation information appears to be easily overridden. In this paper, we offer a different interpretation of Mitchell\u2019s \u00a3ndings. This rests on the observation that although intransitive verbs such as sneezed do not subcategorise for object NPs, there is a class of NPs which can legitimately follow them: namely, bare NP adverbs (Larson, 1985). For example, the sentence in (3) is a perfectly acceptable sentence in English. (3) After the child sneezed the other day, the doctor wrote him a prescription. The other day serves an adverbial function; that is, it seems to modify, rather than serve as an argument of, the verb sneezed. If participants are initially aware of the subcategorisation properties of verbs, the delay in reading the doctor in (2b) relative to its control might be accounted for by a system which was working on the assumption that any NP following an intransitive verb such as sneezed would be a bare NP adverb; the delay re\u00a4ects the fact that the doctor must be rejected in this case.","901":"EDD Online, the online version of Joseph Wright\u2018s English Dialect Dictionary, was completed by a project team at the University of Innsbruck in 2019. The sophisticated search-engine of the new interface 3.0 reveals the multifaceted role of semantics in dialect words. Its complexity is due to both the fuzziness of lexical forms and the ambiguity of their meanings. This paper, beyond the theory-biased \u2015complexity debate\u2016, supports the opinion that traditional regional dialects, qua low-contact varieties, have developed a higher degree of lexical complexity than high-contact varieties, i.e. pidgins and creoles, and, in terms of word formation, than the Standard variety of English. The paper first discusses the often polysemous or homophonous meanings of headwords, then of strings within word compositions and phrases. The lemmas also sometimes turn out to be (bound) morphemes or variants. A major aspect in this paper is the wealth of figurative meanings in dialect. This is simply due to the essential role of iconicity, that is, a result of the fact that dialect speakers (\u2015people\u2016) want to \u2015see\u2016 in their minds what they mean.","902":"With the increasing amount of text data in applications, the task of keyphrase extraction receives more attention that aims to extract concise and important information from a document. In this paper, we propose a novel graph-based keyphrase extraction method using word and document embedding vectors. Two graph construction schemes named GKE-w and GKE-p are designed in which candidate words and phrases are represented as nodes respectively. By calculating the similarity between a word\/phrase and the document, each node is assigned an initial weight that reflects the preference to be a keyphrase. Then, we calculate the score of each candidate word\/phrase using a semantic biased random walk strategy. Finally, the Top N scored candidate phrases are selected as the final keyphrases. Experiments on two widely used datasets show that the proposed keyphrase extraction algorithm outperforms the state-of-the-art keyphrase extraction methods in terms of precision, recall, and F1 measures.","903":"Decomposing models into multiple components is critically important in many applications such as language modeling (LM) as it enables adapting individual components separately and biasing of some components to the user's personal preferences. Conventionally, contextual and personalized adaptation for language models, are achieved through class-based factorization, which requires class-annotated data, or through biasing to individual phrases which is limited in scale. In this paper, we propose a system that combines model-defined components, by learning when to activate the generation process from each individual component, and how to combine probability distributions from each component, directly from unlabeled text data.","904":"This paper presents the system description of Machine Translation (MT) systems for English-Bangla language pair. Our goal was to create two benchmark MT systems that produce a better quality translation and comparatively higher evaluation score than existing MT systems for English to Bangla. In our experiments, we implemented two baseline MT systems using both statistical and neural methods for the said language pair. Our phrase-based statistical model and 2-layer LSTM neural model were trained and evaluated with a large dataset that is carefully pre-processed and contains unique training data to avoid biases from the cross-validation and test data. We achieved the highest scoring BLEU for our experiments with these setups. Furthermore, we improved the performance of the neural model using pre-trained embedding and synthetic monolingual data which are cutting-edge technology for neural models.","905":null,"906":"A growing number of studies support the partial compositionality of idiomatic phrases, while idioms are thought to vary in their syntactic flexibility. Some idioms, like kick the bucket, have been classified as inflexible and incapable of being passivized without losing their figurative interpretation (i.e., the bucket was kicked \u2260 died). Crucially, this has never been substantiated by empirical findings. In the current study, we used eye-tracking to examine whether the passive forms of (flexible and inflexible) idioms retain or lose their figurative meaning. Active and passivized idioms (he kicked the bucket\/the bucket was kicked) and incongruous active and passive control phrases (he kicked the apple\/the apple was kicked) were inserted in sentences biasing the figurative meaning of the respective idiom (die). Active idioms served as a baseline. We hypothesized that if passivized idioms retain their figurative meaning (the bucket was kicked = died), they should be processed more efficiently than the control phrases, since their figurative meaning would be congruous in the context. If, on the other hand, passivized idioms lose their figurative interpretation (the bucket was kicked = the pail was kicked), then their meaning should be just as incongruous as that of both control phrases, in which case we would expect no difference in their processing. Eye movement patterns demonstrated a processing advantage for passivized idioms (flexible and inflexible) over control phrases, thus indicating that their figurative meaning was not compromised. These findings challenge classifications of idiom flexibility and highlight the creative nature of language.","907":"The problem of sentiment analysis has been widely studied in the past several decades. The research in the area has been predominantly based on data collated from online messages, microblogs, reviews, etc. Significantly fewer studies have been conducted based on academic discourse and especially school textbooks. However, sentiment analysis of academic texts can help answer pressing issues relating the ways in which different referents are presented in contemporary Russian school textbooks. In this paper, we analyze the distribution of sentiment words and phrases in a Corpus of Russian school textbooks on History (Grades 10\u201311) and Social Sciences (Grades 5-11). The results of the study demonstrate that the discourse within (1) History textbooks used in the 10th and 11th grades of Russian schools and (2) Social Studies textbooks written by Nikitin for Russian schools (Grades 5-11) contains predominantly negative sentiment: the writers select negatively valenced words and prefer presenting negative referents. By contrast, the discourse within the set of Social Studies textbooks written by Bogolubov revealed a predominantly positive bias. The authors discuss the implications of these trends in relation to the potential impact of the tone of educational discourse on learning.","908":"This paper describes Designovel's systems which are submitted to the Fashion IQ Challenge 2019. Goal of the challenge is building an image retrieval system where input query is a candidate image plus two text phrases describe user's feedback about visual differences between the candidate image and the search target. We built the systems by combining methods from recent work on deep metric learning, multi-modal retrieval and natual language processing. First, we encode both candidate and target images with CNNs into high-level representations, and encode text descriptions to a single text vector using Transformer-based encoder. Then we compose candidate image vector and text representation into a single vector which is exptected to be biased toward target image vector. Finally, we compute cosine similarities between composed vector and encoded vectors of whole dataset, and rank them in desceding order to get ranked list. We experimented with Fashion IQ 2019 dataset in various settings of hyperparameters, achieved 39.12% average recall by a single model and 43.67% average recall by an ensemble of 16 models on test dataset.","909":"Many of us rely on \u201cGoogle Translate\u201d and other Artificial Intelligence and Machine Learning (\u201cAI\u201d) online translation on a daily basis for personal or commercial use. These AI systems have become ubiquitous and are poised to revolutionize human communication across the globe. Promising increased fluency across cultures by breaking down linguistic barriers and promoting cross-cultural relationships in a way that many civilizations have historically sought and struggled to achieve, AI translation affords users the means to turn any text \u2014 from phrases to books \u2014 into cognizable expression. \n \nThis Article discusses the burgeoning possibilities in the 3A Era (Advanced, Autonomous, AI systems), of AI online translation as accessible tools, whose users are data suppliers and feedback providers, and hence, contributors to the programing and improvement processes of these AI translation tools. On the other hand, this Article also acknowledges the real concerns this new realm raises, stemming from malicious uses of AI, which are most often concealed from the public. Such hidden aspects include built-in algorithmic biases, such as race, sex and gender, color, religion, or national origin biases, which this article addresses in a discussion of AI systems\u2019 systemic shortcomings. Because AI translation systems learn and function through the data they receive from data providers, they are vulnerable to societal biases; when users offer feedback, these systems may perpetuate sexist, racist, or otherwise objectionable expressions, of which other users, when consulting the systems, are unaware. \n \nFurthermore, examining the current copyright regime, the Article claims, for the first time, that we (as users), have become inadvertent infringers of legal rights, since a translation, according to copyright law, is a derivative work owned and controlled by the author. As such, an author\u2019s permission is necessary prior to the creation of a translation, with the author in a position to collect payment when due. Moreover, under current law, the Fair Use doctrine is frequently inapplicable. This Article claims that the legal and academic communities, and policy makers, have failed to address AI translation systems within the copyright regime and further argues that this failure renders the current copyright regime outdated and ill-equipped to handle the advent of sophisticated AI tools. Additionally, this Article states that the present inability of AI technology to routinely capture the nuance of human prose gives rise to another concern. The ubiquitous role such (as-yet) flawed AI online translation systems play in translation services, for personal or commercial purposes, should be better balanced with the concerns of authors \u2014 who may worry about the linguistic integrity of an AI translation of their work \u2014 and their rights, in certain circumstances, to control translations of their work and object to unauthorized AI translations. \n \nUnderstanding the concerns attending unauthorized AI translations under the current copyright regime, while still recognizing that users should be able to profit from the wellspring of literacy which AI translation offers, this Article argues for a harmonization of AI translation with amended copyright protection. \n \nTo that end, this Article calls on policymakers to adjust the current legal regime to include advanced technologies and suggests new principles for combining legal tools with technological ones. Such an approach would better balance the benefits of accessible AI translation systems with the requirements of a modified, modern copyright regime, via the implementation of a method coined \u201cfair use and equality by design.\u201d Additionally, by recognizing the conflicting interests at stake, this Article invites international policymakers, such as WIPO (the World Intellectual Property Organization), to promote the development of international standardized guidelines for the use of AI translation systems, and possibly other AI systems, by emphasizing fair use (exemptions and limitations). \n \nThis Article concludes that by understanding the significant drawbacks of AI translation systems and adopting the suggested principles, as discussed throughout this study, policymakers can promote access to an evolving AI technology, while also recognizing the integrity of authors\u2019 linguistic choices and preserving the beauty of linguistic diversity \u2014 which, as the ancient story of Babel hinted, is valuable because of, not despite, the challenges it poses.","910":null,"911":"Contents: Part I: Refereed Papers. M. Abu-Bakar, N. Chater, Distribution and Frequency: Modelling the Effects of Speaking Rate on Category Boundaries Using a Recurrent Neural Network. W. Ahn, J. Bailenson, B. Gordon, Causal Attribution as Mechanism-Based Story Construction: An Explanation of the Conjunction Fallacy and the Discounting Principle. B.G. Bara, M. Bucciarelli, P.N. Johnson-Laird, V. Lombardo, Mental Models in Propositional Reasoning. J.A. Barnden, S. Helmreich, E. Iverson, G.C. Stein, Combining Simulative and Metaphor-Based Reasoning About Beliefs. J. Batali, Artificial Evolution of Syntactic Aptitude. B. Bell, S. Kedar, R. Bareiss, Interactive Model-Driven Case Adaptation for Instructional Software Design. K. Bielaczyc, P.L. Pirolli, A.L. Brown, Collaborative Explanations and Metacognition: Identifying Successful Learning Activities in the Acquisition of Cognitive Skills. A. Blackwell, E. Bates, Inducing Agrammatic Profiles in Normals. S.B. Blessing, B.H. Ross,Problem Content Affects the Categorization and Solutions of Problems. N. Braisby, B. Franks, J. Hampton, On the Psychological Basis for Rigid Designation. W.F. Brewer, C.A. Chinn, The Theory-Ladenness of Data: An Experimental Demonstration. A. Brook ,Kant and Cognitive Science. D. Buckingham, T.R Shultz, A Connectionist Model of the Development of Velocity, Time, and Distance Concepts. J.A. Bullinaria ,Connectionist Modelling of Spelling. J.A. Bullinaria, Internal Representations of a Connectionist Model of Reading Aloud. C. Burgess, K. Lund, Multiple Constraints in Syntactic Ambiguity Resolution: A Connectionist Account of Psycholinguistic Data. C. Burgess, M.K. Tanenhaus, M. Hoffman, Parafoveal and Semantic Effects on Syntactic Ambiguity Resolution. B.D. Burns, K.J. Holyoak, Competing Models of Analogy: ACME Versus Copycat. M.H. Burstein, Case Age: Selecting the Best Exemplars for Plausible Reasoning Using Distance in Time or Space. J.G. Bush, H.M. Johnson, C.M. Seifert, The Implications of Corrections: Then Why Did You Mention It? M.D. Byrne, Integrating, Not Debating, Situated Action and Computational Models: Taking the Environment Seriously. R.M.J. Byrne, A. Tasso, Counterfactual Reasoning: Inferences From Hypothetical Conditionals. A. Cabrera, Functional and Conditional Equivalence: Conceptual Contributions From Behavior Analysis. P. Cairns, R. Shillcock, N. Chater, J. Levy,Lexical Segmentation: The Role of Sequential Statistics in Supervised and Un-Supervised Models. T. Carpenter, R. Alterman, A Taxonomy for Planned Reading. T.A. Cartwright, M.R. Brent, Segmenting Speech Without a Lexicon: Evidence for a Bootstrapping Model of Lexical Acquisition. J. Cassell, M. Stone, B. Douville, S. Prevost, B. Achorn, M. Steedman, N. Badler, C. Pelachaud, Modeling the Interaction Between Speech and Gesture. R. Catrambone, The Effects of Labels in Examples on Problem Solving Transfer. H. Chalupsky, S.C. Shapiro,SL: A Subjective, Intensional Logic of Belief. P.C-H. Cheng, An Empirical Investigation of Law Encoding Diagrams for Instruction. C.A. Chinn, Are Scientific Theories That Predict Data More Believable Than Theories That Retrospectively Explain Data? A Psychological Investigation. M.M. Chiu, J. Gutwill, The Architecture of Intuition: Converging Views From Physics Education and Linguistics. T.C. Clausner, Commonsense Knowledge and Conceptual Structure in Container Metaphors. C. Cleary, R. Bareiss, A Descriptive Model of Question Asking During Acquisition Interviews. J. Clement,Imagistic Simulation and Physical Intuition in Expert Problem Solving. A. Content, P. Sternon, Modelling Retroactive Context Effects in Spoken Word Recognition With a Simple Recurrent Network. A.T. Corbett, J.R. Anderson, V.H Carver, S.A. Brancolini, Individual Differences and Predictive Validity in Student Modeling. S. Coulson, N.V. Flor, Rational Choice and Framing Devices: Argumentation and Computer Programming. M.T. Cox,Machines That Forget: Learning From Retrieval Failure of Mis-Indexed Explanations. M.T. Cox, A. Ram, Failure-Driven Learning as Input Bias. R. Cox, K. Stenning, J. Oberlander, Graphical Effects in Learning Logic: Reasoning, Representation and Individual Differences. S. Dennis, The Null List Strength Effect in Recognition Memory: Environmental Statistics and Connectionist Accounts. S. Derry, K. Tookey, Effects of Collaborative Interaction and Computer Tool Use. S.M. Doane, Y.W. Sohn. D. Adams, D.S. McNamara, Learning From Instruction: A Comprehension-Based Approach. R. Elio, F.J. Pelletier, The Effect of Syntactic Form on Simple Belief Revisions and Updates. R.A. Engle, J.G. Greeno, Managing Disagreement in Intellectual Conversations Coordinating Interpersonal and Conceptual Concerns in the Collaborative Construction of Mathematical Explanations. J. Epelboim, H. Collewijn, E. Kowler, C.J. Erkelens, M. Edwards, Z. Pizlo, R.M. Steinman, Natural Oculomotor Performance in Looking and Tapping Tasks. J.M. Faries, K.R. Schlossberg, The Effect of Similarity on Memory for Prior Problems. R.W. Ferguson, MAGI: Analogy-Based Encoding Using Regularity and Symmetry. E.C. Ferstl, The Construction-Integration Model: A Framework for Studying Context Effects in Sentence Processing. E.C. Ferstl, Context Effects in Syntactic Ambiguity Resolution: The Location of Prepositional Phrase Attachment. S. Finch, N. Chater, Distributional Bootstrapping: From Word Class to Proto-Sentence. M.H. Fischer, Attention Allocation During Movement Preparation. K.D. Forbus, R.W. Ferguson, D. Gentner, Incremental Structure-Mapping. N. Forrester, K. Plunkett, Learning the Arabic Plural: The Case for Minority Default Mappings in Connectionist Networks. S. Fox, D. Leake, Using Introspective Reasoning to Guide Index Refinement in Case-Based Reasoning. G. Francis, S. Grossberg, How Do Representations of Visual Form Organize Our Percepts of Visual Motion? R.M. French, Dynamically Constraining Connectionist Networks to Produce Distributed, Orthogonal Representations to Reduce Catastrophic Interference. G. Gaskell, W. Marslen-Wilson, Inference Processes in Speech Perception. M. Gattis, K.J. Holyoak, How Graphs Mediate Analog and Symbolic Representation. D. Gentner, B.F. Bowdle, The Coherence Imbalance Hypothesis: A Functional Approach to Asymmetry in Comparison. E. Gibson, J. Loomis, A Corpus Analysis of Recency Preference and Predicate Proximity. S.A. Gilbert, W. Richards, Using Trajectory Mapping to Analyze Musical Intervals. S. Gillis, W. Daelemans, G. Durieux, Are Children 'Lazy Learners'? A Comparison of Natural and Machine Learning of Stress. J. Glasgow, Array Representations for Model-Based Spatial Reasoning. A. Gordon, P. Edwards, D. Sleeman, Y. Kodratoff, Scientific Discovery in a Space of Structural Models: An Example From the History of Solution Chemistry. A. Grunewald, S. Grossberg, Binding of Object Representations by Synchronous Cortical Dynamics Explains Temporal Order and Spatial Pooling Data. M. Harm, L. Altmann, M.S. Seidenberg, Using Connectionist Networks to Examine the Role of Prior Constraints in Human Learning. P.M. Hastings, S.L. Lytinen, Objects, Actions, Nouns, and Verbs. C. Hewson, Empirical Evidence Regarding the Folk Psychological Concept of Belief. C. Hewson, C. Vogel, Psychological Evidence for Assumptions of Path-Based Inheritance Reasoning. K. Hiraki, Abstraction of Sensory-Motor F","912":"Expanding abbreviations in source code to their full meanings is very useful for software maintainers to comprehend the source code. The existing approaches, however, focus on expanding an abbreviation to a single word, i.e., unigram. They do not perform well when dealing with abbreviations of phrases that consist of multiple unigrams. This paper proposes a bigram-based approach for retrieving abbreviated phrases automatically. Key to this approach is a bigram-based inference model for choosing the best phrase from all candidates. It utilizes the statistical properties of unigrams and bigrams as prior knowledge and a bigram language model for estimating the likelihood of each candidate phrase of a given abbreviation. We have applied the bigram-based approach to 100 phrase abbreviations, randomly selected from eight open source projects. The experiment results show that it has correctly retrieved 78% of the abbreviations by using the unigram and bigram properties of a source code repository. This is 9% more accurate than the unigram-based approach and much better than other existing approaches. The bigram-based approach is also less biased towards specific phrase sizes than the unigram-based approach.","913":"ABSTRACT Restrictive contextual information has been found to bias syntactic disambiguation, when only one alternative leads to a meaningful interpretation. The current study tests whether disambiguation can be influenced by nonrestrictive cues \u2013 when several alternatives are equally plausible. We first evaluated if modifier number biased the disambiguation of number- and case-ambiguous nouns in Basque. In a noun phrase comprehension paradigm, ambiguous noun number judgments were biased by preceding modifier number. Then, using a preamble completion paradigm, we examined whether headnoun disambiguation and thus sentence completion was also biased by modifier number. Our results suggest that nonrestrictive information (singular and plural number) can affect disambiguation. We also report task differences in the overall interpretation of ambiguous Basque nouns, as well modifier-induced agreement errors. We suggest that the parser uses any available context information when there is ambiguity, including preceding modifier markings.","914":"While real world challenges typically define visual categories with language words or phrases, most visual classification methods define categories with numerical indices. However, the language specification of the classes provides an especially useful prior for biased and noisy datasets, where it can help disambiguate what features are taskrelevant. Recently, large-scale multimodal models have been shown to recognize a wide variety of high-level concepts from a language specification even without additional image training data, but they are often unable to distinguish classes for more fine-grained tasks. CNNs, in contrast, can extract subtle image features that are required for finegrained discrimination, but will overfit to any bias or noise in datasets. Our insight is to use high-level language specification as advice for constraining the classification evidence to task-relevant features, instead of distractors. To do this, we ground task-relevant words or phrases with attention maps from a pretrained large-scale model. We then use this grounding to supervise a classifier\u2019s spatial attention away from distracting context. We show that supervising spatial attention in this way improves performance on classification tasks with biased and noisy data, including \u223c3\u221215% worst-group accuracy improvements and\u223c41\u221245% relative improvements on fairness metrics.","915":"Contextual biasing is an important and challenging task for end-to-end automatic speech recognition (ASR) systems, which aims to achieve better recognition performance by biasing the ASR system to particular context phrases such as person names, music list, proper nouns, etc. Existing methods mainly include contextual LM biasing and adding bias encoder into end-to-end ASR models. In this work, we introduce a novel approach to do contextual biasing by adding a contextual spelling correction model on top of the end-to-end ASR system. We incorporate contextual information into a sequence-to-sequence spelling correction model with a shared context encoder. Our proposed model includes two different mechanisms: autoregressive (AR) and non-autoregressive (NAR). We propose filtering algorithms to handle large-size context lists, and performance balancing mechanisms to control the biasing degree of the model. We demonstrate the proposed model is a general biasing solution which is domain-insensitive and can be adopted in different scenarios. Experiments show that the proposed method achieves as much as 51% relative word error rate (WER) reduction over ASR system and outperforms traditional biasing methods. Compared to the AR solution, the proposed NAR model reduces model size by 43.2% and speeds up inference by 2.1 times.","916":"Pronoun resolution is part of coreference resolution, the task of pairing an expression to its referring entity. This is an important task for natural language understanding and a necessary component of machine translation systems, chat bots and assistants. Neural machine learning systems perform far from ideally in this task, reaching as low as 73% F1 scores on modern benchmark datasets. Moreover, they tend to perform better for masculine pronouns than for feminine ones. Thus, the problem is both challenging and important for NLP researchers and practitioners. In this project, we describe our BERT-based approach to solving the problem of gender-balanced pronoun resolution. We are able to reach 92% F1 score and a much lower gender bias on the benchmark dataset shared by Google AI Language team.","917":"ABSTRACT It has long been recognised that phrases and sentences are organised hierarchically, but many computational models of language treat them as sequences of words without computing constituent structure. Against this background, we conducted two experiments which showed that participants interpret ambiguous noun phrases, such as second blue ball, in terms of their abstract hierarchical structure rather than their linear surface order. When a neural network model was tested on this task, it could simulate such \u201chierarchical\u201d behaviour. However, when we changed the training data such that they were not entirely unambiguous anymore, the model stopped generalising in a human-like way. It did not systematically generalise to novel items, and when it was trained on ambiguous trials, it strongly favoured the linear interpretation. We argue that these models should be endowed with a bias to make generalisations over hierarchical structure in order to be cognitively adequate models of human language.","918":"Job advertisements in white male-dominated organizations are often biased in ways that discourage female and minority candidates from applying. We explored the use of a female African American virtual agent who provides a first-person reaction to a biased job advertisement, providing an impassioned, vivid description of her feelings about the advertisement, the position, and the organization offering the job, and how the position---as described---would impact her life were she to take the job. We evaluate the impact interactions with this agent have on the effort study participants invest in editing the job advertisement following their interaction with the agent, compared to reading a page of standard educational text on diversity in hiring. Participants who interacted with the agent spent significantly more effort correcting the job ad, as measured both by the number of edit operations and the number of biased phrases removed, compared to participants in the control condition. Implications and a future research agenda for increasing diversity using virtual agents are presented.","919":"Children often interpret first noun phrases (NP1s) as agents, which improves comprehension of actives but hinders passives. While children sometimes withhold the agent-first bias, the reasons remain unclear. The current study tests the hypothesis that children default to the agent-first bias as a \"best guess\" of role assignment when they face uncertainty about sentence properties. Thus, rather than always relying on early-arriving cues, children can attend to different sentence cues across communicative contexts. To test this account, we manipulated interpretive uncertainty by varying cues to the discourse status of initial arguments (referring to new vs. given entities) and measured interpretation accuracy for active (where the agent-first bias predicted verb morphology) and passive sentences (where the two conflicted). Across three experiments, we found that children relied on the agent-first bias more when new discourse entities were signaled by definite NP1s, reference to unmentioned entities, and novel words. This, in turn, led to higher accuracy for actives relative to passives. In contrast, when given entities were implied through pronoun NP1s, reference to mentioned entities, and known words, children avoided the agent-first bias and instead assigned roles using more reliable but later-arriving verb morphology. This led to similar comprehension accuracy across constructions. These findings suggest that children simultaneously interpret relations between sentences (e.g., discourse continuity) and within sentences (e.g., role assignment), such that commitments to the former can influence parsing cues for the latter.","920":"Cleve\u2019s celebrated lower bound (STOC\u201986) showed that a de facto strong fairness notion is impossible in 2-party coin toss, i.e., the corrupt party always has a strategy of biasing the honest party\u2019s outcome by a noticeable amount. Nonetheless, Blum\u2019s famous coin-tossing protocol (CRYPTO\u201981) achieves a strictly weaker \u201cgame-theoretic\u201d notion of fairness \u2014 specifically, it is a 2-party coin toss protocol in which neither party can bias the outcome towards its own preference; and thus the honest protocol forms a Nash equilibrium in which neither party would want to deviate. Surprisingly, an n-party analog of Blum\u2019s famous coin toss protocol was not studied till recently. The work by Chung et al. (TCC\u201918) was the first to explore the feasibility of game-theoretically fair n-party coin toss in the presence of corrupt majority. We may assume that each party has a publicly stated preference for either the bit 0 or 1, and if the outcome agrees with the party\u2019s preference, it obtains utility 1; else it obtains nothing. A natural game-theoretic formulation is to require that the honest protocol form a coalitionresistant Nash equilibrium, i.e., no coalition should have incentive to deviate from the honest behavior. Chung et al. phrased this game-theoretic notion as \u201ccooperative-strategy-proofness\u201d or \u201cCSP-fairness\u201d for short. Unfortunately, Chung et al. showed that under (n\u2212 1)-sized coalitions, it is impossible to design such a CSP-fair coin toss protocol, unless all parties except one prefer the same bit. In this paper, we show that the impossibility of Chung et al. is in fact not as broad as it may seem. When coalitions are majority but not n\u22121 in size, we can indeed get feasibility results in some meaningful parameter regimes. We give a complete characterization of the regime in which CSP-fair coin toss is possible, by providing a matching upperand lower-bound. Our complete characterization theorem also shows that the mathematical structure of game-theoretic fairness is starkly different from the de facto strong fairness notion in the multi-party computation literature. The author ordering is randomized kew2@andrew.cmu.edu gilad.asharov@biu.ac.il runting@gmail.com","921":"We present a novel rational-centric framework with human-in-the-loop \u2013 Rationales-centric Double-robustness Learning (RDL) \u2013 to boost model out-of-distribution performance in few-shot learning scenarios. By using static semi-factual generation and dynamic human-intervened correction, RDL, acting like a sensible \u201cinductive bias\u201d, exploits rationales (i.e. phrases that cause the prediction), human interventions and semi-factual augmentations to decouple spurious associations and bias models towards generally applicable underlying distributions, which enables fast and accurate generalisation. Experimental results show that RDL leads to significant prediction benefits on both in-distribution and out-of-distribution tests, especially for few-shot learning scenarios, compared to many state-of-the-art benchmarks. We also perform extensive ablation studies to support in-depth analyses of each component in our framework.","922":"One of the most ubiquitous techniques for evaluating research, particularly in educational settings, has been Likert-style questionnaires. Having a participant rank their level of engagement, agreement, or interest on a scale can provide powerful insight into an individual's perspective and attitude. However, as computing education matures as a discipline it becomes important for us to examine our practices and ensure that we are employing the techniques of evaluation properly. Likert-style questionnaires can be prone to unintentional biases and noise which, from the perspective of the researcher, may affect the study in unknown, unexpected, and potentially undesirable ways. In this research we seek to aid the computing education researcher not only avoid biases and noise but also improve the reproducibility of their work. First, we establish best practices for these instruments by synthesizing recommendations from the original creator, Rensis Likert, the Center for Disease Control (CDC), the Association of American Medical Colleges (AAMC), and the American Association for Public Opinion Research (AAPOR). We then considered additional sources of unintentional biasing and noise resulting from the measurement scales\/response options, specifically possible biasing resulting from how response options are presented to the study participant. With these recommendations, we then examined 121 evaluation instruments used in computer science education research and curated in the csedresearch.org online database to see how often researchers unintentionally fall victim to the pitfalls of ambiguity, awkward phrasing, use of conjunctions, leading or biased statements, and double negatives. We found that the occurrence of at least one of these problematic statements to be in 82.6% of all instruments. We also examine demographic information for the intended study participants, number of response options, and how those options are presented. Overall, while we see many instrument authors falling victim to a few of these common pitfalls, we believe that increased awareness of potentially problematic statements\/measurement scales and their impact on research bias and reproducibility will help insulate computing education researchers from avoidable complications and strengthen the discipline throughout.","923":"The success of speech assistants requires precise recognition of a number of entities on particular contexts. A common solution is to train a class-based n-gram language model and then expand the classes into specific words or phrases. However, when the class has a huge list, e.g., more than 20 million songs, a fully expansion will cause memory explosion. Worse still, the list items in the class need to be updated frequently, which requires a dynamic model updating technique. In this work, we propose to train pruned language models for the word classes to replace the slots in the root n-gram. We further propose to use a novel technique, named Difference Language Model (DLM), to correct the bias from the pruned language models. Once the decoding graph is built, we only need to recalculate the DLM when the entities in word classes are updated. Results show that the proposed method consistently and significantly outperforms the conventional approaches on all datasets, esp. for large lists, which the conventional approaches cannot handle.","924":null,"925":"Counterfactual statements describe events that did not or cannot take place. We consider the problem of counterfactual detection (CFD) in product reviews. For this purpose, we annotate a multilingual CFD dataset from Amazon product reviews covering counterfactual statements written in English, German, and Japanese languages. The dataset is unique as it contains counterfactuals in multiple languages, covers a new application area of e-commerce reviews, and provides high quality professional annotations. We train CFD models using different text representation methods and classifiers. We find that these models are robust against the selectional biases introduced due to cue phrase-based sentence selection. Moreover, our CFD dataset is compatible with prior datasets and can be merged to learn accurate CFD models. Applying machine translation on English counterfactual examples to create multilingual data performs poorly, demonstrating the language-specificity of this problem, which has been ignored so far.","926":"Each language has its own complex systems of word, phrase, and sentence construction, the guiding principles of which are often summarized in grammar descriptions for the consumption of linguists or language learners. However, manual creation of such descriptions is a fraught process, as creating descriptions which describe the language in \u201cits own terms\u201d without bias or error requires both a deep understanding of the language at hand and linguistics as a whole. We propose an automatic framework AUTOLEX that aims to ease linguists\u2019 discovery and extraction of concise descriptions of linguistic phenomena. Specifically, we apply this framework to extract descriptions for three phenomena: morphological agreement, case marking, and word order, across several languages. We evaluate the descriptions with the help of language experts and propose a method for automated evaluation when human evaluation is infeasible.1","927":"Being a global pandemic, the COVID-19 outbreak received global media attention. In this study, we analyze news publications from CNN and The Guardian - two of the world\u2019s most influential media organizations. The dataset includes more than 36,000 articles, analyzed using the clinical and biomedical Natural Language Processing (NLP) models from the Spark NLP for Healthcare library, which enables a deeper analysis of medical concepts than previously achieved. The analysis covers key entities and phrases, observed biases, and change over time in news coverage by correlating mined medical symptoms, procedures, drugs, and guidance with commonly mentioned demographic and occupational groups. Another analysis is of extracted Adverse Drug Events about drug and vaccine manufacturers, which when reported by major news outlets has an impact on vaccine hesitancy.","928":"On Wikipedia, an online crowdsourced encyclopedia, volunteers enforce the encyclopedia\u2019s editorial policies. Wikipedia\u2019s policy on maintaining a neutral point of view has inspired recent research on bias detection, including \u201cweasel words\u201d and \u201chedges\u201d. Yet to date, little work has been done on identifying \u201cpuffery,\u201d phrases that are overly positive without a verifiable source. We demonstrate that collecting training data for this task requires some care, and construct a dataset by combining Wikipedia editorial annotations and information retrieval techniques. We compare several approaches to predicting puffery, and achieve 0.963 f1 score by incorporating citation features into a RoBERTa model. Finally, we demonstrate how to integrate our model with Wikipedia\u2019s public infrastructure to give back to the Wikipedia editor community.","929":"LSTMs have proven very successful at language modeling. However, it remains unclear to what extent they are able to capture complex morphosyntactic structures. In this paper, we examine whether LSTMs are sensitive to verb argument structures. We introduce a German grammaticality dataset in which ungrammatical sentences are constructed by manipulating case assignments (eg substituting nominative by accusative or dative). We find that LSTMs are better than chance in detecting incorrect argument structures and slightly worse than humans tested on the same dataset. Surprisingly, LSTMs are contaminated by heuristics not found in humans like a preference toward nominative noun phrases. In other respects they show human-similar results like biases for particular orders of case assignments.","930":"We show how the random coefficient logistic demand (BLP) model can be phrased as an automatically differentiable moment function, including the incorporation of numerical safeguards proposed in the literature. This allows gradient-based frequentist and quasi-Bayesian estimation using the Continuously Updating Estimator (CUE). Drawing from the machine learning literature, we outline hitherto under-utilized best practices in both frequentist and Bayesian estimation techniques. Our Monte Carlo experiments compare the performance of CUE, 2S-GMM, and LTE estimation. Preliminary findings indicate that the CUE estimated using LTE and frequentist optimization has a lower bias but higher MAE compared to the traditional 2-Stage GMM (2S-GMM) approach. We also find that using credible intervals from MCMC sampling for the non-linear parameters together with frequentist analytical standard errors for the concentrated out linear parameters provides empirical coverage closest to the nominal level. The accompanying admest Python package provides a platform for replication and extensibility.","931":"Pretrained transformer-based language models achieve state-of-the-art performance in many NLP tasks, but it is an open question whether the knowledge acquired by the models during pretraining resembles the linguistic knowledge of humans. We present both humans and pretrained transformers with descriptions of events, and measure their preference for telic interpretations (the event has a natural endpoint) or atelic interpretations (the event does not have a natural endpoint). To measure these preferences and determine what factors influence them, we design an English test and a novel-word test that include a variety of linguistic cues (noun phrase quantity, resultative structure, contextual information, temporal units) that bias toward certain interpretations. We find that humans\u2019 choice of telicity interpretation is reliably influenced by theoretically-motivated cues, transformer models (BERT and RoBERTa) are influenced by some (though not all) of the cues, and transformer models often rely more heavily on temporal units than humans do.","932":"The underlying structure of natural language is hierarchical; words combine into phrases, which in turn form clauses. An awareness of this hierarchical structure can aid machine learning models in performing many linguistic tasks. However, most such models just process text sequentially and there is no bias towards learning hierarchical structure encoded into their architecture. In this paper, we extend the recent transformer model (Vaswani et al., 2017) by enabling it to learn hierarchical representations. To achieve this, we adapt the ordering mechanism introduced in Shen et al., 2018, to the self-attention module of the transformer architecture. We train our new model on language modelling and then apply it to the task of unsupervised parsing. We achieve reasonable results on the freely available subset of the WSJ10 dataset with an F1-score of about 50%.","933":null,"934":"Temporal Sentence Grounding in Videos (TSGV), which aims to ground a natural language sentence that indicates complex human activities in an untrimmed video, has drawn widespread attention over the past few years. However, recent studies have found that current benchmark datasets may have obvious moment annotation biases, enabling several simple baselines even without training to achieve state-of-the-art (SOTA) performance. In this paper, we take a closer look at existing evaluation protocols for TSGV, and find that both the prevailing dataset splits and evaluation metrics are the devils that lead to untrustworthy benchmarking. Therefore, we propose to re-organize the two widely-used datasets, making the ground-truth moment distributions different in the training and test splits, i.e., out-of-distribution (OOD) test. Meanwhile, we introduce a new evaluation metric \u201cdR@n,IoU@m\u201d that discounts the basic recall scores especially with small IoU thresholds, so as to alleviate the inflating evaluation caused by biased datasets with a large proportion of long ground-truth moments. New benchmarking results indicate that our proposed evaluation protocols can better monitor the research progress in TSGV. Furthermore, we propose a novel causality-based Multi-branch Deconfounding Debiasing (MDD) framework for unbiased moment prediction. Specifically, we design a multi-branch deconfounder to eliminate the effects caused by multiple confounders with causal intervention. In order to help the model better align the semantics between sentence queries and video moments, we enhance the representations during feature encoding. Specifically, for textual information, the query is parsed into several verb-centered phrases to obtain a more fine-grained textual feature. For visual information, the positional information has been decomposed from the moment features to enhance the representations of moments with diverse locations. Extensive experiments demonstrate that our proposed approach can achieve competitive results among existing SOTA approaches and outperform the base model with great gains.","935":"Language coverage bias, which indicates the content-dependent differences between sentence pairs originating from the source and target languages, is important for neural machine translation (NMT) because the target-original training data is not well exploited in current practice. By carefully designing experiments, we provide comprehensive analyses of the language coverage bias in the training data, and find that using only the source-original data achieves comparable performance with using full training data. Based on these observations, we further propose two simple and effective approaches to alleviate the language coverage bias problem through explicitly distinguishing between the sourceand target-original training data, which consistently improve the performance over strong baselines on six WMT20 translation tasks. Complementary to the translationese effect, language coverage bias provides another explanation for the performance drop caused by back-translation (Marie et al., 2020). We also apply our approach to both backand forward-translation and find that mitigating the language coverage bias can improve the performance of both the two representative data augmentation methods and their tagged variants (Caswell et al., 2019).","936":"Estimating the data uncertainty in regression tasks is often done by learning a quantile function or a prediction interval of the true label conditioned on the input. It is frequently observed that quantile regression\u2014a vanilla algorithm for learning quantiles with asymptotic guarantees\u2014tends to under-cover than the desired coverage level in reality. While various fixes have been proposed, a more fundamental understanding of why this under-coverage bias happens in the first place remains elusive. In this paper, we present a rigorous theoretical study on the coverage of uncertainty estimation algorithms in learning quantiles. We prove that quantile regression suffers from an inherent under-coverage bias, in a vanilla setting where we learn a realizable linear quantile function and there is more data than parameters. More quantitatively, for \u03b1 > 0.5 and small d\/n, the \u03b1-quantile learned by quantile regression roughly achieves coverage \u03b1\u2212 (\u03b1\u2212 1\/2) \u00b7 d\/n regardless of the noise distribution, where d is the input dimension and n is the number of training data. Our theory reveals that this under-coverage bias stems from a certain high-dimensional parameter estimation error that is not implied by existing theories on quantile regression. Experiments on simulated and real data verify our theory and further illustrate the effect of various factors such as sample size and model capacity on the under-coverage bias in more practical setups.","937":null,"938":"In this paper, we present the downlink coverage and rate analysis of a cellular vehicle-to-everything (C-V2X) communication network where the locations of vehicular nodes and road side units (RSUs) are modeled as Cox processes driven by a Poisson line process (PLP) and the locations of cellular macro base stations (MBSs) are modeled as a 2D Poisson point process (PPP). Assuming a fixed selection bias and maximum average received power based association, we compute the probability with which a typical receiver, an arbitrarily chosen receiving node, connects to a vehicular node or an RSU and a cellular MBS. For this setup, we derive the signal-to-interference ratio (SIR)-based coverage probability of the typical receiver. One of the key challenges in the computation of coverage probability stems from the inclusion of shadowing effects. As the standard procedure of interpreting the shadowing effects as random displacement of the location of nodes is not directly applicable to the Cox process, we propose an approximation of the spatial model inspired by the asymptotic behavior of the Cox process. Using this asymptotic characterization, we derive the coverage probability in terms of the Laplace transform of interference power distribution. Further, we compute the downlink rate coverage of the typical receiver by characterizing the load on the serving vehicular nodes or RSUs and serving MBSs. We also provide several key design insights by studying the trends in the coverage probability and rate coverage as a function of network parameters. We observe that the improvement in rate coverage obtained by increasing the density of MBSs can be equivalently achieved by tuning the selection bias appropriately without the need to deploy additional MBSs.","939":"Many recommender systems suffer from popularity bias: popular items are recommended frequently while less popular, niche products, are recommended rarely or not at all. However, recommending the ignored products in the `long tail' is critical for businesses as they are less likely to be discovered. In this paper, we introduce a personalized diversification re-ranking approach to increase the representation of less popular items in recommendations while maintaining acceptable recommendation accuracy. Our approach is a post-processing step that can be applied to the output of any recommender system. We show that our approach is capable of managing popularity bias more effectively, compared with an existing method based on regularization. We also examine both new and existing metrics to measure the coverage of long-tail items in the recommendation.","940":"Recommender systems are known to suffer from the popularity bias problem: popular (i.e. frequently rated) items get a lot of exposure while less popular ones are under-represented in the recommendations. Research in this area has been mainly focusing on finding ways to tackle this issue by increasing the number of recommended long-tail items or otherwise the overall catalog coverage. In this paper, however, we look at this problem from the users' perspective: we want to see how popularity bias causes the recommendations to deviate from what the user expects to get from the recommender system. We define three different groups of users according to their interest in popular items (Niche, Diverse and Blockbuster-focused) and show the impact of popularity bias on the users in each group. Our experimental results on a movie dataset show that in many recommendation algorithms the recommendations the users get are extremely concentrated on popular items even if a user is interested in long-tail and non-popular items showing an extreme bias disparity.","941":null,"942":"Media bias can strongly impact the individual and public perception of news events. One difficult-to-detect, yet powerful form of slanted news coverage is bias by word choice and labeling (WCL). Bias by WCL can occur when journalists refer to the same concept, yet use different terms, which results in different sentiments being sparked in the readers, such as the terms \"economic migrants\" vs. \"refugees.\" We present an automated approach to identify bias by WCL that employs models and manual analysis approaches from the social sciences, a research domain in which media bias has been studied for decades. This paper makes three contributions. First, we present NewsWCL50, the first open evaluation dataset for the identification of bias by WCL consisting of 8,656 manual annotations in 50 news articles. Second, we propose a method capable of extracting instances of bias by WCL while outperforming state-of-the-art methods, such as coreference resolution, which currently cannot resolve very broadly defined or abstract coreferences used by journalists. We evaluate our method on the NewsWCL50 dataset, achieving an F1=45.7% compared to F1=29.8% achieved by the best performing state-of-the-art technique. Lastly, we present a prototype demonstrating the effectiveness of our approach in finding frames caused by bias by WCL.","943":"DNA has recently emerged as an attractive medium for future digital data storage because of its extremely high information density and potential longevity. Recent work has shown promising results in developing proof-of-principle prototype systems. However, very uneven (biased) sequencing coverage distributions have been reported, which indicates inefficiencies in the storage process and points to optimization opportunities. These deviations from the average coverage in oligonucleotide copy distribution result in sequence drop-out and make error-free data retrieval from DNA more challenging. The uneven copy distribution was believed to stem from the underlying molecular processes, but the interplay between these molecular processes and the copy number distribution has been poorly understood until now. In this paper, we use millions of unique sequences from a DNA-based digital data archival system to study the oligonucleotide copy unevenness problem and show that two important sources of bias are the synthesis process and the Polymerase Chain Reaction (PCR) process. By mapping the sequencing coverage of a large complex oligonucleotide pool back to its spatial distribution on the synthesis chip, we find that significant bias comes from array-based oligonucleotide synthesis. We also find that PCR stochasticity is another main driver of oligonucleotide copy variation. Based on these findings, we develop a statistical model for each molecular process as well as the overall process and compare the predicted bias with our experimental data. We further use our model to explore the trade-offs between synthesis bias, storage physical density and sequencing redundancy, providing insights for engineering efficient, robust DNA data storage systems.","944":"Background: Exposure mixtures frequently occur in data across many domains, particularly in the fields of environmental and nutritional epidemiology. Various strategies have arisen to answer questions about exposure mixtures, including methods such as weighted quantile sum (WQS) regression that estimate a joint effect of the mixture components. Objectives: We demonstrate a new approach to estimating the joint effects of a mixture: quantile g-computation. This approach combines the inferential simplicity of WQS regression with the flexibility of g-computation, a method of causal effect estimation. We use simulations to examine whether quantile g-computation and WQS regression can accurately and precisely estimate the effects of mixtures in a variety of common scenarios. Methods: We examine the bias, confidence interval (CI) coverage, and bias\u2013variance tradeoff of quantile g-computation and WQS regression and how these quantities are impacted by the presence of noncausal exposures, exposure correlation, unmeasured confounding, and nonlinearity of exposure effects. Results: Quantile g-computation, unlike WQS regression, allows inference on mixture effects that is unbiased with appropriate CI coverage at sample sizes typically encountered in epidemiologic studies and when the assumptions of WQS regression are not met. Further, WQS regression can magnify bias from unmeasured confounding that might occur if important components of the mixture are omitted from the analysis. Discussion: Unlike inferential approaches that examine the effects of individual exposures while holding other exposures constant, methods like quantile g-computation that can estimate the effect of a mixture are essential for understanding the effects of potential public health actions that act on exposure sources. Our approach may serve to help bridge gaps between epidemiologic analysis and interventions such as regulations on industrial emissions or mining processes, dietary changes, or consumer behavioral changes that act on multiple exposures simultaneously. https:\/\/doi.org\/10.1289\/EHP5838","945":"Congratulations to Hahn, Murray and Carvalho on a nice contribution. The authors propose the Bayesian causal forest (BCF) model. It reduces the bias and improves frequentist coverage of Bayesian credible intervals of treatment effect estimates in the presence of strong confounding and treatment effect heterogeneity. The BCF model builds upon the popular and empirically proven prediction method, Bayesian Additive Regression Trees (BART) (Chipman et al., 2010). BCF reformulates the response surface model as the sum of two functions, one modeling the prognostic impact of the control variables and one representing the treatment effect. This formulation directly incorporates estimates of the propensity score (PS) which induces a covariate-dependent prior on the regression function and regularizes treatment effect heterogeneity separately from the prognostic effect of control variables. It is impressive that the proposed method, in many settings, has better bias reduction, more consistent 95% coverage probability and shorter uncertainty intervals compared to the vanilla BART, which boasts better performance in a host of modern causal inference studies, including Hill (2011), Wendling et al. (2018), Dorie et al. (2019) and Hu et al. (2020), to name a few.","946":"Modern weakly supervised methods for event detection (ED) avoid time-consuming human annotation and achieve promising results by learning from auto-labeled data. However, these methods typically rely on sophisticated pre-defined rules as well as existing instances in knowledge bases for automatic annotation and thus suffer from low coverage, topic bias, and data noise. To address these issues, we build a large event-related candidate set with good coverage and then apply an adversarial training mechanism to iteratively identify those informative instances from the candidate set and filter out those noisy ones. The experiments on two real-world datasets show that our candidate selection and adversarial training can cooperate together to obtain more diverse and accurate training data for ED, and significantly outperform the state-of-the-art methods in various weakly supervised scenarios. The datasets and source code can be obtained from https:\/\/github.com\/thunlp\/Adv-ED.","947":"Soil moisture is a key environmental variable, important to, e.g., farmers, meteorologists, and disaster management units. Here, we present a method to retrieve surface soil moisture (SSM) from the Sentinel-1 (S-1) satellites, which carry C-band Synthetic Aperture Radar (CSAR) sensors that provide the richest freely available SAR data source so far, unprecedented in accuracy and coverage. Our SSM retrieval method, adapting well-established change detection algorithms, builds the first globally deployable soil moisture observation data set with 1-km resolution. This paper provides an algorithm formulation to be operated in data cube architectures and high-performance computing environments. It includes the novel dynamic Gaussian upscaling method for spatial upscaling of SAR imagery, harnessing its field-scale information and successfully mitigating effects from the SAR\u2019s high signal complexity. Also, a new regression-based approach for estimating the radar slope is defined, coping with Sentinel-1\u2019s inhomogeneity in spatial coverage. We employ the S-1 SSM algorithm on a 3-year S-1 data cube over Italy, obtaining a consistent set of model parameters and product masks, unperturbed by coverage discontinuities. An evaluation of therefrom generated S-1 SSM data, involving a 1-km soil water balance model over Umbria, yields high agreement over plains and agricultural areas, with low agreement over forests and strong topography. While positive biases during the growing season are detected, the excellent capability to capture small-scale soil moisture changes as from rainfall or irrigation is evident. The S-1 SSM is currently in preparation toward operational product dissemination in the Copernicus Global Land Service.","948":"Plant traits\u2014the morphological, anatomical, physiological, biochemical and phenological characteristics of plants\u2014determine how plants respond to environmental factors, affect other trophic levels, and influence ecosystem properties and their benefits and detriments to people. Plant trait data thus represent the basis for a vast area of research spanning from evolutionary biology, community and functional ecology, to biodiversity conservation, ecosystem and landscape management, restoration, biogeography and earth system modelling. Since its foundation in 2007, the TRY database of plant traits has grown continuously. It now provides unprecedented data coverage under an open access data policy and is the main plant trait database used by the research community worldwide. Increasingly, the TRY database also supports new frontiers of trait\u2010based plant research, including the identification of data gaps and the subsequent mobilization or measurement of new data. To support this development, in this article we evaluate the extent of the trait data compiled in TRY and analyse emerging patterns of data coverage and representativeness. Best species coverage is achieved for categorical traits\u2014almost complete coverage for \u2018plant growth form\u2019. However, most traits relevant for ecology and vegetation modelling are characterized by continuous intraspecific variation and trait\u2013environmental relationships. These traits have to be measured on individual plants in their respective environment. Despite unprecedented data coverage, we observe a humbling lack of completeness and representativeness of these continuous traits in many aspects. We, therefore, conclude that reducing data gaps and biases in the TRY database remains a key challenge and requires a coordinated approach to data mobilization and trait measurements. This can only be achieved in collaboration with other initiatives.","949":null,"950":"Recent effort to test deep learning systems has produced an intuitive and compelling test criterion called neuron coverage (NC), which resembles the notion of traditional code coverage. NC measures the proportion of neurons activated in a neural network and it is implicitly assumed that increasing NC improves the quality of a test suite. In an attempt to automatically generate a test suite that increases NC, we design a novel diversity promoting regularizer that can be plugged into existing adversarial attack algorithms. We then assess whether such attempts to increase NC could generate a test suite that (1) detects adversarial attacks successfully, (2) produces natural inputs, and (3) is unbiased to particular class predictions. Contrary to expectation, our extensive evaluation finds that increasing NC actually makes it harder to generate an effective test suite: higher neuron coverage leads to fewer defects detected, less natural inputs, and more biased prediction preferences. Our results invoke skepticism that increasing neuron coverage may not be a meaningful objective for generating tests for deep neural networks and call for a new test generation technique that considers defect detection, naturalness, and output impartiality in tandem.","951":"We consider a heterogeneous ultra dense network (HUDN) with both the hexagon and Poisson point process (PPP) layouts, which is more relevant for practical scenarios. A user-centric and adaptive interference-aware non-coherent coordinated multi-point transmission (IA-CoMP) scheme is used as a system setup to reduce both the cross-tier and the co-tier inter-cell interference (ICI) for the HUDN with range expansion (RE) in small cells. Due to the involvement of hexagonal macrocells, it is intractable to analyze the coverage performance of HUDNs with IA-CoMP. To this end, we present a mobile station GrouPing (MSGP)-based coverage analysis method, which partitions all MSs into four groups according to their main interference, and the whole coverage is obtained as the sum of the coverage of each MS group. We demonstrate that the proposed MSGP-based coverage analysis method can provide a tight upper bound when compared with Monte Carlo simulations. As the small cell density increases, the system coverage of HUDNs with hexagonal macrocells reduces exponentially, while the system coverage of HUDNs with PPP-based macrocells remains unchanged. Moreover, the system coverage increases with the larger one of the main ICI judging coefficient and the RE bias.","952":"Abstract Cellular life depends on a complex web of functional associations between biomolecules. Among these associations, protein\u2013protein interactions are particularly important due to their versatility, specificity and adaptability. The STRING database aims to integrate all known and predicted associations between proteins, including both physical interactions as well as functional associations. To achieve this, STRING collects and scores evidence from a number of sources: (i) automated text mining of the scientific literature, (ii) databases of interaction experiments and annotated complexes\/pathways, (iii) computational interaction predictions from co-expression and from conserved genomic context and (iv) systematic transfers of interaction evidence from one organism to another. STRING aims for wide coverage; the upcoming version 11.5 of the resource will contain more than 14 000 organisms. In this update paper, we describe changes to the text-mining system, a new scoring-mode for physical interactions, as well as extensive user interface features for customizing, extending and sharing protein networks. In addition, we describe how to query STRING with genome-wide, experimental data, including the automated detection of enriched functionalities and potential biases in the user's query data. The STRING resource is available online, at https:\/\/string-db.org\/.","953":"An open secret in contemporary machine learning is that many models work beautifully on standard benchmarks but fail to generalize outside the lab. This has been attributed to biased training data, which provide poor coverage over real world events. Generative models are no exception, but recent advances in generative adversarial networks (GANs) suggest otherwise - these models can now synthesize strikingly realistic and diverse images. Is generative modeling of photos a solved problem? We show that although current GANs can fit standard datasets very well, they still fall short of being comprehensive models of the visual manifold. In particular, we study their ability to fit simple transformations such as camera movements and color changes. We find that the models reflect the biases of the datasets on which they are trained (e.g., centered objects), but that they also exhibit some capacity for generalization: by \"steering\" in latent space, we can shift the distribution while still creating realistic images. We hypothesize that the degree of distributional shift is related to the breadth of the training data distribution. Thus, we conduct experiments to quantify the limits of GAN transformations and introduce techniques to mitigate the problem. Code is released on our project page: this https URL","954":"We outline a new and improved uncertainty analysis for the Goddard Institute for Space Studies Surface Temperature product version 4 (GISTEMP v4). Historical spatial variations in surface temperature anomalies are derived from historical weather station data and ocean data from ships, buoys, and other sensors. Uncertainties arise from measurement uncertainty, changes in spatial coverage of the station record, and systematic biases due to technology shifts and land cover changes. Previously published uncertainty estimates for GISTEMP included only the effect of incomplete station coverage. Here, we update this term using currently available spatial distributions of source data, state\u2010of\u2010the\u2010art reanalyses, and incorporate independently derived estimates for ocean data processing, station homogenization, and other structural biases. The resulting 95% uncertainties are near 0.05 \u00b0C in the global annual mean for the last 50 years and increase going back further in time reaching 0.15 \u00b0C in 1880. In addition, we quantify the benefits and inherent uncertainty due to the GISTEMP interpolation and averaging method. We use the total uncertainties to estimate the probability for each record year in the GISTEMP to actually be the true record year (to that date) and conclude with 87% likelihood that 2016 was indeed the hottest year of the instrumental period (so far).","955":"Inferring commonsense knowledge is a key challenge in machine learning. Due to the sparsity of training data, previous work has shown that supervised methods for commonsense knowledge mining underperform when evaluated on novel data. In this work, we develop a method for generating commonsense knowledge using a large, pre-trained bidirectional language model. By transforming relational triples into masked sentences, we can use this model to rank a triple\u2019s validity by the estimated pointwise mutual information between the two entities. Since we do not update the weights of the bidirectional model, our approach is not biased by the coverage of any one commonsense knowledge base. Though we do worse on a held-out test set than models explicitly trained on a corresponding training set, our approach outperforms these methods when mining commonsense knowledge from new sources, suggesting that our unsupervised technique generalizes better than current supervised approaches.","956":"The function of fitness (or molecular activity) in the space of all possible sequences is known as the fitness landscape. Evolution is a random walk on the fitness landscape, with a bias toward climbing hills. Mapping the topography of real fitness landscapes is fundamental to understanding evolution, but previous efforts were hampered by the difficulty of obtaining large, quantitative data sets. The accessibility of high-throughput sequencing (HTS) has transformed this study, enabling large-scale enumeration of fitness for many mutants and even complete sequence spaces in some cases. We review the progress of high-throughput studies in mapping molecular fitness landscapes, both in vitro and in vivo, as well as opportunities for future research. Such studies are rapidly growing in number. HTS is expected to have a profound effect on the understanding of real molecular fitness landscapes.","957":null,"958":"Anonymized smartphone-based mobility data has been widely adopted in devising and evaluating COVID-19 response strategies such as the targeting of public health resources. Yet little attention has been paid to measurement validity and demographic bias, due in part to the lack of documentation about which users are represented as well as the challenge of obtaining ground truth data on unique visits and demographics. We illustrate how linking large-scale administrative data can enable auditing mobility data for bias in the absence of demographic information and ground truth labels. More precisely, we show that linking voter roll data---containing individual-level voter turnout for specific voting locations along with race and age---can facilitate the construction of rigorous bias and reliability tests. Using data from North Carolina's 2018 general election, these tests illuminate a sampling bias that is particularly noteworthy in the pandemic context: older and non-white voters are less likely to be captured by mobility data. We show that allocating public health resources based on such mobility data could disproportionately harm high-risk elderly and minority groups.","959":"Citizen science data are increasingly used for modelling species distributions because they offer broad spatiotemporal coverage of local observations. However, such data are often collected without experimental design or set survey methods, raising the risk that bias and noise will compromise modelled predictions. We tested the ability of species distribution models (SDMs) built from these low\u2010structure citizen science data to match the quality of SDMs from systematically collected data and tested whether stringent data filtering improved predictions.","960":"Data-driven technologies are only as good as the data they work with. On the other hand, data scientists have often limited control on how the data is collected. Failing to contain adequate number of instances from minority (sub)groups, known as population bias, is a major reason for model unfairness and disparate performance across different groups. We demonstrate MithraCoverage, a system for investigating population bias over the intersection of multiple attributes. We use the concept of coverage for identifying intersectional subgroups with inadequate representation in the dataset. MithraCoverage is a web application with an interactive visual interface that allows data scientists to explore the dataset and identify subgroups with poor coverage.","961":"In today's data-driven world, it is critical that we use appropriate datasets for analysis and decision-making. Datasets could be biased because they reflect existing inequalities in the world, due to the data scientists' biased world view, or due to the data scientists' limited control over the data collection process. For these reasons, it is important to ensure adequate data coverage across different groups over the intersection of multiple attributes. Often, the dataset to be analyzed is obtained through complex joins and predicate combinations over multiple relational tables in a database. Due to the sheer data volume we often have to deal with, determining adequate coverage can require an unacceptably long execution time. In this paper, we provide an efficient approach for coverage analysis, given a set of attributes across multiple tables. To identify regions with insufficient coverage in the combinatorially large set of value combinations, we design an index scheme to avoid explicit table joins, achieve efficient memory usage, and support predicate combination at a high level of parallelism. We also propose P-WALK, a priority-based search algorithm, to traverse the lattice space. Since in practice, coverage assessment typically does not require precise COUNT aggregation results, we further present approximate methods to reduce computation time. Experimental evaluation using three real-world datasets shows the effectiveness, efficiency, and accuracy of proposed methods.","962":"The inner-product navigable small world graph (ip-NSW) represents the state-of-the-art method for approximate maximum inner product search (MIPS) and it can achieve an order of magnitude speedup over the fastest baseline. However, to date it is still unclear where its exceptional performance comes from. In this paper, we show that there is a strong norm bias in the MIPS problem, which means that the large norm items are very likely to become the result of MIPS. Then we explain the good performance of ip-NSW as matching the norm bias of the MIPS problem \u2014 large norm items have big in-degrees in the ip-NSW proximity graph and a walk on the graph spends the majority of computation on these items, thus effectively avoids unnecessary computation on small norm items. Furthermore, we propose the ip-NSW+ algorithm, which improves ip-NSW by introducing an additional angular proximity graph. Search is first conducted on the angular graph to find the angular neighbors of a query and then the MIPS neighbors of these angular neighbors are used to initialize the candidate pool for search on the inner-product proximity graph. Experiment results show that ip-NSW+ consistently and significantly outperforms ip-NSW and provides more robust performance under different data distributions.","963":"Machine learning models are prone to biased decisions due to biases in the datasets they are trained on. In this paper, we introduce a novel data augmentation technique to create a fairer dataset for model training that could also lend itself to understanding the type of bias existing in the dataset i.e. if bias arises from a lack of representation for a particular group (sampling bias) or if it arises because of human bias reflected in the labels (prejudice based bias). Given a dataset involving a protected attribute with a privileged and unprivileged group, we create an \"ideal world'' dataset: for every data sample, we create a new sample having the same features (except the protected attribute(s)) and label as the original sample but with the opposite protected attribute value. The synthetic data points are sorted in order of their proximity to the original training distribution and added successively to the real dataset to create intermediate datasets. We theoretically show that two different notions of fairness: statistical parity difference (independence) and average odds difference (separation) always change in the same direction using such an augmentation. We also show submodularity of the proposed fairness-aware augmentation approach that enables an efficient greedy algorithm. We empirically study the effect of training models on the intermediate datasets and show that this technique reduces the two bias measures while keeping the accuracy nearly constant for three datasets. We then discuss the implications of this study on the disambiguation of sample bias and prejudice based bias and discuss how pre-processing techniques should be evaluated in general. The proposed method can be used by policy makers who want to use unbiased datasets to train machine learning models for their applications to add a subset of synthetic points to an extent that they are comfortable with to mitigate unwanted bias.","964":"A large literature reports that proximity influences investment. We extend the measurement of proximity beyond distance and report that air travel reduces local investment bias. This result is confirmed using the initiation of connecting flights through recently opened air hubs because investment at destinations served by these connecting flights increases after, not before, their initiation. Air travel also broadens the investor base of firms and lowers their cost of equity by approximately 1%. Overall, air travel improves the diversification of investor portfolios and lowers the cost of equity for firms. This paper was accepted by Tyler Shumway, finance.","965":"This work presents capacitive ultrasonic transceivers based on a dual-backplate MEMS microphone technology. The transducers exploit mechanical and acoustical system resonances in the low ultrasonic frequency range up to 100 kHz for both sending and receiving of ultrasonic signals. Requiring below 10V bias voltage and using standard MEMS microphone housings with dimensions of 4x3x1 mm\u00b3, the proposed system allows an integration into space and power critical systems like e.g. smartphones. While the ultrasonic transceiver functionality enables proximity sensing and presence detection applications, state-of-the-art audio performance of 68 dB(A) signal-to-noise ratio (SNR) is maintained.","966":"Recently, Wall et al. proposed a set of computational metrics for quantifying cognitive bias based on user interaction sequences. The metrics rely on a Markov model to predict a user\u2019s next interaction based on the current interaction. The metrics characterize how a user\u2019s actual interactive behavior deviates from a theoretical baseline, where \"unbiased behavior\" was previously defined to be equal probabilities of all interactions. In this paper, we analyze the assumptions made of these metrics. We conduct a study in which participants, subject to anchoring bias, interact with a scatterplot to complete a categorization task. Our results indicate that, rather than equal probabilities of all interactions, unbiased behavior across both bias conditions can be better approximated by proximity of data points.","967":"Volunteered geographic information (VGI) has great potential to reveal spatial and temporal dynamics of geographic phenomena. However, a variety of potential biases in VGI are recognized, many of which root from volunteer data contribution activities. Examining patterns in volunteer data contribution activities helps understand the biases. Using eBird as a case study, this study investigates spatial and temporal patterns in data contribution activities of eBird contributors. eBird sampling efforts are biased in space and time. Most sampling efforts are concentrated in areas of denser populations and\/or better accessibility, with the most intensively sampled areas being in proximity to big cities in developed regions of the world. Reported bird species are also spatially biased towards areas where more sampling efforts occur. Temporally, eBird sampling efforts and reported bird species are increasing over the years, with significant monthly fluctuations and notably more data reported on weekends. Such trends are driven by the expansion of eBird and characteristics of bird species and observers. The fitness of use of VGI should be assessed in the context of applications by examining spatial, temporal and other biases. Action may need to be taken to account for the biases so that robust inferences can be made from VGI observations.","968":"Graph representation learning has attracted lots of attention recently. Existing graph neural networks fed with the complete graph data are not scalable due to limited computation and memory costs. Thus, it remains a great challenge to capture rich information in large-scale graph data. Besides, these methods mainly focus on supervised learning and highly depend on node label information, which is expensive to obtain in the real world. As to unsupervised network embedding approaches, they overemphasize node proximity instead, whose learned representations can hardly be used in downstream application tasks directly. In recent years, emerging self-supervised learning provides a potential solution to address the aforementioned problems. However, existing self-supervised works also operate on the complete graph data and are biased to fit either global or very local (1-hop neighborhood) graph structures in defining the mutual information based loss terms. In this paper, a novel self-supervised representation learning method via Sub-graph Contrast, namely Subg-Con, is proposed by utilizing the strong correlation between central nodes and their sampled subgraphs to capture regional structure information. Instead of learning on the complete input graph data, with a novel data augmentation strategy, Subg-Con learns node representations through a contrastive loss defined based on subgraphs sampled from the original graph instead. Compared with existing graph representation learning approaches, Subg-Con has prominent performance advantages in weaker supervision requirements, model learning scalability, and parallelization. Extensive experiments verify both the effectiveness and the efficiency of our work compared with both classic and state-of-the-art graph representation learning approaches on multiple realworld large-scale benchmark datasets from different domains.","969":"Typically, recommender systems from any domain, be it movies, music, restaurants, etc., are organized in a centralized fashion. The service provider holds all the data, biases in the recommender algorithms are not transparent to the user, and the service providers often create lock-in effects making it inconvenient for the user to switch providers. In this paper, we argue that the user's smartphone already holds a lot of the data that feeds into typical recommender systems for movies, music, or POIs. With the ubiquity of the smartphone and other users in proximity in public places or public transportation, data can be exchanged directly between users in a device-to-device manner. This way, each smartphone can build its own database and calculate its own recommendations. One of the benefits of such a system is that it is not restricted to recommendations for just one user - ad-hoc group recommendations are also possible. While the infrastructure for such a platform already exists - the smartphones already in the palms of the users - there are challenges both with respect to the mobile recommender system platform as well as to its recommender algorithms. In this paper, we present a mobile architecture for the described system - consisting of data collection, data exchange, and recommender system - and highlight its challenges and opportunities.","970":"The flow of information reaching us via the online media platforms is optimized not by the information content or relevance but by popularity and proximity to the target. This is typically performed in order to maximise platform usage. As a side effect, this introduces an algorithmic bias that is believed to enhance polarization of the societal debate. To study this phenomenon, we modify the well-known continuous opinion dynamics model of bounded confidence in order to account for the algorithmic bias and investigate its consequences. In the simplest version of the original model the pairs of discussion participants are chosen at random and their opinions get closer to each other if they are within a fixed tolerance level. We modify the selection rule of the discussion partners: there is an enhanced probability to choose individuals whose opinions are already close to each other, thus mimicking the behavior of online media which suggest interaction with similar peers. As a result we observe: a) an increased tendency towards polarization, which emerges also in conditions where the original model would predict convergence, and b) a dramatic slowing down of the speed at which the convergence at the asymptotic state is reached, which makes the system highly unstable. Polarization is augmented by a fragmented initial population.","971":null,"972":"Our ability to perceive and discriminate textures is based on the processing of high-frequency vibrations generated on the fingertip as it scans across a surface. Although much is known about the processing of vibration amplitude and frequency information when cutaneous stimulation is experienced at a single location on the body, how these stimulus features are processed when touch occurs at multiple locations is poorly understood. We evaluated participants' ability to discriminate tactile cues (100-300 Hz) on one hand while they ignored distractor cues experienced on their other hand. We manipulated the relative positions of the hands to characterize how limb position influenced cutaneous touch interactions. In separate experiments, participants judged either the frequency or intensity of mechanical vibrations. We found that vibrations experienced on one hand always systematically modulated the perception of vibrations on the other hand. Notably, bimanual interaction patterns and their sensitivity to hand locations differed according to stimulus feature. Somatosensory interactions in intensity perception were only marked by attenuation that was invariant to hand position manipulations. In contrast, interactions in frequency perception consisted of both bias and sensitivity changes that were more pronounced when the hands were held in close proximity. We implemented models to infer the neural computations that mediate somatosensory interactions in the intensity and frequency dimensions. Our findings reveal obligatory and feature-dependent somatosensory interactions that may be supported by both feature-specific and feature-general operations. NEW & NOTEWORTHY Little is known about the neural computations mediating feature-specific sensory interactions between the hands. We show that vibrations experienced on one hand systematically modulate the perception of vibrations felt on the other hand. Critically, interaction patterns and their dependence on the relative positions of the hands differed depending on whether participants judged vibration intensity or frequency. These results, which we recapitulate with models, imply that somatosensory interactions are mediated by feature-dependent neural computations.","973":"This study provides a comprehensive model of an agent\u2019s behavior in response to multiple sales management instruments, including compensation, recruiting\/termination, and training. The model takes into account many of the key elements that constitute a realistic sales force setting: allocation of effort, forward-looking behavior, present bias, training effectiveness, and employee selection and attrition. By understanding how these elements jointly affect agents\u2019 behavior, the study provides guidance on the optimal design of sales management policies. A field validation, by comparing counterfactual and actual outcomes under a new policy, attests to the accuracy of the model. The results demonstrate a tradeoff between adjusting fixed and variable pay; how sales training serves as an alternative to compensation; a potential drawback of hiring high-performing, experienced salespeople; and how utilizing a leave package leads to sales force restructuring. In addition, the study offers a key methodological contribution by providing formal identification conditions for hyperbolic time preference. The key to identification is that under a multiperiod nonlinear incentive system, an agent\u2019s proximity to a goal affects only future payoffs in nonpecuniary benefit periods, providing exclusion restrictions on the current payoff. This paper was accepted by Matthew Shum, marketing.","974":"Machine learning-guided optical proximity correction, called ML-OPC in this paper, has recently been proposed to alleviate long runtime of model-based OPC. ML-OPC using regression methods has been presented but with limited prediction accuracy. We propose neural network classifier-based OPC (NNC-OPC), in which a neural network classifier serves as a mask bias model. A few techniques are applied to enhance basic NNC-OPC: parameterization of layout segments using polar Fourier transform signals, dimensionality reduction through weighted principal component analysis, and sampling of training layout segments. Training segments are typically imbalanced over the range of mask biases, which may cause large prediction error for segments that appear less frequently. This is resolved by three techniques: 1) synthetic data generation; 2) class reorganization; and 3) an adaptive learning rate. Experiments with NNC-OPC with all techniques applied indicate that prediction error of mask bias and training time are reduced by 29% and 80%, respectively, compared to state-of-the-art ML-OPC with regression methods.","975":"Click data collected by modern recommendation systems are an important source of observational data that can be utilized to train learning-to-rank (LTR) systems. However, these data suffer from a number of biases that can result in poor performance for LTR systems. Recent methods for bias correction in such systems mostly focus on position bias, the fact that higher ranked results (e.g., top search engine results) are more likely to be clicked even if they are not the most relevant results given a user\u2019s query. Less attention has been paid to correcting for selection bias, which occurs because clicked documents are reflective of what documents have been shown to the user in the first place. Here, we propose new counterfactual approaches which adapt Heckman\u2019s two-stage method and accounts for selection and position bias in LTR systems. Our empirical evaluation shows that our proposed methods are much more robust to noise and have better accuracy compared to existing unbiased LTR algorithms, especially when there is moderate to no position bias.","976":"Federated learning is a distributed optimization paradigm that enables a large number of resource-limited client nodes to cooperatively train a model without data sharing. Several works have analyzed the convergence of federated learning by accounting of data heterogeneity, communication and computation limitations, and partial client participation. However, they assume unbiased client participation, where clients are selected at random or in proportion of their data sizes. In this paper, we present the first convergence analysis of federated optimization for biased client selection strategies, and quantify how the selection bias affects convergence speed. We reveal that biasing client selection towards clients with higher local loss achieves faster error convergence. Using this insight, we propose Power-of-Choice, a communication- and computation-efficient client selection framework that can flexibly span the trade-off between convergence speed and solution bias. Our experiments demonstrate that Power-of-Choice strategies converge up to 3 $\\times$ faster and give $10$% higher test accuracy than the baseline random selection.","977":"In this paper, we introduce a large scale multi-objective ranking system for recommending what video to watch next on an industrial video sharing platform. The system faces many real-world challenges, including the presence of multiple competing ranking objectives, as well as implicit selection biases in user feedback. To tackle these challenges, we explored a variety of soft-parameter sharing techniques such as Multi-gate Mixture-of-Experts so as to efficiently optimize for multiple ranking objectives. Additionally, we mitigated the selection biases by adopting a Wide & Deep framework. We demonstrated that our proposed techniques can lead to substantial improvements on recommendation quality on one of the world's largest video sharing platforms.","978":"ModelTest-NG is a re-implementation from scratch of jModelTest and ProtTest, two popular tools for selecting the best-fit nucleotide and amino acid substitution models, respectively. ModelTest-NG is one to two orders of magnitude faster than jModelTest and ProtTest but equally accurate, and introduces several new features, such as ascertainment bias correction, mixture and FreeRate models, or the automatic processing of partitioned datasets. ModelTest-NG is available under a GNU GPL3 license at https:\/\/github.com\/ddarriba\/modeltest.","979":"Network meta\u2010analysis (NMA) compares several interventions that are linked in a network of comparative studies and estimates the relative treatment effects between all treatments, using both direct and indirect evidence. NMA is increasingly used for decision making in health care, however, a user\u2010friendly system to evaluate the confidence that can be placed in the results of NMA is currently lacking. This paper is a tutorial describing the Confidence In Network Meta\u2010Analysis (CINeMA) web application, which is based on the framework developed by Salanti et al (2014, PLOS One, 9, e99682) and refined by Nikolakopoulou et al (2019, bioRxiv). Six domains that affect the level of confidence in the NMA results are considered: (a) within\u2010study bias, (b) reporting bias, (c) indirectness, (d) imprecision, (e) heterogeneity, and (f) incoherence. CINeMA is freely available and open\u2010source and no login is required. In the configuration step users upload their data, produce network plots and define the analysis and effect measure. The dataset should include assessments of study\u2010level risk of bias and judgments on indirectness. CINeMA calls the netmeta routine in R to estimate relative effects and heterogeneity. Users are then guided through a systematic evaluation of the six domains. In this way reviewers assess the level of concerns for each relative treatment effect from NMA as giving rise to \u201cno concerns,\u201d \u201csome concerns,\u201d or \u201cmajor concerns\u201d in each of the six domains, which are graphically summarized on the report page for all effect estimates. Finally, judgments across the domains are summarized into a single confidence rating (\u201chigh,\u201d \u201cmoderate,\u201d \u201clow,\u201d or \u201cvery low\u201d). In conclusion, the user\u2010friendly web\u2010based CINeMA platform provides a transparent framework to evaluate evidence from systematic reviews with multiple interventions.","980":"We found that many of the reported erroneous cases in popular DNN image classifiers occur because the trained models confuse one class with another or show biases towards some classes over others. Most existing DNN testing techniques focus on per-image violations, so fail to detect class-level confusions or biases. We developed a testing technique to automatically detect class-based confusion and bias errors in DNN-driven image classification software. We evaluated our implementation, DeepInspect, on several popular image classifiers with precision up to 100% (avg. 72.6%) for confusion errors, and up to 84.3% (avg. 66.8%) for bias errors.","981":"The automatic detection of bias in news articles can have a high impact on society because undiscovered news bias may influence the political opinions, social views, and emotional feelings of readers. While various analyses and approaches to news bias detection have been proposed, large data sets with rich bias annotations on a fine-grained level are still missing. In this paper, we firstly aggregate the aspects of news bias in related works by proposing a new annotation schema for labeling news bias. This schema covers the overall bias, as well as the bias dimensions (1) hidden assumptions, (2) subjectivity, and (3) representation tendencies. Secondly, we propose a methodology based on crowdsourcing for obtaining a large data set for news bias analysis and identification. We then use our methodology to create a dataset consisting of more than 2,000 sentences annotated with 43,000 bias and bias dimension labels. Thirdly, we perform an in-depth analysis of the collected data. We show that the annotation task is difficult with respect to bias and specific bias dimensions. While crowdworkers' labels of representation tendencies correlate with experts' bias labels for articles, subjectivity and hidden assumptions do not correlate with experts' bias labels and, thus, seem to be less relevant when creating data sets with crowdworkers. The experts' article labels better match the inferred crowdworkers' article labels than the crowdworkers' sentence labels. The crowdworkers' countries of origin seem to affect their judgements. In our study, non-Western crowdworkers tend to annotate more bias either directly or in the form of bias dimensions (e.g., subjectivity) than Western crowdworkers do.","982":"The present level of proliferation of fake, biased, and propagandistic content online has made it impossible to fact-check every single suspicious claim or article, either manually or automatically. Thus, many researchers are shifting their attention to higher granularity, aiming to profile entire news outlets, which makes it possible to detect likely \u201cfake news\u201d the moment it is published, by simply checking the reliability of its source. Source factuality is also an important element of systems for automatic fact-checking and \u201cfake news\u201d detection, as they need to assess the reliability of the evidence they retrieve online. Political bias detection, which in the Western political landscape is about predicting left-center-right bias, is an equally important topic, which has experienced a similar shift towards profiling entire news outlets. Moreover, there is a clear connection between the two, as highly biased media are less likely to be factual; yet, the two problems have been addressed separately. In this survey, we review the state of the art on media profiling for factuality and bias, arguing for the need to model them jointly. We further discuss interesting recent advances in using different information sources and modalities, which go beyond the text of the articles the target news outlet has published. Finally, we discuss current challenges and outline future research directions.","983":"A typical journalistic convention in news articles is to deliver the most salient information in the beginning, also known as the lead bias. While this phenomenon can be exploited in generating a summary, it has a detrimental effect on teaching a model to discriminate and extract important information in general. We propose that this lead bias can be leveraged in our favor in a simple and effective way to pre-train abstractive news summarization models on large-scale unlabeled news corpora: predicting the leading sentences using the rest of an article. We collect a massive news corpus and conduct data cleaning and filtering via statistical analysis. We then apply self-supervised pre-training on this dataset to existing generation models BART and T5 for domain adaptation. Via extensive experiments on six benchmark datasets, we show that this approach can dramatically improve the summarization quality and achieve state-of-the-art results for zero-shot news summarization without any fine-tuning. For example, in the DUC2003 dataset, the ROUGE-1 score of BART increases 13.7% after the lead-bias pre-training. We deploy the model in Microsoft News and provide public APIs as well as a demo website for multi-lingual news summarization.","984":"To attract unsuspecting readers, news article headlines and abstracts are often written with speculative sentences or clauses. Male dominance in the news is very evident, whereas females are seen as \u201ceye candy\u201d or \u201cinferior\u201d, and are underrepresented and under-examined within the same news categories as their male counterparts. In this paper, we present an initial study on gender bias in news abstracts in two large English news datasets used for news recommendation and news classification. We perform three large-scale, yet effective text-analysis fairness measurements on 296,965 news abstracts. In particular, to our knowledge we construct two of the largest benchmark datasets of possessive (gender-specific and gender-neutral) nouns and attribute (career-related and family-related) words datasets1 which we will release to foster both bias and fairness research aid in developing fair NLP models to eliminate the paradox of gender bias. Our studies demonstrate that females are immensely marginalized and suffer from socially-constructed biases in the news. This paper individually devises a methodology whereby news content can be analyzed on a large scale utilizing natural language processing (NLP) techniques from machine learning (ML) to discover both implicit and explicit gender biases.","985":"News recommendation is critical for personalized news access. Existing news recommendation methods usually infer users\u2019 personal interest based on their historical clicked news, and train the news recommendation models by predicting future news clicks. A core assumption behind these methods is that news click behaviors can indicate user interest. However, in practical scenarios, beyond the relevance between user interest and news content, the news click behaviors may also be affected by other factors, such as the bias of news presentation in the online platform. For example, news with higher positions and larger sizes are usually more likely to be clicked. The bias of clicked news may bring noises to user interest modeling and model training, which may hurt the performance of the news recommendation model. In this paper, we propose a bias-aware personalized news recommendation method named DebiasRec, which can handle the bias information for more accurate user interest inference and model training. The core of our method includes a bias representation module, a bias-aware user modeling module, and a bias-aware click prediction module. The bias representation module is used to model different kinds of news bias and their interactions to capture their joint effect on click behaviors. The bias-aware user modeling module aims to infer users\u2019 debiased interest from the clicked news articles by using their bias information to calibrate the interest model. The bias-aware click prediction module is used to train a debiased news recommendation model from the biased click behaviors, where the click score is decomposed into a preference score indicating user\u2019s interest in the news content and a news bias score inferred from its different bias features. Experiments on two real-world datasets show that our method can effectively improve the performance of news recommendation. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and\/or a fee. Request permissions from permissions@acm.org. Conference\u201917, July 2017, Washington, DC, USA \u00a9 2021 Association for Computing Machinery. ACM ISBN 978-x-xxxx-xxxx-x\/YY\/MM. . . $15.00 https:\/\/doi.org\/10.1145\/nnnnnnn.nnnnnnn 1","986":"Media bias may often affect individuals' opinions on reported topics. Many existing methods that aim to identify such bias forms employ individual, specialized techniques and focus only on English texts. We propose to combine the state-of-the-art in order to further improve the performance in bias identification. Our prototype consists of three analysis components to identify media bias words in German news articles. We use an IDF-based component, a component utilizing a topic-dependent bias dictionary created using word embeddings, and an extensive dictionary of German emotional terms compiled from multiple sources. Finally, we discuss two not yet implemented analysis components that use machine learning and network analysis to identify media bias. All dictionary-based analysis components are experimentally extended with the use of general word embeddings. We also show the results of a user study.","987":"With the spread of false and misleading information in current news, many algorithmic tools have been introduced with the aim of assessing bias and reliability in written content. However, there has been little work exploring how effective these tools are at changing human perceptions of content. To this end, we conduct a study with 654 participants to understand if algorithmic assistance improves the accuracy of reliability and bias perceptions, and whether there is a difference in the effectiveness of the AI assistance for different types of news consumers. We find that AI assistance with feature-based explanations improves the accuracy of news perceptions. However, some consumers are helped more than others. Specifically, we find that participants who read and share news often on social media are worse at recognizing bias and reliability issues in news articles than those who do not, while frequent news readers and those familiar with politics perform much better. We discuss these differences and their implication to offer insights for future research.","988":"Language is a powerful tool which can be used to state the facts as well as express our views and perceptions. Most of the times, we find a subtle bias towards or against someone or something. When it comes to politics, media houses and journalists are known to create bias by shrewd means such as misinterpreting reality and distorting viewpoints towards some parties. This misinterpretation on a large scale can lead to the production of biased news and conspiracy theories. Automating bias detection in newspaper articles could be a good challenge for research in NLP. We proposed a headline attention network for this bias detection. Our model has two distinctive characteristics: (i) it has a structure that mirrors a person\u2019s way of reading a news article (ii) it has attention mechanism applied on the article based on its headline, enabling it to attend to more critical content to predict bias. As the required datasets were not available, we created a dataset comprising of 1329 news articles collected from various Telugu newspapers and marked them for bias towards a particular political party. The experiments conducted on it demonstrated that our model outperforms various baseline methods by a substantial margin.","989":"Lead bias is a common phenomenon in news summarization, where early parts of an article often contain the most salient information. While many algorithms exploit this fact in summary generation, it has a detrimental effect on teaching the model to discriminate and extract important information. We propose that the lead bias can be leveraged in a simple and effective way in our favor to pretrain abstractive news summarization models on large-scale unlabeled corpus: predicting the leading sentences using the rest of an article. Via careful data cleaning and filtering, our transformer-based pretrained model without any finetuning achieves remarkable results over various news summarization tasks. With further finetuning, our model outperforms many competitive baseline models. Human evaluations further show the effectiveness of our method.","990":"Rankings are the primary interface through which many online platforms match users to items (e.g. news, products, music, video). In these two-sided markets, not only the users draw utility from the rankings, but the rankings also determine the utility (e.g. exposure, revenue) for the item providers (e.g. publishers, sellers, artists, studios). It has already been noted that myopically optimizing utility to the users -- as done by virtually all learning-to-rank algorithms -- can be unfair to the item providers. We, therefore, present a learning-to-rank approach for explicitly enforcing merit-based fairness guarantees to groups of items (e.g. articles by the same publisher, tracks by the same artist). In particular, we propose a learning algorithm that ensures notions of amortized group fairness, while simultaneously learning the ranking function from implicit feedback data. The algorithm takes the form of a controller that integrates unbiased estimators for both fairness and utility, dynamically adapting both as more data becomes available. In addition to its rigorous theoretical foundation and convergence guarantees, we find empirically that the algorithm is highly practical and robust.","991":null,"992":"Contemporary debates on filter bubbles and polarization in public and social media raise the question to what extent news media of the past exhibited biases. This paper specifically examines bias related to gender in six Dutch national newspapers between 1950 and 1990. We measure bias related to gender by comparing local changes in word embedding models trained on newspapers with divergent ideological backgrounds. We demonstrate clear differences in gender bias and changes within and between newspapers over time. In relation to themes such as sexuality and leisure, we see the bias moving toward women, whereas, generally, the bias shifts in the direction of men, despite growing female employment number and feminist movements. Even though Dutch society became less stratified ideologically (depillarization), we found an increasing divergence in gender bias between religious and social-democratic on the one hand and liberal newspapers on the other. Methodologically, this paper illustrates how word embeddings can be used to examine historical language change. Future work will investigate how fine-tuning deep contextualized embedding models, such as ELMO, might be used for similar tasks with greater contextual information.","993":"News recommendation is important for online news services. Most news recommendation methods model users' interests from their news click behaviors. Usually the behaviors of users with the same sensitive attributes have similar patterns, and existing news recommendation models can inherit these biases and encode them into news ranking results. Thus, their recommendation results may be heavily influenced by the biases related to sensitive user attributes, which is unfair since users cannot receive sufficient news information that they are interested in. In this paper, we propose a fairness-aware news recommendation approach with decomposed adversarial learning and orthogonality regularization, which can alleviate unfairness in news recommendation brought by the biases of sensitive user attributes. For model training, we propose to learn a bias-aware user embedding that captures the bias information on user attributes from click behaviors, and learn a bias-free user embedding that only encodes attribute-independent user interest information for fairness-aware news recommendation. In addition, we propose to apply an attribute prediction task to the bias-aware user embedding to enhance its ability on bias modeling, and we apply adversarial learning to the bias-free user embedding to remove the bias information from it. Moreover, we propose an orthogonality regularization method to encourage the bias-free user embeddings to be orthogonal to the bias-aware one to further purify the bias-free user embedding. For fairness-aware news ranking, we only use the bias-free user embedding. Extensive experiments on benchmark dataset show that our approach can effectively improve fairness in news recommendation with acceptable performance loss.","994":"Fake news is increasingly an issue on social media platforms. In this work, rather than detect misinformation, we propose the use of nudges to help steer internet users into fact checking the news they read online. We discuss two types of nudging strategies, by presentation and by information. We present the tool BalancedView, a proof-of-concept that shows news stories relevant to a tweet. The method presents the user with a selection of articles from a range of reputable news sources providing alternative opinions from the whole political spectrum, with these alternative articles identified as matching the original one by a combination of natural language processing and search. The results of an initial user study of BalancedView suggest that nudging by information may change the behavior of users towards that of informed news readers.","995":null,"996":"Disinformation and fake news have posed detrimental effects on individuals and society in recent years, attracting broad attention to fake news detection. The majority of existing fake news detection algorithms focus on mining news content and\/or the surrounding exogenous context for discovering deceptive signals; while the endogenous preference of a user when he\/she decides to spread a piece of fake news or not is ignored. The confirmation bias theory has indicated that a user is more likely to spread a piece of fake news when it confirms his\/her existing beliefs\/preferences. Users' historical, social engagements such as posts provide rich information about users' preferences toward news and have great potentials to advance fake news detection. However, the work on exploring user preference for fake news detection is somewhat limited. Therefore, in this paper, we study the novel problem of exploiting user preference for fake news detection. We propose a new framework, UPFD, which simultaneously captures various signals from user preferences by joint content and graph modeling. Experimental results on real-world datasets demonstrate the effectiveness of the proposed framework. We release our code and data as a benchmark for GNN-based fake news detection: https:\/\/github.com\/safe-graph\/GNN-FakeNews.","997":"Toxic comments in online platforms are an unavoidable social issue under the cloak of anonymity. Hate speech detection has been actively done for languages such as English, German, or Italian, where manually labeled corpus has been released. In this work, we first present 9.4K manually labeled entertainment news comments for identifying Korean toxic speech, collected from a widely used online news platform in Korea. The comments are annotated regarding social bias and hate speech since both aspects are correlated. The inter-annotator agreement Krippendorff\u2019s alpha score is 0.492 and 0.496, respectively. We provide benchmarks using CharCNN, BiLSTM, and BERT, where BERT achieves the highest score on all tasks. The models generally display better performance on bias identification, since the hate speech detection is a more subjective issue. Additionally, when BERT is trained with bias label for hate speech detection, the prediction score increases, implying that bias and hate are intertwined. We make our dataset publicly available and open competitions with the corpus and benchmarks.","998":"The spread of biased news and its consumption by the readers has become a considerable issue. Researchers from multiple domains including social science and media studies have made efforts to mitigate this media bias issue. Specifically, various techniques ranging from natural language processing to machine learning have been used to help determine news bias automatically. However, due to the lack of publicly available datasets in this field, especially ones containing labels concerning bias on a fine-grained level (e.g., on sentence level), it is still challenging to develop methods for effectively identifying bias embedded in new articles. In this paper, we propose a novel news bias dataset which facilitates the development and evaluation of approaches for detecting subtle bias in news articles and for understanding the characteristics of biased sentences. Our dataset consists of 966 sentences from 46 English-language news articles covering 4 different events and contains labels concerning bias on the sentence level. For scalability reasons, the labels were obtained based on crowd-sourcing. Our dataset can be used for analyzing news bias, as well as for developing and evaluating methods for news bias detection. It can also serve as resource for related researches including ones focusing on fake news detection.","999":"In this paper, we present a dataset of 713k articles collected between 02\/2018-11\/2018. These articles are collected directly from 194 news and media outlets including mainstream, hyper-partisan, and conspiracy sources. We incorporate ground truth ratings of the sources from 8 different assessment sites covering multiple dimensions of veracity, including reliability, bias, transparency, adherence to journalistic standards, and consumer trust. The NELA-GT-2018 dataset can be found at this https URL.","1000":"News\u2014real or fake\u2014is now abundant on social media. News posts on social media focus users\u2019 attention on the headlines, but does it matter who wrote the article? We investigate whether changing the presentation format to highlight the source of the article affects its believability and how social media users choose to engage with it. We conducted two experiments and found that nudging users to think about who wrote the article influenced the extent to which they believed it. The presentation format of highlighting the source had a main effect; it made users more skeptical of all articles, regardless of the source\u2019s credibility. For unknown sources, low source ratings had a direct effect on believability. Believability, in turn, influenced the extent to which users would engage with the article (e.g., read, like, comment, and share). We also found confirmation bias to be rampant: users were more likely to believe articles that aligned with their beliefs, over and above the effects of other factors.","1001":"Fake news (i.e., misinformation) on social media has sharply increased in the past few years. We conducted a behavioral experiment with EEG data from 83 social media users to understand whether they could detect fake news on social media, and whether the presence of a fake news flag affected their cognition and judgment. We found that the presence of a fake news flag triggered increased cognitive activity and users spent more time considering the headline. However, the flag had no effect on judgments about truth; flagging headlines as false did not influence users\u2019 beliefs. A post hoc analysis shows that confirmation bias is pervasive, with users more likely to believe news headlines that align with their political opinions. Headlines that challenge their opinions receive little cognitive attention (i.e., they are ignored) and users are less likely to believe them.","1002":"The rising prevalence of fake news and its alarming downstream impact have motivated both the industry and academia to build a substantial number of fake news classification models, each with its unique architecture. Yet, the research community currently lacks a comprehensive model evaluation framework that can provide multifaceted comparisons between these models beyond the simple evaluation metrics such as accuracy or f1 scores. In our work, we examine a representative subset of classifiers using a very simple set of performance evaluation and error analysis steps. We demonstrate that model performance varies considerably based on i) dataset, ii) evaluation archetype, and iii) performance metrics. Additionally, classifiers also demonstrate a potential bias against small and conservative-leaning credible news sites. Finally, models' performance varies based on external events and article topics. In sum, our results highlight the need to move toward systematic benchmarking.","1003":"ABSTRACT Most people receive political news from social media platforms. Unlike traditional media, these platforms algorithmically determine the order in which news is presented, in part relying on an article\u2019s popularity (i.e. number of likes, shares, and comments) to determine its ranking. To what extent does sorting the news by popularity influence people\u2019s attitudes toward politics? With two large, nationally representative samples of adults and a novel experimental design, we find that ranking news articles by their popularity has consequential effects that vary depending on the partisan composition of the group upon which the rankings are based. Overall, algorithmic sorting exacerbates the tendency to \u201clike\u201d news that conform to the dominant viewpoint of the reference group. For example, when the group is ideologically like-minded, the in-party bias in \u201cliking\u201d creates a self-perpetuating cycle, where attitudinally congruent articles remain at the top of the feed. When the reference group is rather composed of out-party members, politically incongruent items rise to the top. While this helps to expose readers to new information, they also become disengaged from reading and sharing political news. Overall, our study holds important implications for how using social media as an outlet for political information can influence \u2013 and even polarize \u2013 our political preferences.","1004":null,"1005":"The majority of news published online presents one or more images or videos, which make the news more easily consumed and therefore more attractive to huge audiences. As a consequence, news with catchy multimedia content can be spread and get viral extremely quickly. Unfortunately, the availability and sophistication of photo editing software are erasing the line between pristine and manipulated content. Given that images have the power of bias and influence the opinion and behavior of readers, the need of automatic techniques to assess the authenticity of images is straightforward. This paper aims at detecting images published within online news that have either been maliciously modified or that do not represent accurately the event the news is mentioning. The proposed approach composes image forensic algorithms for detecting image tampering, and textual analysis as a verifier of images that are misaligned to textual content. Furthermore, textual analysis can be considered as a complementary source of information supporting image forensics techniques when they falsely detect or falsely ignore image tampering due to heavy image postprocessing. The devised method is tested on three datasets. The performance on the first two shows interesting results, with F1-score generally higher than 75%. The third dataset has an exploratory intent; in fact, although showing that the methodology is not ready for completely unsupervised scenarios, it is possible to investigate possible problems and controversial cases that might arise in real-world scenarios.","1006":"In this work, we develop a social reinforcement learning approach to combat the spread of fake news. Specifically, we aim to learn an intervention model to promote the spread of true news in a social network\u2014in order to mitigate the impact of fake news. We model news diffusion as a Multivariate Hawkes Process (MHP) and make interventions that are learnt via policy optimization. The key insight is to estimate the response a user will get from the social network upon sharing a post, as it indicates her impact on diffusion, and will thus help in efficient allocation of incentive. User responses also depend on political bias and peerinfluence, which we model as a second MHP, interleaving it with the news diffusion process. We evaluate our model on semi-synthetic and real-world data. The results demonstrate that our proposed model outperforms other alternatives that do not consider estimates of user responses and political bias when learning how to allocate incentives.","1007":"To apply eyeshadow without a brush, should I use a cotton swab or a toothpick? Questions requiring this kind of physical commonsense pose a challenge to today's natural language understanding systems. While recent pretrained models (such as BERT) have made progress on question answering over more abstract domains \u2013 such as news articles and encyclopedia entries, where text is plentiful \u2013 in more physical domains, text is inherently limited due to reporting bias. Can AI systems learn to reliably answer physical commonsense questions without experiencing the physical world?In this paper, we introduce the task of physical commonsense reasoning and a corresponding benchmark dataset Physical Interaction: Question Answering or PIQA. Though humans find the dataset easy (95% accuracy), large pretrained models struggle (\u223c75%). We provide analysis about the dimensions of knowledge that existing models lack, which offers significant opportunities for future research.","1008":"Many applications of computational social science aim to infer causal conclusions from non-experimental data. Such observational data often contains confounders, variables that influence both potential causes and potential effects. Unmeasured or latent confounders can bias causal estimates, and this has motivated interest in measuring potential confounders from observed text. For example, an individual\u2019s entire history of social media posts or the content of a news article could provide a rich measurement of multiple confounders.Yet, methods and applications for this problem are scattered across different communities and evaluation practices are inconsistent.This review is the first to gather and categorize these examples and provide a guide to data-processing and evaluation decisions. Despite increased attention on adjusting for confounding using text, there are still many open problems, which we highlight in this paper.","1009":"We propose a model of optimal decision making subject to a memory constraint. The constraint is a limit on the complexity of memory measured using Shannon's mutual information, as in models of rational inattention; but our theory differs from that of Sims (2003) in not assuming costless memory of past cognitive states. We show that the model implies that both forecasts and actions will exhibit idiosyncratic random variation; that average beliefs will also differ from rational-expectations beliefs, with a bias that fluctuates forever with a variance that does not fall to zero even in the long run; and that more recent news will be given disproportionate weight in forecasts. We solve the model under a variety of assumptions about the degree of persistence of the variable to be forecasted and the horizon over which it must be forecasted, and examine how the nature of forecast biases depends on these parameters. The model provides a simple explanation for a number of features of reported expectations in laboratory and field settings, notably the evidence of over-reaction in elicited forecasts documented by Afrouzi et al. (2020) and Bordalo et al. (2020a).","1010":"Despite the recent developments on neural summarization systems, the underlying logic behind the improvements from the systems and its corpus-dependency remains largely unexplored. Position of sentences in the original text, for example, is a well known bias for news summarization. Following in the spirit of the claim that summarization is a combination of sub-functions, we define three sub-aspects of summarization: position, importance, and diversity and conduct an extensive analysis of the biases of each sub-aspect with respect to the domain of nine different summarization corpora (e.g., news, academic papers, meeting minutes, movie script, books, posts). We find that while position exhibits substantial bias in news articles, this is not the case, for example, with academic papers and meeting minutes. Furthermore, our empirical study shows that different types of summarization systems (e.g., neural-based) are composed of different degrees of the sub-aspects. Our study provides useful lessons regarding consideration of underlying sub-aspects when collecting a new summarization dataset or developing a new system.","1011":"We address the problem of predicting the leading political ideology, i.e., left-center-right bias, for YouTube channels of news media. Previous work on the problem has focused exclusively on text and on analysis of the language used, topics discussed, sentiment, and the like. In contrast, here we study videos, which yields an interesting multimodal setup. Starting with gold annotations about the leading political ideology of major world news media from Media Bias\/Fact Check, we searched on YouTube to find their corresponding channels, and we downloaded a recent sample of videos from each channel. We crawled more than 1,000 YouTube hours along with the corresponding subtitles and metadata, thus producing a new multimodal dataset. We further developed a multimodal deep-learning architecture for the task. Our analysis shows that the use of acoustic signal helped to improve bias detection by more than 6% absolute over using text and metadata only. We release the dataset to the research community, hoping to help advance the field of multi-modal political bias detection.","1012":"Personalized news recommendation methods are widely used in online news services. These methods usually recommend news based on the matching between news content and user interest inferred from historical behaviors. However, these methods usually have difficulties in making accurate recommendations to cold-start users, and tend to recommend similar news with those users have read. In general, popular news usually contain important information and can attract users with different interests. Besides, they are usually diverse in content and topic. Thus, in this paper we propose to incorporate news popularity information to alleviate the cold-start and diversity problems for personalized news recommendation. In our method, the ranking score for recommending a candidate news to a target user is the combination of a personalized matching score and a news popularity score. The former is used to capture the personalized user interest in news. The latter is used to measure time-aware popularity of candidate news, which is predicted based on news content, recency, and real-time CTR using a unified framework. Besides, we propose a popularity-aware user encoder to eliminate the popularity bias in user behaviors for accurate interest modeling. Experiments on two real-world datasets show our method can effectively improve the accuracy and diversity for news recommendation.","1013":"We now have almost no filters on information that we can access, and this requires a much more vigilant, knowledgeable reader. Learning false information from the web can have dire consequences for personal, social, and personal decision making. Given how our memory works and our biases in selecting and interpreting information, now more than ever we must control our own cognitive and affective processing. As examples: Simply repeating information can increase confidence in its perceived truth; initial incorrect information remains available and can continue to have an effect despite learning the corrected information; and we are more likely to accept information that is consistent with our beliefs. Information evaluation requires readers (a) to set and monitor their goals of accuracy, coherence, and completeness; (b) to employ strategies to achieve these goals; and (c) to value this time- and effort-consuming systematic evaluation. Several recommendations support a reasoned approach to fake news and manipulation.","1014":"Although fake news has been present in human history at any time, nowadays, with social media, deceptive information has a stronger effect on society than before. This article answers two research questions, namely (1) Is the dissemination of fake news supported by machines through the automatic con...","1015":"Comparative summarization is an effective strategy to discover important similarities and differences in collections of documents biased to users' interests. A natural method of this task is to find important and corresponding content. In this paper, we propose a novel research task of automatic query-based across-time summarization in news archives as well as we introduce an effective method to solve this task. The proposed model first learns an orthogonal transformation between temporally distant news collections. Then, it generates a set of corresponding sentence pairs based on a concise integer linear programming framework. We experimentally demonstrate the effectiveness of our method on the New York Times Annotated Corpus.","1016":"With the development of NLP technologies, news can be automatically categorized and labeled according to a variety of characteristics, at the same time be represented as low dimensional embeddings. However, it lacks a systematic approach that effectively integrates the inherited features and inter-textual knowledge of news to represent the collective information with a dense vector. With the aim of filling this gap, the News2vec model is proposed to allow the distributed representation of news taking into account its associated features. To describe the cross-document linkages between news, a network consisting of news and its attributes is constructed. Moreover, the News2vec model treats the news node as a bag of features by developing the Subnode model. Based on the biased random walk and the skip-gram model, each news feature is mapped to a vector, and the news is thus represented as the sum of its features. This approach offers an easy solution to create embeddings for unseen news nodes based on its attributes. To evaluate our model, dimension reduction plots and correlation heat-maps are created to visualize the news vectors, together with the application of two downstream tasks, the stock movement prediction and news recommendation. By comparing with other established text\/sentence embedding models, we show that News2vec achieves state-of-the-art performance on these news-related tasks.","1017":"In the past, news recommender systems have been built to recommend list of news items similar to those that a user has accessed before (content-based); or similar to those that have been read by similar users (collaborative filtering). However, the highly volatile nature of the news content and the dynamic and evolving user preferences are either ignored or not taken into full consideration in these systems. In a news recommender system, it is very likely that a user\u2019s short-term interest or preference may have a sudden change due to an emerging social or personal event or breaking news while their long-term interests may change gradually or remain. For these long-term interests of the readers, it is often more appropriate to associate them with news categories than with individual news items. In this paper, we propose a biased matrix factorization model with consideration of both temporal dynamics of user preferences and news taxonomy to build a news recommender system. By conducting an extensive experiment on a collection of news data, we demonstrate the effectiveness of our proposed model against traditional matrix factorization models as well as other neural recommender baselines. The findings from our experiments show that news category is an important factor when readers choose news articles to read, and temporal factors with consideration of different temporal resolution also play a role in this process.","1018":"Temporal point process is widely used for sequential data modeling. In this article, we focus on the problem of modeling sequential event propagation in graph, such as retweeting by social network users and news transmitting between websites. Given a collection of event propagation sequences, the conventional point process model considers only the event history, i.e., embed event history into a vector, not the latent graph structure. We propose a graph biased temporal point process (GBTPP) leveraging the structural information from graph representation learning, where the direct influence between nodes and indirect influence from event history is modeled. Moreover, the learned node embedding vector is also integrated into the embedded event history as side information. Experiments on a synthetic data set and two real-world data sets show the efficacy of our model compared with conventional methods and state-of-the-art ones.","1019":"While Big Data has garnered attention for its impact on firms and consumers, the algorithms that make sense of the large data sets are recently in the news \u2013 and not only for creating value but for being biased and unfair. Algorithms \u2013 including artificial intelligence, machine learning, and neural networks \u2013 drive critical decisions such as which patient is seen, who is offered insurance, or what street is patrolled by the police. Such algorithmic decisions, like all decisions, are biased and make mistakes. However the question remains, who is responsible for managing those mistakes? What is the appropriate role of algorithms in critical decisions such as being promoted, receiving medical care, or being offered a loan? I turn to focus on the design of ethical algorithms and the responsibility of developers and users of algorithms to ensure algorithms support good decisions. \n \nI make two ethical arguments. First, while mistakes may be unintentional, ignoring or even fostering mistakes is unethical \u2013mistakes can diminish rights, cause harms, or be unfair. Ethical algorithms should be designed to be governed by identifying, judging, and correcting mistakes. Second, by creating inscrutable, autonomous algorithms, developers may voluntarily take on accountability for the role of the algorithm in the decision including the ability to correct mistakes.","1020":"We develop a general framework for measuring biases in expectation formation. The method is based on the insight that biases can be inferred from the response of forecast errors to past news. Empirically, biases are measured by flexibly estimating the impulse response function of forecast errors. The framework does not require precise knowledge of the true data-generating process, and it nests all major existing models of expectations. Monte Carlo simulations show that the method is able to detect biases in empirically relevant settings. We illustrate the methodology using data on inflation forecasts. Our framework can guide future models of expectations.","1021":"Recent work has shown that distributional word vector spaces often encode human biases like sexism or racism. In this work, we conduct an extensive analysis of biases in Arabic word embeddings by applying a range of recently introduced bias tests on a variety of embedding spaces induced from corpora in Arabic. We measure the presence of biases across several dimensions, namely: embedding models (Skip-Gram, CBOW, and FastText) and vector sizes, types of text (encyclopedic text, and news vs. user-generated content), dialects (Egyptian Arabic vs. Modern Standard Arabic), and time (diachronic analyses over corpora from different time periods). Our analysis yields several interesting findings, e.g., that implicit gender bias in embeddings trained on Arabic news corpora steadily increases over time (between 2007 and 2017). We make the Arabic bias specifications (AraWEAT) publicly available.","1022":"Currently, social media for news consumption is preferred over the conventional media and attracted many people due to its low cost, easy access, simplistic way of commenting & sharing, more timely nature, and rapid information sharing capabilities. On the other hand, it aggravates the prompt and wide spreading of fake news. Fake news may be fabricated for the purpose of, commercial gain, political propaganda, seeking attention, and intent of defamation. Interest of individuals, and various groups to influence events and policies around the globe is the other reason for fake news generation and dissemination. The extensive spread of fake news is progressively becoming a threat to individuals and society as a whole. It disrupts the authenticity balance of the news ecosystem; induces biased or false beliefs into consumers; creates real-life fears in the society and threatens freedom of speech, freedom of the press and democracy. The craving to mitigate the undesirable effects of fake news, recently makes fake news detection on social media an emerging research area attracting tremendous attention. Following this warm concern, various researches have been conducted and showed promising results. In this work, we propose a model for early detection of fake news using deep learning, and news content. Deep learning and heterogeneous dataset has been used to create a more generic model that could perform better in the real world. We conducted experiments on two real world datasets and a third dataset which is obtained by combining the two datasets and randomly shuffled them. Our experiment results have shown that early detection of fake news using news content and deep learning models, without waiting for news propagation, is achievable and should be given better attention to combat fake news effectively before it proliferates and misleads many people. The experimental results obtained are interesting.","1023":"As civil discourse increasingly takes place online, misinformation and the polarization of news shared in online communities have become ever more relevant concerns with real world harms across our society. Studying online news sharing at scale is challenging due to the massive volume of content which is shared by millions of users across thousands of communities. Therefore, existing research has largely focused on specific communities or specific interventions, such as bans. However, understanding the prevalence and spread of misinformation and polarization more broadly, across thousands of online communities, is critical for the development of governance strategies, interventions, and community design. Here, we conduct the largest study of news sharing on reddit to date, analyzing more than 550 million links spanning 4 years. We use non-partisan news source ratings from Media Bias\/Fact Check to annotate links to news sources with their political bias and factualness. We find that, compared to leftleaning communities, right-leaning communities have 105% more variance in the political bias of their news sources, and more links to relatively-more biased sources, on average. We observe that reddit users\u2019 voting and re-sharing behaviors generally decrease the visibility of extremely biased and low factual content, which receives 20% fewer upvotes and 30% fewer exposures from crossposts than more neutral or more factual content. This suggests that reddit is more resilient to low factual content than Twitter. We show that extremely biased and low factual content is very concentrated, with 99% of such content being shared in only 0.5% of communities, giving credence to the recent strategy of community-wide bans and quarantines.","1024":"In recent years, we have witnessed a rise in fake news, i.e., provably false pieces of information created with the intention of deception. The dissemination of this type of news poses a serious threat to cohesion and social well-being, since it fosters political polarization and the distrust of people with respect to their leaders. The huge amount of news that is disseminated through social media makes manual verification unfeasible, which has promoted the design and implementation of automatic systems for fake news detection. The creators of fake news use various stylistic tricks to promote the success of their creations, with one of them being to excite the sentiments of the recipients. This has led to sentiment analysis, the part of text analytics in charge of determining the polarity and strength of sentiments expressed in a text, to be used in fake news detection approaches, either as a basis of the system or as a complementary element. In this article, we study the different uses of sentiment analysis in the detection of fake news, with a discussion of the most relevant elements and shortcomings, and the requirements that should be met in the near future, such as multilingualism, explainability, mitigation of biases, or treatment of multimedia elements.","1025":"Users are known to interact more with fresh content in certain temporally associated domains such as news search or job seeking, leading to an uneven distribution of interactions over items of different degrees of freshness. Data collected under such an \"aging effect'' is usually used unconditionally on all sort of recommendation tasks, and as a result more recently published content may be over-represented during model training and evaluation. In this study, we characterize this temporal influence as a recency bias, and present an analysis in the domain of job recommendation. We show that, by correcting for recency bias using an unbiased learning to rank approach, one can improve the quality of recommendation significantly over a recent neural collaborative filtering model on RecSys Challenge 2017 data.","1026":"Sentence position is a strong feature for news summarization, since the lead often (but not always) summarizes the key points of the article. In this paper, we show that recent neural systems excessively exploit this trend, which although powerful for many inputs, is also detrimental when summarizing documents where important content should be extracted from later parts of the article. We propose two techniques to make systems sensitive to the importance of content in different parts of the article. The first technique employs \u2018unbiased\u2019 data; i.e., randomly shuffled sentences of the source document, to pretrain the model. The second technique uses an auxiliary ROUGE-based loss that encourages the model to distribute importance scores throughout a document by mimicking sentence-level ROUGE scores on the training data. We show that these techniques significantly improve the performance of a competitive reinforcement learning based extractive system, with the auxiliary loss being more powerful than pretraining.","1027":"Technical interviews\u2014a problem-solving form of interview in which candidates write code\u2014are commonplace in the software industry, and are used by several well-known companies including Facebook, Google, and Microsoft. These interviews are intended to objectively assess candidates and determine fit within the company. But what do developers say about them?To understand developer perceptions about technical interviews, we conducted a qualitative study using the online social news website, Hacker News\u2014a venue for software practitioners. Hacker News posters report several concerns and negative perceptions about interviews, including their lack of real-world relevance, bias towards younger developers, and demanding time commitment. Posters report that these interviews cause unnecessary anxiety and frustration, requiring them to learn arbitrary, implicit, and obscure norms. The findings from our study inform inclusive hiring guidelines for technical interviews, such as collaborative problem-solving sessions.","1028":"Security and privacy researchers often rely on data collected from Amazon Mechanical Turk (MTurk) to evaluate security tools, to understand users' privacy preferences and to measure online behavior. Yet, little is known about how well Turkers' survey responses and performance on security- and privacy-related tasks generalizes to a broader population. This paper takes a first step toward understanding the generalizability of security and privacy user studies by comparing users' self-reports of their security and privacy knowledge, past experiences, advice sources, and behavior across samples collected using MTurk (n=480), a census-representative web-panel (n=428), and a probabilistic telephone sample (n=3,000) statistically weighted to be accurate within 2.7% of the true prevalence in the U.S. Surprisingly, the results suggest that: (1) MTurk responses regarding security and privacy experiences, advice sources, and knowledge are more representative of the U.S. population than are responses from the census-representative panel; (2) MTurk and general population reports of security and privacy experiences, knowledge, and advice sources are quite similar for respondents who are younger than 50 or who have some college education; and (3) respondents' answers to the survey questions we ask are stable over time and robust to relevant, broadly-reported news events. Further, differences in responses cannot be ameliorated with simple demographic weighting, possibly because MTurk and panel participants have more internet experience compared to their demographic peers. Together, these findings lend tempered support for the generalizability of prior crowdsourced security and privacy user studies; provide context to more accurately interpret the results of such studies; and suggest rich directions for future work to mitigate experience- rather than demographic-related sample biases.","1029":"Text summarization aims to extract essential information from a piece of text and transform the text into a concise version. Existing unsupervised abstractive summarization models leverage recurrent neural networks framework while the recently proposed transformer exhibits much more capability. Moreover, most of previous summarization models ignore abundant unlabeled corpora resources available for pretraining. In order to address these issues, we propose TED, a transformer-based unsupervised abstractive summarization system with pretraining on large-scale data. We first leverage the lead bias in news articles to pretrain the model on millions of unlabeled corpora. Next, we finetune TED on target domains through theme modeling and a denoising autoencoder to enhance the quality of generated summaries. Notably, TED outperforms all unsupervised abstractive baselines on NYT, CNN\/DM and English Gigaword datasets with various document styles. Further analysis shows that the summaries generated by TED are highly abstractive, and each component in the objective function of TED is highly effective.","1030":"This paper presents our on-going research on studying the actors responsible for misinformation spread and identifying potential victims. Preliminary results show that (i) there is a correlation between fake news publisher bias and its credibility and (ii) social network properties help in identifying active fake news spreaders. Moreover, we discuss the most vulnerable victims of fake news and report on our experience in educating seniors about online misinformation.","1031":"IN M ARCH 2011, the catastrophic accident known as \u201cThe Fukushima Daiichi nuclear disaster\u201d took place, initiated by the Tohoku earthquake and tsunami in Japan. The only nuclear accident to receive a Level-7 classification on the International Nuclear Event Scale since the Chernobyl nuclear power plant disaster in 1986, the Fukushima event triggered global concerns and rumors regarding radiation leaks. Among the false rumors was an image, which had been described as a map of radioactive discharge emanating into the Pacific Ocean, as illustrated in the accompanying figure. In fact, this figure, depicting the wave height of the tsunami that followed, still to this date circulates on social media with the inaccurate description. Social media is ideal for spreading rumors, because it lacks censorship. Confirmation bias and filter-bubble effects further amplify the spread of unconfirmed information. Upon public outcry, independent fact-checking organizations have emerged globally, and many platforms are making efforts to fight against fake news. For example, the state-run Factually website in Singapore has been known to clarify falsehoods since its inception in May 2012, which was followed recently by the implementation of the Protection from Online Falsehoods and Manipulation Act (POFMA) in October 2019. In Taiwan, the government officially created a feature on the website of the Executive Yuan (the executive branch of Taiwan\u2019s government) to identify erroneous reporting and combat the spread of fake news. Taiwan\u2019s Open Culture Foundation has also developed and introduced the well-known anti-fake fact-checking chatbot Cofacts in May 2018. The Indonesia government since 2018 has held weekly briefings on hoax news; that same year, the country revised its Criminal Code to permit the imprisonment for up to six years of anyone spreading fake news. Governments in the Asia and Oceania region, including South Korea, Singapore, Japan, Taiwan, Philippines, Cambodia, Malaysia, have enacted relevant laws to prevent fake news from spreading. Nonetheless, fact-checking of fake news remains daunting, and requires tremendous time and effort in terms of human investigation. Moreover, it is prone to low efficiency and inadequate coverage due to the complexity of the topics being checked, and is incapable of keeping up with the fast DOI:10.1145\/3378422","1032":"The problem of social influence maximization is widely applicable in designing viral campaigns, news dissemination, or medical aid. State-of-the-art algorithms often select \u201cearly adopters\u201d that are most central in a network unfortunately mirroring or exacerbating historical biases and leaving under-represented communities out of the loop. Through a theoretical model of biased networks, we characterize the intricate relationship between diversity and efficiency, which sometimes may be at odds but may also reinforce each other. Most importantly, we find a mathematically proven analytical condition under which more equitable choices of early adopters lead simultaneously to fairer outcomes and larger outreach. Analysis of data on the DBLP network confirms that our condition is often met in real networks. We design and test a set of algorithms leveraging the network structure to optimize the diffusion of a message while avoiding to create disparate impact among participants based on their demographics, such as gender or race.","1033":null,"1034":"News media bias is commonly associated with framing information so as to influence readers judgments. It is not rare to find different news outlets reporting the same events under different perspectives with the intention to deliberately influence the reader. For example, making one side's ideological perspective look better than another. This may be an indication of a well known cognitive bias, the framing effect, which states that people may change their judgment based on how the information is presented (or framed). According to a 2017's survey from the Knight Foundation and Gallup, Americans believe that 62% of the news they consume is biased [1]. Still according to the survey, there is a sharp divergence of bias perception across Republicans and Democrats regarding news organizations. This implies that the perception of bias may be affected by whether one agrees (or not) with the ideological leaning (when present) of the news source. How to expose such biases in an automatic fashion from textual content only? One way to do that is by comparing different news outlets on the same stories and look for divergences. In this talk, we present an investigation on news media bias in the context of Brazilian presidential elections by comparing four popular news outlets during three consecutive election years (2010, 2014, and 2018). We analyse the textual content of news stories in search for three kinds of bias: coverage, association, and subjective language. Coverage bias is related to differences in mention rates of candidates and parties. Association bias [2] occurs when, for example, one candidate is associated with a negative concept while another not. Subjective bias [3], has to do with wording that attempts to influence the readers by appealing to emotion, stereotypes, or persuasive language. We perform a thorough analysis on a large scale news data set where several such biases are exposed.","1035":"Media platforms, technological systems, and search engines act as conduits and gatekeepers for all kinds of information. They often influence, reflect, and reinforce gender stereotypes, including those that represent occupations. This study examines the prevalence of gender stereotypes on digital media platforms and considers how human efforts to create and curate messages directly may impact these stereotypes. While gender stereotyping in social media and algorithms has received some examination in the recent literature, its prevalence in different types of platforms (for example, wiki vs. news vs. social network) and under differing conditions (for example, degrees of human\u2010 and machine\u2010led content creation and curation) has yet to be studied. This research explores the extent to which stereotypes of certain strongly gendered professions (librarian, nurse, computer programmer, civil engineer) persist and may vary across digital platforms (Twitter, the New York Times online, Wikipedia, and Shutterstock). The results suggest that gender stereotypes are most likely to be challenged when human beings act directly to create and curate content in digital platforms, and that highly algorithmic approaches for curation showed little inclination towards breaking stereotypes. Implications for the more inclusive design and use of digital media platforms, particularly with regard to mediated occupational messaging, are discussed.","1036":"Online news consumers have the tendency to select political news that confirms their prior attitudes, which may further fuel polarized divides in society. Despite scholarly attention to drivers of selective exposure, we know too little about how healthier cross-cutting news exposure patterns can be stimulated in digital media environments. Study 1 (N\u2009=\u2009553) exposed people to news media literacy (NML) interventions using injunctive and descriptive normative language. The findings reveal the conditional effect of such online interventions: Participants with pro-immigration attitudes engaged in more cross-cutting exposure while the intervention was only to a certain extent effective for Democrats, ineffective for Republicans, and even boomeranged for partisans with anti-immigration attitudes. In response to these findings, Study 2 (N\u2009=\u2009579) aimed to design interventions that work across issue publics and party affiliation. We show that NML messages tailored on immigration beliefs can be effective across the board. These findings inform the design of more successful NML interventions.","1037":"In this study we present in-depth quantitative and qualitative analyses of the behavior of multimodal deceptive news classification models. We present several neural network architectures trained on thousands of tweets that leverage combinations of text, lexical, and, most importantly, image input signals. The behavior of these models is analyzed across four deceptive news prediction tasks. Our quantitative analysis reveals that text only models outperform those leveraging only the image signals (by 3-13% absolute in F-measure). Neural network models that combine image and text signals with lexical features e.g., biased and subjective language markers perform even better e.g., F-measure is as high as 0.74 for binary classification setup for distinguishing between verified and deceptive content identified as disinformation and propaganda. Our qualitative analysis of model performance, that goes beyond the F-score, performed using a novel interactive tool ERRFILTER1 allows a user to characterize text and image traits of suspicious news content and analyze patterns of errors made by the various models, which in turn will inform the design of future deceptive news prediction models.","1038":"A common task among social scientists is to mine and interpret public opinion using social media data. Scientists tend to employ off-theshelf state-of-the-art short-text classification models. Those algorithms, however, require a large amount of labeled data. Recent efforts aim to decrease the compulsory number of labeled data via self-supervised learning and fine-tuning. In this work, we explore the use of news data on a specific topic in fine-tuning opinion mining models learned from social media data, such as Twitter. Particularly, we investigate the influence of biased news data on models trained on Twitter data by considering both the balanced and unbalanced cases. Results demonstrate that tuning with biased news data of different properties changes the classification accuracy up to 9.5%. The experimental studies reveal that the characteristics of the text of the tuning dataset, such as bias, vocabulary diversity and writing style, are essential for the final classification results, while the size of the data is less consequential. Moreover, a state-of-the-art algorithm is not robust on unbalanced twitter dataset, and it exaggerates when predicting the most frequent label. Copyright c \u00a9 2019 for the individual papers by the papers\u2019 authors. Copying permitted for private and academic purposes. This volume is published and copyrighted by its editors. In: A. Aker, D. Albakour, A. Barr\u00f3n-Cede\u00f1o, S. Dori-Hacohen, M. Martinez, J. Stray, S. Tippmann (eds.): Proceedings of the NewsIR\u201919 Workshop at SIGIR, Paris, France, 25-July-2019, published at http:\/\/ceur-ws.org","1039":"We describe our submission to SemEval-2019 Task 4 on Hyperpartisan News Detection. We rely on a variety of engineered features originally used to detect propaganda. This is based on the assumption that biased messages are propagandistic and promote a particular political cause or viewpoint. In particular, we trained a logistic regression model with features ranging from simple bag of words to vocabulary richness and text readability. Our system achieved 72.9% accuracy on the manually annotated testset, and 60.8% on the test data that was obtained with distant supervision. Additional experiments showed that significant performance gains can be achieved with better feature pre-processing.","1040":"The internet and the high use of social media have enabled the modern-day journalism to publish, share and spread news that is difficult to distinguish if it is true or fake. Defining \u201cfake news\u201d is not well established yet, however, it can be categorized under several labels: false, biased, or framed to mislead the readers that are characterized as propaganda. Digital content production technologies with logical fallacies and emotional language can be used as propaganda techniques to gain more readers or mislead the audience. Recently, several researchers have proposed deep learning (DL) models to address this issue. This research paper provides an ensemble deep learning model using BiLSTM, XGBoost, and BERT to detect propaganda. The proposed model has been applied on the dataset provided by the challenge NLP4IF 2019, Task 1 Sentence Level Classification (SLC) and it shows a significant performance over the baseline model.","1041":"Emotion analysis has been attracting researchers\u2019 attention. Most previous works in the artificial-intelligence field focus on recognizing emotion rather than mining the reason why emotions are not or wrongly recognized. The correlation among emotions contributes to the failure of emotion recognition. In this article, we try to fill the gap between emotion recognition and emotion correlation mining through natural language text from Web news. The correlation among emotions, expressed as the confusion and evolution of emotion, is primarily caused by human emotion cognitive bias. To mine emotion correlation from emotion recognition through text, three kinds of features and two deep neural-network models are presented. The emotion confusion law is extracted through an orthogonal basis. The emotion evolution law is evaluated from three perspectives: one-step shift, limited-step shifts, and shortest path transfer. The method is validated using three datasets: 1) the titles; 2) the bodies; and 3) the comments of news articles, covering both objective and subjective texts in varying lengths (long and short). The experimental results show that in subjective comments, emotions are easily mistaken as anger. Comments tend to arouse emotion circulations of love\u2013anger and sadness\u2013anger. In objective news, it is easy to recognize text emotion as love and cause fear\u2013joy circulation. These findings could provide insights for applications regarding affective interaction, such as network public sentiment, social media communication, and human\u2013computer interaction.","1042":"Social media has become the backbone of today\u2019s lifestyle. It has a widespread effect on nearly every walk of life. One of the well-known social media applications WhatsApp Messenger is a free and cross-platform text messaging software that also provides services for sending and receiving multimedia messages. But at the same time in recent years, its easy accessibility has served a way for propagating fake and biased news articles, blogs and messages. Fake news and messages have paved their way for Political polarization, ethnic tensions, unwanted panic and mass hysteria. A solution is proposed that uses Natural Language Processing for analyzing the messages and leverage Transfer Learning Models to detect the authenticity of the information. Claims are filtered from the bulk of forwarded messages disseminated on WhatsApp. The solution comprises of a semantic search mechanism between each claim and associated news sources. The similarity comparison done by the model predicts the truthfulness of the claim.","1043":"Users of music streaming, video streaming, news recommendation, and e-commerce services often engage with content in a sequential manner. Providing and evaluating good sequences of recommendations is therefore a central problem for these services. Prior reweighting-based counterfactual evaluation methods either suffer from high variance or make strong independence assumptions about rewards. We propose a new counterfactual estimator that allows for sequential interactions in the rewards with lower variance in an asymptotically unbiased manner. Our method uses graphical assumptions about the causal relationships of the slate to reweight the rewards in the logging policy in a way that approximates the expected sum of rewards under the target policy. Extensive experiments in simulation and on a live recommender system show that our approach outperforms existing methods in terms of bias and data efficiency for the sequential track recommendations problem.","1044":"Media coverage has a substantial effect on the public perception of events. Nevertheless, media outlets are often biased. One way to bias news articles is by altering the word choice. The automatic identification of bias by word choice is challenging, primarily due to the lack of a gold standard data set and high context dependencies. This paper presents BABE, a robust and diverse data set created by trained experts, for media bias research. We also analyze why expert labeling is essential within this domain. Our data set offers better annotation quality and higher inter-annotator agreement than existing work. It consists of 3,700 sentences balanced among topics and outlets, containing media bias labels on the word and sentence level. Based on our data, we also introduce a way to detect bias-inducing sentences in news articles automatically. Our best performing BERT-based model is pre-trained on a larger corpus consisting of distant labels. Fine-tuning and evaluating the model on our proposed supervised data set, we achieve a macro F1-score of 0.804, outperforming existing methods.","1045":"Many recent news headlines have labeled face recognition technology as \"biased\" or \"racist\". We report on a methodical investigation into differences in face recognition accuracy between African-American and Caucasian image cohorts of the MORPH dataset. We find that, for all four matchers considered, the impostor and the genuine distributions are statistically significantly different between cohorts. For a fixed decision threshold, the African-American image cohort has a higher false match rate and a lower false non-match rate. ROC curves compare verification rates at the same false match rate, but the different cohorts achieve the same false match rate at different thresholds. This means that ROC comparisons are not relevant to operational scenarios that use a fixed decision threshold. We show that, for the ResNet matcher, the two cohorts have approximately equal separation of impostor and genuine distributions. Using ICAO compliance as a standard of image quality, we find that the initial image cohorts have unequal rates of good quality images. The ICAO-compliant subsets of the original image cohorts show improved accuracy, with the main effect being to reducing the low-similarity tail of the genuine distributions.","1046":"Facebook News Feed personalization algorithm has a significant impact, on a daily basis, on the lifestyle, mood and opinion of millions of Internet users. Nonetheless, the behavior of such algorithm lacks transparency, motivating measurements, modeling and analysis in order to understand and improve its properties. In this paper, we propose a reproducible methodology encompassing measurements, an analytical model and a fairness-based News Feed design. The model leverages the versatility and analytical tractability of time-to-live (TTL) counters to capture the visibility and occupancy of publishers over a News Feed. Measurements are used to parameterize and to validate the expressive power of the proposed model. Then, we conduct a what-if analysis to assess the visibility and occupancy bias incurred by users against a baseline derived from the model. Our results indicate that a significant bias exists and it is more prominent at the top position of the News Feed. In addition, we find that the bias is non-negligible even for users that are deliberately set as neutral with respect to their political views, motivating the proposal of a novel and more transparent fairness-based News Feed design.","1047":"In this work, we empirically validate three common assumptions in building political media bias datasets, which are (i) labelers' political leanings do not affect labeling tasks, (ii) news articles follow their source outlet's political leaning, and (iii) political leaning of a news outlet is stable across different topics. We build a ground-truth dataset of manually annotated article-level political leaning and validate the three assumptions. Our findings warn that the three assumptions could be invalid even for a small dataset. We hope that our work calls attention to the (in)validity of common assumptions in building political media bias datasets.","1048":null,"1049":"This workshop is the fourth issue of a series of workshops on automatic extraction of socio-political events from news, organized by the Emerging Market Welfare Project, with the support of the Joint Research Centre of the European Commission and with contributions from many other prominent scholars in this field. The purpose of this series of workshops is to foster research and development of reliable, valid, robust, and practical solutions for automatically detecting descriptions of socio-political events, such as protests, riots, wars and armed conflicts, in text streams. This year workshop contributors make use of the state-of-the-art NLP technologies, such as Deep Learning, Word Embeddings and Transformers and cover a wide range of topics from text classification to news bias detection. Around 40 teams have registered and 15 teams contributed to three tasks that are i) multilingual protest news detection detection, ii) fine-grained classification of socio-political events, and iii) discovering Black Lives Matter protest events. The workshop also highlights two keynote and four invited talks about various aspects of creating event data sets and multi- and cross-lingual machine learning in few- and zero-shot settings.","1050":"Lead bias is a common phenomenon in news summarization, where early parts of an article often contain the most salient information. While many algorithms exploit this fact in summary generation, it has a detrimental effect on teaching the model to discriminate and extract important information in general. We propose that the lead bias can be leveraged in our favor in a simple and effective way to pre-train abstractive news summarization models on large-scale unlabeled news corpora: predicting the leading sentences using the rest of an article. We collect a massive news corpus and conduct data cleaning and filtering via statistical analysis. We then apply the proposed self-supervised pre-training to existing generation models BART and T5 for domain adaptation. Via extensive experiments on six benchmark datasets, we show that this approach can dramatically improve the summarization quality and achieve state-of-the-art results for zero-shot news summarization without any fine-tuning. For example, in the DUC2003 dataset, the ROUGE-1 score of BART increases 13.7% after the lead-bias pre-training. We deploy the model in Microsoft News and provide public APIs as well as a demo website for multi-lingual news summarization.","1051":"News articles covering policy issues are an essential source of information in the social sciences and are also frequently used for other use cases, e.g., to train NLP language models. To derive meaningful insights from the analysis of news, large datasets are required that represent real-world distributions, e.g., with respect to the contained outlets' popularity, topically, or across time. Information on the political leanings of media publishers is often needed, e.g., to study differences in news reporting across the political spectrum, which is one of the prime use cases in the social sciences when studying media bias and related societal issues. Concerning these requirements, existing datasets have major flaws, resulting in redundant and cumbersome effort in the research community for dataset creation. To fill this gap, we present POLUSA, a dataset that represents the online media landscape as perceived by an average US news consumer. The dataset contains 0.9M articles covering policy topics published between Jan. 2017 and Aug. 2019 by 18 news outlets representing the political spectrum. Each outlet is labeled by its political leaning, which we derive using a systematic aggregation of eight data sources. The news dataset is balanced with respect to publication date and outlet popularity. POLUSA enables studying a variety of subjects, e.g., media effects and political partisanship. Due to its size, the dataset allows to utilize data-intense deep learning methods.","1052":"With the growing complexity of the available online information, search engines via rankings and recommender systems come to the rescue, providing suggestions to users about items of potential interest, from movies and products to news articles and even potential friends. Such results and suggestions aim at covering the user information needs and play an important role in guiding users\u2019 decisions and in forming their opinions. However, the same technology, if not used responsibly, may lead to discrimination, amplify potential biases in the original data, restrict transparency and strengthen unfairness. For example, consider scenarios in which models based on biased data produce results that abet violence, decrease diversity, or have an adverse impact on economic policies. While the potential benefits of rankings and recommenders are well-accepted and understood, the importance of using such systems in a fair manner has only recently attracted attention. In this tutorial, we cover recent advancements and highlight future research directions in this increasingly relevant research area.","1053":"Most general-purpose extractive summarization models are trained on news articles, which are short and present all important information upfront. As a result, such models are biased on position and often perform a smart selection of sentences from the beginning of the document. When summarizing long narratives, which have complex structure and present information piecemeal, simple position heuristics are not sufficient. In this paper, we propose to explicitly incorporate the underlying structure of narratives into general unsupervised and supervised extractive summarization models. We formalize narrative structure in terms of key narrative events (turning points) and treat it as latent in order to summarize screenplays (i.e., extract an optimal sequence of scenes). Experimental results on the CSI corpus of TV screenplays, which we augment with scene-level summarization labels, show that latent turning points correlate with important aspects of a CSI episode and improve summarization performance over general extractive algorithms leading to more complete and diverse summaries.","1054":null,"1055":null,"1056":"We present an automated method for measuring media bias. Inferring which newspaper published a given article, based only on the frequencies with which it uses different phrases, leads to a conditional probability distribution whose analysis lets us automatically map newspapers and phrases into a bias space. By analyzing roughly a million articles from roughly a hundred newspapers for bias in dozens of news topics, our method maps newspapers into a two-dimensional bias landscape that agrees well with previous bias classifications based on human judgement. One dimension can be interpreted as traditional left-right bias, the other as establishment bias. This means that although news bias is inherently political, its measurement need not be. Author summary Many argue that news media they dislike are biased, while their favorite news sources aren\u2019t. Can we move beyond such subjectivity and measure media bias objectively, from data alone? Our answer is a resounding \u201cyes\u201d after analyzing roughly a million articles from roughly a hundred newspapers. By simply aiming to machine-learn which newspapers published which articles, hundreds of politically charged phrases such as \u201cundocumented immigrant\u201d and \u201cillegal immigrant\u201d are auto-identified, whose relative frequencies enable us to map all newspapers into a two-dimensional media bias landscape. These data-driven results agree well with human-judgement classifications of left-right bias and establishment bias. Introduction Political polarization has increased in recent years, both in the United States and internationally [1], with pernicious consequences for democracy and its ability to solve pressing problems [2] It is often argued that such polarization is stoked by the media ecosystem, with machine-learning-fueled filter bubbles [3] increasing the demand for and supply of more biased media. Media bias is defined by [4] as favoring, disfavoring, emphasizing or ignoring certain political actors, policies, events, or topics in a way that is deceptive toward the reader, and can be accomplished through many different techniques. In response, there has been significant efforts to protect democracy by studying and flagging media bias. However, there is a widespread perception that fact-checkers and bias-checkers can themselves be biased and lack transparency [5]. It is therefore of great interest to develop objective and transparent measures of bias that are based on data rather than subjective human judgement calls. Early work in this area is reviewed in [6], September 2, 2021 1\/29 ar X iv :2 10 9. 00 02 4v 1 [ cs .C Y ] 3 1 A ug 2 02 1 Fig 1. Generalized principal components for articles about BLM. The colors and sizes of the dots were predetermined by external assessments and thus in no way influenced by our data. The positions of the dots thus suggest that the horizontal axis can be interpreted as the traditional left-right bias axis, here automatically rediscovered by our algorithm directly from the data.","1057":"Disparate biases associated with datasets and trained classifiers in hateful and abusive content identification tasks have raised many concerns recently. Although the problem of biased datasets on abusive language detection has been addressed more frequently, biases arising from trained classifiers have not yet been a matter of concern. In this paper, we first introduce a transfer learning approach for hate speech detection based on an existing pre-trained language model called BERT (Bidirectional Encoder Representations from Transformers) and evaluate the proposed model on two publicly available datasets that have been annotated for racism, sexism, hate or offensive content on Twitter. Next, we introduce a bias alleviation mechanism to mitigate the effect of bias in training set during the fine-tuning of our pre-trained BERT-based model for hate speech detection. Toward that end, we use an existing regularization method to reweight input samples, thereby decreasing the effects of high correlated training set\u2019 s n-grams with class labels, and then fine-tune our pre-trained BERT-based model with the new re-weighted samples. To evaluate our bias alleviation mechanism, we employed a cross-domain approach in which we use the trained classifiers on the aforementioned datasets to predict the labels of two new datasets from Twitter, AAE-aligned and White-aligned groups, which indicate tweets written in African-American English (AAE) and Standard American English (SAE), respectively. The results show the existence of systematic racial bias in trained classifiers, as they tend to assign tweets written in AAE from AAE-aligned group to negative classes such as racism, sexism, hate, and offensive more often than tweets written in SAE from White-aligned group. However, the racial bias in our classifiers reduces significantly after our bias alleviation mechanism is incorporated. This work could institute the first step towards debiasing hate speech and abusive language detection systems.","1058":null,"1059":"Systems incorporating biometric technologies have become ubiquitous in personal, commercial, and governmental identity management applications. Both cooperative (e.g., access control) and noncooperative (e.g., surveillance and forensics) systems have benefited from biometrics. Such systems rely on the uniqueness of certain biological or behavioral characteristics of human beings, which enable for individuals to be reliably recognized using automated algorithms. Recently, however, there has been a wave of public and academic concerns regarding the existence of systemic bias in automated decision systems (including biometrics). Most prominently, face recognition algorithms have often been labeled as \u201cracist\u201d or \u201cbiased\u201d by the media, nongovernmental organizations, and researchers alike. The main contributions of this article are: 1) an overview of the topic of algorithmic bias in the context of biometrics; 2) a comprehensive survey of the existing literature on biometric bias estimation and mitigation; 3) a discussion of the pertinent technical and social matters; and 4) an outline of the remaining challenges and future work items, both from technological and social points of view.","1060":"Technologies for abusive language detection are being developed and applied with little consideration of their potential biases. We examine racial bias in five different sets of Twitter data annotated for hate speech and abusive language. We train classifiers on these datasets and compare the predictions of these classifiers on tweets written in African-American English with those written in Standard American English. The results show evidence of systematic racial bias in all datasets, as classifiers trained on them tend to predict that tweets written in African-American English are abusive at substantially higher rates. If these abusive language detection systems are used in the field they will therefore have a disproportionate negative impact on African-American social media users. Consequently, these systems may discriminate against the groups who are often the targets of the abuse we are trying to detect.","1061":"Word embeddings are a widely used set of natural language processing techniques that map words to vectors of real numbers. These vectors are used to improve the quality of generative and predictive models. Recent studies demonstrate that word embeddings contain and amplify biases present in data, such as stereotypes and prejudice. In this study, we provide a complete overview of bias in word embeddings. We develop a new technique for bias detection for gendered languages and use it to compare bias in embeddings trained on Wikipedia and on political social media data. We investigate bias diffusion and prove that existing biases are transferred to further machine learning models. We test two techniques for bias mitigation and show that the generally proposed methodology for debiasing models at the embeddings level is insufficient. Finally, we employ biased word embeddings and illustrate that they can be used for the detection of similar biases in new data. Given that word embeddings are widely used by commercial companies, we discuss the challenges and required actions towards fair algorithmic implementations and applications.","1062":"With the ever-increasing cases of hate spread on social media platforms, it is critical to design abuse detection mechanisms to pro-actively avoid and control such incidents. While there exist methods for hate speech detection, they stereotype words and hence suffer from inherently biased training. Bias removal has been traditionally studied for structured datasets, but we aim at bias mitigation from unstructured text data. In this paper, we make two important contributions. First, we systematically design methods to quantify the bias for any model and propose algorithms for identifying the set of words which the model stereotypes. Second, we propose novel methods leveraging knowledge-based generalizations for bias-free learning. Knowledge-based generalization provides an effective way to encode knowledge because the abstraction they provide not only generalizes content but also facilitates retraction of information from the hate speech detection classifier, thereby reducing the imbalance. We experiment with multiple knowledge generalization policies and analyze their effect on general performance and in mitigating bias. Our experiments with two real-world datasets, a Wikipedia Talk Pages dataset (WikiDetox) of size ~ 96k and a Twitter dataset of size ~ 24k, show that the use of knowledge-based generalizations results in better performance by forcing the classifier to learn from generalized content. Our methods utilize existing knowledge-bases and can easily be extended to other tasks.","1063":"Discovering the stances of media outlets and influential people on current, debatable topics is important for social statisticians and policy makers. Many supervised solutions exist for determining viewpoints, but manually annotating training data is costly. In this paper, we propose a cascaded method that uses unsupervised learning to ascertain the stance of Twitter users with respect to a polarizing topic by leveraging their retweet behavior; then, it uses supervised learning based on user labels to characterize both the general political leaning of online media and of popular Twitter users, as well as their stance with respect to the target polarizing topic. We evaluate the model by comparing its predictions to gold labels from the Media Bias\/Fact Check website, achieving 82.6% accuracy.","1064":"The pervasive use of mobile information technologies brings new patterns of media usage, but also challenges to the measurement of media exposure. Researchers wishing to, for example, understand the nature of selective exposure on algorithmically driven platforms need to precisely attribute individuals\u2019 exposure to specific content. Prior research has used tracking data to show that survey-based self-reports of media exposure are critically unreliable. So far, however, little effort has been invested into assessing the specific biases of tracking methods themselves. Using data from a multimethod study, we show that tracking data from mobile devices is linked to systematic distortions in self-report biases. Further inherent but unobservable sources of bias, along with potential solutions, are discussed.","1065":"Are social media posts with pictures more popular than those without? Why do pictures with certain characteristics induce higher engagement than some other pictures? Using data sets of social media posts about major airlines and sport utility vehicle brands collected from Twitter and Instagram, the authors empirically examine the influence of image content on social media engagement. After accounting for selection bias on the inclusion of image content, the authors find a significant and robust positive mere presence effect of image content on user engagement in both product categories on Twitter. They also find that high-quality and professionally shot pictures consistently lead to higher engagement on both platforms for both product categories. However, the effect of colorfulness varies by product category, while the presence of human face and image\u2013text fit can induce higher user engagement on Twitter but not on Instagram. These findings shed light on how to improve social media engagement using image content.","1066":"Social media provide access to behavioural data at an unprecedented scale and granularity. However, using these data to understand phenomena in a broader population is difficult due to their non-representativeness and the bias of statistical inference tools towards dominant languages and groups. While demographic attribute inference could be used to mitigate such bias, current techniques are almost entirely monolingual and fail to work in a global environment. We address these challenges by combining multilingual demographic inference with post-stratification to create a more representative population sample. To learn demographic attributes, we create a new multimodal deep neural architecture for joint classification of age, gender, and organization-status of social media users that operates in 32 languages. This method substantially outperforms current state of the art while also reducing algorithmic bias. To correct for sampling biases, we propose fully interpretable multilevel regression methods that estimate inclusion probabilities from inferred joint population counts and ground-truth population counts. In a large experiment over multilingual heterogeneous European regions, we show that our demographic inference and bias correction together allow for more accurate estimates of populations and make a significant step towards representative social sensing in downstream applications with multilingual social media.","1067":"A growing body of research is combining social media data with machine learning to predict mental health states of individuals. An implication of this research lies in informing evidence-based diagnosis and treatment. However, obtaining clinically valid diagnostic information from sensitive patient populations is challenging. Consequently, researchers have operationalized characteristic online behaviors as \"proxy diagnostic signals\" for building these models. This paper posits a challenge in using these diagnostic signals, purported to support clinical decision-making. Focusing on three commonly used proxy diagnostic signals derived from social media, we find that predictive models built on these data, although offer strong internal validity, suffer from poor external validity when tested on mental health patients. A deeper dive reveals issues of population and sampling bias, as well as of uncertainty in construct validity inherent in these proxies. We discuss the methodological and clinical implications of these gaps and provide remedial guidelines for future research.","1068":"Hate speech is a challenging issue plaguing the online so- cial media. While better models for hate speech detection are continuously being developed, there is little research on the bias and interpretability aspects of hate speech. In this paper, we introduce HateXplain, the \ufb01rst benchmark hate speech dataset covering multiple aspects of the issue. Each post in our dataset is annotated from three different perspectives: the basic, commonly used 3-class classi\ufb01cation (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech\/offensive speech in the post), and the rationales , i.e., the portions of the post on which their labelling decision (as hate, offensive or normal) is based. We utilize existing state-of-the-art models and observe that even models that perform very well in classi\ufb01cation do not score high on explainability metrics like model plausibility and faithfulness . We also observe that models, which utilize the human rationales for training, perform better in re- ducing unintended bias towards target communities. We have made our code and dataset public 1 for other researchers. Disclaimer : The article contains material that many will \ufb01nd offensive or hateful; however this cannot be avoided owing to the nature of the work.","1069":"Journalism and media studies lack robust theoretical concepts for studying journalistic knowledge generation. More specifically, conceptual challenges attend the emergence of big data and algorithmic sources of journalistic knowledge. A family of frameworks apt to this challenge is provided by \u201csocial epistemology\u201d: a young philosophical field which regards society\u2019s participation in knowledge generation as inevitable. Social epistemology offers the best of both worlds for journalists and media scholars: a thorough familiarity with biases and failures of obtaining knowledge, and a strong orientation toward best practices in the realm of knowledge-acquisition and truth-seeking. This article articulates the lessons of social epistemology for two central nodes of knowledge-acquisition in contemporary journalism: human-mediated knowledge and technology-mediated knowledge.","1070":"Powered by machine learning techniques, social media provides an unobtrusive lens into individual behaviors, emotions, and psychological states. Recent research has successfully employed social media data to predict mental health states of individuals, ranging from the presence and severity of mental disorders like depression to the risk of suicide. These algorithmic inferences hold great potential in supporting early detection and treatment of mental disorders and in the design of interventions. At the same time, the outcomes of this research can pose great risks to individuals, such as issues of incorrect, opaque algorithmic predictions, involvement of bad or unaccountable actors, and potential biases from intentional or inadvertent misuse of insights. Amplifying these tensions, there are also divergent and sometimes inconsistent methodological gaps and under-explored ethics and privacy dimensions. This paper presents a taxonomy of these concerns and ethical challenges, drawing from existing literature, and poses questions to be resolved as this research gains traction. We identify three areas of tension: ethics committees and the gap of social media research; questions of validity, data, and machine learning; and implications of this research for key stakeholders. We conclude with calls to action to begin resolving these interdisciplinary dilemmas.","1071":"Background: Concern about the health impact of novel coronavirus SARS-CoV-2 has resulted in widespread enforced reductions in people\u2019s movement (\u201clockdowns\u201d). However, there are increasing concerns about the severe economic and wider societal consequences of these measures. Some countries have begun to lift some of the rules on physical distancing in a stepwise manner, with differences in what these \u201cexit strategies\u201d entail and their timeframes. The aim of this work was to inform such exit strategies by exploring the types of indoor and outdoor settings where transmission of SARS-CoV-2 has been reported to occur and result in clusters of cases. Identifying potential settings that result in transmission clusters allows these to be kept under close surveillance and\/or to remain closed as part of strategies that aim to avoid a resurgence in transmission following the lifting of lockdown measures. Methods: We performed a systematic review of available literature and media reports to find settings reported in peer reviewed articles and media with these characteristics. These sources are curated and made available in an editable online database. Results: We found many examples of SARS-CoV-2 clusters linked to a wide range of mostly indoor settings. Few reports came from schools, many from households, and an increasing number were reported in hospitals and elderly care settings across Europe. Conclusions: We identified possible places that are linked to clusters of COVID-19 cases and could be closely monitored and\/or remain closed in the first instance following the progressive removal of lockdown restrictions. However, in part due to the limits in surveillance capacities in many settings, the gathering of information such as cluster sizes and attack rates is limited in several ways: inherent recall bias, biased media reporting and missing data.","1072":"With digital communication increasingly shifting to mobile devices, communication research needs to explore ways to retrieve, process, and analyze digital trace data on people\u2019s most personal devices. This study presents a new methodological approach, mobile data donations, in which smartphone usage data is collected unobtrusively with the help of mobile log data. The iOS Screen Time function is used as a test case for gathering log data with the help of screenshots. The study investigates the feasibility of the method, sample biases, and accuracy of smartphone usage self-reports on a general population sample of Dutch citizens (n=404). Importantly, it explores how mobile data donations can be used as add-ons or substitutes for conventional media exposure measures. Results indicate that (a) users\u2019 privacy concerns and technical skills are crucial factors for the willingness to donate mobile log data and (b) there is a strong tendency for underreporting of smartphone usage duration and frequency.","1073":"This article proposes \u2018sexist assemblages\u2019 as a way of understanding how the human and mechanical elements that make up social media content moderation assemble to perpetuate normative gender roles, particularly white femininities, and to police content related to women and their bodies. It investigates sexist assemblages through three of many potential elements: (1) the normatively gendered content presented to users through in-platform keyword and hashtag searches; (2) social media platforms\u2019 community guidelines, which lay out platforms\u2019 codes of conduct and reveal biases and subjectivities and (3) the over-simplification of gender identities that is necessary to algorithmically recommend content to users as they move through platforms. By the time the reader finds this article, the elements of the assemblages we identify might have shifted, but we hope the framework remains useful for those aiming to understand the relationship between content moderation and long-standing forms of inequality.","1074":"The COVID-19 pandemic created a noticeable challenge to the cryptographic community with the development of contact tracing applications. The media reported a dispute between designers proposing a centralized or a decentralized solution (namely, the PEPP-PT and the DP3T projects). Perhaps, the time constraints to develop and deploy efficient solutions led to non-optimal (in terms of privacy) solutions. Moreover, arguments have been severely biased and the scientific debate did not really happen until recently. In this paper, we show the vulnerabilities and the advantages of both solutions systematically. We believe that none offers any sufficient level of privacy protection and the decision to use one or another is as hard as using automated contact tracing at the first place. A third way could be explored. We list here a few possible directions.","1075":"Social media serves as a platform to share thoughts and connect with others. The ubiquitous use of social media also enables researchers to study human behavior as the data can be collected in an inexpensive and unobtrusive way. Not only does social media provide a passive means to collect historical data at scale, it also functions as a \"verbal\" sensor, providing rich signals about an individual's social ecological context. This case study introduces an infrastructural framework to illustrate the feasibility of passively collecting social media data at scale in the context of an ongoing multimodal sensing study of workplace performance (N=757). We study our dataset in its relationship with demographic, personality, and wellbeing attributes of individuals. Importantly, as a means to study selection bias, we examine what characterizes individuals who choose to consent to social media data sharing vs. those who do not. Our work provides practical experiences and implications for research in the HCI field who seek to conduct similar longitudinal studies that harness the potential of social media data.","1076":"In public media as well as in scientific publications, the term \\emph{bias} is used in conjunction with machine learning in many different contexts, and with many different meanings. This paper proposes a taxonomy of these different meanings, terminology, and definitions by surveying the, primarily scientific, literature on machine learning. In some cases, we suggest extensions and modifications to promote a clear terminology and completeness. The survey is followed by an analysis and discussion on how different types of biases are connected and depend on each other. We conclude that there is a complex relation between bias occurring in the machine learning pipeline that leads to a model, and the eventual bias of the model (which is typically related to social discrimination). The former bias may or may not influence the latter, in a sometimes bad, and sometime good way.","1077":"Recent media attention aimed at migrant caravans at the US\u2013Mexico border has increased interest from different actors in the political and social spheres. Parallel to traditional and mainstream media, social media has become the prime context where narratives about the border develop, molding broader societal perspectives on the immigration issue. Through a content and discourse analysis of 105 posts connected by the #MigrantCaravan or #CaravanaMigrante hashtags, we delved into how media representations of immigration on Instagram effectively establish otherness between the different characters involved in this phenomenon. The border wall emerges as one of the main components in these narratives and a symbol of the temporal and spatial stages of the migratory journey. Meanwhile, the voice of the main character, the migrant, is mostly absent, often conveyed through biased views, filtered by the opinions of posters about immigration and characterized by new narrative configurations enabled by the Instagram format.","1078":"Algorithms are widely applied to detect hate speech and abusive language in social media. We investigated whether the human-annotated data used to train these algorithms are biased. We utilized a publicly available annotated Twitter dataset (Founta et al. 2018) and classified the racial, gender, and party identification dimensions of 99,996 tweets. The results showed that African American tweets were up to 3.7 times more likely to be labeled as abusive, and African American male tweets were up to 77% more likely to be labeled as hateful compared to the others. These patterns were statistically significant and robust even when party identification was added as a control variable. This study provides the first systematic evidence on intersectional bias in datasets of hate speech and abusive language.","1079":"We present the results and the main findings of SemEval-2020 Task 11 on Detection of Propaganda Techniques in News Articles. The task featured two subtasks. Subtask SI is about Span Identification: given a plain-text document, spot the specific text fragments containing propaganda. Subtask TC is about Technique Classification: given a specific text fragment, in the context of a full document, determine the propaganda technique it uses, choosing from an inventory of 14 possible propaganda techniques. The task attracted a large number of participants: 250 teams signed up to participate and 44 made a submission on the test set. In this paper, we present the task, analyze the results, and discuss the system submissions and the methods they used. For both subtasks, the best systems used pre-trained Transformers and ensembles.","1080":"Fake news is risky, since it has been created to manipulate readers\u2019 opinions and beliefs. In this work, we compared the language of false news to the real one of real news from an emotional perspective, considering a set of false information types (propaganda, hoax, clickbait, and satire) from social media and online news article sources. Our experiments showed that false information has different emotional patterns in each of its types, and emotions play a key role in deceiving the reader. Based on that, we proposed an LSTM neural network model that is emotionally infused to detect false news.","1081":"Previous works that integrated news articles to better process stock prices used a variety of neural networks to predict price movements. The textual and price information were both encoded in the neural network, and it is therefore difficult to apply this approach in situations other than the original framework of the notoriously hard problem of price prediction. In contrast, this paper presents a method to encode the influence of news articles through a vector representation of stocks called a stock embedding. The stock embedding is acquired with a deep learning framework using both news articles and price history. Because the embedding takes the operational form of a vector, it is applicable to other financial problems besides price prediction. As one example application, we show the results of portfolio optimization using Reuters & Bloomberg headlines, producing a capital gain 2.8 times larger than that obtained with a baseline method using only stock price data. This suggests that the proposed stock embedding can leverage textual financial semantics to solve financial prediction problems.","1082":"Understanding discourse structures of news articles is vital to effectively contextualize the occurrence of a news event. To enable computational modeling of news structures, we apply an existing theory of functional discourse structure for news articles that revolves around the main event and create a human-annotated corpus of 802 documents spanning over four domains and three media sources. Next, we propose several document-level neural-network models to automatically construct news content structures. Finally, we demonstrate that incorporating system predicted news structures yields new state-of-the-art performance for event coreference resolution. The news documents we annotated are openly available and the annotations are publicly released for future research.","1083":"Social media and microblogging platforms generally contain elements of figurative and nonliteral language, including satire. The identification of figurative language is a fundamental task for sentiment analysis. It will not be possible to obtain sentiment analysis methods with high classification accuracy if elements of figurative language have not been properly identified. Satirical text is a kind of figurative language, in which irony and humor have been utilized to ridicule or criticize an event or entity. Satirical news is a pervasive issue on social media platforms, which can be deceptive and harmful. This paper presents an ensemble scheme for satirical news identification in Turkish news articles. In the presented scheme, linguistic and psychological feature sets have been utilized to extract the feature sets i.e. linguistic, psychological, personal, spoken categories, and punctuation . In the classification phase, accuracy rates of five supervised learning algorithms i.e. naive Bayes algorithm, logistic regression, support vector machines, random forest, and k-nearest neighbor algorithm with three widely utilized ensemble methods i.e. AdaBoost, bagging, and random subspace have been considered. Based on the results, we concluded that the random forest algorithm yielded the highest performance, with a classification accuracy of 96.92% for satire detection in Turkish. For deep learning-based architectures, we have achieved classification accuracy of 97.72% with the recurrent neural network architecture with attention mechanism.","1084":"Big web data from sources including online news and Twitter are good resources for investigating deep learning. However, collected news articles and tweets almost certainly contain data unnecessary for learning, and this disturbs accurate learning. This paper explores the performance of word2vec Convolutional Neural Networks (CNNs) to classify news articles and tweets into related and unrelated ones. Using two word embedding algorithms of word2vec, Continuous Bag-of-Word (CBOW) and Skip-gram, we constructed CNN with the CBOW model and CNN with the Skip-gram model. We measured the classification accuracy of CNN with CBOW, CNN with Skip-gram, and CNN without word2vec models for real news articles and tweets. The experimental results indicated that word2vec significantly improved the accuracy of the classification model. The accuracy of the CBOW model was higher and more stable when compared to that of the Skip-gram model. The CBOW model exhibited better performance on news articles, and the Skip-gram model exhibited better performance on tweets. Specifically, CNN with word2vec models was more effective on news articles when compared to that on tweets because news articles are typically more uniform when compared to tweets.","1085":"News agencies produce thousands of multimedia stories describing events happening in the world that are either scheduled such as sports competitions, political summits and elections, or breaking events such as military conflicts, terrorist attacks, natural disasters, etc. When writing up those stories, journalists refer to contextual background and to compare with past similar events. However, searching for precise facts described in stories is hard. In this paper, we propose a general method that leverages the Wikidata knowledge base to produce semantic annotations of news articles. Next, we describe a semantic search engine that supports both keyword based search in news articles and structured data search providing filters for properties belonging to specific event schemas that are automatically inferred.","1086":"Twitter has become an essential platform for the news media sources to disseminate news. The opinions expressed through Twitter can be mined by news media sources to obtain users\u2019 reactions centered around different news articles. A comprehensive summary of the users\u2019 reactions with respect to a news article can be crucial due to various reasons like: 1) understanding the sensitivity\/importance of the news; 2) obtaining insights about the diverse opinions of the readers with respect to the news; and 3) understanding the key aspects that draw the interest of the readers. However, the selected summary tweets must fulfill multiple objectives, like relevance to the news article, diversity among the selected tweets, and should cover the entire spectrum of opinions expressed through the tweets. Existing methods primarily attempt to identify a set of relevant tweets from which the summary tweets are selected that maintains the diversity and coverage requirements. However, the noise and the nontemporal behavior of the article-specific tweets make the identification of such relevant tweets extremely difficult, resulting in poor summary quality. In this paper, through empirical investigations, we show that initially identifying the diverse opinions can lead to better identification of the relevant tweets, i.e., following a specific ordering of the objectives can lead to the improved summary. We, subsequently, propose a tweet summarization technique that follows such a specific ordering. Validation of our proposed approach for 800 news articles with 2.1 billion related tweets shows that the proposed approach produces 11.6%\u201334.8% improvement in summary quality as compared to existing state-of-the-art techniques.","1087":"Event extraction from news articles is a commonly required prerequisite for various tasks, such as article summarization, article clustering, and news aggregation. Due to the lack of universally applicable and publicly available methods tailored to news datasets, many researchers redundantly implement event extraction methods for their own projects. The journalistic 5W1H questions are capable of describing the main event of an article, i.e., by answering who did what, when, where, why, and how. We provide an in-depth description of an improved version of Giveme5W1H, a system that uses syntactic and domain-specific rules to automatically extract the relevant phrases from English news articles to provide answers to these 5W1H questions. Given the answers to these questions, the system determines an article's main event. In an expert evaluation with three assessors and 120 articles, we determined an overall precision of p=0.73, and p=0.82 for answering the first four W questions, which alone can sufficiently summarize the main event reported on in a news article. We recently made our system publicly available, and it remains the only universal open-source 5W1H extractor capable of being applied to a wide range of use cases in news analysis.","1088":"Vectorization is imperative for processing textual data in natural language processing applications. Vectorization enables the machines to understand the textual contents by converting them into meaningful numerical representations. The proposed work targets at identifying unifiable news articles for performing multi-document summarization. A framework is introduced for identification of news articles related to top trending topics\/hashtags and multi-document summarization of unifiable news articles based on the trending topics, for capturing opinion diversity on those topics. Text clustering is applied to the corpus of news articles related to each trending topic to obtain smaller unifiable groups. The effectiveness of various text vectorization methods, namely the bag of word representations with tf-idf scores, word embeddings, and document embeddings are investigated for clustering news articles using the k-means. The paper presents the comparative analysis of different vectorization methods obtained on documents from DUC 2004 benchmark dataset in terms of purity.","1089":"Modern technological era has reshaped traditional lifestyle in several domains. The medium of publishing news and events has become faster with the advancement of Information Technology (IT). IT has also been flooded with immense amounts of data, which is being published every minute of every day, by millions of users, in the shape of comments, blogs, news sharing through blogs, social media micro-blogging websites and many more. Manual traversal of such huge data is a challenging job; thus, sophisticated methods are acquired to perform this task automatically and efficiently. News reports events that comprise of emotions \u2013 good, bad, neutral. Sentiment analysis is utilized to investigate human emotions (i.e., sentiments) present in textual information. This paper presents a lexicon-based approach for sentiment analysis of news articles. The experiments have been performed on BBC news dataset, which expresses the applicability and validation of the adopted approach.","1090":"Intentionally deceptive content presented under the guise of legitimate journalism is a worldwide information accuracy and integrity problem that affects opinion forming, decision making, and voting patterns. Most so-called \u2018fake news' is initially distributed over social media conduits like Facebook and Twitter and later finds its way onto mainstream media platforms such as traditional television and radio news. The fake news stories that are initially seeded over social media platforms share key linguistic characteristics such as making excessive use of unsubstantiated hyperbole and non-attributed quoted content. In this paper, the results of a fake news identification study that documents the performance of a fake news classifier are presented. The Textblob, Natural Language, and SciPy Toolkits were used to develop a novel fake news detector that uses quoted attribution in a Bayesian machine learning system as a key feature to estimate the likelihood that a news article is fake. The resultant process precision is 63.333% effective at assessing the likelihood that an article with quotes is fake. This process is called influence mining and this novel technique is presented as a method that can be used to enable fake news and even propaganda detection. In this paper, the research process, technical analysis, technical linguistics work, and classifier performance and results are presented. The paper concludes with a discussion of how the current system will evolve into an influence mining system.","1091":"ABSTRACT With most Internet users now getting news from social media, there is growing concern about how to verify the content that appears on these platforms. Two experiments tested the effects of fact-checking labels (confirmed vs. disputed) by source (peer vs. third-party) on credibility, virality, and information seeking of news posted on social media. Study 1 (N = 312) tested the effects of these labels on memes, and Study 2 (N = 452) tested the same effects on news articles. Results indicate that, although fact-checking labels do not seem to have a beneficial effect on credibility perceptions of individual news posts, their presence does seem to increase judgments of the site\u2019s quality overall. This presents key implications for theory and design in fact-checking and news consumption on social media.","1092":null,"1093":"Automatic article commenting is helpful in encouraging user engagement on online news platforms. However, the news documents are usually too long for models under traditional encoder-decoder frameworks, which often results in general and irrelevant comments. In this paper, we propose to generate comments with a graph-to-sequence model that models the input news as a topic interaction graph. By organizing the article into graph structure, our model can better understand the internal structure of the article and the connection between topics, which makes it better able to generate coherent and informative comments. We collect and release a large scale news-comment corpus from a popular Chinese online news platform Tencent Kuaibao. Extensive experiment results show that our model can generate much more coherent and informative comments compared with several strong baseline models.","1094":"Personalized news recommendation is an essential technique for online news services. News articles usually contain rich textual content, and accurate news modeling is important for personalized news recommendation. Existing news recommendation methods mainly model news texts based on traditional text modeling methods, which is not optimal for mining the deep semantic information in news texts. Pre-trained language models (PLMs) are powerful for natural language understanding, which has the potential for better news modeling. However, there is no public report that shows PLMs have been applied to news recommendation. In this paper, we report our work on pre-trained language models empowered news recommendation (PLM-NR). Offline experimental results on both monolingual and multilingual news recommendation datasets show that leveraging PLMs for news modeling can effectively improve the performance of news recommendation. Our PLM-NR models have been deployed to the Microsoft News platform, and online flight results show that they can achieve significant performance gains in both English-speaking and global markets.","1095":"News recommendation is an important technique for personalized news service. Compared with product and movie recommendations which have been comprehensively studied, the research on news recommendation is much more limited, mainly due to the lack of a high-quality benchmark dataset. In this paper, we present a large-scale dataset named MIND for news recommendation. Constructed from the user click logs of Microsoft News, MIND contains 1 million users and more than 160k English news articles, each of which has rich textual content such as title, abstract and body. We demonstrate MIND a good testbed for news recommendation through a comparative study of several state-of-the-art news recommendation methods which are originally developed on different proprietary datasets. Our results show the performance of news recommendation highly relies on the quality of news content understanding and user interest modeling. Many natural language processing techniques such as effective text representation methods and pre-trained language models can effectively improve the performance of news recommendation. The MIND dataset will be available at https:\/\/msnews.github.io.","1096":"Fake news articles often stir the readers\u2019 attention by means of emotional appeals that arouse their feelings. Unlike in short news texts, authors of longer articles can exploit such affective factors to manipulate readers by adding exaggerations or fabricating events, in order to affect the readers\u2019 emotions. To capture this, we propose in this paper to model the flow of affective information in fake news articles using a neural architecture. The proposed model, FakeFlow, learns this flow by combining topic and affective information extracted from text. We evaluate the model\u2019s performance with several experiments on four real-world datasets. The results show that FakeFlow achieves superior results when compared against state-of-the-art methods, thus confirming the importance of capturing the flow of the affective information in news articles.","1097":"Filtering, vetting, and verifying digital information is an area of core interest in information science. Online fake news is a specific type of digital misinformation that poses serious threats to democratic institutions, misguides the public, and can lead to radicalization and violence. Hence, fake news detection is an important problem for information science research. While there have been multiple attempts to identify fake news, most of such efforts have focused on a single modality (e.g., only text\u2010based or only visual features). However, news articles are increasingly framed as multimodal news stories, and hence, in this work, we propose a multimodal approach combining text and visual analysis of online news stories to automatically detect fake news. Drawing on key theories of information processing and presentation, we identify multiple text and visual features that are associated with fake or credible news articles. We then perform a predictive analysis to detect features most strongly associated with fake news. Next, we combine these features in predictive models using multiple machine\u2010learning techniques. The experimental results indicate that a multimodal approach outperforms single\u2010modality approaches, allowing for better fake news detection.","1098":"In this paper, we present a first multilingual cross-domain dataset of 5182 fact-checked news articles for COVID-19, collected from 04\/01\/2020 to 15\/05\/2020. We have collected the fact-checked articles from 92 different fact-checking websites after obtaining references from Poynter and Snopes. We have manually annotated articles into 11 different categories of the fact-checked news according to their content. The dataset is in 40 languages from 105 countries. We have built a classifier to detect fake news and present results for the automatic fake news detection and its class. Our model achieves an F1 score of 0.76 to detect the false class and other fact check articles. The FakeCovid dataset is available at Github.","1099":"First identified in Wuhan, China, in December 2019, the outbreak of COVID-19 has been declared as a global emergency in January, and a pandemic in March 2020 by the World Health Organization (WHO). Along with this pandemic, we are also experiencing an \"infodemic\" of information with low credibility such as fake news and conspiracies. In this work, we present ReCOVery, a repository designed and constructed to facilitate research on combating such information regarding COVID-19. We first broadly search and investigate ~2,000 news publishers, from which 60 are identified with extreme [high or low] levels of credibility. By inheriting the credibility of the media on which they were published, a total of 2,029 news articles on coronavirus, published from January to May 2020, are collected in the repository, along with 140,820 tweets that reveal how these news articles have spread on the Twitter social network. The repository provides multimodal information of news articles on coronavirus, including textual, visual, temporal, and network information. The way that news credibility is obtained allows a trade-off between dataset scalability and label accuracy. Extensive experiments are conducted to present data statistics and distributions, as well as to provide baseline performances for predicting news credibility so that future methods can be compared. Our repository is available at http:\/\/coronavirus-fakenews.com.","1100":null,"1101":"Automatic generation of summaries from multiple news articles is a valuable tool as the number of online publications grows rapidly. Single document summarization (SDS) systems have benefited from advances in neural encoder-decoder model thanks to the availability of large datasets. However, multi-document summarization (MDS) of news articles has been limited to datasets of a couple of hundred examples. In this paper, we introduce Multi-News, the first large-scale MDS news dataset. Additionally, we propose an end-to-end model which incorporates a traditional extractive summarization model with a standard SDS model and achieves competitive results on MDS datasets. We benchmark several methods on Multi-News and hope that this work will promote advances in summarization in the multi-document setting.","1102":"Today social media has become the primary source for news. Via social media platforms, fake news travel at unprecedented speeds, reach global audiences and put users and communities at great risk. Therefore, it is extremely important to detect fake news as early as possible. Recently, deep learning based approaches have shown improved performance in fake news detection. However, the training of such models requires a large amount of labeled data, but manual annotation is time-consuming and expensive. Moreover, due to the dynamic nature of news, annotated samples may become outdated quickly and cannot represent the news articles on newly emerged events. Therefore, how to obtain fresh and high-quality labeled samples is the major challenge in employing deep learning models for fake news detection. In order to tackle this challenge, we propose a reinforced weakly-supervised fake news detection framework, i.e., WeFEND, which can leverage users' reports as weak supervision to enlarge the amount of training data for fake news detection. The proposed framework consists of three main components: the annotator, the reinforced selector and the fake news detector. The annotator can automatically assign weak labels for unlabeled news based on users' reports. The reinforced selector using reinforcement learning techniques chooses high-quality samples from the weakly labeled data and filters out those low-quality ones that may degrade the detector's prediction performance. The fake news detector aims to identify fake news based on the news content. We tested the proposed framework on a large collection of news articles published via WeChat official accounts and associated user reports. Extensive experiments on this dataset show that the proposed WeFEND model achieves the best performance compared with the state-of-the-art methods.","1103":"Propaganda aims at influencing people\u2019s mindset with the purpose of advancing a specific agenda. Previous work has addressed propaganda detection at document level, typically labelling all articles from a propagandistic news outlet as propaganda. Such noisy gold labels inevitably affect the quality of any learning system trained on them. A further issue with most existing systems is the lack of explainability. To overcome these limitations, we propose a novel task: performing fine-grained analysis of texts by detecting all fragments that contain propaganda techniques as well as their type. In particular, we create a corpus of news articles manually annotated at fragment level with eighteen propaganda techniques and propose a suitable evaluation measure. We further design a novel multi-granularity neural network, and we show that it outperforms several strong BERT-based baselines.","1104":null,"1105":"News articles usually contain knowledge entities such as celebrities or organizations. Important entities in articles carry key messages and help to understand the content in a more direct way. An industrial news recommender system contains various key applications, such as personalized recommendation, item-to-item recommendation, news category classification, news popularity prediction and local news detection. We find that incorporating knowledge entities for better document understanding benefits these applications consistently. However, existing document understanding models either represent news articles without considering knowledge entities (e.g., BERT) or rely on a specific type of text encoding model (e.g., DKN) so that the generalization ability and efficiency is compromised. In this paper, we propose KRED, which is a fast and effective model to enhance arbitrary document representation with a knowledge graph. KRED first enriches entities\u2019 embeddings by attentively aggregating information from their neighborhood in the knowledge graph. Then a context embedding layer is applied to annotate the dynamic context of different entities such as frequency, category and position. Finally, an information distillation layer aggregates the entity embeddings under the guidance of the original document representation and transforms the document vector into a new one. We advocate to optimize the model with a multi-task framework, so that different news recommendation applications can be united and useful information can be shared across different tasks. Experiments on a real-world Microsoft News dataset demonstrate that KRED greatly benefits a variety of news recommendation applications.","1106":"In recent times, fake news and misinformation have had a disruptive and adverse impact on our lives. Given the prominence of microblogging networks as a source of news for most individuals, fake news now spreads at a faster pace and has a more profound impact than ever before. This makes detection of fake news an extremely important challenge. Fake news articles, just like genuine news articles, leverage multimedia content to manipulate user opinions but spread misinformation. A shortcoming of the current approaches for the detection of fake news is their inability to learn a shared representation of multimodal (textual + visual) information. We propose an end-to-end network, Multimodal Variational Autoencoder (MVAE), which uses a bimodal variational autoencoder coupled with a binary classifier for the task of fake news detection. The model consists of three main components, an encoder, a decoder and a fake news detector module. The variational autoencoder is capable of learning probabilistic latent variable models by optimizing a bound on the marginal likelihood of the observed data. The fake news detector then utilizes the multimodal representations obtained from the bimodal variational autoencoder to classify posts as fake or not. We conduct extensive experiments on two standard fake news datasets collected from popular microblogging websites: Weibo and Twitter. The experimental results show that across the two datasets, on average our model outperforms state-of-the-art methods by margins as large as ~ 6% in accuracy and ~ 5% in F1 scores.","1107":"Hyperpartisan news is news that takes an extreme left-wing or right-wing standpoint. If one is able to reliably compute this meta information, news articles may be automatically tagged, this way encouraging or discouraging readers to consume the text. It is an open question how successfully hyperpartisan news detection can be automated, and the goal of this SemEval task was to shed light on the state of the art. We developed new resources for this purpose, including a manually labeled dataset with 1,273 articles, and a second dataset with 754,000 articles, labeled via distant supervision. The interest of the research community in our task exceeded all our expectations: The datasets were downloaded about 1,000 times, 322 teams registered, of which 184 configured a virtual machine on our shared task cloud service TIRA, of which in turn 42 teams submitted a valid run. The best team achieved an accuracy of 0.822 on a balanced sample (yes : no hyperpartisan) drawn from the manually tagged corpus; an ensemble of the submitted systems increased the accuracy by 0.048.","1108":"News recommendation aims to display news articles to users based on their personal interest. Existing news recommendation methods rely on centralized storage of user behavior data for model training, which may lead to privacy concerns and risks due to the privacy-sensitive nature of user behaviors. In this paper, we propose a privacy-preserving method for news recommendation model training based on federated learning, where the user behavior data is locally stored on user devices. Our method can leverage the useful information in the behaviors of massive number users to train accurate news recommendation models and meanwhile remove the need of centralized storage of them. More specifically, on each user device we keep a local copy of the news recommendation model, and compute gradients of the local model based on the user behaviors in this device. The local gradients from a group of randomly selected users are uploaded to server, which are further aggregated to update the global model in the server. Since the model gradients may contain some implicit private information, we apply local differential privacy (LDP) to them before uploading for better privacy protection. The updated global model is then distributed to each user device for local model update. We repeat this process for multiple rounds. Extensive experiments on a real-world dataset show the effectiveness of our method in news recommendation model training with privacy protection.","1109":"In recent years, there has been a substantial rise in the consumption of news via online platforms. The ease of publication and lack of editorial rigour in some of these platforms have further led to the proliferation of fake news. In this paper, we study the problem of detecting fake news on the FakeNewsNet repository, a collection of full length articles along with associated images. We present SpotFake+, a multimodal approach that leverages transfer learning to capture semantic and contextual information from the news articles and its associated images and achieves the better accuracy for fake news detection. To the best of our knowledge, this is the first work that performs a multimodal approach for fake news detection on a dataset that consists of full length articles. It outperforms the performance shown by both single modality and multiple-modality models. We also release the pretrained model for the benefit of the community.","1110":"News recommendation is very important to help users find interested news and alleviate information overload. Different users usually have different interests and the same user may have various interests. Thus, different users may click the same news article with attention on different aspects. In this paper, we propose a neural news recommendation model with personalized attention (NPA). The core of our approach is a news representation model and a user representation model. In the news representation model we use a CNN network to learn hidden representations of news articles based on their titles. In the user representation model we learn the representations of users based on the representations of their clicked news articles. Since different words and different news articles may have different informativeness for representing news and users, we propose to apply both word- and news-level attention mechanism to help our model attend to important words and news articles. In addition, the same news article and the same word may have different informativeness for different users. Thus, we propose a personalized attention network which exploits the embedding of user ID to generate the query vector for the word- and news-level attentions. Extensive experiments are conducted on a real-world news recommendation dataset collected from MSN news, and the results validate the effectiveness of our approach on news recommendation.","1111":"Although many fact-checking systems have been developed in academia and industry, fake news is still proliferating on social media. These systems mostly focus on fact-checking but usually neglect online users who are the main drivers of the spread of misinformation. How can we use fact-checked information to improve users' consciousness of fake news to which they are exposed? How can we stop users from spreading fake news? To tackle these questions, we propose a novel framework to search for fact-checking articles, which address the content of an original tweet (that may contain misinformation) posted by online users. The search can directly warn fake news posters and online users (e.g. the posters' followers) about misinformation, discourage them from spreading fake news, and scale up verified content on social media. Our framework uses both text and images to search for fact-checking articles, and achieves promising results on real-world datasets. Our code and datasets are released at this https URL.","1112":null,"1113":"Online news recommender systems aim to make personalized recommendations according to user preferences, which require modeling users\u2019 short-term reading interest. However, due to the limited logged user interactions in practice, news recommendation at session-level becomes very challenging. Existing methods on session-based news recommendation mainly focus on extracting features from news articles and sequential user-item interactions, but they usually ignore the semantic-level structural information among news articles and do not explore external knowledge sources. In this paper, we propose a novel Context-Aware Graph Embedding (CAGE) framework for session-based news recommendation, which builds an auxiliary knowledge graph to enrich the semantic meaning of entities involved in articles, and further refines the article embeddings by graph convolutional networks. Experimental results on a real-world news dataset demonstrate the effectiveness of our method compared with the state-of-the-art methods on session-based news recommendation.","1114":"Millions of news articles are published online every day, which can be overwhelming for readers to follow. Grouping articles that are reporting the same event into news stories is a common way of assisting readers in their news consumption. However, it remains a challenging research problem to efficiently and effectively generate a representative headline for each story. Automatic summarization of a document set has been studied for decades, while few studies have focused on generating representative headlines for a set of articles. Unlike summaries, which aim to capture most information with least redundancy, headlines aim to capture information jointly shared by the story articles in short length and exclude information specific to each individual article. In this work, we study the problem of generating representative headlines for news stories. We develop a distant supervision approach to train large-scale generation models without any human annotation. The proposed approach centers on two technical components. First, we propose a multi-level pre-training framework that incorporates massive unlabeled corpus with different quality-vs.-quantity balance at different levels. We show that models trained within the multi-level pre-training framework outperform those only trained with human-curated corpus. Second, we propose a novel self-voting-based article attention layer to extract salient information shared by multiple articles. We show that models that incorporate this attention layer are robust to potential noises in news stories and outperform existing baselines on both clean and noisy datasets. We further enhance our model by incorporating human labels, and show that our distant supervision approach significantly reduces the demand on labeled data. Finally, to serve the research community, we publish the first manually curated benchmark dataset on headline generation for news stories, NewSHead, which contains 367K stories (each with 3-5 articles), 6.5 times larger than the current largest multi-document summarization dataset.","1115":"Fake news has become more prevalent than ever, correlating with the rise of social media that allows every user to rapidly publish their views or hearsay. Today, fake news spans almost every realm of human activity, across diverse fields such as politics and healthcare. Most existing methods for fake news detection leverage supervised learning methods and expect a large labelled corpus of articles and social media user engagement information, which are often hard, time-consuming and costly to procure. In this paper, we consider the task of unsupervised fake news detection, which considers fake news detection in the absence of labelled historical data. We develop GTUT, a graph-based approach for the task which operates in three phases. Starting off with identifying a seed set of fake and legitimate articles exploiting high-level observations on inter-user behavior in fake news propagation, it progressively expands the labelling to all articles in the dataset. Our technique draws upon graph-based methods such as biclique identification, graph-based feature vector learning and label spreading. Through an extensive empirical evaluation over multiple real-world datasets, we establish the improved effectiveness of our method over state-of-the-art techniques for the task.","1116":"The Web has become the main source for news acquisition. At the same time, news discussion has become more social: users can post comments on news articles or discuss news articles on other platforms like Reddit. These features empower and enable discussions among the users; however, they also act as the medium for the dissemination of toxic discourse and hate speech. The research community lacks a general understanding on what type of content attracts hateful discourse and the possible effects of social networks on the commenting activity on news articles. In this work, we perform a large-scale quantitative analysis of 125M comments posted on 412K news articles over the course of 19 months. We analyze the content of the collected articles and their comments using temporal analysis, user-based analysis, and linguistic analysis, to shed light on what elements attract hateful comments on news articles. We also investigate commenting activity when an article is posted on either 4chan\u2019s Politically Incorrect board (\/pol\/) or six selected subreddits. We find statistically significant increases in hateful commenting activity around real-world divisive events like the \u201cUnite the Right\u201d rally in Charlottesville and political events like the second and third 2016 US presidential debates. Also, we find that articles that attract a substantial number of hateful comments have different linguistic characteristics when compared to articles that do not attract hateful comments. Furthermore, we observe that the post of a news articles on either \/pol\/ or the six subreddits is correlated with an increase of (hateful) commenting activity on the news articles.","1117":"We investigate how news values differ between online and print news articles. We hypothesize that print and online articles differ in terms of news values because of differences in the routines used to produce them. Based on a quantitative automated content analysis of N\u2009=\u2009762,095 Dutch news items, we show that online news items are more likely to be follow-up items than print items, and that there are further differences regarding news values like references to persons, the power elite, negativity, and positivity. In order to conduct this large-scale analysis, we developed innovative methods to automatically code a wide range of news values. In particular, this article demonstrates how techniques such as sentiment analysis, named entity recognition, supervised machine learning, and automated queries of external databases can be combined and used to study journalistic content. Possible explanations for the difference found between online and offline news are discussed.","1118":"On the one hand, nowadays, fake news articles are easily propagated through various online media platforms and have become a grand threat to the trustworthiness of information. On the other hand, our understanding of the language of fake news is still minimal. Incorporating hierarchical discourse-level structure of fake and real news articles is one crucial step toward a better understanding of how these articles are structured. Nevertheless, this has rarely been investigated in the fake news detection domain and faces tremendous challenges. First, existing methods for capturing discourse-level structure rely on annotated corpora which are not available for fake news datasets. Second, how to extract out useful information from such discovered structures is another challenge. To address these challenges, we propose Hierarchical Discourse-level Structure for Fake news detection. HDSF learns and constructs a discourse-level structure for fake\/real news articles in an automated and data-driven manner. Moreover, we identify insightful structure-related properties, which can explain the discovered structures and boost our understating of fake news. Conducted experiments show the effectiveness of the proposed approach. Further structural analysis suggests that real and fake news present substantial differences in the hierarchical discourse-level structures.","1119":"Fake news has become an important topic of research in a variety of disciplines including linguistics and computer science. In this paper, we explain how the problem is approached from the perspective of natural language processing, with the goal of building a system to automatically detect misinformation in news. The main challenge in this line of research is collecting quality data, i.e., instances of fake and real news articles on a balanced distribution of topics. We review available datasets and introduce the MisInfoText repository as a contribution of our lab to the community. We make available the full text of the news articles, together with veracity labels previously assigned based on manual assessment of the articles\u2019 truth content. We also perform a topic modelling experiment to elaborate on the gaps and sources of imbalance in currently available datasets to guide future efforts. We appeal to the community to collect more data and to make it available for research purposes.","1120":"Predicting stock market prices has been a topic of interest among both analysts and researchers for a long time. Stock prices are hard to predict because of their high volatile nature which depends on diverse political and economic factors, change of leadership, investor sentiment, and many other factors. Predicting stock prices based on either historical data or textual information alone has proven to be insufficient. Existing studies in sentiment analysis have found that there is a strong correlation between the movement of stock prices and the publication of news articles. Several sentiment analysis studies have been attempted at various levels using algorithms such as support vector machines, naive Bayes regression, and deep learning. The accuracy of deep learning algorithms depends upon the amount of training data provided. However, the amount of textual data collected and analyzed during the past studies has been insufficient and thus has resulted in predictions with low accuracy. In our paper, we improve the accuracy of stock price predictions by gathering a large amount of time series data and analyzing it in relation to related news articles, using deep learning models. The dataset we have gathered includes daily stock prices for S&P500 companies for five years, along with more than 265,000 financial news articles related to these companies. Given the large size of the dataset, we use cloud computing as an invaluable resource for training prediction models and performing inference for a given stock in real time.","1121":"Most currently available fake news datasets revolve around US politics, entrainment news or satire. They are typically scraped from fact-checking websites, where the articles are labeled by human experts. In this paper, we present FA-KES, a fake news dataset around the Syrian war. Given the specific nature of news reporting on incidents of wars and the lack of available sources from which manually-labeled news articles can be scraped, we believe a fake news dataset specifically constructed for this domain is crucial. To ensure a balanced dataset that covers the many facets of the Syrian war, our dataset consists of news articles from several media outlets representing mobilisation press, loyalist press, and diverse print media. To avoid the difficult and often-subjective task of manually labeling news articles as true or fake, we employ a semi-supervised fact-checking approach to label the news articles in our dataset. With the help of crowdsourcing, human contributors are prompted to extract specific and easy-to-extract information that helps match a given article to information representing \u201cground truth\u201d obtained from the Syrian Violations Documentation Center. The information extracted is then used to cluster the articles into two separate sets using unsupervised machine learning. The result is a carefully annotated dataset consisting of 804 articles labeled as true or fake and that is ideal for training machine learning models to predict the credibility of news articles. Our dataset is publicly available at https:\/\/doi.org\/10.5281\/zenodo.2607278. Although our dataset is focused on the Syrian crisis, it can be used to train machine learning models to detect fake news in other related domains. Moreover, the framework we used to obtain the dataset is general enough to be used to build other fake news datasets around military conflicts, provided there is some corresponding ground-truth available.","1122":"We present proppy, the first publicly available real-world, real-time propaganda detection system for online news, which aims at raising awareness, thus potentially limiting the impact of propaganda and helping fight disinformation. The system constantly monitors a number of news sources, deduplicates and clusters the news into events, and organizes the articles about an event on the basis of the likelihood that they contain propagandistic content. The system is trained on known propaganda sources using a variety of stylistic features. The evaluation results on a standard dataset show stateof-the-art results for propaganda detection.","1123":"The spread of \u2018fake\u2019 health news is a big problem with even bigger consequences. In this study, we examine a collection of health-related news articles published by reliable and unreliable media outlets. Our analysis shows that there are structural, topical, and semantic patterns which are different in contents from reliable and unreliable media outlets. Using machine learning, we leverage these patterns and build classification models to identify the source (reliable or unreliable) of a health-related news article. Our model can predict the source of an article with an F-measure of 96%. We argue that the findings from this study will be useful for combating the health disinformation problem.","1124":"Fake news and misinformation have been increasingly used to manipulate popular opinion and influence political processes. To better understand fake news, how they are propagated, and how to counter their effect, it is necessary to first identify them. Recently, approaches have been proposed to automatically classify articles as fake based on their content. An important challenge for these approaches comes from the dynamic nature of news: as new political events are covered, topics and discourse constantly change and thus, a classifier trained using content from articles published at a given time is likely to become ineffective in the future. To address this challenge, we propose a topic-agnostic (TAG) classification strategy that uses linguistic and web-markup features to identify fake news pages. We report experimental results using multiple data sets which show that our approach attains high accuracy in the identification of fake news, even as topics evolve over time.","1125":null,"1126":"Social networks have become the main platforms for information dissemination. Nevertheless, due to the increasing number of users, social media platforms tend to be highly vulnerable to the propagation of disinformation - making the detection of fake news a challenging task. In this work, we focus on content-based methods for detecting fake news - casting the problem to a binary text classification one (an article corresponds to either fake news or not). In particular, our work proposes a graph-based semi-supervised fake news detection method based on graph neural networks. The experimental results indicate that the proposed methodology achieves better performance compared to traditional classification techniques, especially when trained on limited number of labeled articles 11Our code is publicly available at: https:\/\/github.com\/bdvllrs\/misinformation-detection-tensor-embeddings..","1127":"Content-based news recommendation systems need to recommend news articles based on the topics and content of articles without using user specific information. Many news articles describe the occurrence of specific events and named entities including people, places or objects. In this paper, we propose a graph traversal algorithm as well as a novel weighting scheme for cold-start content based news recommendation utilizing these named entities. Seeking to create a higher degree of user-specific relevance, our algorithm computes the shortest distance between named entities, across news articles, over a large knowledge graph. Moreover, we have created a new human annotated data set for evaluating content based news recommendation systems. Experimental results show our method is suitable to tackle the hard cold-start problem and it produces stronger Pearson correlation to human similarity scores than other cold-start methods. Our method is also complementary and a combination with the conventional cold-start recommendation methods may yield significant performance gains. The dataset, CNRec, is available at: https:\/\/github.com\/kevinj22\/CNRec","1128":"Popular fake news articles spread faster than mainstream articles on the same topic which renders manual fact checking inefficient. At the same time, creating tools for automatic detection is as challenging due to lack of dataset containing articles which present fake or manipulated stories as compelling facts. In this paper, we introduce manually verified corpus of compelling fake and questionable news articles on the USA politics, containing around 700 articles from Aug-Nov, 2016. We present various analyses on this corpus and finally implement classification model based on linguistic features. This work is still in progress as we plan to extend the dataset in the future and use it for our approach towards automated fake news detection.","1129":"This paper introduces the SAMSum Corpus, a new dataset with abstractive dialogue summaries. We investigate the challenges it poses for automated summarization by testing several models and comparing their results with those obtained on a corpus of news articles. We show that model-generated summaries of dialogues achieve higher ROUGE scores than the model-generated summaries of news \u2013 in contrast with human evaluators\u2019 judgement. This suggests that a challenging task of abstractive dialogue summarization requires dedicated models and non-standard quality measures. To our knowledge, our study is the first attempt to introduce a high-quality chat-dialogues corpus, manually annotated with abstractive summarizations, which can be used by the research community for further studies.","1130":"This paper applies BERT to ad hoc document retrieval on news articles, which requires addressing two challenges: relevance judgments in existing test collections are typically provided only at the document level, and documents often exceed the length that BERT was designed to handle. Our solution is to aggregate sentence-level evidence to rank documents. Furthermore, we are able to leverage passage-level relevance judgments fortuitously available in other domains to fine-tune BERT models that are able to capture cross-domain notions of relevance, and can be directly used for ranking news articles. Our simple neural ranking models achieve state-of-the-art effectiveness on three standard test collections.","1131":"In this paper we consider clustering problems in which each point is endowed with a color. The goal is to cluster the points to minimize the classical clustering cost but with the additional constraint that no color is over-represented in any cluster. This problem is motivated by practical clustering settings, e.g., in clustering news articles where the color of an article is its source, it is preferable that no single news source dominates any cluster. For the most general version of this problem, we obtain an algorithm that has provable guarantees of performance; our algorithm is based on finding a fractional solution using a linear program and rounding the solution subsequently. For the special case of the problem where no color has an absolute majority in any cluster, we obtain a simpler combinatorial algorithm also with provable guarantees. Experiments on real-world data shows that our algorithms are effective in finding good clustering without over-representation.","1132":"Document\/Text Classification has become an important area in the field of Machine Learning. On account of its wide applications in business, ham\/spam filtering, health, e-commerce, social media sentiment, product sentiment among customers etc., various approaches have been devised to accurately predict the category or to classify any of the new text\/document under consideration. Nowadays, news articles in the newspaper present various kinds of sentiments or inclination of the news article towards a negative or positive sentiment and hence, the content of the news can actively be used to judge the impact on the reader. The paper aims to predict that whether the sentiment of the news article is positive or negative using the two popular approaches of Na\u00efve Bayes Text Categorization i.e. Multivariate Bernoulli Na\u00efve Bayes Classification and Multinomial Na\u00efve Bayes Classification. Also, the research aims to identify that which approach between the given two approaches perform better for the given dataset.","1133":"News publishers have decreased disseminating news through conventional newspapers and have migrated to the use of digital means like websites and purpose-built mobile applications. It is observed that news recommendation systems can automatically process lengthy articles and identify similar articles for readers considering predefined criteria. The objectives of the current work are to identify and classify the challenges in news recommendation domain, to identify state-of-the-art approaches and classify on the application domain, to identify datasets used for evaluation and their sources, the evaluation approaches used and to highlight the challenges explicitly addressed. The literature is thoroughly studied over the time span of 2001\u20132019 and shortlisted 81 related studies, broadly classified into six categories and discussed. The analysis showed that 60% of news recommendation system adopted a hybrid approach, 66% studies little talk about datasets, and addresses a few challenges from a long list of challenges in the news domain. This article is the first in the field to draw a comprehensive big picture of news recommendation and explore different dimensions covered in the studies. The last section presents the future research opportunities that lead to improving the recommendation of news articles in the news domain.","1134":"As language models become more powerful, training and evaluation are increasingly bottlenecked by the data and metrics used for a particular task. For example, summarization models are often trained to predict human reference summaries and evaluated using ROUGE, but both of these metrics are rough proxies for what we really care about---summary quality. In this work, we show that it is possible to significantly improve summary quality by training a model to optimize for human preferences. We collect a large, high-quality dataset of human comparisons between summaries, train a model to predict the human-preferred summary, and use that model as a reward function to fine-tune a summarization policy using reinforcement learning. We apply our method to a version of the TL;DR dataset of Reddit posts and find that our models significantly outperform both human reference summaries and much larger models fine-tuned with supervised learning alone. Our models also transfer to CNN\/DM news articles, producing summaries nearly as good as the human reference without any news-specific fine-tuning. We conduct extensive analyses to understand our human feedback dataset and fine-tuned models We establish that our reward model generalizes to new datasets, and that optimizing our reward model results in better summaries than optimizing ROUGE according to humans. We hope the evidence from our paper motivates machine learning researchers to pay closer attention to how their training loss affects the model behavior they actually want.","1135":"Automatic summarization is typically treated as a 1-to-1 mapping from document to summary. Documents such as news articles, however, are structured and often cover multiple topics or aspects; and readers may be interested in only some of them. We tackle the task of aspect-based summarization, where, given a document and a target aspect, our models generate a summary centered around the aspect. We induce latent document structure jointly with an abstractive summarization objective, and train our models in a scalable synthetic setup. In addition to improvements in summarization over topic-agnostic baselines, we demonstrate the benefit of the learnt document structure: we show that our models (a) learn to accurately segment documents by aspect; (b) can leverage the structure to produce both abstractive and extractive aspect-based summaries; and (c) that structure is particularly advantageous for summarizing long documents. All results transfer from synthetic training documents to natural news articles from CNN\/Daily Mail and RCV1.","1136":"Recommendation of a relevant and suitable news article is an essential but a challenging task due to changes in the user interest categories over time. Moreover, the Internet technology provides abundant news articles from a huge amount of resources. Meanwhile, nowadays, many people are confronted with viral news articles through social media cost-free without considering the news sites. Therefore, mining of social media for addressing such viral news articles has become another key challenge. To overcome the above challenges, this paper proposes fuzzy logic approach for predicting users' diversified interest and its categories by analysing their implicit user profile. Depending on users' interest categories, the viral news articles and their categories were determined and analysed through mining social media feeds-Facebook and Twitter. Furthermore, fresh news articles are retrieved from news feeds incorporated with retrieved viral news articles provided as recommendation with respect to users' diversified interest. The performance of the proposed approach for predicting overall users' interest for all categories attained 84.238%, and recommendation accuracy from News feed, Facebook, and Twitter attained 100%, 90%, and 100% with respect to users' interest categories.","1137":"Random forests (Breiman, 2001, Machine Learning 45: 5\u201332) is a statistical- or machine-learning algorithm for prediction. In this article, we introduce a corresponding new command, rforest. We overview the random forest algorithm and illustrate its use with two examples: The first example is a classification problem that predicts whether a credit card holder will default on his or her debt. The second example is a regression problem that predicts the logscaled number of shares of online news articles. We conclude with a discussion that summarizes key points demonstrated in the examples.","1138":"Portfolio management (PM) is a fundamental financial planning task that aims to achieve investment goals such as maximal profits or minimal risks. Its decision process involves continuous derivation of valuable information from various data sources and sequential decision optimization, which is a prospective research direction for reinforcement learning (RL). In this paper, we propose SARL, a novel State-Augmented RL framework for PM. Our framework aims to address two unique challenges in financial PM: (1) data heterogeneity \u2013 the collected information for each asset is usually diverse, noisy and imbalanced (e.g., news articles); and (2) environment uncertainty \u2013 the financial market is versatile and non-stationary. To incorporate heterogeneous data and enhance robustness against environment uncertainty, our SARL augments the asset information with their price movement prediction as additional states, where the prediction can be solely based on financial data (e.g., asset prices) or derived from alternative sources such as news. Experiments on two real-world datasets, (i) Bitcoin market and (ii) HighTech stock market with 7-year Reuters news articles, validate the effectiveness of SARL over existing PM approaches, both in terms of accumulated profits and risk-adjusted profits. Moreover, extensive simulations are conducted to demonstrate the importance of our proposed state augmentation, providing new insights and boosting performance significantly over standard RL-based PM method and other baselines.","1139":"Stock price prediction is important for value investments in the stock market. In particular, short-term prediction that exploits financial news articles is promising in recent years. In this paper, we propose a novel deep neural network DP-LSTM for stock price prediction, which incorporates the news articles as hidden information and integrates difference news sources through the differential privacy mechanism. First, based on the autoregressive moving average model (ARMA), a sentiment-ARMA is formulated by taking into consideration the information of financial news articles in the model. Then, an LSTM-based deep neural network is designed, which consists of three components: LSTM, VADER model and differential privacy (DP) mechanism. The proposed DP-LSTM scheme can reduce prediction errors and increase the robustness. Extensive experiments on S&P 500 stocks show that (i) the proposed DP-LSTM achieves 0.32% improvement in mean MPA of prediction result, and (ii) for the prediction of the market index S&P 500, we achieve up to 65.79% improvement in MSE.","1140":"The COVID-19 pandemic requires a fast response from researchers to help address biological, medical, and public health issues to minimize its impact. In this rapidly evolving context, scholars, professionals, and the public may need to identify important new studies quickly. In response, this paper assesses the coverage of scholarly databases and impact indicators during March 21, 2020 to April 18, 2020. The rapidly increasing volume of research is particularly accessible through Dimensions, and less through Scopus, the Web of Science, and PubMed. Google Scholar\u2019s results included many false matches. A few COVID-19 papers from the 21,395 in Dimensions were already highly cited, with substantial news and social media attention. For this topic, in contrast to previous studies, there seems to be a high degree of convergence between articles shared in the social web and citation counts, at least in the short term. In particular, articles that are extensively tweeted on the day first indexed are likely to be highly read and relatively highly cited 3 weeks later. Researchers needing wide scope literature searches (rather than health-focused PubMed or medRxiv searches) should start with Dimensions (or Google Scholar) and can use tweet and Mendeley reader counts as indicators of likely importance.","1141":"Deep-learning-based models have been successfully applied to the problem of detecting fake news on social media. While the correlations among news articles have been shown to be effective cues for online news analysis, existing deep-learning-based methods often ignore this information and only consider each news article individually. To overcome this limitation, we develop a graph-theoretic method that inherits the power of deep learning while at the same time utilizing the correlations among the articles. We formulate fake news detection as an inference problem in a Markov random field (MRF) which can be solved by the iterative mean-field algorithm. We then unfold the mean-field algorithm into hidden layers that are composed of common neural network operations. By integrating these hidden layers on top of a deep network, which produces the MRF potentials, we obtain our deep MRF model for fake news detection. Experimental results on well-known datasets show that the proposed model improves upon various state-of-the-art models.","1142":"Knowledge graph, which contains rich knowledge facts and well structured relations, is an ideal auxiliary data source for alleviating the data sparsity issue and improving the explainability of recommender systems. However, preliminary studies usually simply leverage a generic knowledge graph which is not specially designed for particular tasks. In this paper, we consider the scenario of news recommendations. We observe that both collaborative relations of entities (\\eg entities frequently appear in same news articles or clicked by same users) and the topic context of news article can be well utilized to construct a more powerful graph for news recommendations. Thus we propose an enhanced knowledge graph called \\textbf{news graph}. Compared with a generic knowledge graph, the news graph is enhanced from three aspects: (1) adding a new group of entities for recording topic context information;\u00a0 (2) adding collaborative edges between entities based on users\u2019 click behaviors and co-occurrence in news articles; and (3) removing news-irrelevant relations. To the best of our knowledge, it is the first time that a domain specific graph is constructed for news recommendations. Extensive experiments on a real-world news reading dataset demonstrate that our news graph can greatly benefit a wide range of news recommendation tasks, including personalized article recommendation, article category classification, article popularity prediction, and local news detection.","1143":"Social media is one of the most revolutionary inventions of the present times. With its own set of advantages and disadvantages it is extremely essential for each one of us. Today Fake News has become a major problem wreaking havoc all over the world. Therefore building an algorithm with the best possible accuracy will be a revelation and it will have a massive impact on the social issues which are prevalent as well as on the current political scenario. Social Media and online news articles serve as a major source of news and for data for people since it can be approached easily, has a subsidized costing and is readily available-just a click away. However, it does have several negative impacts too such as no check on the source or authenticity and validity of the views being endorsed. Hence, we have proposed a new solution for fake news detection which incorporates sentiment as an important feature to improve the accuracy. It also investigates the performance of proposed method using three different data sets. Results show that proposed solution performs well. Moreover, the comparison is also made with other methods under this study.","1144":"We investigate the presence (and the influence) of disinformation spreading on online social networks in Italy, in the 5-month period preceding the 2019 European Parliament elections. To this aim we collected a large-scale dataset of tweets associated to thousands of news articles published on Italian disinformation websites. In the observation period, a few outlets accounted for most of the deceptive information circulating on Twitter, which focused on controversial and polarizing topics of debate such as immigration, national safety and (Italian) nationalism. We found evidence of connections between Italian disinformation sources and different disinformation outlets across Europe, U.S. and Russia, featuring similar, even translated, articles in the period before the elections. Overall, the spread of disinformation on Twitter was confined in a limited community, strongly (and explicitly) related to the Italian conservative and far-right political environment, who had a limited impact on online discussions on the up-coming elections.","1145":"Stock Market trend prediction will always remain a challenging task due to stochastic nature. The enormous amount of data generated by the news, blogs, reviews, financial reports and social media are considered a treasure of knowledge for researchers and investors. The present work focuses to observe fluctuations in stock prices with respect to the relevant news articles of a company. In this paper, a daily prediction model is proposed using historical data and news articles to predict the Indian stock market movements. Classifier Na\u00efve Bayes is used to categorize the news text having negative or positive sentiment. The count of the positive and negative sentiment of news articles for each day and variance of adjacent days close price along with historical data is used for prediction purpose and an accuracy ranging from 65.30 to 91.2 % achieved with various machine learning techniques.","1146":null,"1147":"Online social media are changing the news industry and revolutionizing the traditional role of journalists and newspapers. In this scenario, investigating the behaviour of users in relationship to news sharing is relevant, as it provides means for understanding the impact of online news, their propagation within social communities, their impact on the formation of opinions, and also for effectively detecting individual stances relative to specific news or topics.Our contribution is two-fold. First, we build a robust pipeline for collecting datasets describing news sharing; the pipeline takes as input a list of news sources and generates a large collection of articles, of the accounts that provide them on the social media either directly or by retweeting, and of the social activities performed by these accounts. Second, we also provide a large-scale dataset, built using the aforementioned tool, that can be used to study the social behavior of Twitter users and their involvement in the dissemination of news items. Finally we show an application of our data collection in the context of political stance classification and we suggest other potential usages of the presented resources.","1148":"This paper describes, develops, and validates SciLens, a method to evaluate the quality of scientific news articles. The starting point for our work are structured methodologies that define a series of quality aspects for manually evaluating news. Based on these aspects, we describe a series of indicators of news quality. According to our experiments, these indicators help non-experts evaluate more accurately the quality of a scientific news article, compared to non-experts that do not have access to these indicators. Furthermore, SciLens can also be used to produce a completely automated quality score for an article, which agrees more with expert evaluators than manual evaluations done by non-experts. One of the main elements of SciLens is the focus on both content and context of articles, where context is provided by (1) explicit and implicit references on the article to scientific literature, and (2) reactions in social media referencing the article. We show that both contextual elements can be valuable sources of information for determining article quality. The validation of SciLens, done through a combination of expert and non-expert annotation, demonstrates its effectiveness for both semi-automatic and automatic quality evaluation of scientific news.","1149":"ABSTRACT Algorithms are playing an increasingly important role in the production of news content as their computation capacity in manipulating large-scale data continues to grow. In this article, we present Personalized and Interactive News Generation System (PINGS), an algorithm-driven news generation system that is designed to provide personalized and interactive news for sports. We designed PINGS to generate baseball news based on the statistical importance of data and the direct manipulation of user interface components that alter the underlying algorithmic computation. We discuss the base-level algorithm framework for automated news content generation and describe the architecture of the system in terms of how it is designed to support the generation of personalized news stories. An evaluation revealed that the algorithm is capable of generating news stories that are significantly more interesting and pleasant to read than traditional baseball news articles.","1150":"Automatic document categorization gains more importance in view of the plethora of textual documents added constantly on the web. Text categorization or classification is the process of automatically tagging a textual document with most relevant label. Text categorization for Arabic language is interesting in the absence of large and free datasets. Our objective is to automatically identify the category of a document based on its linguistic features. To achieve this goal, we constructed a new dataset which contains almost 90k Arabic news articles with their tags from Arabic news portals. The dataset shall be made freely available to the research community on Arabic computational linguistics. The dataset has four main categories: Business, Sports, Technology and Middle East. Each collected article was cleaned from Latin characters, numbers, punctuation and stop words. To investigate the effectiveness of the dataset, we used an array of classical supervised machine learning classifiers. Namely, the following 10 popular classifiers were used: Logistic Regression, Nearest Centroid, Decision Tree (DT), Support Vector Machines (SVM), K-nearest neighbors (KNN), XGBoost Classifier, Random Forest Classifier, Multinomial Classifier, Ada-Boost Classifier, and Multi-Layer Perceptron (MLP). In pursuit of high accuracy, we implemented an ensemble model to combine best classifiers together in a majority-voting classifier. Our experimental results showed solid performance with a minimum Fl-score of 87.7%, achieved by Ada-Boost and top performance of 97.9% achieved by SVM. The experimental results are presented in terms of confusion matrices, Fl-scores, and accuracy.","1151":"In this paper, we present a semi-automated framework called AMUSED for gathering multi-modal annotated data from the multiple social media platforms. The framework is designed to mitigate the issues of collecting and annotating social media data by cohesively combining machine and human in the data collection process. From a given list of the articles from professional news media or blog, AMUSED detects links to the social media posts from news articles and then downloads contents of the same post from the respective social media platform to gather details about that specific post. The framework is capable of fetching the annotated data from multiple platforms like Twitter, YouTube, Reddit. The framework aims to reduce the workload and problems behind the data annotation from the social media platforms. AMUSED can be applied in multiple application domains, as a use case, we have implemented the framework for collecting COVID-19 misinformation data from different social media platforms.","1152":"\n Exploiting a unique identification strategy based on inaccurate news analytics, we document an effect of news analytics on the market independent of the informational content of the news. We show that news analytics speed up the stock price and trading volume response to articles, but reduce liquidity. Inaccurate news analytics lead to small price distortions that are corrected quickly. The market impact of news analytics is greatest for press releases, as news analytics exhibit a particular skill in \u201cseeing through\u201d the positive spin of press releases. Furthermore, we provide evidence that high-frequency traders rely on the information from news analytics for directional trading on company-specific news.\n Received: May 17, 2018; Editorial decision: June 14, 2019 by Editor: Thierry Foucault. Authors have furnished an Internet Appendix, which is available on the Oxford University Press Web site next to the link to the final published paper online.","1153":"One can easily say in today's world, information aka news to few is more precious than money itself. This news needs to be in authentic form which is usually found in adulterated version. Leading us to have a dire need for an identification of real news from any possible fake news. News, being a form of information can be subjective to the proofs and source for its authenticity. As a human, one can easily identify real news from fake news with the help of one's innate capability to deduce logic and outlandish source of the information piece. Just that one needs few trusted sources to check for the facts and myths. But on a real time basis, there is a dire need for some software which can nip such \u2018false news\u2019 in its bud. Leading it to be one of the most researched area nowadays. Primarily being a part of Information Retrieval, this area is taking up a lot of attention from researchers worldwide to come up with a real-time solution for such an issue. In this article we have checked and analysed many research articles along with many survey articles and summed up this paper so as to provide the readers with a short idea of what fake news is, it's different flavours in the news spectrum, its characteristics and identification basic. We also included the different methods used by prior researchers in the same field. Using few researches as examples we learned about the basics of those methods used in fake news identification. The future aspects are also included in this article along with the challenges one faces while doing research in this very field.","1154":"Nearly 70% of people are concerned about the propagation of fake news. This paper aims to detect fake news in online articles through the use of semantic features and various machine learning techniques. In this research, we investigated recurrent neural networks vs. the naive bayes classifier and random forest classifiers using five groups of linguistic features. Evaluated with real or fake dataset from kaggle.com, the best performing model achieved an accuracy of 95.66% using bigram features with the random forest classifier. The fact that bigrams outperform unigrams, trigrams, and quadgrams show that word pairs as opposed to single words or phrases best indicate the authenticity of news.","1155":"In the wake of the 2016 U.S. presidential election, social-media platforms are facing increasing pressure to combat the propagation of \u201cfake news\u201d (i.e., articles whose content is fabricated). Motivated by recent attempts in this direction, we consider the problem faced by a social-media platform that is observing the sharing actions of a sequence of rational agents and is dynamically choosing whether to conduct an inspection (i.e., a \u201cfact-check\u201d) of an article whose validity is ex ante unknown. We first characterize the agents\u2019 inspection and sharing actions and establish that, in the absence of any platform intervention, the agents\u2019 news-sharing process is prone to the proliferation of fabricated content, even when the agents are intent on sharing only truthful news. We then study the platform\u2019s inspection problem. We find that because the optimal policy is adapted to crowdsource inspection from the agents, it exhibits features that may appear a priori nonobvious; most notably, we show that the optimal inspection policy is nonmonotone in the ex ante probability that the article being shared is fake. We also investigate the effectiveness of the platform\u2019s policy in mitigating the detrimental impact of fake news on the agents\u2019 learning environment. We demonstrate that in environments characterized by a low (high) prevalence of fake news, the platform\u2019s policy is more effective when the rewards it collects from content sharing are low relative to the penalties it incurs from the sharing of fake news (when the rewards it collects from content sharing are high in absolute terms).","1156":"Transcripts of natural, multi-person meetings differ significantly from documents like news articles, which can make Natural Language Generation models for generating summaries unfocused. We develop an abstractive meeting summarizer from both videos and audios of meeting recordings. Specifically, we propose a multi-modal hierarchical attention across three levels: segment, utterance and word. To narrow down the focus into topically-relevant segments, we jointly model topic segmentation and summarization. In addition to traditional text features, we introduce new multi-modal features derived from visual focus of attention, based on the assumption that the utterance is more important if the speaker receives more attention. Experiments show that our model significantly outperforms the state-of-the-art with both BLEU and ROUGE measures.","1157":"The use of the internet as a fast medium of spreading fake news reinforces the need for computational tools that combat it. Techniques that train fake news classifiers exist, but they all assume an abundance of resources including large labeled datasets and expert-curated corpora, which low-resource languages may not have. In this work, we make two main contributions: First, we alleviate resource scarcity by constructing the first expertly-curated benchmark dataset for fake news detection in Filipino, which we call \u201cFake News Filipino.\u201d Second, we benchmark Transfer Learning (TL) techniques and show that they can be used to train robust fake news classifiers from little data, achieving 91% accuracy on our fake news dataset, reducing the error by 14% compared to established few-shot baselines. Furthermore, lifting ideas from multitask learning, we show that augmenting transformer-based transfer techniques with auxiliary language modeling losses improves their performance by adapting to writing style. Using this, we improve TL performance by 4-6%, achieving an accuracy of 96% on our best model. Lastly, we show that our method generalizes well to different types of news articles, including political news, entertainment news, and opinion articles.","1158":"This paper provides causal evidence on how partisan news messaging from cable television influences the content published by newspapers in U.S. localities. We introduce a new parallel corpus of newspaper articles (24M articles in 600+ local newspapers) and transcribed television news shows (40K cable news episodes from Fox News Channel CNN, and MSNBC) for the years 2005-2008. We measure media influence using a supervised learning model that predicts, for a given piece of text, the probability that it comes from a Fox News transcript, rather than from CNN or MSNBC. After validating the measure, we apply it to the local newspaper article texts. Exogenous variation in news viewership across localities comes from relative channel numbering, which we use as instruments. We find that an exogenous increase in local viewership of a cable news network shifts the textual content of local newspapers toward that network\u2019s content. Televised media slant works not just through persuading viewers, but through influencing other media outlets.","1159":"A prominent approach to combating online misinformation is to debunk false content. Here we investigate downstream consequences of social corrections on users\u2019 subsequent sharing of other content. Being corrected might make users more attentive to accuracy, thus improving their subsequent sharing. Alternatively, corrections might not improve subsequent sharing - or even backfire - by making users feel defensive, or by shifting their attention away from accuracy (e.g., towards various social factors). We identified N=2,000 users who shared false political news on Twitter, and replied to their false tweets with links to fact-checking websites. We find causal evidence that being corrected decreases the quality, and increases the partisan slant and language toxicity, of the users\u2019 subsequent retweets (but has no significant effect on primary tweets). This suggests that being publicly corrected by another user shifts one's attention away from accuracy - presenting an important challenge for social correction approaches.","1160":"This work advances and tests a theory of how news information evolves as it is successively retold by consumers. Drawing on data from over 11,000 participants across ten experiments, the authors offer evidence that when news is repeatedly retold, it undergoes a stylistic transformation termed \u201cdisagreeable personalization,\u201d wherein original facts are increasingly supplanted by opinions and interpretations with a slant toward negativity. The central thesis is that when retellers believe they are more (vs. less) knowledgeable than their recipient about the information they are relaying, they feel more compelled to provide guidance on its meaning and to do so in a persuasive manner. This enhanced motivation to guide persuasively, in turn, leads retellers to not only select the subset of facts they deem most essential but, critically, to provide their interpretations and opinions on those facts, with negativity being used as a means of grabbing their audience\u2019s attention. Implications of this work for research on retelling and consumer information diffusion are explored.","1161":": Obtaining a balanced view of an issue can be a time consuming and arduous task. A reader using only one source of information is in danger of being exposed to an author\u2019s particular slant on a given issue. For many events, social media provides a range of expressions and views on a topic. In this paper we explore the feasibility of mining alternative data and information-sources to better inform users on the issues associated with a topic. For the purpose of gauging the feasibility of augmenting available content with related information, a text similarity metric is adopted to measure relevance of the auxiliary text. The developed system extracts related content from two distinct social media sources, Reddit and Twitter. The results are evaluated through conducting a user survey on the relevance of the returned results. A two tailed Wilcoxon test is applied to evaluate the relevance of addition information snippets. Our results show that by partaking the experiment a users\u2019 level of awareness is augmented, second, that it is possible to better inform the user with information extract from a online microblogging sites.","1162":"The role that YouTube and its behind-the-scenes recommendation algorithm plays in encouraging online radicalization has been suggested by both journalists and academics alike. This study directly quantifies these claims by examining the role that YouTube\u2019s algorithm plays in suggesting radicalized content. After categorizing nearly 800 political channels, we were able to differentiate between political schemas in order to analyze the algorithm traffic flows out and between each group. After conducting a detailed analysis of recommendations received by each channel type, we refute the popular radicalization claims. On the contrary, these data suggest that YouTube\u2019s recommendation algorithm actively discourages viewers from visiting radicalizing or extremist content. Instead, the algorithm is shown to favor mainstream media and cable news content over independent YouTube channels with a slant towards left-leaning or politically neutral channels. Our study thus suggests that YouTube\u2019s recommendation algorithm fails to promote inflammatory or radicalized content, as previously claimed by several outlets.","1163":"Ideological biases in the mass media can shape public opinion. In this study, we aim to understand ideological bias in the Indian mass media, in terms of the coverage it provides to statements made by prominent people on key economic and technology policies. We build an end-to-end system that starts with a news article and parses it to obtain statements made by people in the article; on these statements, we apply a Recursive Neural Network based model to detect whether the statements express an ideological bias or not. The system then classifies the stance of the non-neutral statements. For economic policies, we determine if the statements express a pro or anti slant about the policy, and for technology policies, we determine if the statements are positive or skeptical about technology. The proposed research method can be applied to other domains as well and can serve as a basis to contrast social media self-expression by prominent people with how the mass media portrays them.","1164":"Slanted news coverage strongly affects public opinion. This is especially true for coverage on politics and related issues, where studies have shown that bias in the news may influence elections and other collective decisions. Due to its viable importance, news coverage has long been studied in the social sciences, resulting in comprehensive models to describe it and effective yet costly methods to analyze it, such as content analysis. We present an in-progress system for news recommendation that is the first to automate the manual procedure of content analysis to reveal person-targeting biases in news articles reporting on policy issues. In a large-scale user study, we find very promising results regarding this interdisciplinary research direction. Our recommender detects and reveals substantial frames that are actually present in individual news articles. In contrast, prior work rather only facilitates the visibility of biases, e.g., by distinguishing leftand right-wing outlets. Further, our study shows that recommending news articles that differently frame an event significantly improves respondents\u2019 awareness of bias.","1165":"Media bias and its extreme form, fake news, can decisively affect public opinion. Especially when reporting on policy issues, slanted news coverage may strongly influence societal decisions, e.g., in democratic elections. Our paper makes three contributions to address this issue. First, we present a system for bias identification, which combines state-of-the-art methods from natural language understanding. Second, we devise bias-sensitive visualizations to communicate bias in news articles to non-expert news consumers. Third, our main contribution is a large-scale user study that measures bias-awareness in a setting that approximates daily news consumption, e.g., we present respondents with a news overview and individual articles. We not only measure the visualizations' effect on respondents' bias-awareness, but we can also pinpoint the effects on individual components of the visualizations by employing a conjoint design. Our bias-sensitive overviews strongly and significantly increase bias-awareness in respondents. Our study further suggests that our content-driven identification method detects groups of similarly slanted news articles due to substantial biases present in individual news articles. In contrast, the reviewed prior work rather only facilitates the visibility of biases, e.g., by distinguishing left- and right-wing outlets.","1166":"This issue's complexity theory column is by Ben Lee Volk on algebraic natural proofs. My warmest thanks to Ben Lee for his terrific article.","1167":"In this column, we will discuss some papers in online algorithms that appeared in 2021. As usual, we make no claim at complete coverage here, and have instead made a selection. If we have unaccountably missed your favorite paper and you would like to write about it or about any other topic in online algorithms, please don't hesitate to contact us!","1168":"Warmest thanks to Rafael Pass and Muthu Venkitasubramaniam for this issue's guest column, \"Average-Case Complexity Through the Lens of Interactive Puzzles.\" When I mentioned to them that my introduction would have a section on Alan Selman's passing, they immediately wrote back that they were very sorry to hear of Alan's passing, and mentioned (as you will see discussed in the second page of their article), \"The main problem that we are addressing actually goes back to a paper of Even, Selman, and Yacobi from 1984: \"The Complexity of Promise Problems with Applications to Public-Key Cryptography'.\" It is beautiful, and a tribute to the lasting influence of Alan's research, that in the 2020s his work from many decades earlier is helping shape the field's dialogue.","1169":"My deepest thanks to Beatrice and Carlo for their fascinating article, Quantum Finite Automata: From Theory to Practice. Regarding the extent to which their article brings to life both parts of its subtitle... wow! And I think Section 4 is an absolute first for this column; please don't miss it!","1170":"Warmest thanks to Alexander Knop, Shachar Lovett, Sam McGuire, and Weiqiang Yuan for this issue's guest column, \\Models of computation between decision trees and communication.\" (Their article came in early, and I wrote back thanking them for being three days early, mentioning that that happens surprisingly rarely. Then two days later, I said, \\Wow!\", as I realized that they actually had somehow|even during a remote-teaching, social-distancing time period|prepared and sent in their article a month and three days early.)","1171":null,"1172":"This paper studies the properties of socially popular news with a focused interest on the emotions conveyed through their headlines. We delve deeply into the notion of emotional salience in news values and extract the emotion intensities features across the valence, joy, anger, fear and sadness dimensions. A novel dataset consisting of 47,611 English news headlines from six publishers that received more than 17 million shares and likes were retrieved using Facebook APIs over ten consecutive months in 2018. In contrast with the conventional knowledge that only high-arousal, negative emotions are associated with viral news, the data revealed that headlines with higher intensities across all five emotion dimensions (including positive, joyful news) are significantly associated with social popularity, though the emotion-popularity correlation patterns differ for different publishers (e.g., daily broadcast vs. politics-slanted publishers). From the predictive experiments, we found that the emotion features had complimentary benefits to existing features, which included strong baselines features and word embedding. The final hybrid model achieved the highest predictive performance (R^2 = .54, tau = .53; F1 = .44, AUC = .85). Using two additional publishers' data, robustness tests further showed the advantage of the proposed model against a state-of-the-art method: The Guardian (tau = .45 vs. .37) and The New York Times (tau = .46 vs. .32).","1173":"In this column, we will discuss some papers in online algorithms that appeared in 2020. As usual, we make no claim at complete coverage here, and have instead made a selection. If we have unaccountably missed your favorite paper and you would like to write about it or about any other topic in online algorithms, please don't hesitate to contact us!","1174":"My deepest thanks to Sabine Broda, Antonio Machiavelo, Nelma Moreira, and Rogerio Reis for welcoming the year 2020 with their exciting tutorial, \\Analytic Combinatorics and Descriptional Complexity of Regular Languages on Average.\"","1175":"As I write this in July 2020, I have no idea what the COVID-19 situation will be like when this September 2020 issue reaches your mailbox or your previewer. My typical advice is to prove exciting theorems. But in these times, all I can share are my hopes: that you'll each be safe and well (and that the medical profes- sion will create an effective vac- cine quickly enough that early in 2021 schools can return to fully in-person teaching); that you'll nd ways to, if a faculty member, help your students thrive even in the hybrid-mode-learning settings they'll probably nd themselves in for the fall semester; and that you'll (while staying careful and safe) nd time to (yes, here it comes) prove exciting theorems.","1176":"This is being written during the COVID-19 pandemic, and no one knows what things will be like even when Eshan's article reaches you (psst: please skip this introduction and go right to Eshan's great article now!), much less this coming fall semester, which as this is being written seems likely to be at least in part still shaped by the COVID-19 crisis.","1177":"Warmest thanks to Mark Bun and Justin Thaler for their terri c article, \\Approximate Degree in Classical and Quantum Computing.\" And, amazingly, they made the time to craft it during a time of worldwide pandemic|wow!","1178":"Emerging technologies are changing how local television (TV) stations gather and disseminate news. One increasingly used technology is drone journalism. The present study sought to determine the extent to which local TV stations across the United States were adopting this technology as part of their news operations. A survey of news managers (n = 94) found that half of the stations were using drones for news, but only to a moderate degree.","1179":"The term \u201cpost-truth\u201d was declared by Oxford Dictionaries to be its 2016 \u201cInternational Word of the Year,\u201d signifying the advent of a so-called post-truth era with rising misinformation and declining trust in media. Meanwhile, the \u201cage of data\u201d has seen a proliferation of big data alongside an increase in data-driven journalism, which is one critical way to make professional journalists distinctive with the production of fact-based, authoritative news. Using devised variations of one news report as stimuli, this experiment involves five test groups to determine whether data and data visualizations impact the perceived credibility of news. Results show that only when accompanied by visualizations does the use of data have a positive effect. Findings suggest the necessity and significant role of data visualizations in news production. The study also reveals that increased use of data components in the news does not always contribute to its audience\u2019s perception of news credibility.","1180":"The digitalization of media has simplified the process of consuming news by society. One example of digitalization of media is LINE Today which provides access to information for society through news feed. LINE Today as news aggregator compiles various news content from several news portals. Ideally, LINE Today is supposed to apply gatekeeping which include validation level, accuracy, and news balancing. However LINE Today is frequently found to abandon validity of news source and balancing news to provide news as soon as possible. Thus this research aims to find news balance level in LINE Today as news aggregator by using descriptive quantitative analysis and probability sampling purposive technique. The number of sample as many as 50 news article are obtained from LINE Today which consist of five online news portal. They are Suara.com, Kompas.com, VIVA.co.id, Liputan6.com and Kumparan.com. This study found that news contents in LINE Today apply news balance at different levels. News balance is applied gradually in the news updates. Furthermore, observation of Ahmad Dhani\u2019s hate speech verdict coverage in LINE Today is found biased. The result found that only slant element is applied in the news from total three element of news balance level. This is proven by using one-sided news coverage (source bias) which show in selection of opposing and supporting sources portion in the news.","1181":"Warmest thanks to Emanuele Viola for his fascinating article, \\Non-abelian Combinatorics and Communication Complexity.\" And since this issue will be coming out right around the start of the academic year|a natural time for people to be wondering, \\What might I think about and look into this year?\"|it is particularly great that Manu has generously included in his article many open problems.","1182":"Stance detection on social media can help to identify and understand slanted news or commentary in everyday life. In this work, we propose a new model for zero-shot stance detection on Twitter that uses adversarial learning to generalize across topics. Our model achieves state-of-the-art performance on a number of unseen test topics with minimal computational costs. In addition, we extend zero-shot stance detection to topics not previously considered, highlighting future directions for zero-shot transfer.","1183":"The relative hostile media effect suggests that partisans tend to perceive the bias of slanted news differently depending on whether the news is slanted in favor of or against their sides. To explore the effect of an algorithmic vs. human source on hostile media perceptions, this study conducts a 3 (author attribution: human, algorithm, or human-assisted algorithm) x 3 (news attitude: pro-issue, neutral, or anti-issue) mixed factorial design online experiment (N = 511). This study uses a transformer-based adversarial network to auto-generate comparable news headlines. The framework was trained with a dataset of 364,986 news stories from 22 mainstream media outlets. The results show that the relative hostile media effect occurs when people read news headlines attributed to all types of authors. News attributed to a sole human source is perceived as more credible than news attributed to two algorithm-related sources. For anti-Trump news headlines, there exists an interaction effect between author attribution and issue partisanship while controlling for people\u2019s prior belief in machine heuristics. The difference of hostile media perceptions between the two partisan groups was relatively larger in anti-Trump news headlines compared with pro-Trump news headlines.","1184":"Synchrotron radiation newS, Vol. 32, No. 3, 2019 19 Introduction To address the growing scale of data at user facilities, a multi-facility collaboration is developing a collection of Python libraries, which are co-developed but may be used a la carte, to leverage existing opensource scientific software in general and the scientific Python software ecosystem in particular to improvise cutting-edge experiments and data analysis at the beamline. The growing velocity and volume of data from third-generation synchrotron light sources and radiation facilities are exposing a data variety problem that is particular to user facilities. User facilities manage a large and often changing collection of instruments with a wide span of data rates, structures, and access patterns. Measurements are analyzed with a mix of well-established procedures and improvised techniques. To manage these challenges, user facilities must leverage the growing ecosystem of open-source scientific software, sharing tools and ideas with our counterparts in astronomy, climate science, and particle physics. Tools like GitHub [1], BinderHub [2], and the communities that have arisen around them reduce the friction of distributed collaboration within and between facilities and science domains. The Bluesky Project is an end-to-end solution [3], encompassing hardware integration [4], experiment specification and orchestration [5], online visualization and analysis, data export [6], and data access [7]. The software is currently in use at all beamlines at the National Synchrotron Light Source II (NSLS-II), a Department of Energy (DOE) Office of Science User Facility located at Brookhaven National Laboratory. It has some adoption at the Advanced Light Source (ALS), another DOE Office of Science User Facility located at Lawrence Berkeley National Laboratory, and is formally planned for wide adoption at the Linear Coherent Light Source II (LCLS-II), located at SLAC National Laboratory, and at the beamlines of the Advanced Photon Source Upgrade (APS-U), located at Argonne National Laboratory\u2014both DOE Office of Science User Facilities. All of the software components have also been employed successfully by an electrical engineering lab [8], working at the lab-bench scale rather than the facility scale, to benchmark hardware performance. To drive wide collaboration and to overcome \u201cnot-invented-here\u201dism, the Bluesky Project comprises components with well-defined boundaries that are co-developed but separately useful, and which can be adopted piecemeal. Drawing inspiration from the numpy project, which is the array representation at the core of the scientific Python ecosystem, Bluesky embraces the idea of protocols to drive interoperability. As in the case of numpy, protocols enable individually useful parts to be repurposed and extended in ways unforeseen by the original authors. Facilities and groups can meet their own needs and deadlines, while collaborating on a shared core. Figure 1 illustrates the roles and relationships of the project\u2019s software libraries.","1185":"\nPurpose\nThis paper aims to propose an Immersive Virtual Reality program to teach Information Literacy skills to college students. The proposal aims to expand the horizon of instruction into cyberspace.\n\n\nDesign\/methodology\/approach\nThe paper explains the planning, cost and logistics required to implement such a program. The virtual reality (VR) program puts students in everyday situations that require \u201ccommon sense\u201d decision-making actions, then transfers them into a library setting requiring them to use the exact same reasoning. A crucial component of Information Literacy is Digital Literacy, so this program includes scenarios that require students to identify \u201cFake News.\u201d\n\n\nFindings\nThe paper provides insights about the Game Design Document, Concept and Design Phases as well as Performance Specifications, Deliverables and for Return on Investments used for formative assessments.\n\n\nResearch limitations\/implications\nWithout securing sponsorships or collaborations due to the inordinate expense of creating virtual worlds this program remains unfunded.\n\n\nPractical implications\nThe program is a revolutionary approach to Information Literacy instruction. It shows students that they inherently possess the cognitive tools necessary for critical evaluation skills needed to be Information Literate.\n\n\nSocial implications\nVR can transmit knowledge without students feeling they are being preached at.\n\n\nOriginality\/value\nThis program fulfills an identified need to keep libraries relevant in this technologically advanced Digital Age. This radical VR program represents a truly transformational approach to instruction that can catapult us into the virtual and eventual future of Libraries.\n","1186":"In recent years, to mitigate the problem of fake news, computational detection of fake news has been studied, producing some promising early results. While important, however, we argue that a critical missing piece of the study be the explainability of such detection, i.e., why a particular piece of news is detected as fake. In this paper, therefore, we study the explainable detection of fake news. We develop a sentence-comment co-attention sub-network to exploit both news contents and user comments to jointly capture explainable top-k check-worthy sentences and user comments for fake news detection. We conduct extensive experiments on real-world datasets and demonstrate that the proposed method not only significantly outperforms 7 state-of-the-art fake news detection methods by at least 5.33% in F1-score, but also (concurrently) identifies top-k user comments that explain why a news piece is fake, better than baselines by 28.2% in NDCG and 30.7% in Precision.","1187":"Social media are nowadays one of the main news sources for millions of people around the globe due to their low cost, easy access and rapid dissemination. This however comes at the cost of dubious trustworthiness and significant risk of exposure to 'fake news', intentionally written to mislead the readers. Automatically detecting fake news poses challenges that defy existing content-based analysis approaches. One of the main reasons is that often the interpretation of the news requires the knowledge of political or social context or 'common sense', which current NLP algorithms are still missing. Recent studies have shown that fake and real news spread differently on social media, forming propagation patterns that could be harnessed for the automatic fake news detection. Propagation-based approaches have multiple advantages compared to their content-based counterparts, among which is language independence and better resilience to adversarial attacks. In this paper we show a novel automatic fake news detection model based on geometric deep learning. The underlying core algorithms are a generalization of classical CNNs to graphs, allowing the fusion of heterogeneous data such as content, user profile and activity, social graph, and news propagation. Our model was trained and tested on news stories, verified by professional fact-checking organizations, that were spread on Twitter. Our experiments indicate that social network structure and propagation are important features allowing highly accurate (92.7% ROC AUC) fake news detection. Second, we observe that fake news can be reliably detected at an early stage, after just a few hours of propagation. Third, we test the aging of our model on training and testing data separated in time. Our results point to the promise of propagation-based approaches for fake news detection as an alternative or complementary strategy to content-based approaches.","1188":"A large body of recent works has focused on understanding and detecting fake news stories that are disseminated on social media. To accomplish this goal, these works explore several types of features extracted from news stories, including source and posts from social media. In addition to exploring the main features proposed in the literature for fake news detection, we present a new set of features and measure the prediction performance of current approaches and features for automatic detection of fake news. Our results reveal interesting findings on the usefulness and importance of features for detecting false news. Finally, we discuss how fake news detection approaches can be used in the practice, highlighting challenges and opportunities.","1189":"Social media has become one of the main channels for people to access and consume news, due to the rapidness and low cost of news dissemination on it. However, such properties of social media also make it a hotbed of fake news dissemination, bringing negative impacts on both individuals and society. Therefore, detecting fake news has become a crucial problem attracting tremendous research effort. Most existing methods of fake news detection are supervised, which require an extensive amount of time and labor to build a reliably annotated dataset. In search of an alternative, in this paper, we investigate if we could detect fake news in an unsupervised manner. We treat truths of news and users\u2019 credibility as latent random variables, and exploit users\u2019 engagements on social media to identify their opinions towards the authenticity of news. We leverage a Bayesian network model to capture the conditional dependencies among the truths of news, the users\u2019 opinions, and the users\u2019 credibility. To solve the inference problem, we propose an efficient collapsed Gibbs sampling approach to infer the truths of news and the users\u2019 credibility without any labelled data. Experiment results on two datasets show that the proposed method significantly outperforms the compared unsupervised methods.","1190":"News recommendation can help users find interested news and alleviate information overload. Precisely modeling news and users is critical for news recommendation, and capturing the contexts of words and news is important to learn news and user representations. In this paper, we propose a neural news recommendation approach with multi-head self-attention (NRMS). The core of our approach is a news encoder and a user encoder. In the news encoder, we use multi-head self-attentions to learn news representations from news titles by modeling the interactions between words. In the user encoder, we learn representations of users from their browsed news and use multi-head self-attention to capture the relatedness between the news. Besides, we apply additive attention to learn more informative news and user representations by selecting important words and news. Experiments on a real-world dataset validate the effectiveness and efficiency of our approach.","1191":"The explosive growth in fake news and its erosion to democracy, justice, and public trust has increased the demand for fake news detection and intervention. This survey reviews and evaluates methods that can detect fake news from four perspectives: the false knowledge it carries, its writing style, its propagation patterns, and the credibility of its source. The survey also highlights some potential research tasks based on the review. In particular, we identify and detail related fundamental theories across various disciplines to encourage interdisciplinary research on fake news. It is our hope that this survey can facilitate collaborative efforts among experts in computer and information sciences, social sciences, political science, and journalism to research fake news, where such efforts can lead to fake news detection that is not only efficient but, more importantly, explainable.","1192":"The explosive growth of fake news and its erosion to democracy, justice, and public trust increased the demand for fake news detection. As an interdisciplinary topic, the study of fake news encourages a concerted effort of experts in computer and information science, political science, journalism, social science, psychology, and economics. A comprehensive framework to systematically understand and detect fake news is necessary to attract and unite researchers in related areas to conduct research on fake news. This tutorial aims to clearly present (1) fake news research, its challenges, and research directions; (2) a comparison between fake news and other related concepts (e.g., rumors); (3) the fundamental theories developed across various disciplines that facilitate interdisciplinary research; (4) various detection strategies unified under a comprehensive framework for fake news detection; and (5) the state-of-the-art datasets, patterns, and models. We present fake news detection from various perspectives, which involve news content and information in social networks, and broadly adopt techniques in data mining, machine learning, natural language processing, information retrieval and social search. Facing the upcoming 2020 U.S. presidential election, challenges for automatic, effective and efficient fake news detection are also clarified in this tutorial.","1193":"Personalized news recommendation is very important for online news platforms to help users find interested news and improve user experience. News and user representation learning is critical for news recommendation. Existing news recommendation methods usually learn these representations based on single news information, e.g., title, which may be insufficient. In this paper we propose a neural news recommendation approach which can learn informative representations of users and news by exploiting different kinds of news information. The core of our approach is a news encoder and a user encoder. In the news encoder we propose an attentive multi-view learning model to learn unified news representations from titles, bodies and topic categories by regarding them as different views of news. In addition, we apply both word-level and view-level attention mechanism to news encoder to select important words and views for learning informative news representations. In the user encoder we learn the representations of users based on their browsed news and apply attention mechanism to select informative news for user representation learning. Extensive experiments on a real-world dataset show our approach can effectively improve the performance of news recommendation.","1194":"The purpose of this study is to find out what the main agenda of social formation is and how it changes through the media by utilizing the news big data of COVID-19 which is spreading recently, and to suggest the direction of future reporting. In order to achieve the purpose of the research, 47,816 cases of news big data reported from December 31, 2019 to March 11, 2020 were divided into four periods based on the fourth stage of the crisis warning for infectious diseases, and a total of 20 topics were derived. Based on the results of the Topic Modeling analysis, this study proposed the following. First, it is necessary to refrain from provocative expressions such as \"anxiety\" and \"fear\" and use neutral and objective reporting terms. Second, more in-depth and contextual news production is required, breaking away from simple event news production. Third, it is necessary to prepare detailed crisis communication manuals for each situation related to infectious diseases. Fourth, we need reports that focus on citizens-led efforts to overcome the crisis. This research has the academic significance that it is the first paper to analyze news big data on COVID-19 using the Topic Modeling Analysis method, and the policy significance that can be used as the basis for developing national crisis communication policy. \u25a0 keyword :\u2223COVID-19\u2223Infectious Disease\u2223News Big Data\u2223News Analysis\u2223Topic Modeling Analysis\u2223 \uc811\uc218\uc77c\uc790 : 2020\ub144 04\uc6d4 10\uc77c \uc218\uc815\uc77c\uc790 : 2020\ub144 04\uc6d4 21\uc77c \uc2ec\uc0ac\uc644\ub8cc\uc77c : 2020\ub144 04\uc6d4 21\uc77c \uad50\uc2e0\uc800\uc790 : \uae40\ud0dc\uc885, e-mail : k2boy3@naver.com \ud55c\uad6d\ucf58\ud150\uce20\ud559\ud68c\ub17c\ubb38\uc9c0 '20 Vol. 20 No. 5 458","1195":"Fake news can confuse many people in the area of politics, culture, healthcare, etc. Fake news refers to news containing misleading or fabricated contents that are actually groundless; they are intentionally exaggerated or provide false information. As such, fake news can distort reality and cause social problems, such as self-misdiagnosis of medical issues. Many academic researchers have been collecting data from social and medical media, which are sources of various information flows, and conducting studies to analyse and detect fake news. However, in the case of conventional studies, the features used for analysis are limited, and the consideration for newly added features of social media is lacking. Therefore, this study proposes a fake news analysis modelling method by identifying a variety of features and collecting various data from Twitter, a social media outlet with a good deal of power in terms of spreading information. The method proposed in this study can increase the accuracy of fake news analysis by acquiring more potential information from the Quote Retweet feature added to Twitter in 2015, compared to the more conventional and common Retweet only. Furthermore, fake news was analysed through neural network-based classification modelling by using the preprocessed data and the identified best features in the learning data. In the performance results, using the neural network-based classifier, the classification model that also used Quote Retweet, showed an improvement in performance over the conventional methods, and it was confirmed that the identified best features had a significant impact on increasing the classification accuracy of fake news.","1196":"The COVID-19 pandemic has not only had severe political, economic, and societal effects, it has also affected media and communication systems in unprecedented ways. While traditional journalistic media has tried to adapt to the rapidly evolving situation, alternative news media on the Internet have given the events their own ideological spin. Such voices have been criticized for furthering societal confusion and spreading potentially dangerous \"fake news\" or conspiracy theories via social media and other online channels. The current study analyzes the factual basis of such fears in an initial computational content analysis of alternative news media's output on Facebook during the early Corona crisis, based on a large German data set from January to the second half of March 2020. Using computational content analysis, methods, reach, interactions, actors, and topics of the messages were examined, as well as the use of fabricated news and conspiracy theories. The analysis revealed that the alternative news media stay true to message patterns and ideological foundations identified in prior research. While they do not spread obvious lies, they are predominantly sharing overly critical, even anti-systemic messages, opposing the view of the mainstream news media and the political establishment. With this pandemic populism, they contribute to a contradictory, menacing, and distrusting worldview, as portrayed in detail in this analysis.","1197":null,"1198":"Consuming news from social media is becoming increasingly popular. However, social media also enables the widespread of fake news. Because of its detrimental effects brought by social media, fake news detection has attracted increasing attention. However, the performance of detecting fake news only from news content is generally limited as fake news pieces are written to mimic true news. In the real world, news pieces spread through propagation networks on social media. The news propagation networks usually involve multi-levels. In this paper, we study the challenging problem of investigating and exploiting news hierarchical propagation network on social media for fake news detection. \nIn an attempt to understand the correlations between news propagation networks and fake news, first, we build a hierarchical propagation network from macro-level and micro-level of fake news and true news; second, we perform a comparative analysis of the propagation network features of linguistic, structural and temporal perspectives between fake and real news, which demonstrates the potential of utilizing these features to detect fake news; third, we show the effectiveness of these propagation network features for fake news detection. We further validate the effectiveness of these features from feature important analysis. Altogether, this work presents a data-driven view of hierarchical propagation network and fake news and paves the way towards a healthier online news ecosystem.","1199":null,"1200":"In this article, we uncover a network of Twitterbots comprising 13,493 accounts that tweeted the United Kingdom European Union membership referendum, only to disappear from Twitter shortly after the ballot. We compare active users to this set of political bots with respect to temporal tweeting behavior, the size and speed of retweet cascades, and the composition of their retweet cascades (user-to-bot vs. bot-to-bot) to evidence strategies for bot deployment. Our results move forward the analysis of political bots by showing that Twitterbots can be effective at rapidly generating small- to medium-sized cascades; that the retweeted content comprises user-generated hyperpartisan news, which is not strictly fake news, but whose shelf life is remarkably short; and, finally, that a botnet may be organized in specialized tiers or clusters dedicated to replicating either active users or content generated by other bots.","1201":"Consuming news from social media is becoming increasingly popular. Social media appeals to users due to its fast dissemination of information, low cost, and easy access. However, social media also enables the widespread of fake news. Due to the detrimental societal effects of fake news, detecting fake news has attracted increasing attention. However, the detection performance only using news contents is generally not satisfactory as fake news is written to mimic true news. Thus, there is a need for an in-depth understanding on the relationship between user profiles on social media and fake news. In this paper, we study the problem of understanding and exploiting user profiles on social media for fake news detection. In an attempt to understand connections between user profiles and fake news, first, we measure users' sharing behaviors and group representative users who are more likely to share fake and real news; then, we perform a comparative analysis of explicit and implicit profile features between these user groups, which reveals their potential to help differentiate fake news from real news. To exploit user profile features, we demonstrate the usefulness of these user profile features in a fake news classification task. We further validate the effectiveness of these features through feature importance analysis. The findings of this work lay the foundation for deeper exploration of user profile features of social media and enhance the capabilities for fake news detection.","1202":"In this demo paper, we present the XFake system, an explainable fake news detector that assists end-users to identify news credibility. To effectively detect and interpret the fakeness of news items, we jointly consider both attributes (e.g., speaker) and statements. Specifically, MIMIC, ATTN and PERT frameworks are designed, where MIMIC is built for attribute analysis, ATTN is for statement semantic analysis and PERT is for statement linguistic analysis. Beyond the explanations extracted from the designed frameworks, relevant supporting examples as well as visualization are further provided to facilitate the interpretation. Our implemented system is demonstrated on a real-world dataset crawled from PolitiFact1, where thousands of verified political news have been collected.","1203":"News plays a significant role in shaping people's beliefs and opinions. Fake news has always been a problem, which wasn't exposed to the mass public until the past election cycle for the 45th President of the United States. While quite a few detection methods have been proposed to combat fake news since 2015, they focus mainly on linguistic aspects of an article without any fact checking. In this paper, we argue that these models have the potential to misclassify fact-tampering fake news as well as under-written real news. Through experiments on Fakebox, a state-of-the-art fake news detector, we show that fact tampering attacks can be effective. To address these weaknesses, we argue that fact checking should be adopted in conjunction with linguistic characteristics analysis, so as to truly separate fake news from real news. A crowdsourced knowledge graph is proposed as a straw man solution to collecting timely facts about news events.","1204":"Deep learning--based models have surpassed classical machine learning--based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this article, we provide a comprehensive review of more than 150 deep learning--based models for text classification developed in recent years, and we discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and we discuss future research directions.","1205":"\nPurpose\nThe purpose of this paper is to provide an overview of NodeXL in the context of news diffusion. Journalists often include a social media dimension in their stories but lack the tools to get digital photos of the virtual crowds about which they write. NodeXL is an easy to use tool for collecting, analysing, visualising and reporting on the patterns found in collections of connections in streams of social media. With a network map patterns emerge that highlight key people, groups, divisions and bridges, themes and related resources.\n\n\nDesign\/methodology\/approach\nThis study conducts a literature review of previous empirical work which has utilised NodeXL and highlights the potential of NodeXL to provide network insights of virtual crowds during emerging news events. It then develops a number of guidelines which can be utilised by news media teams to measure and map information diffusion during emerging news events.\n\n\nFindings\nOne emergent software application known as NodeXL has allowed journalists to take \u201cgroup photos\u201d of the connections among a group of users on social media. It was found that a diverse range of disciplines utilise NodeXL in academic research. Furthermore, based on the features of NodeXL, a number of guidelines were developed which provide insight into how to measure and map emerging news events on Twitter.\n\n\nSocial implications\nWith a set of social media network images a journalist can cover a set of social media content streams and quickly grasp \u201csituational awareness\u201d of the shape of the crowd. Since social media popular support is often cited but not documented, NodeXL social media network maps can help journalists quickly document the social landscape utilising an innovative approach.\n\n\nOriginality\/value\nThis is the first empirical study to review literature on NodeXL, and to provide insight into the value of network visualisations and analytics for the news media domain. Moreover, it is the first empirical study to develop guidelines that will act as a valuable resource for newsrooms looking to acquire insight into emerging news events from the stream of social media posts. In the era of fake news and automated accounts, i.e., bots the ability to highlight opinion leaders and ascertain their allegiances will be of importance in today\u2019s news climate.\n","1206":null,"1207":"In the recent years, online social networks have become an important source of news and the primary place for political debates for a growing part of the population. At the same time, the spread of fake news and digital wildfires (fast-spreading and harmful misinformation) has become a growing concern worldwide, and in online social networks the problem is most prevalent. Thus, the study of social networks is an essential component in the understanding of the fake news phenomenon. Of particular interest is the network connectivity between participants, since it makes communication patterns visible. These patterns are hidden in the offline world, but they have a profound impact on the spread of ideas, opinions and news. Among the major social networks, Twitter is of special interest. Because of its public nature, Twitter offers the possibility to perform research without the risk of breaching the expectation of privacy. However, obtaining sufficient amounts of data from Twitter is a fundamental challenge for many researchers. Thus, in this paper, we present a scalable framework for gathering the graph structure of follower networks, posts and profiles. We also show how to use the collected data for high-performance social network analysis.","1208":"Society and individuals are negatively influenced both politically and socially by the widespread increase of fake news either way generated by humans or machines. In the era of social networks, the quick rotation of news makes it challenging to evaluate its reliability promptly. Therefore, automated fake news detection tools have become a crucial requirement. To address the aforementioned issue, a hybrid Neural Network architecture, that combines the capabilities of CNN and LSTM, is used with two different dimensionality reduction approaches, Principle Component Analysis (PCA) and Chi-Square. This work proposed to employ the dimensionality reduction techniques to reduce the dimensionality of the feature vectors before passing them to the classifier. To develop the reasoning, this work acquired a dataset from the Fake News Challenges (FNC) website which has four types of stances: agree, disagree, discuss, and unrelated. The nonlinear features are fed to PCA and chi-square which provides more contextual features for fake news detection. The motivation of this research is to determine the relative stance of a news article towards its headline. The proposed model improves results by ~4% and ~20% in terms of $Accuracy$ and $F1-score$ . The experimental results show that PCA outperforms than Chi-square and state-of-the-art methods with 97.8% accuracy.","1209":"The spread of content produced by fake news publishers was one of the most discussed characteristics of the 2016 U.S. Presidential Election. Yet, little is known about the prevalence and focus of such content, how its prevalence changed over time, and how this prevalence related to important election dynamics. In this paper, we address these questions using tweets that mention the two presidential candidates sampled at the daily level, the news content mentioned in such tweets, and open-ended responses from nationally representative telephone interviews. The results of our analysis highlight various important lessons for news consumers and journalists. We find that (i.) traditional news producers outperformed fake news producers in aggregate, (ii.) the prevalence of content produced by fake news publishers increased over the course of the campaign-particularly among tweets that mentioned Clinton, and (iii.) changes in such prevalence were closely following changes in net Clinton favorability. Turning to content, we (iv.) identify similarities and differences in agenda setting by fake and traditional news media and show that (v.) information individuals most commonly reported to having read, seen or heard about the candidates was more closely aligned with content produced by fake news outlets than traditional news outlets, in particular for information Republican voters retained about Clinton. We also model fake-ness of retained information as a function of demographics characteristics. Implications for platform owners, news consumers, and journalists are discussed.","1210":"\n Simulation is an established tool to develop and validate camera systems. The goal of autonomous driving is pushing simulation into a more important and fundamental role for safety, validation and coverage of billions of miles. Realistic camera models are moving more and more into\n focus, as simulations need to be more then photo-realistic, they need to be physical-realistic, representing the actual camera system onboard the self-driving vehicle in all relevant physical aspects \u2013 and this is not only true for cameras, but also for radar and lidar. But when the\n camera simulations are becoming more and more realistic, how is this realism tested? Actual, physical camera samples are tested in laboratories following norms like ISO12233, EMVA1288 or the developing P2020, with test charts like dead leaves, slanted edge or OECF-charts. In this article we\n propose to validate the realism of camera simulations by simulating the physical test bench setup, and then comparing the synthetical simulation result with physical results from the real-world test bench using the established normative metrics and KPIs. While this procedure is used sporadically\n in industrial settings we are not aware of a rigorous presentation of these ideas in the context of realistic camera models for autonomous driving. After the description of the process we give concrete examples for several different measurement setups using MTF and SFR, and show how these\n can be used to characterize the quality of different camera models.\n","1211":null,"1212":null,"1213":null,"1214":"High spatiotemporal resolution atmospheric water vapor can be retrieved using the Global Navigation Satellite System (GNSS) tomography technique, in which the remained ill-posed problem of the tomography system resulting from the acquisition geometry is a vital issue to be addressed. Remote sensing (RS) water vapor data, with high-resolution and global coverage, show great potential for retrieval of slant water vapor (SWV) observations to improve the tomographic geometrical distribution. In this article, we develop a GNSS-RS (GNSS combining RS) tomography model to fully exploit the value of observation signals from GNSS and RS measurements. The two key factors of retrieving the RS SWV are performed by calibrating the original precipitable water vapor (PWV) images and adding the tropospheric horizontal gradients. The results reveal that when introducing the RS SWV observations into the tomography model, the acquisition geometry is significantly improved, with the average rate of voxels crossed by rays from 62% to 95% and the mean number of observation signals from 395 to 508 during the tomographic periods. Independent radiosonde data are used to validate the tomographic water vapor fields. The mean root-mean-square error (RMSE) and bias of the water vapor profiles derived from GNSS-RS solutions are decreased by 28% and 45% with respect to the GNSS-only results, respectively. Such improvements highlight that GNSS-RS troposphere tomography has significant potential to improve the reconstruction of the atmospheric water vapor fields.","1215":"Snow avalanches cause a sudden change of snow properties making them detectable with synthetic aperture radar (SAR). However, steep alpine terrain combined with the slant view geometry of SAR sensors complicates detection: the avalanche brightness depends on the incidence angle and the observed area is limited by radar layover and shadow. Likewise, the spatial resolution varies strongly with the local incidence angle relative to the terrain. To increase the avalanche brightness and to improve the imaging coverage and resolution we apply local resolution weighting (LRW) on Sentinel-1 (S1) backscatter images from ascending and descending orbits. LRW merges acquisitions by averaging them, weighted with the local ground-range resolution. To analyze the relative avalanche brightness with respect to the local incidence angle and polarization, and to quantify the benefit of LRW, we created a dataset of 914 manually drawn avalanche outlines based on S1 imagery of an extreme avalanche event on January 4, 2018 in the Swiss Alps. We show that avalanches appear brightest at slopes facing away from the radar at local incidence angles of $55\\pm 20^\\circ$; such slopes are weighted considerably stronger through LRW. With a processing pipeline for avalanche segmentation using a fixed threshold on the backscatter difference we obtain a higher F1 score (0.75) with LRW compared to an unweighted orbit average (F1 = 0.68) or single orbit acquisitions (F1 = 0.5). For automatic segmentation, we used the manually drawn dataset for training and testing of a deep neural U-Net and achieved a F1 score of 0.81 on LRW backscatter differences.","1216":"This paper presents a conformal ultra-high-frequency (UHF) radio frequency identification (RFID) reader antenna array for doorway portal applications. The dual-patch antenna is only 100 mm wide and right-angled (V-shaped) to fit the corners of a regular portal. Patches are arranged orthogonally to create horizontal and vertical-linearly polarized fields at near-zones and at far-field distances they provide slant-polarized fields. Beam steering is enabled by phase delaying the array elements to enhance the field coverage within the doorway portal. The antenna operates in the European UHF RFID band (865-868 MHz) with a 38 MHz, 10 dB impedance bandwidth. The antenna\u2019s azimuth and elevation half-power beamwidth is 90\u00b0 and 130\u00b0. The azimuth beam is tilted to 35\u00b0 from the boresight where the gain is peaked at 5.5 dBi. This antenna is low-profile, low-cost and flame retardant and paintable. Inherited properties of the antenna\u2019s substrate make the antenna non-toxic, self-extinguishing, lightweight and highly chemical resistant. The reader antenna is compatible with both RAIN and non-RAIN alliance UHF RFID readers.","1217":"In this paper, the authors have attempted to provide a comprehensive account of the Indian Regional Navigation Satellite System (IRNSS). The paper describes the coverage area, the space segment, ground segment, and user segment of IRNSS. The orbital parameters of all seven satellites in the IRNSS constellation have been reported. Some important definitions related to space crafts have been explained. The paper presents the method to estimate the receiver\u2019s position and the algorithm involved. The paper also discusses various sources of error in position estimation. The paper gives a detailed description of the trajectories of all seven satellites in the constellation. The paper presents the Slant Tropospheric Delay (STD) obtained over the National Atmospheric Research Laboratory, Gadanki; National Institute of Oceanography, Goa; Regional Meteorological Centre, Kolkata; Indian Institute of Technology, Bhubaneswar; and Sona Synthetics, Kanakapura, Bangalore.","1218":"We compare tropospheric delays from Global Navigation Satellite Systems (GNSS) and Synthetic Aperture Radar (SAR) Interferometry (InSAR) in a challenging mountainous environment in the Swiss Alps, where strong spatial variations of the local tropospheric conditions are often observed. Tropospheric delays are usually considered to be an error for both GNSS and InSAR, and are typically removed. However, recently these delays are also recognized as a signal of interest, for example for assimilation into numerical weather models or climate studies. The GNSS and InSAR are techniques of complementary nature, as one has sparse spatial but high temporal resolution, and the other very dense spatial coverage but repeat pass of only a few days. This raises expectations for a combination of these techniques. For this purpose, a comprehensive comparison between the techniques must be first performed. Due to the relative nature of InSAR estimates, we compare the difference slant tropospheric delays ( d S T D ) retrieved from GNSS with the d S T D s estimated using Persistent Scatterer Interferometry (PSI) of 32 COSMO-SkyMed SAR images taken in a snow-free period from June to October between 2008 and 2013. The GNSS estimates calculated at permanent geodetic stations are interpolated to the locations of persistent scatterers using an in-house developed least-squares collocation software COMEDIE. The Pearson\u2019s correlation coefficient between InSAR and GNSS estimates averaged over all acquisitions is equal to 0.64 and larger than 0.8 for approximately half of the layers. Better agreement is obtained mainly for days with high variability of the troposphere (relative to the tropospheric conditions at the time of the reference acquisition), expressed as standard deviations of the GNSS-based d S T D s. On the other hand, the most common feature for the days with poor agreement is represented by very stable, almost constant GNSS estimates. In addition, there is a weak correlation between the agreement and the water vapor values in the area, as well as with the number of stations in the closest vicinity of the study area. Adding low-cost L-1 only GPS stations located within the area of the study increases the biases for most of the dates, but the standard deviations between InSAR and GNSS decrease for the limited area with low-cost stations.","1219":"Geosynchronous synthetic aperture radar (GEO SAR) has the characteristics of wide coverage and short revisit time, which makes GEO SAR moving target indication more valuable than other platforms. This article analyses the influence of moving target on \u2018Stop-and-Go\u2019 error in GEO SAR, and then the accurate slant range model of moving target is constructed. The signal-to-noise ratio of the raw data echoes for moving ship target is very low because of the high satellite orbit altitude, so it cannot be detected by constant false alarm detection. Based on the accurate slant range model of moving target in GEO SAR, three kinds of integration methods are reconstructed, including moving target detection, Radon transform and generalised Radon Fourier transform (GRFT). The performance of these methods is compared through numerical simulation. GRFT can provide the best detection performance in a reasonable integration time.","1220":"The ever-growing exploitation of various telecommunication services and radar applications resulted in saturation of low frequency bands supporting them and therefore being unable to handle new incoming traffic demands for services such as broad coverage network connection and supper high and extreme speed data transmission. Hence, a call for utilization of higher bands radio waves spectrums become imperative to address spectrum congestion and telecommunication service demands by the users. There are two platforms of communication at these upper frequencies, terrestrial and satellite. Although, rain attenuation affects the two platforms, the focus of this paper is on the satellite communication. Rain-induced attenuation is a main challenge of signal propagation in satellite communication networks operating in upper frequency bands and its impact becomes pronounced at frequency above 10 GHz. Therefore, accurate rain fading estimation for links path is of outmost importance in building reliable networks. This paper presents the adoption of Artificial Neural Networks (ANNs) as a technique in estimating rain-induced attenuation along the satellite links at the higher frequency in South Africa. The proposed ANNs model indicated improvement in estimation performance in terms of root mean square error and correlation coefficient.","1221":"Geosynchronous synthetic aperture radar (GEO SAR) has great potentials in synthetic aperture radar ground moving target indication (SAR-GMTI) due to its high time resolution and wide swath coverage. But the signal-to-noise ratio (SNR) of echo is too low and multichannel configuration cannot be realize in GEO monostatic SAR. Therefore, geosynchronous spaceborne-airborne bistatic multichannel synthetic aperture radar (GEO-SABM SAR) can realize enhanced SNR and multichannel configuration. In this paper, we establish the slant range model for GEO-SABM SAR and give the VSAR processing flowchart. Finally, the numerical experiments is given to verify the effectiveness of proposed method.","1222":"The aim of this research paper was to tap the role of anchorpersons of talk shows in promotion of media agenda and shaping political reality through measuring correspondence between time consumed by the anchorpersons and panel of experts. For the purpose, systematic random sampling technique has been used to select prime time talk shows of Geo News for one year. On the basis of wide coverage, three issues memo gate, law and order and corruption were selected to gauge the relationship between the variables. The results show a significant correlation between slant for the issues and time consumed by the anchors has been observed on all the three issues. The results showed that more the time grabbed by anchorpersons, more the programs remained in unfavorable state towards government. The results also revealed that 71% of total talk shows\u2019 time was grabbed by the anchorpersons while panel of experts allotted 29% percent time in the issues. Anchorpersons remained unfavorable and biased in its deliberations towards government to a great extent by snatching the maximum time of the programs for molding the public opinion in a certain direction.","1223":"This study proposes a design of a low-profile ultra wide-band cylindrical antenna array with plus\/minus 45-degree dual polarization. The proposed compact cylindrical antenna array produces an omnidirectional radiation pattern in the azimuth plane to cover all directions. It consists of $20\\times 4$ dual-polarized elements within a diameter of 131 mm and a height of 116 mm. The array elements are tightly coupled slant-polarized wideband dipole antennas, and hence, rotational symmetry of radiation patterns in the horizontal plane is achieved for the two orthogonal polarizations. Furthermore, a metasurface structure has been designed and placed over the interconnected array elements to achieve ultrawideband capabilities. The proposed array provides less than \u221210 dB reflection coefficient over a frequency band between 1.7 GHz and 5.9 GHz. The cross-polarization discrimination (XPD) is 15 dB at boresight in the azimuth plane. The electromagnetic characteristics of the cylindrical array and its corresponding planar array before bending have been evaluated and compared via simulations, and verified by measurements. The compact size, lightweight, and printable design of the proposed antenna array enable low-cost manufacturing and ease of installation. The proposed array design overcomes many challenges encountered in wide-band MIMO systems by covering the entire sub-6 GHz band while providing wide 360-degree coverage in the azimuth plane, hence, supporting multibeam applications.","1224":"GPS tomography has been investigated since 2000 as an attractive tool for retrieving the 3D field of water vapour and wet refractivity. However, this observational technique still remains a challenging task that requires improvement of its methodology. This was the purpose of this study, and for this, GPS data from the Australian Continuously Operating Research Station (CORS) network during a severe weather event were used. Sensitivity tests and statistical cross-comparisons of tomography retrievals with independent observations from radiosonde and radio-occultation profiles showed improved results using the presented methodology. The initial conditions, which were associated with different time-convergence of tomography inversion, play a critical role in GPS tomography. The best strategy can reduce the normalised root mean square (RMS) of the tomography solution by more than 3 with respect to radiosonde estimates. Data stacking and pseudo-slant observations can also significantly improve tomography retrievals with respect to non-stacked solutions. A normalised RMS improvement up to 17% in the 0\u20138 km layer was found by using 30 min data stacking, and RMS values were divided by 5 for all the layers by using pseudo-observations. This result was due to a better geometrical distribution of mid- and low-tropospheric parts (a 30% coverage improvement). Our study of the impact of the uncertainty of GPS observations shows that there is an interest in evaluating tomography retrievals in comparison to independent external measurements and in estimating simultaneously the quality of weather forecasts. Finally, a comparison of multi-model tomography with numerical weather prediction shows the relevant use of tomography retrievals to improving the understanding of such severe weather conditions.","1225":"The coverage problem in wireless sensor networks (WSNs) can be generally defined as a measure of how effectively a network field is monitored by its sensor nodes. This problem has attracted a lot of interest over the years and as a result, many coverage protocols were proposed. In this survey, we first propose a taxonomy for classifying coverage protocols in WSNs. Then, we classify the coverage protocols into three categories (i.e., coverage-aware deployment protocols, sleep scheduling protocols for flat networks, and cluster-based sleep scheduling protocols) based on the network stage where the coverage is optimized. For each category, relevant protocols are thoroughly reviewed and classified based on the adopted coverage techniques. Finally, we discuss open issues (and recommend future directions to resolve them) associated with the design of realistic coverage protocols. Issues such as realistic sensing models, realistic energy consumption models, realistic connectivity models and sensor localization are covered.","1226":"Most research on emotion analysis from text focuses on the task of emotion classification or emotion intensity regression. Fewer works address emotions as a phenomenon to be tackled with structured learning, which can be explained by the lack of relevant datasets. We fill this gap by releasing a dataset of 5000 English news headlines annotated via crowdsourcing with their associated emotions, the corresponding emotion experiencers and textual cues, related emotion causes and targets, as well as the reader\u2019s perception of the emotion of the headline. This annotation task is comparably challenging, given the large number of classes and roles to be identified. We therefore propose a multiphase annotation procedure in which we first find relevant instances with emotional content and then annotate the more fine-grained aspects. Finally, we develop a baseline for the task of automatic prediction of semantic role structures and discuss the results. The corpus we release enables further research on emotion classification, emotion intensity prediction, emotion cause detection, and supports further qualitative studies.","1227":"Fake news has become an important topic in our social and political environment. While research is coming up for the U.S. and European countries, many aspects remain uncovered as long as existing work only marginally investigates people\u2019s attitudes towards fake news. In this work, we present the results of a representative study (N=1023) in Germany asking participants about their attitudes towards fake news and approaches to counteract disinformation. More than 80% of the participants agree that fake news poses a threat. 78% see fake news as harming democracy. Even though about half of the respondents (48%) have noticed fake news, most participants stated to have never liked, shared or commented on fake news. Regarding demographic factors, our findings support the view of younger and relatively educated people being more informed about fake news. Concerning ideological motives, the evaluation suggests left-wing or liberal respondents to be more critical of fake news.","1228":"This case study describes a game designed to serve as new literacy education tool, playful polling system for research audience perceptions. The game underwent two primary designer iterations. As a result of design changes and renewed political chatter about fake news, the game's second iteration gathered more than 500,000 plays. The data collected reveals useful patterns in understanding news literacy and the perception of play experiences. This data of more than 45,000 players, indicates that the older the person the better they are at identifying fake news, until the approximate age of 70. It also indicates that higher education correlates to better performance at identifying real news from fake, although the time it takes to do so varies. This case study demonstrates the potential for such game designs to collect data useful to non-game contexts.","1229":null,"1230":"Hoax is information that generally does not exist or not true and dangerous because it can mislead people perception and give an assumption to the news that not truly happen become a truth. In 2016, the election for US president has been held, due to this event, there are several fake news spread through social media. This incident has to take responsibility for the huge effect on the election result. Therefore, a method for detecting hoax should be developed to prevent the impact of the hoax. The purpose of this research is evaluating several machine learning methods for detecting fake news. The dataset that uses in this research is hoax news collected from Department Communication and Information of Central Java Province (November 20018 and December 2018) and www.turnbackhoax.id (December 2018 until March 2019). The number of documents used for this research is 150 documents consist of 75 documents with true category and 75 documents hoax category. Feature extraction used in this research is TF-IDF algorithm. This research evaluates the performance of several machine learning methods such as MNB, k-NN, Logistic classification, and LSVM in classifying fake news. Base on the test result using 10-fold validation, Logistic classification have the best accuracy with 84.67%.","1231":"ABSTRACT The World Health Organisation has emphasised that misinformation \u2013 spreading rapidly through social media \u2013 poses a serious threat to the COVID-19 response. Drawing from theories of health perception and cognitive load, we develop and test a research model hypothesising why people share unverified COVID-19 information through social media. Our findings suggest a person\u2019s trust in online information and perceived information overload are strong predictors of unverified information sharing. Furthermore, these factors, along with a person\u2019s perceived COVID-19 severity and vulnerability influence cyberchondria. Females were significantly more likely to suffer from cyberchondria, with males more likely to share news without verifying its reliability. Our findings suggest that to mitigate the spread of COVID-19 misinformation and cyberchondria, measures should be taken to enhance a healthy scepticism of health news while simultaneously guarding against information overload.","1232":"The World Health Organization have emphasised that misinformation - spreading rapidly through social media - poses a serious threat to the COVID-19 response. Drawing from theories of health perception and cognitive load, we develop and test a research model hypothesizing why people share unverified COVID-19 information through social media. Our findings suggest a person's trust in online information and perceived information overload are strong predictors of unverified information sharing. Furthermore, these factors, along with a person's perceived COVID-19 severity and vulnerability influence cyberchondria. Females were significantly more likely to suffer from cyberchondria, however, males were more likely to share news without fact checking their source. Our findings suggest that to mitigate the spread of COVID-19 misinformation and cyberchondria, measures should be taken to enhance a healthy skepticism of health news while simultaneously guarding against information overload.","1233":"This research investigates how digital news headlines influence contemporary news information seeking. In two studies (a lab experiment and a field test), we examine how the presentation of news information\u2014traditional, summary news headlines or clickbait, curiosity news headlines\u2014influences the attitudinal and behavioral components of news seeking. Study 1 models the news-seeking process, finding that summary headlines heighten perceptions of headline information adequacy, which increase expectations that an article will provide clear information, which in turn increase anticipated audience engagement with news compared to some curiosity headlines. Study 2 determines that individuals\u2019 selection behavior on nine local newspaper websites also favors summary headlines. The findings encourage researchers to employ information-seeking mechanisms in understanding news selection decisions.","1234":"With the rapid development of the internet, social media has become an essential tool for getting information, and attracted a large number of people join the social media platforms because of its low cost, accessibility and amazing content. It greatly enriches our life. However, its rapid development and widespread also have provided an excellent convenience for the range of fake news, people are constantly exposed to fake news and suffer from it all the time. Fake news usually uses hyperbole to catch people\u2019s eyes with dishonest intention. More importantly, it often misleads the reader and causes people to have wrong perceptions of society. It has the potential for negative impacts on society and individuals. Therefore, it is significative research on detecting fake news. In the paper, we built a model named SMHA-CNN (Self Multi-Head Attention-based Convolutional Neural Networks) that can judge the authenticity of news with high accuracy based only on content by using convolutional neural networks and self multi-head attention mechanism. In order to prove its validity, we conducted experiments on a public dataset and achieved a precision rate of 95.5% with a recall rate of 95.6% under the 5-fold cross-validation. Our experimental result indicates that the model is more effective at detecting fake news.","1235":"Humanoid robots, unmanned rovers, entertainment pets, drones, and so on are great examples of mobile robots. They can be distinguished from other robots by their ability to move autonomously, with enough intelligence to react and make decisions based on the perception they receive from the environment. Mobile robots must have some source of input data, some way of decoding that input, and a way of taking actions (including its own motion) to respond to a changing world. The need to sense and adapt to an unknown environment requires a powerful cognition system. Nowadays, there are mobile robots that can walk, run, jump, and so on like their biological counterparts. Several fields of robotics have arisen, such as wheeled mobile robots, legged robots, flying robots, robot vision, artificial intelligence, and so on, which involve different technological areas such as mechanics, electronics, and computer science. In this article, the world of mobile robots is explored including the new trends. These new trends are led by artificial intelligence, autonomous driving, network communication, cooperative work, nanorobotics, friendly human\u2013robot interfaces, safe human\u2013robot interaction, and emotion expression and perception. Furthermore, these news trends are applied to different fields such as medicine, health care, sports, ergonomics, industry, distribution of goods, and service robotics. These tendencies will keep going their evolution in the coming years.","1236":"Publics' perceptions of new scientific advances such as AI are often informed and influenced by news coverage. To understand how artificial intelligence (AI) was framed in U.S. newspapers, a content analysis based on framing theory in journalism and science communication was conducted. This study identified the dominant topics and frames, as well as the risks and benefits of AI covered in five major American newspapers from 2009 to 2018. Results indicated that business and technology were the primary topics in news coverage of AI. The benefits of AI were discussed more frequently than its risks, but risks of AI were generally discussed with greater specificity. Additionally, episodic issue framing and societal impact framing were more frequently used.","1237":"With the ever increase in social media usage, it has become necessary to combat the spread of false information and decrease the reliance of information retrieval from such sources. Social platforms are under constant pressure to come up with efficient methods to solve this problem because users' interaction with fake and unreliable news leads to its spread at an individual level. This spreading of misinformation adversely affects the perception about an important activity, and as such, it needs to be dealt with using a modern approach. In this paper, we collect 1356 news instances from various users via Twitter and media sources such as PolitiFact and create several datasets for the real and the fake news stories. Our study compares multiple state\u2010of\u2010the\u2010art approaches such as convolutional neural networks (CNNs), long short\u2010term memories (LSTMs), ensemble methods, and attention mechanisms. We conclude that CNN + bidirectional LSTM ensembled network with attention mechanism achieved the highest accuracy of 88.78%, whereas Ko et al tackled the fake news identification problem and achieved a detection rate of 85%.","1238":"The social media environment in China has become the dominant source of information and news over the past decade. This news environment has naturally suffered from challenges related to mis- and dis-information, encumbered by an increasingly complex landscape of factors and players including social media services, fact-checkers, censorship policies, and astroturfing. Interviews with 44 Chinese WeChat users were conducted to understand how individuals perceive misinformation and how it impacts their news consumption practices. Overall, this work exposes the diverse attitudes and coping strategies that Chinese users employ in complex social media environments. Due to the complex nature of censorship in China and participants' lack of understanding of censor-ship, they expressed varied opinions about its influence on the credibility of online information sources. Further, although most participants claimed that their opinions would not be easily swayed by astroturfers, many admitted that they could not effectively distinguish astroturfers from ordinary Internet users. Participants' inability to make sense of comments found online lead many participants to hold pro-censorship attitudes: the Government's Dividend.","1239":"With a rapid increase in the use of digital technologies, people in the Global South including Bangladesh are exposed to a wide-range of smartphone applications (termed as apps in this paper), which offer a variety of features and services. However, privacy leakage through apps has increasingly become a major concern in Bangladesh, where the app collecting users' sensitive information without their consent was reported in news media for privacy violation. Our study with 32 participants from varying age, literacy level, and profession in Dhaka, Bangladesh unveils the perceptions of people around data collection and sharing by the app reported in privacy leakage news. All of our participants were aware of information leakage through the app they use, where they possess varying perceptions around providing personal information, like a sense of benefit, necessity and contribution, indifference, fear, or (no) authority over data collection. Our analysis reveals the relation between users' privacy perceptions, local infrastructure, and social practices in Bangladesh, where we identify the situated challenges that interfere with people's understanding of privacy notice. Our results lead to a discussion on how people's privacy perceptions are influenced by rapid urbanization and the opportunities offered by digitization in Bangladesh. Based on our findings, we provide recommendations to develop situated and sustainable strategies to enhance privacy awareness and practices in the social setting of Bangladesh, and Global South.","1240":"The use of chatbots in news media platforms, although relatively recent, offers many advantages to journalists and media professionals and, at the same time, facilitates users\u2019 interaction with useful and timely information. This study shows the usability of a news chatbot during a crisis situation, employing the 2020 COVID-19 pandemic as a case study. The basic targets of the research are to design and implement a chatbot in a news media platform with a two-fold aim in regard to evaluation: first, the technical effort of creating a functional and robust news chatbot in a crisis situation both from the AI perspective and interoperability with other platforms, which constitutes the novelty of the approach; and second, users\u2019 perception regarding the appropriation of this news chatbot as an alternative means of accessing existing information during a crisis situation. The chatbot designed was evaluated in terms of effectively fulfilling the social responsibility function of crisis reporting, to deliver timely and accurate information on the COVID-19 pandemic to a wide audience. In this light, this study shows the advantages of implementing chatbots in news platforms during a crisis situation, when the audience\u2019s needs for timely and accurate information rapidly increase.","1241":"This study investigates undergraduates\u2019 news consumption and their perceptions of fake news in science while they took an online introductory geography course at a large Midwestern university. The authors collaborated with university science instructors to design and integrate a news literacy curriculum into a set of learning activities to promote critical thinking and research skills. A qualitative analysis of 108 students\u2019 written essays presents empirical evidence of their perceptions of fake news in terms of content (what), purpose (why), and source (who). The results show that students primarily sought news from traditional sources, such as CNN, the British Broadcasting Corporation (BBC), and the New York Times, while working on their research assignments. They spent, on average, about 7 hours per week reading, watching, or listening to news while taking the online course. More than half the students indicated that they used mobile devices to browse news most of the time. The strategies and tools the students used to manage multiple news sources are discussed.","1242":null,"1243":null,"1244":"Despite a fast-growing body of literature on fake news and mis-\/disinformation, there remains surprisingly little empirical work on the social\/political consequences of exposure to false information. Addressing this issue, this study provides initial evidence that perceptions of false information exposure catalyze political cynicism. The findings from a two-wave panel survey during the 2018 US midterm elections reveal that perceptions of false information exposure 2 weeks before the election significantly predict the changes in political cynicism immediately after the election day. We also find that social media news use in Wave 1 significantly relates to political cynicism in Wave 2 indirectly through perceptions of mis-\/disinformation exposure. The autoregressive regression model indicates that our findings are robust after controlling for prior levels of cynicism.","1245":"Although algorithms have been widely used to deliver useful services, how users actually experience algorithm-driven news remains unclear. This study examines user attitude and perception of algorithmic journalism and identifies the similarities and differences in experience and satisfaction formation. A comparative study between the United States (U.S.) and South Korea was conducted to examine how the two countries' users experience the quality of algorithm-driven news services and how individuals perceive the topics of fairness, accountability, and transparency. The notable similarities and differences are found by performing a comparison of cognitive processes. The major attitudes toward algorithm news are similar between the two countries, although the weights placed on the qualities differ. South Korean users put more weight on performance qualities, and U.S. users place relatively greater emphasis on procedural features. Different patterns of algorithm news experience imply the contextual nature of algorithm: how users perceive and feel about topics in algorithm news and how they use and engage with algorithm news depend on the context where the experience is taking place. The analysis suggests the importance of user-perceived issues and the contextual nature of such issues.","1246":"Ever since Russian trolls have been brought to light, their interference in the 2016 US Presidential elections has been monitored and studied. These Russian trolls employ fake accounts registered on several major social media sites to influence public opinion in other countries. Our work involves discovering patterns in these tweets and classifying them by training different machine learning models such as Support Vector Machines, Word2vec, Google BERT, and neural network models, and then applying them to several large Twitter datasets to compare the effectiveness of the different models. Two classification tasks are utilized for this purpose. The first one is used to classify any given tweet as either troll or non-troll tweet. The second model classifies specific tweets as coming from left trolls or right trolls, based on apparent extreme political orientations. On the given data sets, Google BERT provides the best results, with an accuracy of 89.4% for the left\/right troll detector and 99% for the troll\/non-troll detector. Temporal, geographic, and sentiment analyses were also performed and results were visualized.","1247":"Content moderation, the AI-human hybrid process of removing (toxic) content from social media to promote community health, has attracted increasing attention from lawmakers due to allegations of political bias. Hitherto, this allegation has been made based on anecdotes rather than logical reasoning and empirical evidence, which motivates us to audit its validity. In this paper, we first introduce two formal criteria to measure bias (i.e., independence and separation) and their contextual meanings in content moderation, and then use YouTube as a lens to investigate if the political leaning of a video plays a role in the moderation decision for its associated comments. Our results show that when justifiable target variables (e.g., hate speech and extremeness) are controlled with propensity scoring, the likelihood of comment moderation is equal across left- and right-leaning videos.","1248":"In an A\/B test, the typical objective is to measure the total average treatment effect (TATE), which measures the difference between the average outcome if all users were treated and the average outcome if all users were untreated. However, a simple difference-in-means estimator will give a biased estimate of the TATE when outcomes of control units depend on the outcomes of treatment units, an issue we refer to as test-control interference. Using a simulation built on top of data from Airbnb, this paper considers the use of methods from the network interference literature for online marketplace experimentation. We model the marketplace as a network in which an edge exists between two sellers if their goods substitute for one another. We then simulate seller outcomes, specifically considering a \"status quo\" context and \"treatment\" context that forces all sellers to lower their prices. We use the same simulation framework to approximate TATE distributions produced by using blocked graph cluster randomization, exposure modeling, and the Hajek estimator for the difference in means. We find that while blocked graph cluster randomization reduces the bias of the naive difference-in-means estimator by as much as 62%, it also significantly increases the variance of the estimator. On the other hand, the use of more sophisticated estimators produces mixed results. While some provide (small) additional reductions in bias and small reductions in variance, others lead to increased bias and variance. Overall, our results suggest that experiment design and analysis techniques from the network experimentation literature are promising tools for reducing bias due to test-control interference in marketplace experiments.","1249":"Information about the ideological positions of different political actors is crucial in answering questions regarding political representation, polarization, and voting behavior. One way to obtain such information is to ask survey respondents to place actors on a common ideological scale, but, unfortunately, respondents typically display a set of biases when performing such placements. Key among these are rationalization bias and differential item functioning (DIF). While Aldrich\u2013McKelvey (AM) scaling offers a useful solution to DIF, it ignores the issue of rationalization bias, and this study presents Monte Carlo simulations demonstrating that AM-type models thus can give inaccurate results. As a response to this challenge, this study develops an alternative Bayesian scaling approach, which simultaneously estimates DIF and rationalization bias, and therefore performs better when the latter bias is present.","1250":"Social media platforms have been the subject of controversy and scrutiny due to the spread of hateful content. To address this problem, the platforms implement content moderation using a mix of human and algorithmic processes. However, content moderation itself has lead to further accusations against the platforms of political bias. In this study, we investigate how channel partisanship and video misinformation affect the likelihood of comment moderation on YouTube. Using a dataset of 84,068 comments on 258 videos, we find that although comments on right-leaning videos are more heavily moderated from a correlational perspective, we find no evidence to support claims of political bias when using a causal model that controls for common confounders (e.g., hate speech). Additionally, we find that comments are more likely to be moderated if the video channel is ideologically extreme, if the video content is false, and if the comments were posted after a fact-check.","1251":"This article offers a description and discussion of \u201cshadowing\u201d as a data collection and analytic tool, highlighting potential research opportunities related to the direct observation of individuals\u2014principally political elites\u2014in their normal daily routine for an extended period of time, often between one day and one week. In contrast with large-scale data collection methods, including surveys, shadowing enables researchers to develop detailed observations of political behavior that are not limited by the availability of administrative data or the constraints of a questionnaire or an interview guide. Unlike more in-depth qualitative methods, such as ethnography, shadowing is scalable in a manner that allows for larger sample sizes and the potential for medium-N inference. I provide a detailed account of how to design and conduct a shadowing study, including sampling strategies, techniques for coding shadowing data, and processes for drawing inferences about the behavior of shadowed subjects, drawing on examples from a completed shadowing-based study. I also discuss ways to mitigate selection and observer biases, presenting results that suggest these can be no more pronounced when shadowing political elites than in other forms of observational research.","1252":"Abstract A primary challenge for researchers that make use of observational data is selection bias (i.e. the units of analysis exhibit systematic differences and dis-homogeneities due to non-random selection into treatment). This article encourages researchers in acknowledging this problem and discusses how and \u2013 more importantly \u2013 under which assumptions they may resort to statistical matching techniques to reduce the imbalance in the empirical distribution of pre-treatment observable variables between the treatment and control groups. With the aim of providing a practical guidance, the article engages with the evaluation of the effectiveness of peacekeeping missions in the case of the Bosnian civil war, a research topic in which selection bias is a structural feature of the observational data researchers have to use, and shows how to apply the Coarsened Exact Matching (CEM), the most widely used matching algorithm in the fields of Political Science and International Relations.","1253":"One challenge that social media platforms are facing nowadays is hate speech. Hence, automatic hate speech detection has been increasingly researched in recent years - in particular with the rise of deep learning. A problem of these models is their vulnerability to undesirable bias in training data. We investigate the impact of political bias on hate speech classification by constructing three politically-biased data sets (left-wing, right-wing, politically neutral) and compare the performance of classifiers trained on them. We show that (1) political bias negatively impairs the performance of hate speech classifiers and (2) an explainable machine learning model can help to visualize such bias within the training data. The results show that political bias in training data has an impact on hate speech classification and can become a serious issue.","1254":"Declining telephone response rates have forced several transformations in survey methodology, including cell phone supplements, nonprobability sampling, and increased reliance on model-based inferences. At the same time, advances in statistical methods and vast amounts of new data sources suggest that new methods can combat some of these problems. We focus on one type of data source\u2014voter registration databases\u2014and show how they can improve inferences from political surveys. These databases allow survey methodologists to leverage political variables, such as party registration and past voting behavior, at a large scale and free of overreporting bias or endogeneity between survey responses. We develop a general process to take advantage of this data, which is illustrated through an example where we use multilevel regression and poststratification to produce vote choice estimates for the 2012 presidential election, projecting those estimates to 195 million registered voters in a postelection context. Our inferences are stable and reasonable down to demographic subgroups within small geographies and even down to the county or congressional district level. They can be used to supplement exit polls, which have become increasingly problematic and are not available in all geographies. We discuss problems, limitations, and open areas of research.","1255":"Abstract When working with grouped data, investigators may choose between \u201cfixed effects\u201d models (FE) with specialized (e.g., cluster-robust) standard errors, or \u201cmultilevel models\u201d (MLMs) employing \u201crandom effects.\u201d We review the claims given in published works regarding this choice, then clarify how these approaches work and compare by showing that: (i) random effects employed in MLMs are simply \u201cregularized\u201d fixed effects; (ii) unmodified MLMs are consequently susceptible to bias\u2014but there is a longstanding remedy; and (iii) the \u201cdefault\u201d MLM standard errors rely on narrow assumptions that can lead to undercoverage in many settings. Our review of over 100 papers using MLM in political science, education, and sociology show that these \u201cknown\u201d concerns have been widely ignored in practice. We describe how to debias MLM\u2019s coefficient estimates, and provide an option to more flexibly estimate their standard errors. Most illuminating, once MLMs are adjusted in these two ways the point estimate and standard error for the target coefficient are exactly equal to those of the analogous FE model with cluster-robust standard errors. For investigators working with observational data and who are interested only in inference on the target coefficient, either approach is equally appropriate and preferable to uncorrected MLM.","1256":"Abstract This paper proposes a Bayesian alternative to the synthetic control method for comparative case studies with a single or multiple treated units. We adopt a Bayesian posterior predictive approach to Rubin\u2019s causal model, which allows researchers to make inferences about both individual and average treatment effects on treated observations based on the empirical posterior distributions of their counterfactuals. The prediction model we develop is a dynamic multilevel model with a latent factor term to correct biases induced by unit-specific time trends. It also considers heterogeneous and dynamic relationships between covariates and the outcome, thus improving precision of the causal estimates. To reduce model dependency, we adopt a Bayesian shrinkage method for model searching and factor selection. Monte Carlo exercises demonstrate that our method produces more precise causal estimates than existing approaches and achieves correct frequentist coverage rates even when sample sizes are small and rich heterogeneities are present in data. We illustrate the method with two empirical examples from political economy.","1257":null,"1258":"One of the hallmarks of a free and fair society is the ability to conduct a peaceful and seamless transfer of power from one leader to another. Democratically, this is measured in a citizen population\u2019s trust in the electoral system of choosing a representative government. In view of the well documented issues of the 2016 US Presidential election, we conducted an in-depth analysis of the 2018 US Midterm elections looking specifically for voter fraud or suppression. The Midterm election occurs in the middle of a 4 year presidential term. For the 2018 midterms, 35 Senators and all the 435 seats in the House of Representatives were up for re-election, thus, every congressional district and practically every state had a federal election. In order to collect election related tweets, we analyzed Twitter during the month prior to, and the two weeks following, the November 6, 2018 election day. In a targeted analysis to detect statistical anomalies or election interference, we identified several biases that can lead to wrong conclusions. Specifically, we looked for divergence between actual voting outcomes and instances of the #ivoted hashtag on the election day. This analysis highlighted three states of concern: New York, California, and Texas. We repeated our analysis discarding malicious accounts, such as social bots. Upon further inspection and against a backdrop of collected general election-related tweets, we identified some confounding factors, such as population bias, or bot and political ideology inference, that can lead to false conclusions. We conclude by providing an in-depth discussion of the perils and challenges of using social media data to explore questions about election manipulation.","1259":null,"1260":"This themed issue of the journal has come together in response to a call launched in 2019 that asked for contributions in novel causal inference methods motivated by substantive applications. As questions regarding causes and effects arise in a variety of settings, so do the contributions included here, which range from applications in clinical medicine (Andrews and his colleagues and Hunt and his colleagues), public health (Cuellar and Kennedy, Longford, and Samartsidis and his colleagues), health policy (Keele and his colleagues and Pimentel and his colleagues), epidemiology (Kim and his colleagues, Resa and Zubizarreta, von Cube and her colleagues and Zeng and his colleagues), biology (Castelletti and Consonni, and Foraita and her colleagues), economics (Brise\u00f1o Sanchez and his colleagues and Saramago and his colleagues), law and criminology (Mauro and her colleagues, and Ogburn and her colleagues), politics (Imai and Jiang) and education (Corradi and Musio, Licari and Mattei, and Lockwood and McCaffrey). Although these applications are very varied, the challenges that they pose are recognizable across disciplines. Indeed the common thread across these papers is their attempt to draw causal conclusions from observational data, with limitations in data quality and potential biases encountered almost universally. These papers contribute to achieving this goal by adopting the formality of modern causal inference to formulate and address causal questions of interest and to deal with the challenges that are posed by data. They use concepts and language of counterfactual reasoning to define targets of estimation (e.g. the average causal effect and the local average causal effect) and to describe the relevant identifying assumptions (e.g. causal consistency, no interference and ignorability). This commonality of language, but not of applications, makes this issue so interesting: the methodological developments have different motivations but have the potential to extend causal inference across disciplines. We have grouped the contributions from these papers according to the methodological areas that they have extended, namely with regard to methods that","1261":"With the increase of biased information available online, the importance of analysis and detection of such content has also significantly risen. In this paper, we aim to quantify different kinds of social biases using word embeddings. Towards this goal we train such embeddings on two politically biased MediaWiki instances, namely RationalWiki and Conservapedia. Additionally we included Wikipedia as an online encyclopedia, which is accepted by the general public. Utilizing and combining state-of-the-art word embedding models with WEAT and WEFAT, we display to what extent biases exist in the above-mentioned corpora. By comparing embeddings we observe interesting differences between different kinds of wikis.","1262":"Current approaches to A\/B testing in networks focus on limiting interference, the concern that treatment effects can \"spill over\" from treatment nodes to control nodes and lead to biased causal effect estimation. Prominent methods for network experiment design rely on two-stage randomization, in which sparsely-connected clusters are identified and cluster randomization dictates the node assignment to treatment and control. Here, we show that cluster randomization does not ensure sufficient node randomization and it can lead to selection bias in which treatment and control nodes represent different populations of users. To address this problem, we propose a principled framework for network experiment design which jointly minimizes interference and selection bias. We introduce the concepts of edge spillover probability and cluster matching and demonstrate their importance for designing network A\/B testing. Our experiments on a number of real-world datasets show that our proposed framework leads to significantly lower error in causal effect estimation than existing solutions.","1263":"Two-sided marketplace platforms often run experiments (or A\/B tests) to test the effect of an intervention before launching it platform-wide. A typical approach is to randomize users into a treatment group, which receives the intervention, and a control group, which does not. The platform then compares the performance in the two groups to estimate the effect if the intervention were launched to everyone. We focus on two common experiment types, where the platform randomizes users either on the supply side or on the demand side. For these experiments, it is known that the resulting estimates of the treatment effect are typically biased: individuals in the market compete with each other, which creates interference and leads to a biased estimate. Here, we observe that economic interactions (competition among demand and supply) lead to statistical phenomenon (biased estimates). We develop a simple, tractable market model to study bias and variance in these experiments with interference. We focus on two choices available to the platform: (1) Which side of the platform should it randomize on (supply or demand)? (2) What proportion of individuals should be allocated to treatment? We find that both choices affect the bias and variance of the resulting estimators, but in different ways. The bias-optimal choice of experiment type depends on the relative amounts of supply and demand in the market, and we discuss how a platform can use market data to select the experiment type. Importantly, we find that in many circumstances choosing the bias-optimal experiment type has little effect on variance, and in some cases coincide with the variance-optimal type. On the other hand, we find that the choice of treatment proportion can induce a bias-variance tradeoff, where the bias-minimizing proportion increases variance. We discuss how a platform can navigate this tradeoff and best choose the proportion, using a combination of modeling as well as contextual knowledge about the market, the risk of the intervention, and reasonable effect sizes of the intervention.","1264":null,"1265":"Increased polarization and partisanship have become a consistent state of politics, media, and society, especially in the United States. As many news publishers are perceived as \u201cbiased\u201d and some others have come under attack as being \u201cfake news\u201d, efforts to make such labels stick have increased too. In some cases (e.g., InfoWars), the use of such labels is legitimate, because some online publishers deliberately spread conspiracy theories and false stories. Other news publishers are perceived as partisan and biased, in ways that damages their reporting credibility. Whether political bias affects journalism standards appears to be a debated topic with no clear consensus. Meanwhile, labels such as \u201cfar-left\u201d or \u201calt-right\u201d are highly contested and may become cause for prolonged edit wars on the Wikipedia pages of some news sources. In this paper, we try to shine a light into this phenomenon and its extent, in order to start a conversation within the Wikipedia community about transparent processes for assigning political orientation and journalistic reliability labels to news sources, especially to unfamiliar ones, which users would be more likely to verify by looking them up. As more of Wikipedia\u2019s content is used outside Wikipedia\u2019s \u201ccontainer\u201d (e.g., in search results or by voice personal assistants), the issue of where certain statements appear in the Wikipedia page and their verifiability becomes an urgent one to consider not only by Wikipedia editors, but by third-party information providers too.","1266":"Using data from over 300,000 visits to an emergency department (ED), we study the accuracy of gatekeeping decisions\u2014the choices that physicians make regarding patient discharge or admission to the hospital. In our study context, we focus specifically on the effectiveness of a second gatekeeping stage in the ED\u2014a clinical decision unit (CDU). Although only 9.9% of patients in our sample are routed through the CDU, we find that had the unit not been in place during the observation period, the rates of unnecessary hospitalization and wrongful patient discharge from the ED would have increased by 14.3% and 29.6%, respectively. We also find that the CDU is especially beneficial for patients with a high ex ante risk of experiencing unnecessary hospitalization, with the rate for the most high-risk patients reduced from 14.0% without the CDU to just 4.8% had all such patients been routed through the CDU. The appropriateness of referrals is therefore a key contributor to the CDU\u2019s effectiveness: We estimate that random allocation of patients in our study hospital to the CDU would have reduced the unit\u2019s effectiveness by more than half. Finally, we investigate a critical trade-off in designing a two-stage gatekeeping system: Resources must be split between the two stages, increasing congestion in the first stage when the second stage is enlarged. We demonstrate that in the study hospital, the combination of an ED and CDU performs better than a pooled system that combines the capacity of both stages to enlarge the ED but does not have a designated CDU. In fact, we estimate that in this specific case, reducing the size of the first-stage ED in order to expand CDU capacity from the current 9.9% of ED patients to 25% would further reduce unnecessary hospitalizations by up to 33%. We discuss the insights that these results provide as to the circumstances under which it may be advantageous to add a second stage to a gatekeeping system. This paper was accepted by David Simchi-Levi, operations management.","1267":"Since the inception of gatekeeping research in the 1940s, most studies on gatekeeping have been human\u2010centric, treating and studying individuals as gatekeepers, who perform their gatekeeping role using a combination of the following mechanisms: forming communities, and\/or broadcasting, discovering\u2010searching, collecting, organizing, or protecting information. However, the nature of communication channels and how information is produced by and shared with users has fundamentally changed in the last 80\u2009years. One significant change is the growing use of technology\u2010enabled metadata like hashtags when sharing information on social media. Rarely any study investigates whether hashtags can perform gatekeeping of information and what it means for information gatekeeping. This paper fills in the gap by conducting a content analysis of 77 interdisciplinary studies on hashtags and gatekeeping to confirm how they can implement six gatekeeping mechanisms. This study shows that hashtags expand our understanding of the role of technology solutions in gatekeeping and advance research on hierarchical gatekeeping. The benefits of hashtags for gatekeeping suggest that they act as \u201cinformation anchors\u201d for online communities, thereby highlighting the utility of information gatekeepers for society.","1268":"Abstract Computational news discovery (CND) is a particular application area within computational journalism related to the use of algorithms to orient editorial attention to potentially newsworthy events or information prior to publication. Previous work in this area has been concentrated on prototyping CND tools, which can, for instance, send alerts and leads to journalists about social media events, documents of interest, or salient patterns in streams of data. This article describes a qualitative interview study of journalists as they incorporate CND tools into their practices. Findings provide insights into how CND tools interact with the internal attention economy and sociotechnical gatekeeping processes of the newsroom and how future CND tools might better align with necessary journalistic evaluations of newsworthiness and quality, while ensuring configurability, human agency, and flexible applicability to a wide range of use cases. These findings begin to outline a conceptual framework that can help guide the effective design of future CND tools.","1269":"This work presents an audit study of Apple News as a sociotechnical news curation system that exercises gatekeeping power in the media. We examine the mechanisms behind Apple News as well as the content presented in the app, outlining the social, political, and economic implications of both aspects. We focus on the Trending Stories section, which is algorithmically curated, and the Top Stories section, which is human-curated. Results from a crowdsourced audit showed minimal content personalization in the Trending Stories section, and a sock-puppet audit showed no location-based content adaptation. Finally, we perform an extended two-month data collection to compare the human-curated Top Stories section with the algorithmically curated Trending Stories section. Within these two sections, human curation outperformed algorithmic curation in several measures of source diversity, concentration, and evenness. Furthermore, algorithmic curation featured more \"soft news\" about celebrities and entertainment, while editorial curation featured more news about policy and international events. To our knowledge, this study provides the first data-backed characterization of Apple News in the United States.","1270":"\n This study examines the relevance of traditional mass communication\u2019s two-step flow-of-communication theory in relation to algorithmic personalization. I compare the two-step flow theory\u2019s concept of personalized content through opinion leaders with the current notion of personalized algorithms, arguing that opinion leaders and algorithms both function as gatekeeping agents. I also discuss the nature and role of peer groups in the two cases, arguing that while in the original theory, groups were seen as relatively solid (family, friends, and work colleagues), groups in the algorithmic era are much more liquid, transforming according to data inputs and users\u2019 behavior. Finally, the article also considers differences in the source of authority of opinion leaders and algorithms in both eras, as well as the different social settings and public awareness in the second step of the communication flow.","1271":"Significance Online networks carry benefits and risks with high-stakes consequences during contentious political events: They can be tools for organization and awareness, or tools for disinformation and conflict. We combine social media and web-tracking data to measure differences on the visibility of news sources during two events that involved massive political mobilizations in two different countries and time periods. We contextualize the role of social media as an entry point to news, and we cast doubts on the impact that bot activity had on the coverage of those mobilizations. We show that verified, blue-badge accounts were significantly more visible and central. Our findings provide evidence to evaluate the role of social media in facilitating information campaigns and eroding traditional gatekeeping roles. Information manipulation is widespread in today\u2019s media environment. Online networks have disrupted the gatekeeping role of traditional media by allowing various actors to influence the public agenda; they have also allowed automated accounts (or bots) to blend with human activity in the flow of information. Here, we assess the impact that bots had on the dissemination of content during two contentious political events that evolved in real time on social media. We focus on events of heightened political tension because they are particularly susceptible to information campaigns designed to mislead or exacerbate conflict. We compare the visibility of bots with human accounts, verified accounts, and mainstream news outlets. Our analyses combine millions of posts from a popular microblogging platform with web-tracking data collected from two different countries and timeframes. We employ tools from network science, natural language processing, and machine learning to analyze the diffusion structure, the content of the messages diffused, and the actors behind those messages as the political events unfolded. We show that verified accounts are significantly more visible than unverified bots in the coverage of the events but also that bots attract more attention than human accounts. Our findings highlight that social media and the web are very different news ecosystems in terms of prevalent news sources and that both humans and bots contribute to generate discrepancy in news visibility with their activity.","1272":null,"1273":null},"venue":{"0":"WWW","1":"EACL","2":"Inf. Process. Manag.","3":"CogSci","4":"ArXiv","5":"Language Sciences","6":"NAACL","7":"ACL","8":"ACL","9":"FINDINGS","10":"Frontiers in Artificial Intelligence","11":"UMAP","12":"PKDD\/ECML Workshops","13":"ArXiv","14":"ACL","15":"2019 IEEE\/WIC\/ACM International Conference on Web Intelligence (WI)","16":"EMNLP","17":"IEEE Transactions on Knowledge and Data Engineering","18":"Linguistic Typology","19":"ACL","20":"ACL","21":"ACL","22":"BLACKBOXNLP","23":"NAACL","24":"ACL","25":"ACL","26":"Top. Cogn. Sci.","27":"NAACL","28":"Proceedings of the Second Workshop on Shortcomings in Vision and Language","29":"EMNLP","30":"AVEC@MM","31":"PloS one","32":"ACL","33":"GEBNLP","34":"ACL","35":"AAAI","36":"EMNLP","37":"ACM Multimedia","38":"EMNLP","39":"NLPCSS","40":"CogSci","41":"Int. J. Intell. Syst.","42":"ICWSM","43":"Int. J. Intell. Syst.","44":"MTSummit","45":"EMNLP","46":"ICLR","47":"ICLR","48":"ICWSM","49":"2020 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","50":"ACL","51":"IEEE Transactions on Software Engineering","52":"AAAI","53":"ACL","54":"ACL","55":"EMNLP","56":"EMNLP","57":"IWSLT","58":"Nature Human Behaviour","59":"ACL","60":"IJCAI","61":"COLING","62":null,"63":"FINDINGS","64":null,"65":"ACL","66":null,"67":"EMNLP","68":"Proceedings of the Twenty-Fourth Annual Conference of the Cognitive Science Society","69":"EMNLP","70":"NAACL","71":"NAACL","72":"ACL","73":"J. Media Psychol. Theor. Methods Appl.","74":"ArXiv","75":"INTERSPEECH","76":"AAAI","77":"AACL","78":"ACL","79":"GEBNLP","80":"ICMI","81":"ArXiv","82":"BlackboxNLP@ACL","83":"Annual Review of Linguistics","84":"Learn. Publ.","85":"Scientometrics","86":"Cognitive Technologies","87":"ArXiv","88":"ArXiv","89":"ArXiv","90":null,"91":"Cogn. Sci.","92":"ArXiv","93":"ArXiv","94":"SocInfo","95":"AAAI","96":"JCDL","97":"ICER","98":"Proceedings of the National Academy of Sciences","99":"Front. Microbiol.","100":"ACL","101":"WIREs Data Mining Knowl. Discov.","102":"Ecology and evolution","103":"ICLR","104":null,"105":"FAT","106":null,"107":"bioRxiv","108":"IEEE transactions on pattern analysis and machine intelligence","109":"ICLR","110":"WSDM","111":"FAT*","112":"IEEE Transactions on Systems, Man, and Cybernetics: Systems","113":"K\u00fcnstliche Intell.","114":"2020 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","115":"ArXiv","116":"Frontiers in Research Metrics and Analytics","117":"Ethics Inf. Technol.","118":"Proc. ACM Hum. Comput. Interact.","119":"J. Data Min. Digit. Humanit.","120":"BIAS","121":"BIAS","122":"BIAS","123":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","124":"BIAS","125":"BIAS","126":"BIAS","127":"BIAS","128":"BIAS","129":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","130":"BIAS","131":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","132":"BIAS","133":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","134":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","135":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","136":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","137":"CD-MAKE","138":"2021 IEEE Global Engineering Education Conference (EDUCON)","139":"BIAS","140":"ArXiv","141":"BIAS","142":"BIAS","143":"ArXiv","144":"BIAS","145":"BIAS","146":"BIAS","147":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","148":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","149":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","150":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","151":"BIAS","152":"BIAS","153":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","154":"Communications in Information Literacy","155":"Reputation","156":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","157":"BMC Medical Informatics and Decision Making","158":"Medicine, health care, and philosophy","159":null,"160":"2020 32nd International Teletraffic Congress (ITC 32)","161":null,"162":"ArXiv","163":"ArXiv","164":"CSCL","165":"ICCS","166":"Remote. Sens.","167":"FAT","168":"CogSci","169":"ICLR","170":"IEEE Transactions on Neural Networks and Learning Systems","171":"2021 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","172":"2021 IEEE\/CVF International Conference on Computer Vision (ICCV)","173":"2021 IEEE Winter Conference on Applications of Computer Vision (WACV)","174":"NeurIPS","175":"AAAI","176":"ECCV","177":"2020 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","178":"2021 IEEE\/CVF International Conference on Computer Vision (ICCV)","179":"ACL","180":"EMNLP","181":"ECCV","182":"PeerJ Comput. Sci.","183":"ACL","184":"FINDINGS","185":"Journal of Big Data","186":"IJCAI","187":"EMNLP","188":"ECCV","189":"IEEE Signal Processing Letters","190":"AISTATS","191":"ACL","192":"IEEE Transactions on Image Processing","193":"FINDINGS","194":"NeurIPS","195":"EMNLP","196":"2019 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","197":"Multimedia Tools and Applications","198":"EMNLP","199":"NeurIPS","200":"NAACL","201":"EMNLP","202":"MICCAI","203":"Attention, perception & psychophysics","204":"GECCO","205":"iConference","206":"CogSci","207":"ArXiv","208":"PRICAI","209":"ArXiv","210":"ICLR","211":"ACL","212":"ACL","213":"IEEE transactions on pattern analysis and machine intelligence","214":"WWW","215":"ICLR","216":"NeurIPS","217":"2020 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","218":"IEEE Transactions on Medical Imaging","219":"2021 IEEE\/CVF International Conference on Computer Vision (ICCV)","220":"ACM Multimedia","221":"EMNLP","222":"IEEE Transactions on Neural Networks and Learning Systems","223":"ICLR","224":"IEEE Transactions on Image Processing","225":"ECCV","226":"2020 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","227":"MIDL","228":"ECCV","229":"AAAI","230":"ACL","231":"SIGIR","232":"AAAI","233":"Transactions of the Association for Computational Linguistics","234":"COLING","235":"2019 IEEE\/CVF International Conference on Computer Vision (ICCV)","236":"ACAI 2019","237":"ArXiv","238":"BMC Bioinformatics","239":"ACM Multimedia","240":"Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change","241":"ACL","242":"Cogn. Comput.","243":"2021 IEEE\/CVF International Conference on Computer Vision (ICCV)","244":"2020 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","245":"ECCV","246":"Scientific reports","247":"2020 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)","248":"FINDINGS","249":"Int. J. Soc. Robotics","250":"AAAI","251":"FAT*","252":"ECCV","253":"2021 ACM\/IEEE Joint Conference on Digital Libraries (JCDL)","254":"Sensors","255":"IJCAI","256":"2019 IEEE\/CVF International Conference on Computer Vision (ICCV)","257":"2019 IEEE\/CVF International Conference on Computer Vision (ICCV)","258":"ACL","259":"ArXiv","260":"European Journal of Nuclear Medicine and Molecular Imaging","261":"Remote. Sens.","262":"bioRxiv","263":"2021 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","264":null,"265":"NeurIPS","266":"ICLR","267":"2020 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","268":"ACL","269":"Quantitative Science Studies","270":"ICLR","271":"IJCAI","272":"ICLR","273":"ICLR","274":"ICLR","275":"ArXiv","276":"AAAI","277":"2020 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","278":"UAI","279":"Genetic Programming and Evolvable Machines","280":"IEEE Transactions on Image Processing","281":"IEEE Transactions on Image Processing","282":"2019 IEEE\/CVF International Conference on Computer Vision Workshop (ICCVW)","283":"CoNLL","284":"AAAI","285":"2019 International Joint Conference on Neural Networks (IJCNN)","286":"ArXiv","287":"NAACL","288":"NeurIPS","289":"2019 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","290":"NeurIPS","291":"ArXiv","292":"ArXiv","293":"IEEE Signal Processing Letters","294":"BMC Bioinformatics","295":"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","296":"EMNLP","297":"EDM","298":"NeurIPS","299":"ACM Trans. Inf. Syst.","300":"NeurIPS","301":"ArXiv","302":"EMNLP","303":"Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change","304":"CoNLL","305":"Risk-based Bridge Engineering","306":"ESEC\/SIGSOFT FSE","307":null,"308":"ICLR","309":"Journal of Cultural Cognitive Science","310":"Proc. ACM Program. Lang.","311":"Future Internet","312":"ArXiv","313":"Neural Comput. Appl.","314":null,"315":"NeurIPS","316":"Remote. Sens.","317":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","318":"2021 IEEE\/CVF International Conference on Computer Vision (ICCV)","319":"Journal of Digital Imaging","320":"CCKS","321":"AAAI","322":"Sensors","323":"2019 ACM\/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)","324":"Evolutionary Computation","325":null,"326":"IEEE Internet of Things Journal","327":"ArXiv","328":"J. Assoc. Inf. Sci. Technol.","329":"ACM Transactions on Computing for Healthcare","330":"IEEE Transactions on Cybernetics","331":"ArXiv","332":"ICLR","333":"AAAI","334":"AAAI","335":"Synthese","336":"PeerJ Comput. Sci.","337":"ArXiv","338":"ICLR 2020","339":"NAACL","340":"2019 Digital Image Computing: Techniques and Applications (DICTA)","341":"EMNLP","342":"ArXiv","343":"FINDINGS","344":"2021 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","345":"ArXiv","346":"BICA","347":"2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC)","348":"IEEE Transactions on Multimedia","349":"AISTATS","350":"Human Cognitive Processing","351":"ArXiv","352":"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)","353":"Scientific reports","354":"2020 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","355":"BMVC","356":"PEOPLES","357":"ArXiv","358":"INTERSPEECH","359":"EMNLP","360":"Frontiers in Genetics","361":"2019 IEEE International Conference on Big Data (Big Data)","362":"IEEE Transactions on Pattern Analysis and Machine Intelligence","363":"ArXiv","364":"2019 IEEE\/ACM 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)","365":"NAACL","366":"CogSci","367":null,"368":"MICCAI","369":"ArXiv","370":"ArXiv","371":"Remote. Sens.","372":"FINDINGS","373":"ArXiv","374":"IEEE Transactions on Multimedia","375":"Radiology. Artificial intelligence","376":"Attention, perception & psychophysics","377":"FINDINGS","378":"IDA","379":"ACL","380":"BMVC","381":"EMNLP","382":"IEEE Access","383":"ArXiv","384":null,"385":"ArXiv","386":"ArXiv","387":"CL","388":"ArXiv","389":"EMNLP","390":"ACM Comput. Surv.","391":"BMJ","392":"ACL","393":"The Transhumanism Handbook","394":"HCI","395":"AAAI","396":null,"397":"Int. J. Interact. Multim. Artif. Intell.","398":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","399":null,"400":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","401":"ICWSM","402":null,"403":"EMNLP","404":"EMNLP","405":"CHI","406":"EMNLP","407":"J. Chem. Inf. Model.","408":"ICWSM","409":"EMNLP","410":"NAACL","411":"JMIRx med","412":"Physical review letters","413":"ArXiv","414":"Scientific Reports","415":"SIGIR","416":"ArXiv","417":"IEEE Transactions on Computational Social Systems","418":"ArXiv","419":"ArXiv","420":"ArXiv","421":"Physical Review X","422":"New Media Soc.","423":"MIS Q.","424":"JMIRx Med","425":"Internet Res.","426":"ArXiv","427":"ArXiv","428":"2020 13th International Conference \"Management of large-scale system development\" (MLSD)","429":null,"430":"medRxiv","431":"ArXiv","432":"ArXiv","433":"Scientific reports","434":null,"435":"ArXiv","436":"LORI","437":"Proceedings of the Third Workshop on Natural Language Processing and Computational Social Science","438":"ECIS","439":"EMNLP","440":"ECIS","441":"ArXiv","442":"ECIS","443":"SocialSens@CPSIoTWeek","444":"SOCIOLOGIA E POLITICHE SOCIALI","445":"ICWSM","446":"WWW","447":"Proc. ACM Hum. Comput. Interact.","448":"RecSys","449":"RecSys","450":null,"451":"Soc. Netw. Anal. Min.","452":"ACL","453":"EPJ Data Science","454":"First Monday","455":"ArXiv","456":"ArXiv","457":null,"458":"ICWSM","459":"Neural Comput. Appl.","460":"PloS one","461":"WSDM","462":"Scientific Reports","463":"The Journal of Supercomputing","464":"ArXiv","465":"ICWSM","466":"AI Ethics","467":"Handbook of Computational Social Science, Volume 1","468":"KDD","469":"ArXiv","470":"AIES","471":null,"472":"Proceedings of the National Academy of Sciences","473":"Nordic Journal of Media Studies","474":"CHIIR","475":"The Journal of Mathematical Sociology","476":"New Journal of Physics","477":"WWW","478":"Appl. Netw. Sci.","479":null,"480":"ICWSM","481":"ArXiv","482":"Journal of Statistical Mechanics: Theory and Experiment","483":"IEEE Access","484":"ArXiv","485":null,"486":"CHIIR","487":"IEEE Transactions on Medical Imaging","488":"IUI Companion","489":"ArXiv","490":"ICWSM","491":"ArXiv","492":"Ethics and Information Technology","493":"IEEE INFOCOM 2019 - IEEE Conference on Computer Communications","494":"Royal Society Open Science","495":"The International Encyclopedia of Journalism Studies","496":"ArXiv","497":"Inf. Soc.","498":"2019 IEEE\/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)","499":"Ethics and Information Technology","500":"ArXiv","501":null,"502":"Society and the Internet","503":"Int. J. Smart Educ. Urban Soc.","504":null,"505":"FACETS","506":"UMAP","507":"UMAP","508":"Information Retrieval Journal","509":"WebSci","510":"ArXiv","511":"Proceedings of the National Academy of Sciences","512":"Physical review. E","513":"IEEE Transactions on Cognitive Communications and Networking","514":"PloS one","515":"First Monday","516":"Physical Review Research","517":"MIS Q.","518":"AAMAS","519":"Cyberpsychology Behav. Soc. Netw.","520":"NIME","521":"LDK","522":"2020 8th Iranian Joint Congress on Fuzzy and intelligent Systems (CFIS)","523":"ArXiv","524":"Proceedings of the National Academy of Sciences","525":"ArXiv","526":null,"527":null,"528":"ArXiv","529":"ICIMTH","530":null,"531":"The Art of Structuring","532":null,"533":"Mensch & Computer","534":"ArXiv","535":"CogSci","536":"2020 Joint 11th International Conference on Soft Computing and Intelligent Systems and 21st International Symposium on Advanced Intelligent Systems (SCIS-ISIS)","537":"MEDES","538":"ArXiv","539":"Nature Neuroscience","540":"2019 IEEE Visualization Conference (VIS)","541":"IEEE Transactions on Visualization and Computer Graphics","542":"CHI","543":null,"544":"CHI","545":"IEEE Transactions on Biomedical Engineering","546":"Sensors","547":"J. Manag. Inf. Syst.","548":"EURASIP J. Wirel. Commun. Netw.","549":"2021 IEEE\/ACM 43rd International Conference on Software Engineering (ICSE)","550":"IEEE Access","551":"Inf. Syst. Res.","552":"IEEE Access","553":"IEEE Internet of Things Journal","554":"Games","555":"IEEE Transactions on Learning Technologies","556":"2019 34th IEEE\/ACM International Conference on Automated Software Engineering (ASE)","557":"2019 IEEE\/ACM 41st International Conference on Software Engineering (ICSE)","558":"IEEE Transactions on Power Systems","559":"Inf. Syst. Res.","560":"Manag. Sci.","561":"Sensors","562":"IEEE Transactions on Emerging Topics in Computing","563":"Applied Physics Reviews","564":"IEEE Internet of Things Journal","565":"Manuf. Serv. Oper. Manag.","566":"IEEE Transactions on Neural Networks and Learning Systems","567":"IEEE Access","568":"ICCAE 2019","569":"KDD","570":"IEEE Access","571":"AINA","572":"Wirtschaftsinformatik","573":"IEEE Access","574":"IEEE Access","575":"BWCCA","576":"2020 International Conference on COMmunication Systems & NETworkS (COMSNETS)","577":"COLING","578":"Syst.","579":"Ind. Manag. Data Syst.","580":"The Journal of Politics","581":"IFIPTM","582":"Inf. Technol. People","583":"ACL","584":"RecSys","585":null,"586":"JCDL","587":"ICML","588":null,"589":"2021 13th International Conference on Quality of Multimedia Experience (QoMEX)","590":"IJCAI","591":"Attention, perception & psychophysics","592":"J. Web Eng.","593":"ArXiv","594":"IEEE Transactions on Circuits and Systems I: Regular Papers","595":"SIGIR","596":null,"597":"WWW","598":"CIKM","599":"AAAI","600":"IEEE Journal of Solid-State Circuits","601":"EMNLP","602":"2019 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","603":"BMVC","604":null,"605":"IEEE Transactions on Computers","606":"ArXiv","607":"IEEE Transactions on Circuits and Systems II: Express Briefs","608":"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","609":"AAAI","610":"WWW","611":"IEEE Journal on Selected Areas in Communications","612":"Journal of eye movement research","613":"IEEE Transactions on Instrumentation and Measurement","614":"2021 IEEE\/ACM 29th International Symposium on Quality of Service (IWQOS)","615":"J. Knowl. Manag.","616":"IJCAI","617":"ACM Trans. Appl. Percept.","618":"medRxiv","619":"Movement ecology","620":"ICC 2019 - 2019 IEEE International Conference on Communications (ICC)","621":"EACL","622":"2019 15th International Conference on Mobile Ad-Hoc and Sensor Networks (MSN)","623":"Sensors","624":null,"625":"Int. J. Commun. Syst.","626":"Games","627":"UMAP","628":"IOT Companion","629":"J. Integr. Bioinform.","630":"ArXiv","631":"IEEE Trans. Circuits Syst. I Regul. Pap.","632":"IEEE Transactions on Wireless Communications","633":"EURASIP J. Adv. Signal Process.","634":"Behavioral and Brain Sciences","635":"IEEE Transactions on Communications","636":null,"637":"IEEE Transactions on Industrial Informatics","638":"IEEE Internet of Things Journal","639":"Inf. Syst. E Bus. Manag.","640":"IEEE Internet of Things Journal","641":"IEEE Access","642":"IEEE Access","643":"IEEE Access","644":"Trans. Emerg. Telecommun. Technol.","645":"bioRxiv","646":"2019 2nd International Conference on Computing, Mathematics and Engineering Technologies (iCoMET)","647":"Scientific Reports","648":null,"649":"IEEE Transactions on Emerging Topics in Computing","650":"IEEE Access","651":"AAAI 2020","652":"Scientific Reports","653":"IEEE Access","654":"IEEE Wireless Communications","655":null,"656":"IEEE Transactions on Cognitive Communications and Networking","657":"IEEE Transactions on Cognitive Communications and Networking","658":null,"659":null,"660":"Frontiers in Psychiatry","661":"AIIDE","662":"ArXiv","663":"Entropy","664":"IEEE Transactions on Cognitive Communications and Networking","665":"AAAI","666":"Information Systems and Neuroscience","667":"Behavioral and Brain Sciences","668":"IUI","669":"H-WORKLOAD","670":"AIMS","671":"CogSci","672":"Proceedings of the National Academy of Sciences","673":"2019 IEEE World Congress on Services (SERVICES)","674":"2019 53rd Asilomar Conference on Signals, Systems, and Computers","675":"2019 IEEE 58th Conference on Decision and Control (CDC)","676":"Social Network Analysis and Mining","677":"2020 International Conference on Smart Electronics and Communication (ICOSEC)","678":"Journal of experimental psychology. Human perception and performance","679":"Frontiers in Computational Neuroscience","680":"bioRxiv","681":"CogSci","682":"2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","683":"2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA)","684":"Adapt. Behav.","685":"Sensors","686":null,"687":"Cogn. Sci.","688":"ICWSM","689":"Big Data Min. Anal.","690":"IEEE Transactions on Systems, Man, and Cybernetics: Systems","691":"Nature Protocols","692":"IEEE Access","693":"BMJ Evidence-Based Medicine","694":"Frontiers in Virtual Reality","695":"Scientometrics","696":"ICLR","697":"The Journal of Experimental Education","698":"Sociological Perspectives","699":"Methodology","700":"Remote. Sens.","701":"Scientific Reports","702":"ArXiv","703":"Civil Engineering and Environmental Systems","704":"Remote. Sens.","705":"IEEE Transactions on Cognitive and Developmental Systems","706":"ArXiv","707":"AAMAS","708":null,"709":"MTSummit","710":"ACM J. Data Inf. Qual.","711":"Remote. Sens.","712":"Human brain mapping","713":null,"714":"IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","715":"Proc. ACM Hum. Comput. Interact.","716":null,"717":"COLING","718":"NAACL","719":"ICLR","720":"ICLR","721":"ICML","722":"NAACL-HLT","723":"International journal of epidemiology","724":"NeurIPS","725":"NeurIPS","726":"Simulation in healthcare : journal of the Society for Simulation in Healthcare","727":"AIES","728":"ACL","729":"ArXiv","730":"IEEE Transactions on Technology and Society","731":"KDD","732":"ECAI","733":"SIGIR","734":"ACL","735":"ArXiv","736":"ArXiv","737":"The Journal of Neuroscience","738":"FINDINGS","739":"Journal of Soils and Sediments","740":null,"741":"Journal of High Energy Physics","742":"ArXiv","743":"The Journal of Neuroscience","744":"ArXiv","745":null,"746":"EMNLP","747":"ArXiv","748":"Natural Language Engineering","749":"SAC","750":"NAACL","751":"ArXiv","752":"IOP Conference Series: Materials Science and Engineering","753":"PloS one","754":"NAACL","755":"ACL","756":"EMNLP","757":"ACL","758":"ACL","759":"ArXiv","760":"Equine veterinary journal","761":"SOCIALNLP","762":"EMNLP","763":"2019 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","764":"NAACL","765":"CONTEXT","766":"2020 IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS)","767":"Comput. Sci. Educ.","768":"FAccT","769":"The Journal of Politics","770":"ArXiv","771":"FINDINGS","772":"it Inf. Technol.","773":"EMNLP","774":"ArXiv","775":"ACL","776":"AIES","777":"EMNLP","778":"IEEE Transactions on Computational Social Systems","779":"NAACL","780":"NAACL","781":"ArXiv","782":"BMC Bioinform.","783":"NeurIPS","784":"ACL","785":"ArXiv","786":"ACL","787":"AAAI","788":"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","789":"EMNLP","790":"Frontiers in Artificial Intelligence","791":"ACM Computing Surveys","792":"2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020)","793":"WWW","794":"FINDINGS","795":"Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.","796":"Data Min. Knowl. Discov.","797":"Nature Machine Intelligence","798":"Journal of the Text Encoding Initiative","799":"J. Am. Medical Informatics Assoc.","800":"EMNLP","801":"NeurIPS","802":"Journal of the Text Encoding Initiative","803":"Journal of Engineering Education","804":null,"805":"2020 International Joint Conference on Neural Networks (IJCNN)","806":"Proc. ACM Hum. Comput. Interact.","807":null,"808":"2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC)","809":"ACM Trans. Asian Low Resour. Lang. Inf. Process.","810":"Knowledge and Information Systems","811":"Bioinform.","812":"ArXiv","813":"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","814":"AAAI","815":"IEEE Access","816":"AAAI","817":"IEEE Access","818":"IEEE Transactions on Circuits and Systems I: Regular Papers","819":"2019 IEEE International Conference on Image Processing (ICIP)","820":"ArXiv","821":"Environment Systems and Decisions","822":"Frontiers in Big Data","823":"ArXiv","824":"IEEE Transactions on Circuits and Systems II: Express Briefs","825":"IEEE Journal of Solid-State Circuits","826":"IEEE Transactions on Geoscience and Remote Sensing","827":"Scientometrics","828":"Scientometrics","829":"ArXiv","830":"2021 IEEE Spoken Language Technology Workshop (SLT)","831":"2019 34th IEEE\/ACM International Conference on Automated Software Engineering (ASE)","832":"Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering","833":"INLG","834":"2021 Digital Image Computing: Techniques and Applications (DICTA)","835":"IEEE Access","836":"ArXiv","837":"2020 IEEE\/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","838":"TRUSTNLP","839":"Interspeech","840":"ArXiv","841":"ACL","842":"ACM Multimedia","843":"Cogn. Sci.","844":"International journal of environmental research and public health","845":null,"846":"IEEE\/ACM Transactions on Audio, Speech, and Language Processing","847":"Environmental Evidence","848":"J. Inf. Technol. Tour.","849":"The Journal of Experimental Education","850":null,"851":"ECAI","852":"Wirel. Commun. Mob. Comput.","853":"ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","854":"IEEE Transactions on Software Engineering","855":"GEBNLP","856":"Libr. Hi Tech","857":null,"858":"ArXiv","859":"AAAI","860":"ACL","861":"ACL","862":null,"863":"ACL","864":"WNUT","865":"WWW","866":"LREC","867":"International Journal of Data Science and Analytics","868":"Proceedings of the Twenty First Annual Conference of the Cognitive Science Society","869":"CogSci","870":"WWW","871":"PAKDD","872":"Informatics","873":"EAAMO","874":"OSACT","875":"ACL","876":"ArXiv","877":"ArXiv","878":"ALVR","879":"2019 IEEE\/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","880":"FAT*","881":"Methods in Ecology and Evolution","882":"Language, cognition and neuroscience","883":"ArXiv","884":"NAACL","885":"IEEE Transactions on Knowledge and Data Engineering","886":null,"887":"ArXiv","888":"Scientific reports","889":"NeurIPS Datasets and Benchmarks","890":"WWW","891":"ACL","892":"Integr. Comput. Aided Eng.","893":"ACL","894":"SIGIR","895":"EMNLP","896":"WWW","897":"INTERSPEECH","898":null,"899":"USENIX Security Symposium","900":"Proceedings of the Twenty First Annual Conference of the Cognitive Science Society","901":null,"902":"2020 IEEE International Conference on Knowledge Graph (ICKG)","903":"ArXiv","904":null,"905":null,"906":"Language and speech","907":"2019 24th Conference of Open Innovations Association (FRUCT)","908":"ArXiv","909":"SSRN Electronic Journal","910":"Grammatical Approaches to Language Processing","911":null,"912":"EASE","913":null,"914":"ArXiv","915":"ArXiv","916":"Proceedings of the First Workshop on Gender Bias in Natural Language Processing","917":"Language, Cognition and Neuroscience","918":"IVA","919":"Cogn. Sci.","920":"IACR Cryptol. ePrint Arch.","921":"ACL","922":"2021 IEEE Frontiers in Education Conference (FIE)","923":"ArXiv","924":"IHIET","925":"EMNLP","926":"ArXiv","927":"Text2Story@ECIR","928":"WNUT","929":"ArXiv","930":"ArXiv","931":"CONLL","932":"ArXiv","933":"Empir. Softw. Eng.","934":"ArXiv","935":"FINDINGS","936":"NeurIPS","937":"Nature Communications","938":"IEEE Transactions on Wireless Communications","939":"FLAIRS Conference","940":"RMSE@RecSys","941":"ECIR","942":"2019 ACM\/IEEE Joint Conference on Digital Libraries (JCDL)","943":"bioRxiv","944":"Environmental health perspectives","945":null,"946":"NAACL","947":"IEEE Transactions on Geoscience and Remote Sensing","948":"Global change biology","949":"ECCV","950":"ESEC\/SIGSOFT FSE","951":"IEEE Transactions on Wireless Communications","952":"Nucleic Acids Res.","953":"ICLR","954":"Journal of Geophysical Research: Atmospheres","955":"EMNLP","956":"Annual review of biophysics","957":"Nature Communications","958":"FAccT","959":"Diversity and Distributions","960":"SIGMOD Conference","961":"Proc. VLDB Endow.","962":"AAAI","963":"AIES","964":"Manag. Sci.","965":"2019 20th International Conference on Solid-State Sensors, Actuators and Microsystems & Eurosensors XXXIII (TRANSDUCERS & EUROSENSORS XXXIII)","966":"2019 IEEE Visualization Conference (VIS)","967":"ISPRS Int. J. Geo Inf.","968":"2020 IEEE International Conference on Data Mining (ICDM)","969":"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld\/SCALCOM\/UIC\/ATC\/CBDCom\/IOP\/SCI)","970":"ArXiv","971":null,"972":"Journal of neurophysiology","973":"Manag. Sci.","974":"IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","975":"WWW","976":"ArXiv","977":"RecSys","978":"bioRxiv","979":null,"980":"2020 IEEE\/ACM 42nd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)","981":"CIKM","982":"ArXiv","983":"SIGIR","984":"WWW","985":"ArXiv","986":"JCDL","987":"ICWSM","988":"BlackboxNLP@ACL","989":"ArXiv","990":"SIGIR","991":"Nature communications","992":"Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change","993":"AAAI","994":"Front. Big Data","995":"iConference","996":"SIGIR","997":"SOCIALNLP","998":"LREC","999":"ICWSM","1000":"MIS Q.","1001":"MIS Q.","1002":"ICWSM","1003":null,"1004":"INCoS","1005":"Secur. Commun. Networks","1006":"UAI","1007":"AAAI","1008":"ACL","1009":null,"1010":"EMNLP","1011":"INTERSPEECH","1012":"ACL","1013":"Policy Insights from the Behavioral and Brain Sciences","1014":null,"1015":"WSDM","1016":"EMNLP","1017":"2019 IEEE International Conference on Big Data (Big Data)","1018":"IEEE transactions on neural networks and learning systems","1019":"MIS Q. Executive","1020":null,"1021":"WANLP","1022":"ICBDT2019","1023":"ICWSM","1024":null,"1025":"CIKM","1026":"EMNLP","1027":"2019 IEEE Symposium on Visual Languages and Human-Centric Computing (VL\/HCC)","1028":"2019 IEEE Symposium on Security and Privacy (SP)","1029":"FINDINGS","1030":"2019 IEEE\/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)","1031":"Commun. ACM","1032":"WWW","1033":"Frontiers Comput. Sci.","1034":"SIdEWayS@HT","1035":"J. Assoc. Inf. Sci. Technol.","1036":"New Media Soc.","1037":"ICWSM","1038":"NewsIR@SIGIR","1039":"*SEMEVAL","1040":"EMNLP","1041":"IEEE Transactions on Cybernetics","1042":"2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS)","1043":"KDD","1044":"EMNLP","1045":"2019 IEEE\/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","1046":"PERV","1047":"ICWSM","1048":"HCI","1049":"CASE","1050":null,"1051":"JCDL","1052":"EDBT","1053":"ACL","1054":"MISDOOM","1055":null,"1056":"ArXiv","1057":"PloS one","1058":"Online Soc. Networks Media","1059":"IEEE Transactions on Technology and Society","1060":"Proceedings of the Third Workshop on Abusive Language Online","1061":"FAT*","1062":"WWW","1063":"ACL","1064":"Social Science Computer Review","1065":null,"1066":"WWW","1067":"CHI","1068":"AAAI","1069":"New Media Soc.","1070":"FAT","1071":"Wellcome open research","1072":"Mobile Media & Communication","1073":"New Media Soc.","1074":"IACR Cryptol. ePrint Arch.","1075":"CHI Extended Abstracts","1076":"NeHuAI@ECAI","1077":"New Media Soc.","1078":"ArXiv","1079":"SEMEVAL","1080":"ACM Trans. Internet Techn.","1081":"ACL","1082":"ACL","1083":"Turkish J. Electr. Eng. Comput. Sci.","1084":"PloS one","1085":"WWW","1086":"IEEE Transactions on Computational Social Systems","1087":"INRA@RecSys","1088":"International Journal of Advanced Computer Science and Applications","1089":"2019 2nd International Conference on Computing, Mathematics and Engineering Technologies (iCoMET)","1090":"2019 IEEE 13th International Conference on Semantic Computing (ICSC)","1091":null,"1092":"CONSTRAINT@AAAI","1093":"ACL","1094":"SIGIR","1095":"ACL","1096":"EACL","1097":"J. Assoc. Inf. Sci. Technol.","1098":"ArXiv","1099":"CIKM","1100":"PAKDD","1101":"ACL","1102":"AAAI","1103":"EMNLP","1104":"Lang. Resour. Evaluation","1105":"RecSys","1106":"WWW","1107":"*SEMEVAL","1108":"FINDINGS","1109":"AAAI","1110":"KDD","1111":"EMNLP","1112":"NLDB","1113":"RecSys","1114":"WWW","1115":"HT","1116":"WebSci","1117":null,"1118":"NAACL","1119":"Big Data & Society","1120":"2019 IEEE Fifth International Conference on Big Data Computing Service and Applications (BigDataService)","1121":"ICWSM","1122":"AAAI","1123":"WWW","1124":"WWW","1125":"Journal of Computational Social Science","1126":"2019 IEEE\/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)","1127":"WWW","1128":"ACL","1129":"EMNLP","1130":"EMNLP","1131":"KDD","1132":"2019 International Conference on Automation, Computational and Technology Management (ICACTM)","1133":"IEEE Access","1134":"NeurIPS","1135":"ACL","1136":"Comput. Intell. Neurosci.","1137":null,"1138":"AAAI","1139":"ArXiv","1140":"Quantitative Science Studies","1141":"NAACL","1142":"KaRS@CIKM","1143":"2019 Twelfth International Conference on Contemporary Computing (IC3)","1144":"PloS one","1145":"2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)","1146":null,"1147":"ICWSM","1148":"WWW","1149":"Int. J. Hum. Comput. Interact.","1150":"2019 2nd International Conference on new Trends in Computing Sciences (ICTCS)","1151":"ArXiv","1152":"The Review of Asset Pricing Studies","1153":"2019 4th International Conference on Information Systems and Computer Networks (ISCON)","1154":"International Journal on Natural Language Computing","1155":"Manag. Sci.","1156":"ACL","1157":"LREC","1158":"SSRN Electronic Journal","1159":"CHI","1160":"Journal of Marketing Research","1161":"KDIR","1162":"First Monday","1163":"2020 IEEE\/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)","1164":"ArXiv","1165":"2021 ACM\/IEEE Joint Conference on Digital Libraries (JCDL)","1166":"SIGACT News","1167":"SIGACT News","1168":"SIGACT News","1169":"SIGACT News","1170":"SIGACT News","1171":"iConference","1172":"ACM Multimedia","1173":"SIGACT News","1174":"SIGACT News","1175":"SIGACT News","1176":"SIGACT News","1177":"SIGACT News","1178":"Electronic News","1179":"Electronic News","1180":null,"1181":"SIGACT News","1182":"NAACL","1183":"Media and Communication","1184":"Synchrotron Radiation News","1185":"Library Hi Tech News","1186":"KDD","1187":"ArXiv","1188":"IEEE Intelligent Systems","1189":"AAAI","1190":"EMNLP","1191":"ACM Comput. Surv.","1192":"WSDM","1193":"IJCAI","1194":null,"1195":null,"1196":"ArXiv","1197":"ICALP","1198":"ICWSM","1199":null,"1200":null,"1201":"2019 IEEE\/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)","1202":"WWW","1203":"ICAART","1204":"ACM Comput. Surv.","1205":"Online Inf. Rev.","1206":null,"1207":"2019 Sixth International Conference on Social Networks Analysis, Management and Security (SNAMS)","1208":"IEEE Access","1209":"WWW","1210":null,"1211":"IEEE Access","1212":"System Verilog Assertions and Functional Coverage","1213":"System Verilog Assertions and Functional Coverage","1214":"IEEE Transactions on Geoscience and Remote Sensing","1215":"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","1216":"2020 IEEE International Conference on RFID (RFID)","1217":"Remote Sensing","1218":"Remote. Sens.","1219":"The Journal of Engineering","1220":"2019 International Multidisciplinary Information Technology and Engineering Conference (IMITEC)","1221":"IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","1222":"issue1","1223":"IEEE Access","1224":"Remote. Sens.","1225":"Journal of Communications and Networks","1226":"LREC","1227":"Wirtschaftsinformatik","1228":"CHI Extended Abstracts","1229":"Journal on Multimodal User Interfaces","1230":"2019 International Seminar on Application for Technology of Information and Communication (iSemantic)","1231":"Eur. J. Inf. Syst.","1232":"ArXiv","1233":"New Media Soc.","1234":"PloS one","1235":"International Journal of Advanced Robotic Systems","1236":"AIES","1237":"Trans. Emerg. Telecommun. Technol.","1238":"CHI","1239":"COMPASS","1240":"Future Internet","1241":"portal: Libraries and the Academy","1242":"HCI","1243":"CONSTRAINT@AAAI","1244":"New Media Soc.","1245":null,"1246":"WEBIST","1247":"AAAI","1248":null,"1249":"Political Analysis","1250":"ICWSM","1251":"Political Analysis","1252":"Italian Political Science Review\/Rivista Italiana di Scienza Politica","1253":"ALW","1254":"Political Analysis","1255":"Political Analysis","1256":"Political Analysis","1257":"Nature","1258":"WWW","1259":"Sci. Eng. Ethics","1260":"Journal of the Royal Statistical Society: Series A (Statistics in Society)","1261":"HT","1262":"ICWSM","1263":"WWW","1264":"Philosophy & Technology","1265":"WWW","1266":"Manag. Sci.","1267":"J. Assoc. Inf. Sci. Technol.","1268":null,"1269":"ICWSM","1270":"Communication Theory","1271":"Proceedings of the National Academy of Sciences","1272":"AI & SOCIETY","1273":"AI & SOCIETY"},"year":{"0":2021,"1":2021,"2":2021,"3":2020,"4":2020,"5":2019,"6":2020,"7":2020,"8":2021,"9":2021,"10":2020,"11":2020,"12":2020,"13":2020,"14":2020,"15":2019,"16":2019,"17":2019,"18":2020,"19":2019,"20":2021,"21":2019,"22":2019,"23":2020,"24":2020,"25":2020,"26":2020,"27":2019,"28":2019,"29":2019,"30":2019,"31":2019,"32":2020,"33":2020,"34":2020,"35":2020,"36":2020,"37":2020,"38":2020,"39":2020,"40":2020,"41":2019,"42":2019,"43":2019,"44":2019,"45":2020,"46":2021,"47":2021,"48":2020,"49":2020,"50":2020,"51":2020,"52":2020,"53":2019,"54":2020,"55":2019,"56":2019,"57":2019,"58":2019,"59":2019,"60":2019,"61":2020,"62":2021,"63":2020,"64":2021,"65":2021,"66":2021,"67":2020,"68":2019,"69":2019,"70":2021,"71":2021,"72":2021,"73":2019,"74":2021,"75":2020,"76":2020,"77":2020,"78":2019,"79":2020,"80":2019,"81":2021,"82":2019,"83":2019,"84":2020,"85":2019,"86":2020,"87":2019,"88":2019,"89":2021,"90":2020,"91":2019,"92":2019,"93":2020,"94":2020,"95":2019,"96":2020,"97":2019,"98":2021,"99":2019,"100":2019,"101":2020,"102":2019,"103":2019,"104":2019,"105":2019,"106":2021,"107":2019,"108":2020,"109":2019,"110":2019,"111":2020,"112":2020,"113":2020,"114":2020,"115":2021,"116":2021,"117":2021,"118":2022,"119":2021,"120":2021,"121":2021,"122":2021,"123":2019,"124":2021,"125":2020,"126":2021,"127":2021,"128":2021,"129":2019,"130":2020,"131":2019,"132":2020,"133":2019,"134":2019,"135":2019,"136":2019,"137":2021,"138":2021,"139":2021,"140":2021,"141":2021,"142":2021,"143":2020,"144":2020,"145":2020,"146":2020,"147":2019,"148":2019,"149":2019,"150":2019,"151":2020,"152":2020,"153":2019,"154":2019,"155":2019,"156":2019,"157":2019,"158":2020,"159":2020,"160":2020,"161":2021,"162":2021,"163":2022,"164":2019,"165":2020,"166":2021,"167":2019,"168":2020,"169":2020,"170":2020,"171":2021,"172":2021,"173":2020,"174":2020,"175":2021,"176":2020,"177":2020,"178":2021,"179":2020,"180":2020,"181":2020,"182":2020,"183":2020,"184":2020,"185":2020,"186":2020,"187":2020,"188":2020,"189":2020,"190":2019,"191":2020,"192":2019,"193":2020,"194":2019,"195":2019,"196":2019,"197":2019,"198":2019,"199":2019,"200":2019,"201":2019,"202":2019,"203":2020,"204":2019,"205":2019,"206":2019,"207":2019,"208":2019,"209":2021,"210":2020,"211":2019,"212":2019,"213":2020,"214":2019,"215":2020,"216":2020,"217":2020,"218":2020,"219":2021,"220":2021,"221":2020,"222":2020,"223":2021,"224":2020,"225":2020,"226":2020,"227":2020,"228":2020,"229":2020,"230":2019,"231":2020,"232":2020,"233":2020,"234":2020,"235":2019,"236":2019,"237":2019,"238":2019,"239":2019,"240":2019,"241":2020,"242":2020,"243":2021,"244":2020,"245":2020,"246":2020,"247":2020,"248":2019,"249":2020,"250":2020,"251":2020,"252":2020,"253":2021,"254":2020,"255":2020,"256":2019,"257":2019,"258":2019,"259":2020,"260":2019,"261":2019,"262":2019,"263":2020,"264":2022,"265":2021,"266":2020,"267":2020,"268":2021,"269":2020,"270":2021,"271":2020,"272":2020,"273":2019,"274":2020,"275":2020,"276":2019,"277":2020,"278":2020,"279":2020,"280":2019,"281":2020,"282":2019,"283":2019,"284":2019,"285":2019,"286":2019,"287":2019,"288":2020,"289":2019,"290":2020,"291":2019,"292":2019,"293":2020,"294":2019,"295":2021,"296":2020,"297":2020,"298":2020,"299":2020,"300":2019,"301":2020,"302":2020,"303":2019,"304":2019,"305":2019,"306":2021,"307":2020,"308":2021,"309":2019,"310":2019,"311":2020,"312":2021,"313":2020,"314":2021,"315":2021,"316":2020,"317":2019,"318":2021,"319":2020,"320":2020,"321":2020,"322":2020,"323":2019,"324":2019,"325":2020,"326":2020,"327":2021,"328":2019,"329":2021,"330":2019,"331":2019,"332":2020,"333":2020,"334":2021,"335":2019,"336":2020,"337":2021,"338":2020,"339":2021,"340":2019,"341":2019,"342":2019,"343":2021,"344":2021,"345":2020,"346":2019,"347":2020,"348":2019,"349":2020,"350":2019,"351":2020,"352":2019,"353":2020,"354":2020,"355":2020,"356":2020,"357":2019,"358":2019,"359":2019,"360":2020,"361":2019,"362":2020,"363":2020,"364":2019,"365":2021,"366":2020,"367":2020,"368":2019,"369":2021,"370":2021,"371":2021,"372":2020,"373":2021,"374":2020,"375":2020,"376":2020,"377":2020,"378":2020,"379":2021,"380":2019,"381":2021,"382":2019,"383":2021,"384":2021,"385":2020,"386":2021,"387":2021,"388":2021,"389":2020,"390":2019,"391":2019,"392":2019,"393":2019,"394":2019,"395":2019,"396":2021,"397":2019,"398":2019,"399":2021,"400":2019,"401":2020,"402":2020,"403":2019,"404":2020,"405":2019,"406":2019,"407":2019,"408":2019,"409":2020,"410":2019,"411":2021,"412":2019,"413":2021,"414":2020,"415":2020,"416":2021,"417":2021,"418":2021,"419":2021,"420":2020,"421":2020,"422":2020,"423":2020,"424":2021,"425":2020,"426":2020,"427":2020,"428":2020,"429":2020,"430":2020,"431":2020,"432":2020,"433":2021,"434":2019,"435":2019,"436":2019,"437":2019,"438":2019,"439":2019,"440":2019,"441":2019,"442":2019,"443":2019,"444":2019,"445":2020,"446":2021,"447":2021,"448":2021,"449":2021,"450":2021,"451":2021,"452":2020,"453":2019,"454":2019,"455":2019,"456":2019,"457":2021,"458":2021,"459":2021,"460":2021,"461":2020,"462":2019,"463":2020,"464":2020,"465":2021,"466":2021,"467":2021,"468":2021,"469":2021,"470":2019,"471":2020,"472":2020,"473":2020,"474":2020,"475":2020,"476":2019,"477":2019,"478":2020,"479":2020,"480":2020,"481":2020,"482":2019,"483":2020,"484":2020,"485":2020,"486":2020,"487":2019,"488":2020,"489":2020,"490":2019,"491":2019,"492":2019,"493":2019,"494":2019,"495":2019,"496":2019,"497":2019,"498":2019,"499":2019,"500":2019,"501":2019,"502":2019,"503":2019,"504":2019,"505":2019,"506":2019,"507":2019,"508":2019,"509":2019,"510":2021,"511":2021,"512":2021,"513":2020,"514":2019,"515":2020,"516":2019,"517":2019,"518":2019,"519":2019,"520":2019,"521":2021,"522":2020,"523":2022,"524":2021,"525":2022,"526":2019,"527":2021,"528":2020,"529":2022,"530":2021,"531":2019,"532":2020,"533":2019,"534":2021,"535":2019,"536":2020,"537":2019,"538":2022,"539":2019,"540":2019,"541":2020,"542":2019,"543":2019,"544":2019,"545":2019,"546":2019,"547":2019,"548":2019,"549":2021,"550":2020,"551":2020,"552":2019,"553":2019,"554":2019,"555":2019,"556":2019,"557":2019,"558":2019,"559":2020,"560":2019,"561":2020,"562":2020,"563":2019,"564":2019,"565":2020,"566":2019,"567":2019,"568":2019,"569":2019,"570":2020,"571":2020,"572":2019,"573":2019,"574":2020,"575":2019,"576":2020,"577":2020,"578":2020,"579":2020,"580":2021,"581":2019,"582":2019,"583":2021,"584":2020,"585":2020,"586":2020,"587":2021,"588":2020,"589":2021,"590":2021,"591":2019,"592":2020,"593":2019,"594":2019,"595":2020,"596":2020,"597":2019,"598":2020,"599":2021,"600":2019,"601":2021,"602":2019,"603":2020,"604":2020,"605":2019,"606":2019,"607":2020,"608":2019,"609":2020,"610":2019,"611":2019,"612":2019,"613":2019,"614":2021,"615":2019,"616":2021,"617":2019,"618":2020,"619":2019,"620":2019,"621":2021,"622":2019,"623":2020,"624":2019,"625":2019,"626":2020,"627":2021,"628":2020,"629":2021,"630":2020,"631":2019,"632":2021,"633":2019,"634":2019,"635":2019,"636":2019,"637":2020,"638":2021,"639":2020,"640":2019,"641":2019,"642":2019,"643":2019,"644":2019,"645":2019,"646":2019,"647":2019,"648":2021,"649":2020,"650":2020,"651":2020,"652":2019,"653":2020,"654":2019,"655":2019,"656":2019,"657":2019,"658":2020,"659":2020,"660":2020,"661":2019,"662":2020,"663":2019,"664":2020,"665":2020,"666":2019,"667":2020,"668":2021,"669":2019,"670":2019,"671":2019,"672":2020,"673":2019,"674":2019,"675":2019,"676":2020,"677":2020,"678":2019,"679":2020,"680":2019,"681":2020,"682":2019,"683":2021,"684":2019,"685":2019,"686":2019,"687":2019,"688":2020,"689":2021,"690":2019,"691":2020,"692":2020,"693":2019,"694":2021,"695":2020,"696":2020,"697":2019,"698":2020,"699":2020,"700":2020,"701":2020,"702":2020,"703":2019,"704":2020,"705":2020,"706":2021,"707":2020,"708":2021,"709":2019,"710":2021,"711":2020,"712":2019,"713":2020,"714":2019,"715":2019,"716":2020,"717":2020,"718":2019,"719":2019,"720":2019,"721":2019,"722":2019,"723":2019,"724":2019,"725":2020,"726":2020,"727":2021,"728":2020,"729":2021,"730":2021,"731":2020,"732":2020,"733":2020,"734":2020,"735":2019,"736":2020,"737":2019,"738":2020,"739":2019,"740":2020,"741":2019,"742":2021,"743":2019,"744":2019,"745":2019,"746":2020,"747":2020,"748":2021,"749":2022,"750":2019,"751":2022,"752":2019,"753":2020,"754":2019,"755":2019,"756":2020,"757":2019,"758":2021,"759":2022,"760":2020,"761":2020,"762":2019,"763":2019,"764":2019,"765":2019,"766":2020,"767":2019,"768":2021,"769":2021,"770":2021,"771":2021,"772":2021,"773":2019,"774":2020,"775":2020,"776":2020,"777":2021,"778":2021,"779":2019,"780":2019,"781":2021,"782":2021,"783":2019,"784":2019,"785":2022,"786":2019,"787":2019,"788":2019,"789":2019,"790":2020,"791":2021,"792":2020,"793":2019,"794":2020,"795":2019,"796":2021,"797":2021,"798":2019,"799":2021,"800":2019,"801":2019,"802":2019,"803":2020,"804":2020,"805":2020,"806":2019,"807":2020,"808":2020,"809":2021,"810":2019,"811":2019,"812":2021,"813":2020,"814":2020,"815":2019,"816":2020,"817":2019,"818":2020,"819":2019,"820":2022,"821":2019,"822":2022,"823":2021,"824":2019,"825":2021,"826":2019,"827":2019,"828":2020,"829":2021,"830":2020,"831":2019,"832":2019,"833":2021,"834":2021,"835":2019,"836":2020,"837":2020,"838":2021,"839":2021,"840":2020,"841":2021,"842":2021,"843":2021,"844":2020,"845":2019,"846":2020,"847":2019,"848":2020,"849":2021,"850":2020,"851":2020,"852":2021,"853":2021,"854":2020,"855":2021,"856":2021,"857":2020,"858":2022,"859":2021,"860":2021,"861":2021,"862":2021,"863":2021,"864":2021,"865":2020,"866":2020,"867":2020,"868":2020,"869":2020,"870":2019,"871":2019,"872":2021,"873":2021,"874":2020,"875":2021,"876":2022,"877":2022,"878":2021,"879":2019,"880":2020,"881":2019,"882":2020,"883":2019,"884":2019,"885":2019,"886":2021,"887":2021,"888":2021,"889":2021,"890":2021,"891":2022,"892":2020,"893":2021,"894":2021,"895":2021,"896":2020,"897":2019,"898":2020,"899":2019,"900":2020,"901":2020,"902":2020,"903":2020,"904":2020,"905":2020,"906":2020,"907":2019,"908":2019,"909":2019,"910":2019,"911":2019,"912":2020,"913":2020,"914":2022,"915":2022,"916":2019,"917":2021,"918":2021,"919":2022,"920":2021,"921":2022,"922":2021,"923":2019,"924":2020,"925":2021,"926":2022,"927":2022,"928":2021,"929":2019,"930":2021,"931":2021,"932":2020,"933":2022,"934":2022,"935":2021,"936":2021,"937":2020,"938":2019,"939":2019,"940":2019,"941":2019,"942":2019,"943":2019,"944":2019,"945":2020,"946":2019,"947":2019,"948":2019,"949":2020,"950":2020,"951":2019,"952":2020,"953":2019,"954":2019,"955":2019,"956":2019,"957":2020,"958":2020,"959":2019,"960":2020,"961":2020,"962":2019,"963":2020,"964":2019,"965":2019,"966":2019,"967":2020,"968":2020,"969":2019,"970":2019,"971":2020,"972":2019,"973":2021,"974":2019,"975":2020,"976":2020,"977":2019,"978":2019,"979":2020,"980":2019,"981":2020,"982":2021,"983":2021,"984":2021,"985":2021,"986":2020,"987":2019,"988":2019,"989":2019,"990":2020,"991":2020,"992":2019,"993":2020,"994":2019,"995":2021,"996":2021,"997":2020,"998":2020,"999":2019,"1000":2019,"1001":2019,"1002":2020,"1003":2020,"1004":2019,"1005":2019,"1006":2019,"1007":2019,"1008":2020,"1009":2020,"1010":2019,"1011":2019,"1012":2021,"1013":2019,"1014":2019,"1015":2019,"1016":2019,"1017":2019,"1018":2019,"1019":2019,"1020":2019,"1021":2020,"1022":2019,"1023":2021,"1024":2021,"1025":2019,"1026":2019,"1027":2019,"1028":2019,"1029":2020,"1030":2019,"1031":2020,"1032":2020,"1033":2019,"1034":2019,"1035":2019,"1036":2020,"1037":2019,"1038":2019,"1039":2019,"1040":2019,"1041":2020,"1042":2020,"1043":2020,"1044":2021,"1045":2019,"1046":2019,"1047":2020,"1048":2020,"1049":2021,"1050":2019,"1051":2020,"1052":2020,"1053":2020,"1054":2020,"1055":2021,"1056":2021,"1057":2020,"1058":2020,"1059":2020,"1060":2019,"1061":2020,"1062":2019,"1063":2020,"1064":2020,"1065":2020,"1066":2019,"1067":2019,"1068":2020,"1069":2020,"1070":2019,"1071":2020,"1072":2020,"1073":2020,"1074":2020,"1075":2019,"1076":2020,"1077":2019,"1078":2020,"1079":2020,"1080":2019,"1081":2020,"1082":2020,"1083":2020,"1084":2019,"1085":2019,"1086":2019,"1087":2019,"1088":2019,"1089":2019,"1090":2019,"1091":2020,"1092":2020,"1093":2019,"1094":2021,"1095":2020,"1096":2021,"1097":2020,"1098":2020,"1099":2020,"1100":2020,"1101":2019,"1102":2019,"1103":2019,"1104":2019,"1105":2019,"1106":2019,"1107":2019,"1108":2020,"1109":2020,"1110":2019,"1111":2020,"1112":2020,"1113":2020,"1114":2020,"1115":2020,"1116":2020,"1117":2020,"1118":2019,"1119":2019,"1120":2019,"1121":2019,"1122":2019,"1123":2019,"1124":2019,"1125":2019,"1126":2019,"1127":2019,"1128":2019,"1129":2019,"1130":2019,"1131":2019,"1132":2019,"1133":2020,"1134":2020,"1135":2019,"1136":2020,"1137":2020,"1138":2020,"1139":2019,"1140":2020,"1141":2019,"1142":2019,"1143":2019,"1144":2019,"1145":2019,"1146":2020,"1147":2019,"1148":2019,"1149":2019,"1150":2019,"1151":2020,"1152":2020,"1153":2019,"1154":2019,"1155":2020,"1156":2019,"1157":2019,"1158":2020,"1159":2021,"1160":2021,"1161":2020,"1162":2019,"1163":2020,"1164":2021,"1165":2021,"1166":2021,"1167":2021,"1168":2021,"1169":2021,"1170":2021,"1171":2022,"1172":2019,"1173":2020,"1174":2020,"1175":2020,"1176":2020,"1177":2021,"1178":2019,"1179":2019,"1180":2019,"1181":2019,"1182":2021,"1183":2021,"1184":2019,"1185":2019,"1186":2019,"1187":2019,"1188":2019,"1189":2019,"1190":2019,"1191":2020,"1192":2019,"1193":2019,"1194":2020,"1195":2019,"1196":2020,"1197":2019,"1198":2019,"1199":2020,"1200":2019,"1201":2019,"1202":2019,"1203":2019,"1204":2020,"1205":2019,"1206":2020,"1207":2019,"1208":2020,"1209":2019,"1210":2020,"1211":2020,"1212":2019,"1213":2019,"1214":2021,"1215":2021,"1216":2020,"1217":2020,"1218":2019,"1219":2019,"1220":2019,"1221":2019,"1222":2019,"1223":2022,"1224":2019,"1225":2019,"1226":2019,"1227":2019,"1228":2019,"1229":2019,"1230":2019,"1231":2020,"1232":2020,"1233":2020,"1234":2019,"1235":2019,"1236":2019,"1237":2019,"1238":2020,"1239":2020,"1240":2020,"1241":2019,"1242":2020,"1243":2021,"1244":2020,"1245":2021,"1246":2019,"1247":2020,"1248":2020,"1249":2020,"1250":2019,"1251":2020,"1252":2021,"1253":2020,"1254":2020,"1255":2020,"1256":2021,"1257":2019,"1258":2019,"1259":2021,"1260":2020,"1261":2019,"1262":2020,"1263":2021,"1264":2020,"1265":2019,"1266":2020,"1267":2021,"1268":2020,"1269":2019,"1270":2019,"1271":2021,"1272":2020,"1273":2019},"influentialCitationCount":{"0":0,"1":2,"2":1,"3":3,"4":0,"5":0,"6":2,"7":2,"8":1,"9":2,"10":2,"11":0,"12":1,"13":2,"14":0,"15":6,"16":9,"17":0,"18":0,"19":4,"20":20,"21":17,"22":12,"23":1,"24":4,"25":0,"26":1,"27":5,"28":4,"29":2,"30":1,"31":1,"32":5,"33":6,"34":7,"35":1,"36":6,"37":3,"38":7,"39":4,"40":1,"41":3,"42":3,"43":1,"44":3,"45":20,"46":5,"47":1,"48":0,"49":30,"50":8,"51":7,"52":2,"53":18,"54":0,"55":10,"56":3,"57":5,"58":0,"59":1,"60":0,"61":0,"62":0,"63":1,"64":1,"65":0,"66":0,"67":0,"68":2,"69":2,"70":0,"71":1,"72":0,"73":0,"74":4,"75":1,"76":2,"77":0,"78":1,"79":1,"80":2,"81":0,"82":1,"83":0,"84":0,"85":3,"86":0,"87":0,"88":0,"89":0,"90":1,"91":0,"92":0,"93":1,"94":1,"95":12,"96":2,"97":2,"98":2,"99":6,"100":23,"101":6,"102":4,"103":11,"104":3,"105":4,"106":0,"107":4,"108":4,"109":4,"110":3,"111":0,"112":0,"113":4,"114":4,"115":0,"116":0,"117":0,"118":0,"119":0,"120":0,"121":0,"122":0,"123":22,"124":0,"125":0,"126":0,"127":0,"128":0,"129":2,"130":0,"131":1,"132":0,"133":6,"134":1,"135":3,"136":0,"137":0,"138":0,"139":0,"140":0,"141":0,"142":0,"143":0,"144":0,"145":0,"146":0,"147":1,"148":1,"149":0,"150":0,"151":1,"152":0,"153":1,"154":0,"155":0,"156":0,"157":0,"158":0,"159":0,"160":0,"161":0,"162":0,"163":0,"164":0,"165":0,"166":0,"167":25,"168":0,"169":17,"170":3,"171":11,"172":2,"173":1,"174":16,"175":1,"176":5,"177":4,"178":1,"179":2,"180":1,"181":0,"182":1,"183":2,"184":1,"185":1,"186":0,"187":3,"188":1,"189":0,"190":16,"191":0,"192":0,"193":0,"194":10,"195":9,"196":10,"197":0,"198":3,"199":0,"200":6,"201":5,"202":0,"203":0,"204":1,"205":1,"206":0,"207":0,"208":0,"209":10,"210":20,"211":13,"212":10,"213":5,"214":43,"215":18,"216":8,"217":14,"218":0,"219":1,"220":1,"221":1,"222":1,"223":3,"224":5,"225":4,"226":4,"227":0,"228":5,"229":7,"230":21,"231":0,"232":3,"233":2,"234":0,"235":6,"236":2,"237":1,"238":1,"239":0,"240":0,"241":11,"242":2,"243":1,"244":17,"245":9,"246":0,"247":8,"248":11,"249":0,"250":1,"251":6,"252":1,"253":0,"254":3,"255":1,"256":20,"257":36,"258":7,"259":1,"260":2,"261":0,"262":0,"263":72,"264":18,"265":14,"266":9,"267":37,"268":1,"269":16,"270":1,"271":6,"272":22,"273":8,"274":6,"275":4,"276":2,"277":1,"278":1,"279":0,"280":0,"281":2,"282":5,"283":2,"284":1,"285":1,"286":1,"287":1,"288":5,"289":95,"290":8,"291":23,"292":19,"293":1,"294":1,"295":0,"296":3,"297":0,"298":0,"299":1,"300":0,"301":2,"302":0,"303":2,"304":1,"305":0,"306":0,"307":0,"308":1,"309":0,"310":1,"311":2,"312":0,"313":0,"314":0,"315":3,"316":1,"317":0,"318":2,"319":0,"320":0,"321":0,"322":1,"323":0,"324":0,"325":0,"326":0,"327":0,"328":0,"329":0,"330":0,"331":1,"332":3,"333":0,"334":0,"335":0,"336":0,"337":2,"338":0,"339":2,"340":0,"341":0,"342":1,"343":0,"344":2,"345":0,"346":0,"347":0,"348":2,"349":0,"350":0,"351":0,"352":0,"353":1,"354":2,"355":0,"356":1,"357":0,"358":0,"359":0,"360":0,"361":1,"362":0,"363":0,"364":0,"365":1,"366":0,"367":0,"368":0,"369":0,"370":0,"371":0,"372":2,"373":2,"374":0,"375":1,"376":0,"377":0,"378":0,"379":1,"380":0,"381":0,"382":0,"383":0,"384":0,"385":3,"386":0,"387":2,"388":0,"389":5,"390":48,"391":149,"392":35,"393":0,"394":0,"395":6,"396":0,"397":1,"398":4,"399":0,"400":1,"401":0,"402":0,"403":7,"404":8,"405":4,"406":60,"407":7,"408":2,"409":4,"410":2,"411":1,"412":5,"413":2,"414":1,"415":0,"416":0,"417":0,"418":0,"419":0,"420":1,"421":0,"422":0,"423":1,"424":0,"425":1,"426":0,"427":0,"428":0,"429":0,"430":0,"431":0,"432":0,"433":0,"434":1,"435":1,"436":0,"437":2,"438":2,"439":1,"440":0,"441":0,"442":0,"443":0,"444":0,"445":4,"446":1,"447":0,"448":0,"449":0,"450":0,"451":0,"452":1,"453":0,"454":1,"455":0,"456":0,"457":0,"458":0,"459":0,"460":0,"461":2,"462":1,"463":1,"464":0,"465":1,"466":0,"467":0,"468":0,"469":0,"470":8,"471":0,"472":0,"473":0,"474":0,"475":0,"476":0,"477":5,"478":1,"479":1,"480":0,"481":0,"482":0,"483":0,"484":0,"485":1,"486":0,"487":0,"488":0,"489":0,"490":0,"491":0,"492":3,"493":0,"494":0,"495":0,"496":0,"497":0,"498":0,"499":0,"500":0,"501":0,"502":0,"503":0,"504":0,"505":0,"506":0,"507":0,"508":0,"509":0,"510":3,"511":0,"512":0,"513":0,"514":1,"515":0,"516":0,"517":1,"518":1,"519":1,"520":0,"521":0,"522":0,"523":0,"524":0,"525":0,"526":0,"527":0,"528":0,"529":0,"530":0,"531":0,"532":0,"533":0,"534":0,"535":0,"536":0,"537":0,"538":0,"539":6,"540":0,"541":2,"542":5,"543":0,"544":5,"545":1,"546":0,"547":4,"548":0,"549":1,"550":1,"551":1,"552":0,"553":2,"554":0,"555":0,"556":0,"557":4,"558":7,"559":1,"560":1,"561":0,"562":0,"563":1,"564":3,"565":0,"566":0,"567":2,"568":1,"569":2,"570":0,"571":0,"572":3,"573":0,"574":0,"575":0,"576":0,"577":0,"578":0,"579":0,"580":0,"581":0,"582":0,"583":0,"584":1,"585":0,"586":0,"587":0,"588":0,"589":0,"590":1,"591":0,"592":0,"593":1,"594":0,"595":2,"596":3,"597":1,"598":0,"599":8,"600":6,"601":0,"602":0,"603":0,"604":0,"605":0,"606":3,"607":1,"608":1,"609":2,"610":1,"611":0,"612":0,"613":1,"614":0,"615":0,"616":0,"617":3,"618":0,"619":0,"620":0,"621":0,"622":0,"623":0,"624":0,"625":0,"626":0,"627":0,"628":0,"629":0,"630":0,"631":0,"632":0,"633":0,"634":3,"635":2,"636":0,"637":4,"638":0,"639":0,"640":1,"641":4,"642":1,"643":0,"644":0,"645":1,"646":0,"647":0,"648":2,"649":0,"650":1,"651":0,"652":1,"653":0,"654":0,"655":0,"656":0,"657":2,"658":0,"659":0,"660":0,"661":0,"662":0,"663":1,"664":0,"665":0,"666":0,"667":0,"668":0,"669":0,"670":0,"671":0,"672":0,"673":0,"674":0,"675":0,"676":0,"677":1,"678":0,"679":0,"680":1,"681":0,"682":1,"683":0,"684":0,"685":1,"686":0,"687":0,"688":2,"689":0,"690":0,"691":2,"692":0,"693":0,"694":0,"695":0,"696":24,"697":1,"698":1,"699":0,"700":1,"701":0,"702":0,"703":0,"704":0,"705":0,"706":0,"707":0,"708":0,"709":0,"710":0,"711":0,"712":0,"713":0,"714":0,"715":0,"716":0,"717":0,"718":15,"719":12,"720":20,"721":57,"722":28,"723":1,"724":37,"725":5,"726":4,"727":2,"728":40,"729":3,"730":0,"731":8,"732":9,"733":1,"734":0,"735":20,"736":0,"737":0,"738":1,"739":0,"740":0,"741":1,"742":3,"743":2,"744":1,"745":0,"746":0,"747":0,"748":0,"749":0,"750":1,"751":0,"752":0,"753":1,"754":5,"755":3,"756":2,"757":240,"758":2,"759":0,"760":0,"761":0,"762":20,"763":16,"764":1,"765":0,"766":0,"767":3,"768":4,"769":0,"770":4,"771":0,"772":0,"773":3,"774":2,"775":9,"776":8,"777":0,"778":0,"779":27,"780":40,"781":2,"782":0,"783":4,"784":19,"785":0,"786":0,"787":5,"788":0,"789":10,"790":0,"791":9,"792":1,"793":0,"794":0,"795":3,"796":0,"797":0,"798":0,"799":0,"800":11,"801":57,"802":0,"803":0,"804":0,"805":0,"806":0,"807":0,"808":0,"809":0,"810":0,"811":0,"812":0,"813":0,"814":1,"815":0,"816":0,"817":0,"818":0,"819":2,"820":0,"821":0,"822":0,"823":2,"824":0,"825":0,"826":0,"827":0,"828":0,"829":0,"830":1,"831":0,"832":1,"833":0,"834":0,"835":0,"836":0,"837":0,"838":0,"839":0,"840":2,"841":2,"842":2,"843":0,"844":0,"845":0,"846":0,"847":0,"848":0,"849":0,"850":0,"851":0,"852":0,"853":0,"854":0,"855":0,"856":0,"857":0,"858":0,"859":0,"860":0,"861":0,"862":0,"863":0,"864":0,"865":1,"866":1,"867":0,"868":0,"869":0,"870":1,"871":0,"872":0,"873":0,"874":5,"875":0,"876":0,"877":0,"878":0,"879":11,"880":1,"881":0,"882":0,"883":2,"884":3,"885":0,"886":0,"887":0,"888":0,"889":0,"890":0,"891":1,"892":0,"893":0,"894":0,"895":0,"896":2,"897":4,"898":1,"899":3,"900":0,"901":0,"902":0,"903":0,"904":1,"905":0,"906":1,"907":0,"908":0,"909":0,"910":0,"911":0,"912":0,"913":0,"914":0,"915":0,"916":1,"917":0,"918":0,"919":0,"920":0,"921":0,"922":0,"923":0,"924":0,"925":0,"926":0,"927":0,"928":0,"929":0,"930":0,"931":0,"932":0,"933":0,"934":0,"935":0,"936":0,"937":0,"938":2,"939":7,"940":11,"941":1,"942":0,"943":1,"944":3,"945":8,"946":12,"947":7,"948":6,"949":3,"950":2,"951":1,"952":31,"953":25,"954":23,"955":17,"956":0,"957":1,"958":1,"959":1,"960":0,"961":0,"962":0,"963":0,"964":0,"965":0,"966":1,"967":1,"968":9,"969":0,"970":1,"971":0,"972":1,"973":0,"974":0,"975":4,"976":8,"977":21,"978":34,"979":3,"980":1,"981":1,"982":0,"983":2,"984":0,"985":0,"986":1,"987":4,"988":1,"989":0,"990":10,"991":0,"992":0,"993":1,"994":0,"995":2,"996":1,"997":4,"998":5,"999":13,"1000":14,"1001":7,"1002":0,"1003":1,"1004":0,"1005":2,"1006":1,"1007":31,"1008":1,"1009":0,"1010":4,"1011":1,"1012":1,"1013":2,"1014":1,"1015":0,"1016":0,"1017":0,"1018":0,"1019":4,"1020":1,"1021":0,"1022":0,"1023":1,"1024":0,"1025":0,"1026":2,"1027":0,"1028":6,"1029":2,"1030":0,"1031":0,"1032":3,"1033":0,"1034":0,"1035":0,"1036":0,"1037":0,"1038":0,"1039":0,"1040":0,"1041":0,"1042":0,"1043":1,"1044":0,"1045":3,"1046":1,"1047":0,"1048":0,"1049":1,"1050":0,"1051":1,"1052":0,"1053":2,"1054":0,"1055":0,"1056":0,"1057":3,"1058":2,"1059":3,"1060":31,"1061":3,"1062":7,"1063":5,"1064":3,"1065":1,"1066":6,"1067":4,"1068":9,"1069":0,"1070":4,"1071":0,"1072":0,"1073":0,"1074":6,"1075":0,"1076":2,"1077":1,"1078":1,"1079":19,"1080":4,"1081":4,"1082":6,"1083":0,"1084":0,"1085":3,"1086":1,"1087":2,"1088":2,"1089":0,"1090":1,"1091":0,"1092":11,"1093":6,"1094":2,"1095":21,"1096":2,"1097":1,"1098":7,"1099":14,"1100":12,"1101":58,"1102":4,"1103":37,"1104":10,"1105":7,"1106":24,"1107":32,"1108":0,"1109":3,"1110":16,"1111":5,"1112":1,"1113":4,"1114":0,"1115":2,"1116":2,"1117":0,"1118":6,"1119":5,"1120":2,"1121":1,"1122":1,"1123":1,"1124":5,"1125":1,"1126":2,"1127":1,"1128":0,"1129":44,"1130":12,"1131":6,"1132":6,"1133":0,"1134":10,"1135":1,"1136":0,"1137":0,"1138":5,"1139":2,"1140":1,"1141":0,"1142":2,"1143":0,"1144":0,"1145":0,"1146":0,"1147":1,"1148":0,"1149":1,"1150":0,"1151":0,"1152":1,"1153":0,"1154":1,"1155":0,"1156":9,"1157":1,"1158":0,"1159":0,"1160":0,"1161":0,"1162":1,"1163":0,"1164":0,"1165":0,"1166":0,"1167":0,"1168":0,"1169":0,"1170":0,"1171":0,"1172":0,"1173":0,"1174":0,"1175":0,"1176":0,"1177":0,"1178":1,"1179":0,"1180":0,"1181":0,"1182":3,"1183":0,"1184":1,"1185":0,"1186":24,"1187":10,"1188":8,"1189":4,"1190":20,"1191":2,"1192":3,"1193":14,"1194":0,"1195":1,"1196":3,"1197":0,"1198":13,"1199":2,"1200":11,"1201":6,"1202":1,"1203":4,"1204":2,"1205":0,"1206":0,"1207":0,"1208":0,"1209":2,"1210":0,"1211":0,"1212":0,"1213":0,"1214":0,"1215":0,"1216":0,"1217":0,"1218":0,"1219":0,"1220":0,"1221":0,"1222":0,"1223":0,"1224":0,"1225":1,"1226":3,"1227":1,"1228":0,"1229":1,"1230":0,"1231":6,"1232":4,"1233":2,"1234":0,"1235":3,"1236":3,"1237":0,"1238":1,"1239":1,"1240":1,"1241":0,"1242":1,"1243":1,"1244":1,"1245":0,"1246":1,"1247":2,"1248":1,"1249":0,"1250":0,"1251":1,"1252":0,"1253":3,"1254":0,"1255":0,"1256":0,"1257":6,"1258":2,"1259":0,"1260":0,"1261":0,"1262":0,"1263":0,"1264":3,"1265":0,"1266":0,"1267":0,"1268":0,"1269":2,"1270":0,"1271":0,"1272":0,"1273":2},"fieldsOfStudy":{"0":"['Computer Science']","1":"['Computer Science']","2":"['Computer Science']","3":"['Computer Science']","4":"['Computer Science']","5":"['Computer Science']","6":"['Computer Science']","7":"['Computer Science']","8":"['Computer Science']","9":"['Computer Science']","10":"['Computer Science', 'Psychology', 'Medicine']","11":"['Computer Science']","12":"['Computer Science']","13":"['Computer Science']","14":"['Computer Science']","15":"['Computer Science']","16":"['Computer Science']","17":"['Computer Science']","18":"['Computer Science']","19":"['Computer Science']","20":"['Computer Science']","21":"['Computer Science']","22":"['Computer Science']","23":"['Computer Science']","24":"['Computer Science']","25":"['Computer Science']","26":"['Computer Science', 'Medicine']","27":"['Computer Science']","28":"['Computer Science', 'Mathematics']","29":"['Computer Science']","30":"['Computer Science']","31":"['Computer Science', 'Medicine']","32":"['Computer Science']","33":"['Computer Science']","34":"['Computer Science']","35":"['Computer Science']","36":"['Computer Science']","37":"['Computer Science']","38":"['Computer Science']","39":"['Computer Science']","40":"['Computer Science']","41":"['Computer Science']","42":"['Computer Science']","43":"['Computer Science']","44":"['Computer Science']","45":"['Computer Science']","46":"['Computer Science']","47":"['Computer Science']","48":"['Computer Science']","49":"['Computer Science']","50":"['Computer Science']","51":"['Computer Science']","52":"['Computer Science']","53":"['Computer Science']","54":"['Computer Science']","55":"['Computer Science']","56":"['Computer Science']","57":"['Computer Science']","58":"['Computer Science', 'Medicine']","59":"['Computer Science']","60":"['Computer Science', 'Psychology']","61":"['Computer Science']","62":"['Computer Science']","63":"['Computer Science']","64":"['Computer Science']","65":"['Computer Science']","66":"['Computer Science']","67":"['Computer Science']","68":"['Computer Science']","69":"['Computer Science']","70":"['Computer Science']","71":"['Computer Science']","72":"['Computer Science']","73":"['Psychology', 'Computer Science']","74":"['Computer Science']","75":"['Computer Science', 'Engineering', 'Mathematics']","76":"['Computer Science']","77":"['Computer Science']","78":"['Computer Science']","79":"['Computer Science']","80":"['Computer Science', 'Mathematics']","81":"['Computer Science']","82":"['Computer Science']","83":"['Computer Science']","84":"['Computer Science', 'Political Science']","85":"['Computer Science', 'Political Science']","86":"['Computer Science']","87":"['Computer Science', 'Engineering']","88":"['Computer Science', 'Mathematics']","89":"['Computer Science']","90":"['Computer Science']","91":"['Computer Science', 'Medicine']","92":"['Computer Science']","93":"['Computer Science']","94":"['Computer Science', 'Sociology']","95":"['Computer Science']","96":"['Computer Science']","97":"['Computer Science', 'Sociology']","98":"['Medicine', 'Computer Science']","99":"['Medicine', 'Computer Science']","100":"['Computer Science']","101":"['Computer Science']","102":"['Medicine', 'Computer Science']","103":"['Computer Science']","104":"['Computer Science', 'Physics', 'Engineering']","105":"['Computer Science']","106":"['Computer Science']","107":"['Biology', 'Computer Science']","108":"['Medicine', 'Computer Science']","109":"['Computer Science', 'Mathematics']","110":"['Computer Science']","111":"['Computer Science', 'Sociology']","112":"['Computer Science', 'Engineering', 'Mathematics']","113":"['Computer Science']","114":"['Computer Science']","115":"['Computer Science']","116":"['Computer Science', 'Medicine']","117":"['Sociology', 'Computer Science']","118":"['Computer Science']","119":"['Computer Science']","120":"['Computer Science']","121":"['Computer Science']","122":"['Computer Science']","123":"['Computer Science']","124":"['Computer Science']","125":"['Computer Science']","126":"['Computer Science']","127":"['Computer Science']","128":"['Computer Science']","129":"['Computer Science']","130":"['Computer Science']","131":"['Computer Science']","132":"['Computer Science']","133":"['Computer Science']","134":"['Computer Science', 'Mathematics', 'Psychology']","135":"['Computer Science']","136":"['Computer Science']","137":"['Computer Science']","138":"['Computer Science']","139":"['Computer Science']","140":"['Computer Science']","141":"['Computer Science']","142":"['Computer Science']","143":"['Computer Science']","144":"['Computer Science']","145":"['Computer Science']","146":"['Computer Science']","147":"['Computer Science']","148":"['Computer Science']","149":"['Computer Science', 'Sociology']","150":"['Computer Science']","151":"['Computer Science']","152":"['Computer Science']","153":"['Computer Science', 'Psychology']","154":"['Computer Science']","155":"['Computer Science']","156":"['Computer Science']","157":"['Computer Science', 'Medicine', 'Psychology']","158":"['Medicine', 'Computer Science']","159":"['Computer Science']","160":"['Computer Science']","161":"['Computer Science']","162":"['Computer Science']","163":"['Computer Science']","164":"['Computer Science']","165":"['Computer Science']","166":"['Computer Science']","167":"['Computer Science', 'Mathematics', 'Psychology']","168":"['Computer Science']","169":"['Computer Science']","170":"['Computer Science', 'Medicine']","171":"['Computer Science']","172":"['Computer Science']","173":"['Computer Science']","174":"['Computer Science']","175":"['Computer Science']","176":"['Computer Science']","177":"['Computer Science']","178":"['Computer Science']","179":"['Computer Science']","180":"['Computer Science']","181":"['Computer Science']","182":"['Computer Science', 'Medicine']","183":"['Computer Science']","184":"['Computer Science']","185":"['Computer Science']","186":"['Computer Science']","187":"['Computer Science']","188":"['Computer Science']","189":"['Computer Science']","190":"['Computer Science']","191":"['Computer Science']","192":"['Computer Science', 'Medicine']","193":"['Computer Science', 'Mathematics']","194":"['Mathematics', 'Computer Science']","195":"['Computer Science']","196":"['Computer Science']","197":"['Computer Science']","198":"['Computer Science']","199":"['Computer Science']","200":"['Computer Science']","201":"['Computer Science']","202":"['Computer Science']","203":"['Computer Science', 'Medicine']","204":"['Computer Science']","205":"['Computer Science']","206":"['Computer Science', 'Psychology']","207":"['Computer Science']","208":"['Computer Science']","209":"['Computer Science']","210":"['Computer Science']","211":"['Computer Science']","212":"['Computer Science']","213":"['Computer Science', 'Medicine']","214":"['Computer Science', 'Mathematics']","215":"['Computer Science']","216":"['Computer Science', 'Mathematics']","217":"['Computer Science']","218":"['Computer Science', 'Medicine']","219":"['Computer Science']","220":"['Computer Science']","221":"['Computer Science']","222":"['Computer Science', 'Medicine']","223":"['Computer Science']","224":"['Medicine', 'Computer Science']","225":"['Computer Science', 'Mathematics']","226":"['Computer Science']","227":"['Computer Science', 'Engineering']","228":"['Computer Science']","229":"['Computer Science']","230":"['Computer Science']","231":"['Computer Science']","232":"['Computer Science']","233":"['Computer Science']","234":"['Computer Science']","235":"['Computer Science']","236":"['Computer Science']","237":"['Computer Science']","238":"['Computer Science', 'Medicine']","239":"['Computer Science']","240":"['Computer Science']","241":"['Computer Science']","242":"['Computer Science']","243":"['Computer Science']","244":"['Computer Science']","245":"['Computer Science']","246":"['Computer Science', 'Physics', 'Political Science', 'Medicine']","247":"['Computer Science', 'Engineering']","248":"['Computer Science']","249":"['Computer Science', 'Psychology']","250":"['Computer Science']","251":"['Computer Science', 'Psychology']","252":"['Computer Science']","253":"['Computer Science']","254":"['Computer Science', 'Medicine']","255":"['Computer Science']","256":"['Computer Science']","257":"['Computer Science', 'Mathematics']","258":"['Computer Science']","259":"['Computer Science']","260":"['Medicine', 'Computer Science']","261":"['Computer Science']","262":"['Biology', 'Computer Science']","263":"['Computer Science']","264":"['Computer Science']","265":"['Computer Science']","266":"['Computer Science', 'Mathematics']","267":"['Computer Science', 'Engineering']","268":"['Computer Science']","269":"['Computer Science']","270":"['Computer Science']","271":"['Computer Science']","272":"['Computer Science']","273":"['Computer Science']","274":"['Computer Science']","275":"['Computer Science']","276":"['Computer Science']","277":"['Computer Science']","278":"['Computer Science', 'Mathematics']","279":"['Computer Science', 'Medicine']","280":"['Computer Science', 'Medicine']","281":"['Medicine', 'Computer Science']","282":"['Computer Science']","283":"['Computer Science', 'Mathematics']","284":"['Computer Science']","285":"['Computer Science']","286":"['Computer Science']","287":"['Computer Science']","288":"['Computer Science']","289":"['Computer Science']","290":"['Computer Science', 'Mathematics']","291":"['Computer Science']","292":"['Computer Science']","293":"['Computer Science']","294":"['Computer Science', 'Medicine']","295":"['Computer Science']","296":"['Computer Science']","297":"['Psychology', 'Computer Science']","298":"['Computer Science']","299":"['Computer Science']","300":"['Computer Science']","301":"['Computer Science']","302":"['Computer Science']","303":"['History', 'Computer Science']","304":"['Computer Science']","305":"['Computer Science']","306":"['Computer Science']","307":"['Computer Science']","308":"['Computer Science']","309":"['Computer Science']","310":"['Computer Science']","311":"['Computer Science']","312":"['Computer Science', 'Mathematics']","313":"['Computer Science']","314":"['Computer Science']","315":"['Computer Science']","316":"['Computer Science']","317":"['Computer Science']","318":"['Computer Science']","319":"['Computer Science', 'Medicine']","320":"['Computer Science']","321":"['Computer Science']","322":"['Engineering', 'Computer Science']","323":"['Computer Science']","324":"['Computer Science', 'Medicine']","325":"['Computer Science']","326":"['Computer Science']","327":"['Computer Science']","328":"['Computer Science']","329":"['Computer Science', 'Mathematics']","330":"['Medicine', 'Computer Science']","331":"['Computer Science', 'Mathematics']","332":"['Computer Science']","333":"['Computer Science']","334":"['Computer Science']","335":"['Psychology', 'Computer Science']","336":"['Computer Science', 'Psychology', 'Medicine', 'Physics']","337":"['Computer Science']","338":"['Computer Science']","339":"['Computer Science']","340":"['Computer Science']","341":"['Computer Science']","342":"['Computer Science', 'Mathematics']","343":"['Computer Science']","344":"['Computer Science']","345":"['Computer Science', 'Engineering']","346":"['Computer Science']","347":"['Computer Science']","348":"['Computer Science']","349":"['Computer Science']","350":"['Computer Science']","351":"['Computer Science']","352":"['Computer Science']","353":"['Computer Science', 'Medicine']","354":"['Computer Science']","355":"['Computer Science']","356":"['Computer Science']","357":"['Computer Science', 'Mathematics']","358":"['Computer Science']","359":"['Computer Science']","360":"['Computer Science', 'Medicine']","361":"['Computer Science']","362":"['Computer Science', 'Medicine']","363":"['Computer Science']","364":"['Computer Science']","365":"['Computer Science']","366":"['Computer Science']","367":"['Computer Science']","368":"['Computer Science']","369":"['Computer Science']","370":"['Computer Science']","371":"['Computer Science']","372":"['Computer Science']","373":"['Computer Science']","374":"['Computer Science']","375":"['Medicine', 'Computer Science', 'Engineering']","376":"['Medicine', 'Computer Science']","377":"['Computer Science']","378":"['Computer Science']","379":"['Computer Science']","380":"['Computer Science']","381":"['Computer Science']","382":"['Computer Science']","383":"['Computer Science']","384":"['Computer Science', 'Mathematics']","385":"['Computer Science', 'Engineering']","386":"['Computer Science']","387":"['Computer Science']","388":"['Computer Science']","389":"['Computer Science']","390":"['Computer Science', 'Mathematics']","391":"['Computer Science', 'Medicine']","392":"['Computer Science']","393":"['Computer Science']","394":"['Computer Science', 'Psychology']","395":"['Computer Science']","396":"['Computer Science']","397":"['Computer Science']","398":"['Computer Science']","399":"['Computer Science']","400":"['Computer Science']","401":"['Computer Science']","402":"['Computer Science']","403":"['Computer Science']","404":"['Computer Science']","405":"['Computer Science', 'Psychology']","406":"['Computer Science']","407":"['Medicine', 'Computer Science']","408":"['Computer Science', 'Sociology', 'Mathematics']","409":"['Computer Science']","410":"['Computer Science', 'Mathematics']","411":"['Computer Science', 'Medicine']","412":"['Physics', 'Computer Science', 'Sociology', 'Medicine']","413":"['Computer Science']","414":"['Computer Science', 'Medicine']","415":"['Computer Science']","416":"['Computer Science', 'Physics']","417":"['Computer Science']","418":"['Computer Science']","419":"['Computer Science']","420":"['Computer Science', 'Physics']","421":"['Physics', 'Computer Science', 'Sociology', 'Political Science']","422":"['Computer Science', 'Political Science']","423":"['Computer Science', 'Business']","424":"['Computer Science']","425":"['Sociology', 'Computer Science']","426":"['Sociology', 'Computer Science', 'Mathematics']","427":"['Computer Science', 'Business']","428":"['Computer Science']","429":"['Computer Science', 'Economics']","430":"['Medicine', 'Computer Science']","431":"['Computer Science']","432":"['Computer Science', 'Sociology']","433":"['Computer Science', 'Medicine', 'Physics']","434":"['Computer Science']","435":"['Computer Science', 'Physics']","436":"['Computer Science']","437":"['Computer Science']","438":"['Sociology', 'Computer Science']","439":"['Computer Science']","440":"['Computer Science']","441":"['Computer Science', 'Physics']","442":"['Computer Science', 'Sociology']","443":"['Computer Science']","444":"['Computer Science']","445":"['Computer Science', 'Political Science']","446":"['Computer Science']","447":"['Computer Science']","448":"['Computer Science']","449":"['Computer Science']","450":"['Computer Science']","451":"['Medicine', 'Computer Science']","452":"['Computer Science']","453":"['Physics', 'Computer Science']","454":"['Computer Science', 'Political Science']","455":"['Computer Science', 'Physics']","456":"['Physics', 'Computer Science']","457":"['Computer Science']","458":"['Computer Science']","459":"['Computer Science', 'Medicine']","460":"['Computer Science', 'Physics', 'Medicine']","461":"['Computer Science']","462":"['Computer Science', 'Medicine']","463":"['Computer Science']","464":"['Computer Science', 'Physics', 'Psychology']","465":"['Computer Science']","466":"['Medicine', 'Computer Science']","467":"['Computer Science', 'Political Science']","468":"['Computer Science']","469":"['Computer Science']","470":"['Mathematics', 'Computer Science']","471":"['Computer Science']","472":"['Computer Science', 'Medicine']","473":"['Computer Science']","474":"['Sociology', 'Computer Science']","475":"['Computer Science', 'Sociology', 'Physics']","476":"['Physics', 'Computer Science']","477":"['Computer Science']","478":"['Computer Science']","479":"['Computer Science']","480":"['Computer Science']","481":"['Computer Science', 'Political Science']","482":"['Physics', 'Computer Science', 'Mathematics']","483":"['Computer Science']","484":"['Computer Science', 'Business']","485":"['Computer Science']","486":"['Computer Science']","487":"['Computer Science', 'Medicine']","488":"['Computer Science']","489":"['Computer Science', 'Psychology']","490":"['Sociology', 'Computer Science']","491":"['Computer Science']","492":"['Sociology', 'Computer Science']","493":"['Computer Science']","494":"['Computer Science', 'Biology', 'Medicine']","495":"['Computer Science']","496":"['Computer Science']","497":"['Computer Science', 'Political Science']","498":"['Computer Science', 'Sociology']","499":"['Sociology', 'Computer Science']","500":"['Computer Science', 'Engineering', 'Mathematics']","501":"['Computer Science']","502":"['Computer Science']","503":"['Computer Science', 'Sociology']","504":"['Computer Science']","505":"['Computer Science']","506":"['Computer Science']","507":"['Computer Science']","508":"['Computer Science']","509":"['Computer Science']","510":"['Computer Science']","511":"['Computer Science', 'Medicine']","512":"['Medicine', 'Physics', 'Computer Science']","513":"['Computer Science']","514":"['Medicine', 'Computer Science', 'Psychology', 'Physics']","515":"['Computer Science', 'Political Science']","516":"['Physics', 'Computer Science', 'Sociology']","517":"['Computer Science']","518":"['Computer Science']","519":"['Computer Science', 'Psychology', 'Medicine']","520":"['Computer Science']","521":"['Computer Science']","522":"['Computer Science']","523":"['Computer Science']","524":"['Computer Science', 'Medicine']","525":"['Computer Science']","526":"['Computer Science']","527":"['Computer Science']","528":"['Sociology', 'Computer Science']","529":"['Computer Science', 'Medicine']","530":"['Computer Science']","531":"['Computer Science', 'Business']","532":"['Computer Science']","533":"['Computer Science', 'Business']","534":"['Computer Science', 'Physics']","535":"['Computer Science', 'Psychology']","536":"['Computer Science']","537":"['Computer Science']","538":"['Computer Science', 'Physics']","539":"['Medicine', 'Computer Science']","540":"['Computer Science']","541":"['Computer Science', 'Medicine']","542":"['Psychology', 'Computer Science']","543":"['Computer Science']","544":"['Computer Science', 'Sociology']","545":"['Computer Science', 'Medicine']","546":"['Computer Science', 'Medicine']","547":"['Psychology', 'Computer Science']","548":"['Computer Science']","549":"['Computer Science']","550":"['Computer Science']","551":"['Computer Science', 'Business']","552":"['Computer Science']","553":"['Computer Science']","554":"['Business', 'Computer Science']","555":"['Computer Science']","556":"['Computer Science']","557":"['Computer Science']","558":"['Computer Science']","559":"['Computer Science', 'Business']","560":"['Computer Science', 'Economics']","561":"['Medicine', 'Computer Science']","562":"['Computer Science']","563":"['Physics', 'Computer Science', 'Mathematics']","564":"['Computer Science']","565":"['Computer Science', 'Business']","566":"['Medicine', 'Computer Science']","567":"['Computer Science']","568":"['Computer Science']","569":"['Political Science', 'Computer Science']","570":"['Computer Science']","571":"['Computer Science']","572":"['Computer Science']","573":"['Computer Science']","574":"['Computer Science']","575":"['Computer Science']","576":"['Computer Science']","577":"['Computer Science']","578":"['Computer Science']","579":"['Computer Science', 'Psychology']","580":"['Computer Science']","581":"['Computer Science']","582":"['Engineering', 'Computer Science']","583":"['Computer Science']","584":"['Computer Science']","585":"['Computer Science']","586":"['Computer Science']","587":"['Computer Science', 'Mathematics']","588":"['Computer Science']","589":"['Engineering', 'Computer Science']","590":"['Computer Science']","591":"['Medicine', 'Computer Science']","592":"['Computer Science']","593":"['Computer Science']","594":"['Computer Science']","595":"['Computer Science']","596":"['Computer Science']","597":"['Computer Science', 'Mathematics']","598":"['Computer Science']","599":"['Computer Science']","600":"['Computer Science']","601":"['Computer Science']","602":"['Computer Science', 'Geology']","603":"['Computer Science']","604":"['Computer Science']","605":"['Computer Science']","606":"['Computer Science', 'Mathematics']","607":"['Computer Science', 'Physics']","608":"['Computer Science']","609":"['Computer Science']","610":"['Computer Science']","611":"['Computer Science']","612":"['Medicine', 'Computer Science']","613":"['Environmental Science', 'Computer Science']","614":"['Computer Science']","615":"['Computer Science']","616":"['Computer Science']","617":"['Computer Science']","618":"['Computer Science', 'Medicine']","619":"['Medicine', 'Computer Science']","620":"['Computer Science']","621":"['Computer Science']","622":"['Computer Science']","623":"['Computer Science', 'Medicine']","624":"['Computer Science']","625":"['Computer Science']","626":"['Computer Science', 'Psychology']","627":"['Computer Science']","628":"['Computer Science']","629":"['Computer Science', 'Medicine']","630":"['Computer Science']","631":"['Computer Science']","632":"['Computer Science', 'Engineering', 'Mathematics']","633":"['Computer Science']","634":"['Medicine', 'Computer Science']","635":"['Computer Science']","636":"['Computer Science']","637":"['Computer Science']","638":"['Computer Science']","639":"['Computer Science']","640":"['Computer Science']","641":"['Computer Science']","642":"['Computer Science']","643":"['Computer Science']","644":"['Computer Science']","645":"['Biology', 'Computer Science']","646":"['Computer Science']","647":"['Computer Science', 'Medicine']","648":"['Computer Science']","649":"['Computer Science']","650":"['Computer Science']","651":"['Computer Science']","652":"['Computer Science', 'Medicine']","653":"['Computer Science']","654":"['Computer Science']","655":"['Computer Science']","656":"['Computer Science']","657":"['Computer Science', 'Engineering', 'Mathematics']","658":"['Computer Science']","659":"['Computer Science']","660":"['Computer Science', 'Medicine']","661":"['Computer Science', 'Mathematics']","662":"['Computer Science', 'Mathematics']","663":"['Medicine', 'Computer Science', 'Psychology']","664":"['Computer Science']","665":"['Computer Science']","666":"['Computer Science']","667":"['Medicine', 'Computer Science']","668":"['Computer Science']","669":"['Computer Science']","670":"['Computer Science']","671":"['Economics', 'Computer Science']","672":"['Computer Science', 'Medicine']","673":"['Computer Science']","674":"['Computer Science']","675":"['Computer Science', 'Mathematics']","676":"['Computer Science']","677":"['Computer Science']","678":"['Psychology', 'Computer Science', 'Medicine']","679":"['Computer Science', 'Medicine']","680":"['Biology', 'Computer Science']","681":"['Computer Science']","682":"['Computer Science', 'Medicine']","683":"['Computer Science']","684":"['Computer Science']","685":"['Medicine', 'Computer Science']","686":"['Computer Science']","687":"['Medicine', 'Computer Science']","688":"['Computer Science', 'Psychology']","689":"['Computer Science']","690":"['Computer Science', 'Mathematics']","691":"['Medicine', 'Computer Science']","692":"['Computer Science']","693":"['Computer Science', 'Medicine']","694":"['Computer Science']","695":"['Computer Science']","696":"['Computer Science']","697":"['Computer Science']","698":"['Computer Science']","699":"['Computer Science']","700":"['Computer Science', 'Environmental Science']","701":"['Computer Science', 'Medicine']","702":"['Computer Science']","703":"['Computer Science']","704":"['Computer Science']","705":"['Computer Science']","706":"['Computer Science', 'Economics', 'Mathematics']","707":"['Computer Science']","708":"['Computer Science']","709":"['Computer Science']","710":"['Computer Science']","711":"['Computer Science', 'Geology']","712":"['Computer Science', 'Medicine']","713":"['Computer Science']","714":"['Geology', 'Computer Science']","715":"['Computer Science', 'Sociology']","716":"['Computer Science']","717":"['Computer Science']","718":"['Computer Science']","719":"['Computer Science', 'Mathematics']","720":"['Computer Science', 'Mathematics']","721":"['Computer Science', 'Mathematics']","722":"['Computer Science']","723":"['Medicine', 'Computer Science']","724":"['Computer Science']","725":"['Psychology', 'Computer Science']","726":"['Medicine', 'Computer Science']","727":"['Computer Science']","728":"['Computer Science']","729":"['Computer Science']","730":"['Computer Science']","731":"['Computer Science']","732":"['Computer Science']","733":"['Computer Science']","734":"['Computer Science']","735":"['Computer Science']","736":"['Mathematics', 'Computer Science']","737":"['Computer Science', 'Medicine']","738":"['Computer Science']","739":"['Computer Science']","740":"['Computer Science']","741":"['Computer Science', 'Mathematics', 'Physics']","742":"['Computer Science']","743":"['Medicine', 'Computer Science']","744":"['Computer Science']","745":"['Computer Science']","746":"['Computer Science']","747":"['Computer Science']","748":"['Computer Science']","749":"['Computer Science']","750":"['Computer Science']","751":"['Computer Science']","752":"['Computer Science']","753":"['Medicine', 'Computer Science']","754":"['Computer Science']","755":"['Computer Science']","756":"['Computer Science']","757":"['Computer Science', 'Mathematics']","758":"['Computer Science']","759":"['Computer Science']","760":"['Medicine', 'Computer Science']","761":"['Psychology', 'Computer Science']","762":"['Computer Science']","763":"['Computer Science']","764":"['Computer Science']","765":"['Computer Science']","766":"['Computer Science']","767":"['Computer Science']","768":"['Computer Science']","769":"['Computer Science']","770":"['Computer Science']","771":"['Computer Science']","772":"['Computer Science']","773":"['Computer Science']","774":"['Computer Science']","775":"['Computer Science']","776":"['Computer Science']","777":"['Computer Science']","778":"['Computer Science']","779":"['Computer Science']","780":"['Computer Science']","781":"['Computer Science']","782":"['Computer Science', 'Medicine']","783":"['Computer Science', 'Mathematics', 'Psychology']","784":"['Computer Science']","785":"['Computer Science']","786":"['Computer Science', 'Mathematics']","787":"['Computer Science']","788":"['Computer Science']","789":"['Computer Science']","790":"['Computer Science', 'Medicine', 'Psychology']","791":"['Computer Science']","792":"['Computer Science', 'Engineering']","793":"['Computer Science']","794":"['Computer Science']","795":"['Computer Science']","796":"['Computer Science']","797":"['Computer Science']","798":"['Computer Science']","799":"['Computer Science', 'Medicine']","800":"['Computer Science']","801":"['Computer Science']","802":"['Computer Science']","803":"['Computer Science']","804":"['Computer Science']","805":"['Computer Science']","806":"['Computer Science']","807":"['Computer Science']","808":"['Computer Science']","809":"['Computer Science']","810":"['Computer Science']","811":"['Computer Science', 'Medicine']","812":"['Computer Science']","813":"['Computer Science']","814":"['Computer Science']","815":"['Computer Science']","816":"['Computer Science', 'Mathematics']","817":"['Computer Science']","818":"['Computer Science', 'Physics']","819":"['Computer Science']","820":"['Computer Science']","821":"['Computer Science']","822":"['Computer Science', 'Medicine']","823":"['Computer Science']","824":"['Computer Science', 'Physics']","825":"['Computer Science', 'Materials Science']","826":"['Computer Science', 'Mathematics']","827":"['Sociology', 'Computer Science']","828":"['Computer Science']","829":"['Computer Science']","830":"['Computer Science', 'Engineering']","831":"['Computer Science']","832":"['Computer Science']","833":"['Computer Science']","834":"['Computer Science']","835":"['Computer Science']","836":"['Computer Science']","837":"['Computer Science']","838":"['Computer Science']","839":"['Computer Science', 'Engineering']","840":"['Computer Science']","841":"['Computer Science']","842":"['Computer Science']","843":"['Computer Science', 'Medicine']","844":"['Computer Science', 'Medicine']","845":"['Computer Science']","846":"['Computer Science']","847":"['Computer Science']","848":"['Computer Science']","849":"['Computer Science']","850":"['Computer Science']","851":"['Computer Science']","852":"['Computer Science']","853":"['Computer Science']","854":"['Computer Science']","855":"['Computer Science']","856":"['Computer Science']","857":"['Computer Science']","858":"['Computer Science', 'Engineering']","859":"['Computer Science']","860":"['Computer Science']","861":"['Computer Science']","862":"['Computer Science']","863":"['Computer Science']","864":"['Computer Science']","865":"['Computer Science', 'Psychology']","866":"['Computer Science']","867":"['Computer Science']","868":"['Computer Science']","869":"['Computer Science']","870":"['Computer Science']","871":"['Computer Science']","872":"['Computer Science']","873":"['Computer Science']","874":"['Computer Science']","875":"['Computer Science']","876":"['Computer Science', 'Engineering']","877":"['Computer Science', 'Engineering']","878":"['Computer Science']","879":"['Computer Science']","880":"['Computer Science']","881":"['Computer Science']","882":"['Medicine', 'Computer Science']","883":"['Computer Science']","884":"['Computer Science']","885":"['Computer Science', 'Mathematics']","886":"['Computer Science']","887":"['Computer Science']","888":"['Computer Science', 'Mathematics', 'Medicine']","889":"['Computer Science']","890":"['Computer Science']","891":"['Computer Science']","892":"['Computer Science', 'Mathematics']","893":"['Computer Science']","894":"['Computer Science']","895":"['Computer Science']","896":"['Computer Science']","897":"['Computer Science']","898":"['Computer Science']","899":"['Computer Science']","900":"['Computer Science']","901":"['Computer Science']","902":"['Computer Science']","903":"['Computer Science', 'Mathematics']","904":"['Computer Science']","905":"['Computer Science']","906":"['Medicine', 'Computer Science']","907":"['Psychology', 'Computer Science']","908":"['Computer Science']","909":"['Computer Science']","910":"['Computer Science']","911":"['Psychology', 'Political Science', 'Computer Science']","912":"['Computer Science']","913":"['Computer Science']","914":"['Computer Science']","915":"['Computer Science', 'Engineering']","916":"['Computer Science', 'Sociology', 'Mathematics']","917":"['Computer Science']","918":"['Computer Science']","919":"['Computer Science', 'Medicine']","920":"['Computer Science']","921":"['Computer Science']","922":"['Computer Science']","923":"['Computer Science']","924":"['Computer Science']","925":"['Computer Science']","926":"['Computer Science']","927":"['Computer Science']","928":"['Computer Science']","929":"['Computer Science']","930":"['Computer Science', 'Economics', 'Mathematics']","931":"['Computer Science']","932":"['Computer Science']","933":"['Computer Science']","934":"['Computer Science']","935":"['Computer Science']","936":"['Computer Science', 'Mathematics']","937":"['Computer Science', 'Medicine']","938":"['Computer Science', 'Mathematics']","939":"['Computer Science']","940":"['Computer Science']","941":"['Computer Science']","942":"['Computer Science']","943":"['Biology', 'Computer Science']","944":"['Mathematics', 'Medicine', 'Computer Science']","945":"['Computer Science', 'Mathematics']","946":"['Computer Science']","947":"['Computer Science', 'Environmental Science']","948":"['Computer Science', 'Medicine']","949":"['Computer Science']","950":"['Computer Science']","951":"['Computer Science']","952":"['Medicine', 'Biology', 'Computer Science']","953":"['Computer Science']","954":"['Computer Science', 'Environmental Science']","955":"['Computer Science']","956":"['Medicine', 'Computer Science']","957":"['Computer Science', 'Medicine']","958":"['Computer Science', 'Mathematics']","959":"['Computer Science']","960":"['Computer Science']","961":"['Computer Science']","962":"['Computer Science']","963":"['Computer Science']","964":"['Computer Science', 'Business']","965":"['Computer Science']","966":"['Computer Science']","967":"['Computer Science', 'Geography']","968":"['Computer Science', 'Mathematics']","969":"['Computer Science']","970":"['Computer Science', 'Mathematics']","971":"['Computer Science']","972":"['Medicine', 'Computer Science']","973":"['Computer Science']","974":"['Computer Science']","975":"['Computer Science']","976":"['Computer Science', 'Mathematics']","977":"['Computer Science']","978":"['Biology', 'Computer Science']","979":"['Computer Science']","980":"['Computer Science']","981":"['Computer Science']","982":"['Computer Science']","983":"['Computer Science']","984":"['Computer Science']","985":"['Computer Science']","986":"['Computer Science']","987":"['Computer Science', 'Psychology']","988":"['Computer Science']","989":"['Computer Science']","990":"['Computer Science', 'Mathematics']","991":"['Computer Science', 'Medicine']","992":"['Computer Science', 'Mathematics', 'Sociology']","993":"['Computer Science']","994":"['Medicine', 'Computer Science']","995":"['Computer Science']","996":"['Computer Science']","997":"['Computer Science']","998":"['Computer Science']","999":"['Computer Science', 'Sociology', 'History']","1000":"['Psychology', 'Computer Science']","1001":"['Psychology', 'Computer Science']","1002":"['Computer Science']","1003":"['Computer Science']","1004":"['Computer Science']","1005":"['Computer Science']","1006":"['Computer Science']","1007":"['Computer Science']","1008":"['Computer Science']","1009":"['Computer Science']","1010":"['Computer Science']","1011":"['Computer Science', 'Engineering']","1012":"['Computer Science']","1013":"['Computer Science']","1014":"['Computer Science']","1015":"['Computer Science']","1016":"['Computer Science']","1017":"['Computer Science']","1018":"['Computer Science', 'Medicine']","1019":"['Computer Science']","1020":"['Computer Science']","1021":"['Computer Science']","1022":"['Computer Science']","1023":"['Computer Science']","1024":"['Computer Science']","1025":"['Computer Science']","1026":"['Computer Science']","1027":"['Computer Science']","1028":"['Computer Science']","1029":"['Computer Science']","1030":"['Computer Science']","1031":"['Computer Science']","1032":"['Computer Science']","1033":"['Computer Science', 'Psychology']","1034":"['Psychology', 'Computer Science']","1035":"['Computer Science', 'Sociology']","1036":"['Computer Science', 'Political Science']","1037":"['Computer Science']","1038":"['Computer Science']","1039":"['Computer Science', 'Mathematics']","1040":"['Computer Science']","1041":"['Computer Science', 'Psychology', 'Medicine']","1042":"['Computer Science']","1043":"['Computer Science', 'Mathematics']","1044":"['Computer Science']","1045":"['Computer Science']","1046":"['Computer Science']","1047":"['Computer Science']","1048":"['Computer Science', 'Psychology']","1049":"['Computer Science']","1050":"['Computer Science']","1051":"['Computer Science', 'Political Science']","1052":"['Computer Science']","1053":"['Computer Science']","1054":"['Psychology', 'Computer Science']","1055":"['Computer Science']","1056":"['Computer Science']","1057":"['Computer Science', 'Medicine']","1058":"['Computer Science']","1059":"['Computer Science']","1060":"['Computer Science', 'Psychology']","1061":"['Computer Science']","1062":"['Computer Science']","1063":"['Computer Science']","1064":"['Computer Science']","1065":"['Computer Science']","1066":"['Computer Science']","1067":"['Computer Science', 'Psychology']","1068":"['Computer Science']","1069":"['Sociology', 'Computer Science']","1070":"['Computer Science', 'Psychology']","1071":"['Computer Science']","1072":"['Computer Science']","1073":"['Computer Science', 'Sociology']","1074":"['Computer Science']","1075":"['Computer Science', 'Psychology']","1076":"['Computer Science']","1077":"['Computer Science', 'Political Science']","1078":"['Computer Science']","1079":"['Computer Science']","1080":"['Computer Science']","1081":"['Computer Science']","1082":"['Computer Science']","1083":"['Computer Science']","1084":"['Medicine', 'Computer Science']","1085":"['Computer Science']","1086":"['Computer Science']","1087":"['Computer Science']","1088":"['Computer Science']","1089":"['Computer Science']","1090":"['Computer Science']","1091":"['Computer Science']","1092":"['Computer Science']","1093":"['Computer Science']","1094":"['Computer Science']","1095":"['Computer Science']","1096":"['Computer Science']","1097":"['Computer Science']","1098":"['Computer Science']","1099":"['Computer Science']","1100":"['Computer Science', 'Mathematics']","1101":"['Computer Science']","1102":"['Computer Science']","1103":"['Computer Science']","1104":"['Computer Science']","1105":"['Computer Science']","1106":"['Computer Science']","1107":"['Computer Science']","1108":"['Computer Science']","1109":"['Computer Science']","1110":"['Computer Science']","1111":"['Computer Science']","1112":"['Computer Science']","1113":"['Computer Science']","1114":"['Computer Science']","1115":"['Computer Science']","1116":"['Sociology', 'Computer Science']","1117":"['Computer Science']","1118":"['Computer Science', 'Mathematics']","1119":"['Computer Science']","1120":"['Computer Science']","1121":"['Computer Science']","1122":"['Computer Science']","1123":"['Computer Science']","1124":"['Computer Science']","1125":"['Computer Science']","1126":"['Computer Science']","1127":"['Computer Science', 'Mathematics']","1128":"['Computer Science']","1129":"['Computer Science']","1130":"['Computer Science']","1131":"['Computer Science']","1132":"['Computer Science']","1133":"['Computer Science']","1134":"['Computer Science']","1135":"['Computer Science']","1136":"['Computer Science', 'Medicine']","1137":"['Computer Science']","1138":"['Computer Science', 'Economics', 'Mathematics']","1139":"['Computer Science', 'Economics']","1140":"['Computer Science', 'Political Science']","1141":"['Computer Science']","1142":"['Computer Science']","1143":"['Computer Science']","1144":"['Computer Science', 'Political Science', 'Medicine']","1145":"['Computer Science']","1146":"['Computer Science']","1147":"['Computer Science']","1148":"['Computer Science']","1149":"['Computer Science']","1150":"['Computer Science']","1151":"['Computer Science']","1152":"['Computer Science', 'Business']","1153":"['Computer Science']","1154":"['Computer Science']","1155":"['Computer Science']","1156":"['Computer Science']","1157":"['Computer Science']","1158":"['Computer Science', 'Economics']","1159":"['Computer Science']","1160":"['Computer Science']","1161":"['Computer Science']","1162":"['Political Science', 'Computer Science']","1163":"['Computer Science']","1164":"['Computer Science']","1165":"['Computer Science']","1166":"['Computer Science']","1167":"['Computer Science']","1168":"['Computer Science']","1169":"['Computer Science']","1170":"['Computer Science']","1171":"['Computer Science']","1172":"['Computer Science']","1173":"['Computer Science']","1174":"['Computer Science']","1175":"['Computer Science']","1176":"['Computer Science']","1177":"['Mathematics', 'Computer Science']","1178":"['Computer Science']","1179":"['Computer Science']","1180":"['Computer Science']","1181":"['Computer Science']","1182":"['Computer Science']","1183":"['Computer Science']","1184":"['Computer Science']","1185":"['Computer Science']","1186":"['Computer Science']","1187":"['Computer Science', 'Mathematics']","1188":"['Computer Science']","1189":"['Computer Science']","1190":"['Computer Science']","1191":"['Computer Science']","1192":"['Computer Science']","1193":"['Computer Science']","1194":"['Computer Science']","1195":"['Computer Science']","1196":"['Computer Science', 'Political Science']","1197":"['Computer Science']","1198":"['Computer Science']","1199":"['Computer Science']","1200":"['Computer Science']","1201":"['Computer Science']","1202":"['Computer Science']","1203":"['Computer Science']","1204":"['Computer Science', 'Mathematics']","1205":"['Computer Science']","1206":"['Computer Science']","1207":"['Computer Science']","1208":"['Computer Science']","1209":"['Computer Science']","1210":"['Computer Science']","1211":"['Computer Science']","1212":"['Computer Science']","1213":"['Computer Science']","1214":"['Computer Science', 'Environmental Science']","1215":"['Computer Science']","1216":"['Physics', 'Computer Science']","1217":"['Engineering', 'Computer Science']","1218":"['Geology', 'Computer Science']","1219":"['Computer Science']","1220":"['Computer Science']","1221":"['Geology', 'Computer Science']","1222":"['Computer Science']","1223":"['Computer Science']","1224":"['Computer Science', 'Environmental Science']","1225":"['Computer Science']","1226":"['Computer Science']","1227":"['Computer Science']","1228":"['Computer Science', 'Psychology']","1229":"['Computer Science']","1230":"['Computer Science']","1231":"['Computer Science', 'Political Science']","1232":"['Computer Science', 'Psychology']","1233":"['Psychology', 'Computer Science']","1234":"['Computer Science', 'Medicine']","1235":"['Computer Science']","1236":"['Computer Science']","1237":"['Computer Science']","1238":"['Computer Science', 'Political Science']","1239":"['Computer Science', 'Psychology']","1240":"['Computer Science']","1241":"['Computer Science']","1242":"['Computer Science', 'Psychology']","1243":"['Computer Science']","1244":"['Computer Science', 'Political Science']","1245":"['Computer Science']","1246":"['Computer Science']","1247":"['Computer Science']","1248":"['Computer Science', 'Mathematics', 'Economics']","1249":"['Computer Science']","1250":"['Computer Science']","1251":"['Computer Science']","1252":"['Computer Science']","1253":"['Computer Science']","1254":"['Computer Science']","1255":"['Computer Science']","1256":"['Computer Science']","1257":"['Political Science', 'Medicine', 'Computer Science']","1258":"['Computer Science', 'Political Science']","1259":"['Computer Science', 'Medicine']","1260":"['Computer Science']","1261":"['Computer Science']","1262":"['Computer Science', 'Mathematics']","1263":"['Computer Science', 'Mathematics', 'Economics']","1264":"['Computer Science']","1265":"['Computer Science']","1266":"['Computer Science', 'Medicine']","1267":"['Computer Science', 'Sociology']","1268":"['Computer Science']","1269":"['Computer Science', 'Sociology']","1270":"['Computer Science']","1271":"['Medicine', 'Computer Science']","1272":"['Medicine', 'Sociology', 'Computer Science']","1273":"['Sociology', 'Computer Science']"},"s2FieldsOfStudy":{"0":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","2":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","3":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","4":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","5":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","6":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","7":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","8":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","9":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","10":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","11":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","12":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","13":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","14":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","15":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","16":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","17":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","18":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","19":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","20":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","21":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","22":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","23":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","24":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","25":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","26":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","27":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","28":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","29":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","30":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","31":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","32":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","33":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","34":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","35":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","36":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","37":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","38":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","39":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","40":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","41":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","42":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","43":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","44":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","45":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","46":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","47":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","48":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","49":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","50":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","51":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","52":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","53":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","54":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","55":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","56":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","57":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","58":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","59":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","60":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","61":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","62":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","63":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","64":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","65":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","66":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","67":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","68":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","69":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","70":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","71":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","72":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","73":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","74":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","75":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","76":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","77":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","78":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","79":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","80":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","81":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","82":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","83":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","84":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","85":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","86":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}]","87":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","88":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","89":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","90":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","91":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","92":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","93":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","94":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","95":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","96":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","97":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","98":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","99":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","100":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","101":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","102":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","103":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","104":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","105":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","106":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","107":"[{'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","108":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","109":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","110":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","111":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","112":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","113":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","114":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","115":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","116":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Philosophy', 'source': 's2-fos-model'}]","117":"[{'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Philosophy', 'source': 's2-fos-model'}]","118":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","119":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","120":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","121":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","122":"[{'category': 'Computer Science', 'source': 'external'}]","123":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","124":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","125":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","126":"[{'category': 'Computer Science', 'source': 'external'}]","127":"[{'category': 'Computer Science', 'source': 'external'}]","128":"[{'category': 'Computer Science', 'source': 'external'}]","129":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","130":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","131":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","132":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","133":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","134":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","135":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","136":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","137":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Philosophy', 'source': 's2-fos-model'}]","138":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","139":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","140":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Law', 'source': 's2-fos-model'}]","141":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","142":"[{'category': 'Computer Science', 'source': 'external'}]","143":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","144":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","145":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","146":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","147":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","148":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","149":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","150":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","151":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","152":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","153":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","154":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}]","155":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","156":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","157":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","158":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","159":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","160":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","161":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","162":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","163":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","164":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","165":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","166":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","167":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","168":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","169":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","170":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","171":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","172":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","173":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","174":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","175":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","176":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","177":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","178":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","179":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","180":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","181":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","182":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","183":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","184":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","185":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","186":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","187":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","188":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","189":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","190":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","191":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","192":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","193":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","194":"[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","195":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","196":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","197":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","198":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","199":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","200":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","201":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","202":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","203":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","204":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","205":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","206":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","207":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","208":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","209":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","210":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","211":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","212":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","213":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","214":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","215":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","216":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","217":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","218":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","219":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","220":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","221":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","222":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","223":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","224":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","225":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","226":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","227":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","228":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","229":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","230":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","231":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","232":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","233":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","234":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","235":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","236":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","237":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","238":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","239":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","240":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","241":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","242":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","243":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","244":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","245":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","246":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","247":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","248":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","249":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","250":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","251":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","252":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","253":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","254":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","255":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","256":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","257":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","258":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","259":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","260":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","261":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Agricultural And Food Sciences', 'source': 's2-fos-model'}]","262":"[{'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","263":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","264":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","265":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","266":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","267":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","268":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","269":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","270":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","271":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","272":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","273":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","274":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","275":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","276":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","277":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","278":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","279":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","280":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","281":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","282":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","283":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","284":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","285":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","286":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","287":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","288":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","289":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","290":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","291":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","292":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","293":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","294":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","295":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","296":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","297":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","298":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","299":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","300":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","301":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","302":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","303":"[{'category': 'History', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","304":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","305":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","306":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","307":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","308":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","309":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","310":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","311":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","312":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","313":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","314":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","315":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","316":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","317":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","318":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","319":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","320":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","321":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","322":"[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","323":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","324":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","325":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","326":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","327":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","328":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","329":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","330":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","331":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","332":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","333":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","334":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","335":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Philosophy', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","336":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","337":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","338":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","339":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","340":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","341":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","342":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","343":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","344":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","345":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","346":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","347":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","348":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","349":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","350":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","351":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","352":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","353":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","354":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","355":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","356":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","357":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","358":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","359":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","360":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","361":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","362":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","363":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","364":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","365":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","366":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","367":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","368":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","369":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","370":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","371":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","372":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","373":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","374":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","375":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","376":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","377":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","378":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","379":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","380":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","381":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","382":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","383":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","384":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","385":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","386":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","387":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","388":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","389":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","390":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","391":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","392":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","393":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","394":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","395":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","396":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","397":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","398":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","399":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","400":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","401":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","402":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","403":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","404":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","405":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","406":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","407":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","408":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","409":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","410":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","411":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","412":"[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","413":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","414":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","415":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","416":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","417":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","418":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","419":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","420":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","421":"[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","422":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","423":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","424":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","425":"[{'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","426":"[{'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","427":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","428":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","429":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","430":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","431":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","432":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","433":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","434":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","435":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","436":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","437":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","438":"[{'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","439":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","440":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","441":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","442":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","443":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","444":"[{'category': 'Computer Science', 'source': 'external'}]","445":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","446":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","447":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","448":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","449":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","450":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","451":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","452":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","453":"[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","454":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","455":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","456":"[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","457":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","458":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","459":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","460":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","461":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","462":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","463":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","464":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","465":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","466":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","467":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","468":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","469":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","470":"[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","471":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","472":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","473":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","474":"[{'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","475":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","476":"[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","477":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","478":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","479":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","480":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","481":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","482":"[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","483":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","484":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","485":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Philosophy', 'source': 's2-fos-model'}]","486":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","487":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","488":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","489":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","490":"[{'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","491":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","492":"[{'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","493":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","494":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","495":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","496":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","497":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","498":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","499":"[{'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","500":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","501":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","502":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","503":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","504":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","505":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","506":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","507":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","508":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","509":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","510":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","511":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","512":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","513":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","514":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","515":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","516":"[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","517":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","518":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","519":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","520":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}]","521":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","522":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","523":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","524":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","525":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","526":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","527":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","528":"[{'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","529":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","530":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}]","531":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","532":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","533":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","534":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","535":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","536":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","537":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","538":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","539":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","540":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","541":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","542":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","543":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","544":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","545":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","546":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","547":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","548":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","549":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","550":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","551":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","552":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","553":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","554":"[{'category': 'Business', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","555":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","556":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","557":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","558":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","559":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","560":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","561":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","562":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","563":"[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","564":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","565":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","566":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","567":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","568":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","569":"[{'category': 'Political Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","570":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","571":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","572":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","573":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","574":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","575":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","576":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","577":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","578":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","579":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","580":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","581":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","582":"[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","583":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","584":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","585":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","586":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","587":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}, {'category': 'Economics', 'source': 's2-fos-model'}]","588":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","589":"[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","590":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","591":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","592":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","593":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","594":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","595":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","596":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","597":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","598":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","599":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","600":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","601":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","602":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Geology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","603":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","604":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","605":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","606":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","607":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","608":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","609":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","610":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","611":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","612":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","613":"[{'category': 'Environmental Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","614":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","615":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","616":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","617":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","618":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","619":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","620":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","621":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","622":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","623":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","624":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","625":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","626":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","627":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","628":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","629":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","630":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","631":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","632":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","633":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","634":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","635":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","636":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","637":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","638":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","639":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","640":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Business', 'source': 's2-fos-model'}]","641":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","642":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","643":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","644":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Business', 'source': 's2-fos-model'}]","645":"[{'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","646":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","647":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","648":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","649":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","650":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","651":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","652":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","653":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","654":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","655":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","656":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","657":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","658":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","659":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","660":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","661":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","662":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","663":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","664":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Business', 'source': 's2-fos-model'}]","665":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","666":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","667":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","668":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","669":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","670":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","671":"[{'category': 'Economics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","672":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","673":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","674":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","675":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","676":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","677":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Business', 'source': 's2-fos-model'}]","678":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","679":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","680":"[{'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","681":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","682":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","683":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","684":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","685":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","686":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","687":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","688":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","689":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","690":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","691":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","692":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","693":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","694":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","695":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","696":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","697":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","698":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","699":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","700":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","701":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","702":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","703":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","704":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","705":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","706":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","707":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","708":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","709":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","710":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","711":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Geology', 'source': 'external'}, {'category': 'Geology', 'source': 's2-fos-model'}]","712":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","713":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","714":"[{'category': 'Geology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","715":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","716":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","717":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","718":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","719":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","720":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","721":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","722":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","723":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","724":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","725":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","726":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","727":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","728":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","729":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","730":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","731":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","732":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","733":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","734":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","735":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","736":"[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","737":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","738":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","739":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","740":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","741":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","742":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","743":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}, {'category': 'Art', 'source': 's2-fos-model'}]","744":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","745":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","746":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","747":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","748":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","749":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","750":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","751":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","752":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","753":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","754":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","755":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","756":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","757":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","758":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","759":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","760":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","761":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Philosophy', 'source': 's2-fos-model'}]","762":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","763":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","764":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","765":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","766":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","767":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","768":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","769":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","770":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","771":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","772":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Philosophy', 'source': 's2-fos-model'}]","773":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","774":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","775":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","776":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","777":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","778":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","779":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","780":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","781":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","782":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","783":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","784":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","785":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","786":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","787":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","788":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","789":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","790":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","791":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","792":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","793":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","794":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","795":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","796":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","797":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","798":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","799":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","800":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","801":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","802":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}]","803":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","804":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","805":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","806":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}]","807":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","808":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","809":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","810":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","811":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","812":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","813":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","814":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","815":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","816":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","817":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","818":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","819":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","820":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","821":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","822":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","823":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","824":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 'external'}, {'category': 'Engineering', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","825":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Materials Science', 'source': 'external'}, {'category': 'Engineering', 'source': 's2-fos-model'}]","826":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","827":"[{'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","828":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","829":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","830":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","831":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","832":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","833":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","834":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","835":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","836":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","837":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","838":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","839":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","840":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","841":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","842":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","843":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","844":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","845":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","846":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","847":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","848":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","849":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","850":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","851":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","852":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","853":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","854":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","855":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","856":"[{'category': 'Computer Science', 'source': 'external'}]","857":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","858":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","859":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","860":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","861":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","862":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","863":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","864":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","865":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","866":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","867":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","868":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","869":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","870":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","871":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","872":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","873":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","874":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","875":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","876":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","877":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","878":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","879":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","880":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","881":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","882":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","883":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","884":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","885":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","886":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","887":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","888":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","889":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","890":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","891":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","892":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","893":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","894":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","895":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","896":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","897":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","898":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","899":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","900":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","901":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","902":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","903":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","904":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","905":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","906":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","907":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}, {'category': 'Education', 'source': 's2-fos-model'}]","908":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","909":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","910":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","911":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","912":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","913":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","914":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","915":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","916":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","917":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","918":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","919":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","920":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","921":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","922":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","923":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","924":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","925":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","926":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","927":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","928":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","929":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","930":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","931":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","932":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","933":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","934":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","935":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","936":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","937":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","938":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","939":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","940":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","941":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","942":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","943":"[{'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","944":"[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","945":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","946":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","947":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","948":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","949":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","950":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","951":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","952":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","953":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","954":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","955":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","956":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","957":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Materials Science', 'source': 's2-fos-model'}]","958":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","959":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","960":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","961":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","962":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","963":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","964":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}, {'category': 'Economics', 'source': 's2-fos-model'}]","965":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","966":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","967":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Geography', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","968":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","969":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","970":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","971":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","972":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}, {'category': 'Biology', 'source': 's2-fos-model'}]","973":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","974":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","975":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","976":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","977":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","978":"[{'category': 'Biology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","979":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","980":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","981":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","982":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","983":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","984":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","985":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","986":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","987":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","988":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","989":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","990":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","991":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Law', 'source': 's2-fos-model'}]","992":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","993":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","994":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","995":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","996":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","997":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","998":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","999":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'History', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1000":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","1001":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","1002":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1003":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1004":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1005":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1006":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1007":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1008":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1009":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","1010":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1011":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1012":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1013":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1014":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1015":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1016":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1017":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1018":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1019":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1020":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","1021":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1022":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1023":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","1024":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1025":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1026":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1027":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1028":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1029":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1030":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1031":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","1032":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1033":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1034":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","1035":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1036":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","1037":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1038":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1039":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1040":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1041":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1042":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1043":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1044":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1045":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1046":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1047":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1048":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","1049":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1050":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1051":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1052":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1053":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1054":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","1055":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1056":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","1057":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1058":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1059":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1060":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1061":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1062":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1063":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1064":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","1065":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1066":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1067":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","1068":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1069":"[{'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Philosophy', 'source': 's2-fos-model'}]","1070":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","1071":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","1072":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1073":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","1074":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1075":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","1076":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1077":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}]","1078":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1079":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1080":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1081":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1082":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","1083":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1084":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1085":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1086":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1087":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1088":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1089":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1090":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1091":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1092":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1093":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1094":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1095":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1096":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1097":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1098":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1099":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1100":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1101":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1102":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1103":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1104":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1105":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1106":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1107":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1108":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1109":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1110":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1111":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1112":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1113":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1114":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1115":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1116":"[{'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","1117":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1118":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1119":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1120":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1121":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1122":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1123":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1124":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1125":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1126":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1127":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1128":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1129":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1130":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1131":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1132":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1133":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1134":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1135":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1136":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1137":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1138":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1139":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1140":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1141":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1142":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1143":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1144":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","1145":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1146":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1147":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1148":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1149":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1150":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1151":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1152":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1153":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1154":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1155":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1156":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1157":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1158":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1159":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1160":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","1161":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1162":"[{'category': 'Political Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1163":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","1164":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","1165":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1166":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Art', 'source': 's2-fos-model'}]","1167":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1168":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Linguistics', 'source': 's2-fos-model'}]","1169":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Law', 'source': 's2-fos-model'}]","1170":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","1171":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1172":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","1173":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1174":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","1175":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","1176":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'History', 'source': 's2-fos-model'}]","1177":"[{'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1178":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","1179":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1180":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","1181":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","1182":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1183":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1184":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Physics', 'source': 's2-fos-model'}]","1185":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1186":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1187":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1188":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1189":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1190":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1191":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1192":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1193":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1194":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","1195":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1196":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","1197":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1198":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1199":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1200":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1201":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1202":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1203":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1204":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1205":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1206":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1207":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1208":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1209":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","1210":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1211":"[{'category': 'Computer Science', 'source': 'external'}]","1212":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1213":"[{'category': 'Computer Science', 'source': 'external'}]","1214":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","1215":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","1216":"[{'category': 'Physics', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1217":"[{'category': 'Engineering', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","1218":"[{'category': 'Geology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","1219":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","1220":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1221":"[{'category': 'Geology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","1222":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","1223":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1224":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 'external'}, {'category': 'Environmental Science', 'source': 's2-fos-model'}]","1225":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1226":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1227":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","1228":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","1229":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1230":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1231":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1232":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1233":"[{'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1234":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1235":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1236":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Agricultural And Food Sciences', 'source': 's2-fos-model'}]","1237":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1238":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1239":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1240":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1241":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","1242":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1243":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1244":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Law', 'source': 's2-fos-model'}]","1245":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1246":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1247":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1248":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","1249":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Psychology', 'source': 's2-fos-model'}]","1250":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1251":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","1252":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]","1253":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1254":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","1255":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 's2-fos-model'}]","1256":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1257":"[{'category': 'Political Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1258":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","1259":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","1260":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Biology', 'source': 's2-fos-model'}]","1261":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1262":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1263":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Mathematics', 'source': 'external'}, {'category': 'Economics', 'source': 'external'}, {'category': 'Economics', 'source': 's2-fos-model'}]","1264":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1265":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","1266":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Medicine', 'source': 'external'}, {'category': 'Medicine', 'source': 's2-fos-model'}]","1267":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1268":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1269":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 's2-fos-model'}]","1270":"[{'category': 'Computer Science', 'source': 'external'}, {'category': 'Business', 'source': 's2-fos-model'}]","1271":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Political Science', 'source': 's2-fos-model'}]","1272":"[{'category': 'Medicine', 'source': 'external'}, {'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Education', 'source': 's2-fos-model'}]","1273":"[{'category': 'Sociology', 'source': 'external'}, {'category': 'Computer Science', 'source': 'external'}, {'category': 'Sociology', 'source': 's2-fos-model'}]"},"authors":{"0":"[{'authorId': '2914608', 'name': 'K. Madanagopal'}, {'authorId': '1697232', 'name': 'James Caverlee'}]","1":"[{'authorId': '32380598', 'name': 'Eva Vanmassenhove'}, {'authorId': '2848410', 'name': 'D. Shterionov'}, {'authorId': '35543474', 'name': 'M. Gwilliam'}]","2":"[{'authorId': '1845794923', 'name': 'Timo Spinde'}, {'authorId': '2068169039', 'name': 'L. Rudnitckaia'}, {'authorId': '1978832932', 'name': 'Jelena Mitrovi\u0107'}, {'authorId': '3461253', 'name': 'Felix Hamborg'}, {'authorId': '2068175546', 'name': 'ichael Granitzer'}, {'authorId': '145151838', 'name': 'Bela Gipp'}, {'authorId': '2488381', 'name': 'K. Donnay'}]","3":"[{'authorId': '46236380', 'name': 'Alex Warstadt'}, {'authorId': '3644767', 'name': 'Samuel R. Bowman'}]","4":"[{'authorId': '2085843465', 'name': 'Isabel Papadimitriou'}, {'authorId': '1746807', 'name': 'Dan Jurafsky'}]","5":"[{'authorId': '66686718', 'name': 'S. Borchmann'}]","6":"[{'authorId': '4099006', 'name': 'Reid Pryzant'}, {'authorId': '35540755', 'name': 'Dallas Card'}, {'authorId': '1746807', 'name': 'Dan Jurafsky'}, {'authorId': '2974320', 'name': 'Victor Veitch'}, {'authorId': '153485411', 'name': 'Dhanya Sridhar'}]","7":"[{'authorId': '2467508', 'name': 'Tal Linzen'}]","8":"[{'authorId': '34199564', 'name': 'Maria Antoniak'}, {'authorId': '38917723', 'name': 'D. Mimno'}]","9":"[{'authorId': '2145421216', 'name': 'Chang Li'}, {'authorId': '2877164', 'name': 'Dan Goldwasser'}]","10":"[{'authorId': '32163938', 'name': 'Julia Mendelsohn'}, {'authorId': '145317727', 'name': 'Yulia Tsvetkov'}, {'authorId': '1746807', 'name': 'Dan Jurafsky'}]","11":"[{'authorId': '3106764', 'name': 'K. Deshpande'}, {'authorId': '145620432', 'name': 'Shimei Pan'}, {'authorId': '40289577', 'name': 'James R. Foulds'}]","12":"[{'authorId': '1845794923', 'name': 'Timo Spinde'}, {'authorId': '145151838', 'name': 'Bela Gipp'}]","13":"[{'authorId': '3413117', 'name': 'Christoph Alt'}, {'authorId': '3449621', 'name': 'Aleksandra Gabryszak'}, {'authorId': '36943315', 'name': 'Leonhard Hennig'}]","14":"[{'authorId': '3413117', 'name': 'Christoph Alt'}, {'authorId': '3449621', 'name': 'Aleksandra Gabryszak'}, {'authorId': '36943315', 'name': 'Leonhard Hennig'}]","15":"[{'authorId': '2177867', 'name': 'Debora Nozza'}, {'authorId': '35551420', 'name': 'Claudia Volpetti'}, {'authorId': '1847803', 'name': 'E. Fersini'}]","16":"[{'authorId': '2147260344', 'name': 'Lisa Fan'}, {'authorId': '152959826', 'name': 'M. White'}, {'authorId': '49974609', 'name': 'Eva Sharma'}, {'authorId': '153083809', 'name': 'Ruisi Su'}, {'authorId': '3466801', 'name': 'Prafulla Kumar Choubey'}, {'authorId': '40372969', 'name': 'Ruihong Huang'}, {'authorId': '2153518220', 'name': 'Lu Wang'}]","17":"[{'authorId': '2487267', 'name': 'I. Yahav'}, {'authorId': '2395016', 'name': 'O. Shehory'}, {'authorId': '71936382', 'name': 'D. Schwartz'}]","18":"[{'authorId': '47550691', 'name': 'T. Berg'}]","19":"[{'authorId': '31099365', 'name': 'Aparna Garimella'}, {'authorId': '2271847', 'name': 'Carmen Banea'}, {'authorId': '144547315', 'name': 'E. Hovy'}, {'authorId': '145557251', 'name': 'Rada Mihalcea'}]","20":"[{'authorId': '2082648761', 'name': 'Elad Ben-Zaken'}, {'authorId': '51432464', 'name': 'Shauli Ravfogel'}, {'authorId': '79775260', 'name': 'Yoav Goldberg'}]","21":"[{'authorId': '143733211', 'name': 'Julian Salazar'}, {'authorId': '25130521', 'name': 'Davis Liang'}, {'authorId': '32125163', 'name': 'Toan Q. Nguyen'}, {'authorId': '1783839', 'name': 'Katrin Kirchhoff'}]","22":"[{'authorId': '145534175', 'name': 'R. Thomas McCoy'}, {'authorId': '2067798455', 'name': 'Junghyun Min'}, {'authorId': '2467508', 'name': 'Tal Linzen'}]","23":"[{'authorId': '51519704', 'name': 'Candace Ross'}, {'authorId': '143912599', 'name': 'B. Katz'}, {'authorId': '21570451', 'name': 'Andrei Barbu'}]","24":"[{'authorId': '3490018', 'name': 'R. Baly'}, {'authorId': '48764610', 'name': 'Georgi Karadzhov'}, {'authorId': '40660541', 'name': 'Jisun An'}, {'authorId': '2592694', 'name': 'Haewoon Kwak'}, {'authorId': '1379925776', 'name': 'Yoan Dinkov'}, {'authorId': '2141768778', 'name': 'Ahmed Ali'}, {'authorId': '145898106', 'name': 'James R. Glass'}, {'authorId': '1683562', 'name': 'Preslav Nakov'}]","25":"[{'authorId': '153677280', 'name': 'Robik Shrestha'}, {'authorId': '33315685', 'name': 'Kushal Kafle'}, {'authorId': '3290098', 'name': 'Christopher Kanan'}]","26":"[{'authorId': '145512773', 'name': 'C. Fisher'}, {'authorId': '17290122', 'name': 'Kyong-sun Jin'}, {'authorId': '37432883', 'name': 'Rose M. Scott'}]","27":"[{'authorId': '51432464', 'name': 'Shauli Ravfogel'}, {'authorId': '2089067', 'name': 'Yoav Goldberg'}, {'authorId': '2467508', 'name': 'Tal Linzen'}]","28":"[{'authorId': '35748708', 'name': 'Gabriel Grand'}, {'authorId': '2083259', 'name': 'Y. Belinkov'}]","29":"[{'authorId': '144286907', 'name': 'Qian Yang'}, {'authorId': '3382735', 'name': 'Zhouyuan Huo'}, {'authorId': '19178763', 'name': 'Dinghan Shen'}, {'authorId': '145161801', 'name': 'Yong Cheng'}, {'authorId': '2900282', 'name': 'Wenlin Wang'}, {'authorId': '1700522', 'name': 'Guoyin Wang'}, {'authorId': '145006560', 'name': 'L. Carin'}]","30":"[{'authorId': '1390136164', 'name': 'M. R. Makiuchi'}, {'authorId': '40895843', 'name': 'Tifani Warnita'}, {'authorId': '3318094', 'name': 'K. Uto'}, {'authorId': '1704408', 'name': 'Koichi Shinoda'}]","31":"[{'authorId': '51255500', 'name': 'L. Windsor'}, {'authorId': '32233991', 'name': 'J. Cupit'}, {'authorId': '48554493', 'name': 'Alistair Windsor'}]","32":"[{'authorId': '38635490', 'name': 'Danielle Saunders'}, {'authorId': '36126076', 'name': 'B. Byrne'}]","33":"[{'authorId': '2004014761', 'name': 'Marion Bartl'}, {'authorId': '2742475', 'name': 'M. Nissim'}, {'authorId': '1700894', 'name': 'Albert Gatt'}]","34":"[{'authorId': '145814654', 'name': 'Samson Tan'}, {'authorId': '2708940', 'name': 'Shafiq R. Joty'}, {'authorId': '37596605', 'name': 'Min-Yen Kan'}, {'authorId': '2166511', 'name': 'R. Socher'}]","35":"[{'authorId': '1976174397', 'name': 'T. Sumers'}, {'authorId': '2543534', 'name': 'Mark K. Ho'}, {'authorId': '2057580732', 'name': 'R. Hawkins'}, {'authorId': '144958935', 'name': 'Karthik Narasimhan'}, {'authorId': '1799860', 'name': 'T. Griffiths'}]","36":"[{'authorId': '46236380', 'name': 'Alex Warstadt'}, {'authorId': '9227100', 'name': 'Yian Zhang'}, {'authorId': '1993902967', 'name': 'Haau-Sing Li'}, {'authorId': '48447436', 'name': 'Haokun Liu'}, {'authorId': '3644767', 'name': 'Samuel R. Bowman'}]","37":"[{'authorId': '1739188006', 'name': 'Shengyu Zhang'}, {'authorId': '71328060', 'name': 'Tan Jiang'}, {'authorId': '2144750098', 'name': 'Tan Wang'}, {'authorId': '33870528', 'name': 'Kun Kuang'}, {'authorId': '47122432', 'name': 'Zhou Zhao'}, {'authorId': '2141497540', 'name': 'Jianke Zhu'}, {'authorId': '2151481549', 'name': 'Jin Yu'}, {'authorId': '38385080', 'name': 'Hongxia Yang'}, {'authorId': '144894837', 'name': 'Fei Wu'}]","38":"[{'authorId': '1665756307', 'name': 'Isabel Papadimitriou'}, {'authorId': '1746807', 'name': 'Dan Jurafsky'}]","39":"[{'authorId': '2108919537', 'name': 'Wei-Fan Chen'}, {'authorId': '2248209', 'name': 'Khalid Al Khatib'}, {'authorId': '2626599', 'name': 'Henning Wachsmuth'}, {'authorId': '1405867539', 'name': 'Benno Stein'}]","40":"[{'authorId': '145534175', 'name': 'R. Thomas McCoy'}, {'authorId': '145557445', 'name': 'Erin Grant'}, {'authorId': '1748557', 'name': 'P. Smolensky'}, {'authorId': '1799860', 'name': 'T. Griffiths'}, {'authorId': '2467508', 'name': 'Tal Linzen'}]","41":"[{'authorId': '1762182', 'name': 'Peide Liu'}, {'authorId': '1491881005', 'name': 'Weiqiao Liu'}]","42":"[{'authorId': '3456325', 'name': 'Aseel Addawood'}, {'authorId': '9552744', 'name': 'Adam Badawy'}, {'authorId': '1782658', 'name': 'Kristina Lerman'}, {'authorId': '48898287', 'name': 'Emilio Ferrara'}]","43":"[{'authorId': '1762182', 'name': 'Peide Liu'}, {'authorId': '1491881005', 'name': 'Weiqiao Liu'}]","44":"[{'authorId': '32380598', 'name': 'Eva Vanmassenhove'}, {'authorId': '2848410', 'name': 'D. Shterionov'}, {'authorId': '144315616', 'name': 'Andy Way'}]","45":"[{'authorId': '9340968', 'name': 'Ben Krause'}, {'authorId': '144049726', 'name': 'Akhilesh Deepak Gotmare'}, {'authorId': '143775536', 'name': 'Bryan McCann'}, {'authorId': '2844898', 'name': 'N. Keskar'}, {'authorId': '2708940', 'name': 'Shafiq R. Joty'}, {'authorId': '2166511', 'name': 'R. Socher'}, {'authorId': '8937909', 'name': 'Nazneen Rajani'}]","46":"[{'authorId': '10727711', 'name': 'Charles Lovering'}, {'authorId': '35318567', 'name': 'Rohan Jha'}, {'authorId': '2467508', 'name': 'Tal Linzen'}, {'authorId': '2949185', 'name': 'Ellie Pavlick'}]","47":"[{'authorId': '3058753', 'name': 'Boli Chen'}, {'authorId': '46956602', 'name': 'Yao Fu'}, {'authorId': '2149131512', 'name': 'Guangwei Xu'}, {'authorId': '35930962', 'name': 'Pengjun Xie'}, {'authorId': '2111727840', 'name': 'Chuanqi Tan'}, {'authorId': '2108266952', 'name': 'Mosha Chen'}, {'authorId': '144889532', 'name': 'L. Jing'}]","48":"[{'authorId': '75157891', 'name': 'Xavier Ferrer Aran'}, {'authorId': '51999443', 'name': 'T. Nuenen'}, {'authorId': '144622087', 'name': 'J. Such'}, {'authorId': '1799571', 'name': 'N. Criado'}]","49":"[{'authorId': '143891667', 'name': 'Long Chen'}, {'authorId': '2116538002', 'name': 'Xin Yan'}, {'authorId': '145974111', 'name': 'Jun Xiao'}, {'authorId': '5462268', 'name': 'Hanwang Zhang'}, {'authorId': '3290437', 'name': 'Shiliang Pu'}, {'authorId': '2125211', 'name': 'Yueting Zhuang'}]","50":"[{'authorId': '28130078', 'name': 'Paul Pu Liang'}, {'authorId': '47841931', 'name': 'Irene Z Li'}, {'authorId': '2064345025', 'name': 'Emily Zheng'}, {'authorId': '144529448', 'name': 'Y. Lim'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}, {'authorId': '49933077', 'name': 'Louis-Philippe Morency'}]","51":"[{'authorId': '2111287178', 'name': 'Qiao Huang'}, {'authorId': '144558659', 'name': 'Xin Xia'}, {'authorId': '143960553', 'name': 'D. Lo'}, {'authorId': '1739674', 'name': 'G. Murphy'}]","52":"[{'authorId': '1630466739', 'name': 'Shivang Chopra'}, {'authorId': '51042088', 'name': 'Ramit Sawhney'}, {'authorId': '144144799', 'name': 'Puneet Mathur'}, {'authorId': '1753278', 'name': 'R. Shah'}]","53":"[{'authorId': '3413117', 'name': 'Christoph Alt'}, {'authorId': '143914106', 'name': 'Marc H\u00fcbner'}, {'authorId': '36943315', 'name': 'Leonhard Hennig'}]","54":"[{'authorId': '40109754', 'name': 'Forrest Davis'}, {'authorId': '3220165', 'name': 'Marten van Schijndel'}]","55":"[{'authorId': '113477466', 'name': 'Luke Breitfeller'}, {'authorId': '7635153', 'name': 'Emily Ahn'}, {'authorId': None, 'name': 'Aldrian Obaja Muis'}, {'authorId': '3046220', 'name': 'David Jurgens'}, {'authorId': '145317727', 'name': 'Yulia Tsvetkov'}]","56":"[{'authorId': '3331141', 'name': 'Vinodkumar Prabhakaran'}, {'authorId': '2083807', 'name': 'B. Hutchinson'}, {'authorId': '118707418', 'name': 'Margaret Mitchell'}]","57":"[{'authorId': '29847466', 'name': 'Surafel Melaku Lakew'}, {'authorId': '39640268', 'name': 'Mattia Antonino Di Gangi'}, {'authorId': '102811815', 'name': 'Marcello Federico'}]","58":"[{'authorId': '2739905', 'name': 'D. Dediu'}, {'authorId': '2054895024', 'name': 'R. Janssen'}, {'authorId': '2893545', 'name': 'S. Moisik'}]","59":"[{'authorId': '1706980', 'name': 'Rahma Chaabouni'}, {'authorId': '144875326', 'name': 'E. Kharitonov'}, {'authorId': '3254390', 'name': 'A. Lazaric'}, {'authorId': '2202008', 'name': 'Emmanuel Dupoux'}, {'authorId': '145283199', 'name': 'Marco Baroni'}]","60":"[{'authorId': '153485411', 'name': 'Dhanya Sridhar'}, {'authorId': '1746034', 'name': 'L. Getoor'}]","61":"[{'authorId': '2626599', 'name': 'Henning Wachsmuth'}, {'authorId': '2001099931', 'name': 'Till Werner'}]","62":"[{'authorId': '72609120', 'name': 'Xuejing Zhou'}, {'authorId': '2131642860', 'name': 'Wanli Peng'}, {'authorId': '2152929206', 'name': 'Boya Yang'}, {'authorId': '47808650', 'name': 'Juan Wen'}, {'authorId': '9095768', 'name': 'Yiming Xue'}, {'authorId': '143741620', 'name': 'P. Zhong'}]","63":"[{'authorId': '120722271', 'name': 'Pratyay Banerjee'}, {'authorId': '120838645', 'name': 'Tejas Gokhale'}, {'authorId': '1784500', 'name': 'Yezhou Yang'}, {'authorId': '2064619864', 'name': 'Chitta Baral'}]","64":"[{'authorId': '2121801234', 'name': 'Noga Zaslavsky'}, {'authorId': '21745347', 'name': 'Mora Maldonado'}, {'authorId': '2852263', 'name': 'Jennifer Culbertson'}]","65":"[{'authorId': '2119067868', 'name': 'Philine Zeinert'}, {'authorId': '10702047', 'name': 'Nanna Inie'}, {'authorId': '113320522', 'name': 'Leon Derczynski'}]","66":"[{'authorId': '5925649', 'name': 'Elliot Murphy'}]","67":"[{'authorId': '46277361', 'name': 'R. Munro'}, {'authorId': '2007829281', 'name': 'Alex (Carmen) Morrison'}]","68":"[{'authorId': '2180063', 'name': 'G. Lupyan'}, {'authorId': '1726141', 'name': 'Morten H. Christiansen'}]","69":"[{'authorId': '144412704', 'name': 'Tong Niu'}, {'authorId': '143977268', 'name': 'Mohit Bansal'}]","70":"[{'authorId': '1388571351', 'name': 'Tiago Pimentel'}, {'authorId': '1794100', 'name': 'Brian Roark'}, {'authorId': '144385405', 'name': 'S. Wichmann'}, {'authorId': '2070989574', 'name': 'Ryan Cotterell'}, {'authorId': '6894443', 'name': 'Dami\u00e1n E. Blasi'}]","71":"[{'authorId': '123437034', 'name': 'Tianyi Zhang'}, {'authorId': '3056528', 'name': 'Tatsunori B. Hashimoto'}]","72":"[{'authorId': '2111343757', 'name': 'Jason Wei'}, {'authorId': '150953620', 'name': 'Clara Meister'}, {'authorId': '2070989574', 'name': 'Ryan Cotterell'}]","73":"[{'authorId': '48077389', 'name': 'J. Vaes'}, {'authorId': '38463522', 'name': 'M. Latrofa'}, {'authorId': '48901040', 'name': 'Caterina Suitner'}, {'authorId': '12411375', 'name': 'L. Arcuri'}]","74":"[{'authorId': '8318698', 'name': 'Abeba Birhane'}, {'authorId': '2670978', 'name': 'Vinay Uday Prabhu'}, {'authorId': '26432578', 'name': 'Emmanuel Kahembwe'}]","75":"[{'authorId': '51896902', 'name': 'Utkarsh Sarawgi'}, {'authorId': '51438114', 'name': 'Wazeer Zulfikar'}, {'authorId': '121552476', 'name': 'Nouran Soliman'}, {'authorId': '1701876', 'name': 'P. Maes'}]","76":"[{'authorId': '1630294533', 'name': 'Mansi Agarwal'}, {'authorId': '1630428679', 'name': 'Maitree Leekha'}, {'authorId': '51042088', 'name': 'Ramit Sawhney'}, {'authorId': '1753278', 'name': 'R. Shah'}]","77":"[{'authorId': '2936180', 'name': 'Lifeng Jin'}, {'authorId': '1747648', 'name': 'William Schuler'}]","78":"[{'authorId': '145644643', 'name': 'Andr\u00e9 F. T. Martins'}, {'authorId': '3442524', 'name': 'Tsvetomila Mihaylova'}, {'authorId': '10666396', 'name': 'Nikita Nangia'}, {'authorId': '2114966', 'name': 'Vlad Niculae'}]","79":"[{'authorId': '38635490', 'name': 'Danielle Saunders'}, {'authorId': '1993979140', 'name': 'Rosie Sallis'}, {'authorId': '36126076', 'name': 'B. Byrne'}]","80":"[{'authorId': '2073312042', 'name': 'Rui Hou'}, {'authorId': '1396239754', 'name': 'Ver\u00f3nica P\u00e9rez-Rosas'}, {'authorId': '2235946', 'name': 'S. Loeb'}, {'authorId': '2105984203', 'name': 'Rada Mihalcea'}]","81":"[{'authorId': '2110982198', 'name': 'Xudong Han'}, {'authorId': '145465286', 'name': 'Timothy Baldwin'}, {'authorId': '143620680', 'name': 'Trevor Cohn'}]","82":"[{'authorId': '103225608', 'name': 'Will Merrill'}, {'authorId': '134308261', 'name': 'Lenny Khazan'}, {'authorId': '81087552', 'name': 'Noah Amsel'}, {'authorId': '24849771', 'name': 'Yiding Hao'}, {'authorId': '80971705', 'name': 'S. Mendelsohn'}, {'authorId': '32487671', 'name': 'R. Frank'}]","83":"[{'authorId': '2852263', 'name': 'Jennifer Culbertson'}, {'authorId': '13352879', 'name': 'K. Schuler'}]","84":"[{'authorId': '2004770518', 'name': 'Xiaoke Cao'}, {'authorId': '143846033', 'name': 'L. Lei'}, {'authorId': '71043833', 'name': 'J. Wen'}]","85":"[{'authorId': '104494914', 'name': 'J. Ortega'}]","86":"[{'authorId': '34548266', 'name': 'Maria M. Hedblom'}]","87":"[{'authorId': '14952902', 'name': 'Hieu-Thi Luong'}, {'authorId': '1716857', 'name': 'J. Yamagishi'}]","88":"[{'authorId': '1379965853', 'name': 'P. Schwaller'}, {'authorId': '2489264', 'name': 'Riccardo Petraglia'}, {'authorId': '67107146', 'name': 'Valerio Zullo'}, {'authorId': '1380275643', 'name': 'Vishnu H. Nair'}, {'authorId': '47649907', 'name': 'Rico H\u00e4uselmann'}, {'authorId': '2053391657', 'name': 'Riccardo Pisoni'}, {'authorId': '48268669', 'name': 'C. Bekas'}, {'authorId': '10010307', 'name': 'A. Iuliano'}, {'authorId': '1864183', 'name': 'T. Laino'}]","89":"[{'authorId': '2047073132', 'name': 'Vijit Malik'}, {'authorId': '50991767', 'name': 'Sunipa Dev'}, {'authorId': '4078834', 'name': 'A. Nishi'}, {'authorId': '3157053', 'name': 'Nanyun Peng'}, {'authorId': '2782886', 'name': 'Kai-Wei Chang'}]","90":"[{'authorId': '20486050', 'name': 'Nicolas Ballier'}, {'authorId': '1794818', 'name': 'S. Canu'}, {'authorId': '144518944', 'name': 'C. Petitjean'}, {'authorId': '2378576', 'name': 'G. Gasso'}, {'authorId': '6706982', 'name': 'C. Balhana'}, {'authorId': '2689646', 'name': 'T. Alexopoulou'}, {'authorId': '8773816', 'name': 'Thomas Gaillat'}]","91":"[{'authorId': '3370565', 'name': 'M. Schouwstra'}, {'authorId': '7299259', 'name': 'H. D. Swart'}, {'authorId': '49667603', 'name': 'Bill Thompson'}]","92":"[{'authorId': '2804000', 'name': 'Hexiang Hu'}, {'authorId': '1806773', 'name': 'Ishan Misra'}, {'authorId': '1803520', 'name': 'L. V. D. Maaten'}]","93":"[{'authorId': '2592694', 'name': 'Haewoon Kwak'}, {'authorId': '40660541', 'name': 'Jisun An'}, {'authorId': '36663090', 'name': 'Yong-Yeol Ahn'}]","94":"[{'authorId': '1620657808', 'name': 'Negar Mokhberian'}, {'authorId': '2919118', 'name': 'A. Abeliuk'}, {'authorId': '2091919964', 'name': 'Patrick Cummings'}, {'authorId': '1782658', 'name': 'Kristina Lerman'}]","95":"[{'authorId': '4099006', 'name': 'Reid Pryzant'}, {'authorId': '144584594', 'name': 'Richard Diehl Martinez'}, {'authorId': '40556444', 'name': 'Nathan Dass'}, {'authorId': '1795664', 'name': 'S. Kurohashi'}, {'authorId': '1746807', 'name': 'Dan Jurafsky'}, {'authorId': '2022168', 'name': 'Diyi Yang'}]","96":"[{'authorId': '1845794923', 'name': 'Timo Spinde'}, {'authorId': '3461253', 'name': 'Felix Hamborg'}, {'authorId': '2488381', 'name': 'K. Donnay'}, {'authorId': '2070279728', 'name': 'Angelica Becerra'}, {'authorId': '145151838', 'name': 'Bela Gipp'}]","97":"[{'authorId': '1726545', 'name': 'Y. Kafai'}, {'authorId': '145747511', 'name': 'C. Proctor'}, {'authorId': '2153790', 'name': 'Debora Lui'}]","98":"[{'authorId': '3468616', 'name': 'Matteo Cinelli'}, {'authorId': '116041634', 'name': 'Gianmarco De Francisci Morales'}, {'authorId': '30978073', 'name': 'Alessandro Galeazzi'}, {'authorId': '1728390', 'name': 'Walter Quattrociocchi'}, {'authorId': '2081249', 'name': 'M. Starnini'}]","99":"[{'authorId': '145511581', 'name': 'A. Willis'}]","100":"[{'authorId': '2729164', 'name': 'Maarten Sap'}, {'authorId': '119902504', 'name': 'Saadia Gabriel'}, {'authorId': '3444092', 'name': 'Lianhui Qin'}, {'authorId': '1746807', 'name': 'Dan Jurafsky'}, {'authorId': '144365876', 'name': 'Noah A. Smith'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]","101":"[{'authorId': '1804618', 'name': 'Eirini Ntoutsi'}, {'authorId': '2393008', 'name': 'P. Fafalios'}, {'authorId': '2516584', 'name': 'U. Gadiraju'}, {'authorId': '3176896', 'name': 'Vasileios Iosifidis'}, {'authorId': '1744808', 'name': 'W. Nejdl'}, {'authorId': '143858195', 'name': 'Maria-Esther Vidal'}, {'authorId': '2325428', 'name': 'S. Ruggieri'}, {'authorId': '1707206', 'name': 'F. Turini'}, {'authorId': '144178604', 'name': 'S. Papadopoulos'}, {'authorId': '28075447', 'name': 'Emmanouil Krasanakis'}, {'authorId': '119661806', 'name': 'I. Kompatsiaris'}, {'authorId': '1404596968', 'name': 'K. Kinder-Kurlanda'}, {'authorId': '144065562', 'name': 'Claudia Wagner'}, {'authorId': '51118506', 'name': 'F. Karimi'}, {'authorId': '152179862', 'name': 'Miriam Fern\u00e1ndez'}, {'authorId': '145842687', 'name': 'Harith Alani'}, {'authorId': '2990203', 'name': 'Bettina Berendt'}, {'authorId': '3144221', 'name': 'Tina Kruegel'}, {'authorId': '49729602', 'name': 'C. Heinze'}, {'authorId': '2102011', 'name': 'Klaus Broelemann'}, {'authorId': '1686448', 'name': 'Gjergji Kasneci'}, {'authorId': '1726746', 'name': 'T. Tiropanis'}, {'authorId': '1752093', 'name': 'Steffen Staab'}]","102":"[{'authorId': '4026473', 'name': 'T. Hofmeester'}, {'authorId': '145249929', 'name': 'J. Cromsigt'}, {'authorId': '6597879', 'name': 'J. Odden'}, {'authorId': '4912766', 'name': 'H. Andr\u00e9n'}, {'authorId': '5294315', 'name': 'J. Kindberg'}, {'authorId': '4914487', 'name': 'J. Linnell'}]","103":"[{'authorId': '3102850', 'name': 'Rohit Girdhar'}, {'authorId': '1770537', 'name': 'D. Ramanan'}]","104":"[{'authorId': '50039265', 'name': 'K. Morimoto'}, {'authorId': '144915413', 'name': 'Andrei Ardelean'}, {'authorId': '1471890179', 'name': 'Ming-Lo Wu'}, {'authorId': '34986333', 'name': 'A. Ulku'}, {'authorId': '8678576', 'name': 'I. M. Antolovi\u0107'}, {'authorId': '144348134', 'name': 'C. Bruschini'}, {'authorId': '144713024', 'name': 'E. Charbon'}]","105":"[{'authorId': '144776615', 'name': 'L. E. Celis'}, {'authorId': '39893263', 'name': 'Sayash Kapoor'}, {'authorId': '10661595', 'name': 'F. Salehi'}, {'authorId': '1810064', 'name': 'Nisheeth K. Vishnoi'}]","106":"[{'authorId': '2103617373', 'name': 'R. Doescher'}, {'authorId': '1404421872', 'name': 'M. Acosta'}, {'authorId': '145156171', 'name': 'A. Alessandri'}, {'authorId': '11824464', 'name': 'P. Anthoni'}, {'authorId': '2792896', 'name': 'A. Arneth'}, {'authorId': '11966449', 'name': 'T. Arsouze'}, {'authorId': '2124323052', 'name': 'Tommi Bergmann'}, {'authorId': '104572939', 'name': 'R. Bernadello'}, {'authorId': '9257657', 'name': 'S. Bousetta'}, {'authorId': '144467603', 'name': 'L. Caron'}, {'authorId': '50071425', 'name': 'G. Carver'}, {'authorId': '2409978', 'name': 'M. Castrillo'}, {'authorId': '38984168', 'name': 'F. Catalano'}, {'authorId': '30447624', 'name': 'I. Cvijanovic'}, {'authorId': '40209448', 'name': 'P. Davini'}, {'authorId': '2069528661', 'name': 'E. Dekker'}, {'authorId': '1404096456', 'name': 'F. Doblas-Reyes'}, {'authorId': '41094823', 'name': 'D. Docquier'}, {'authorId': '32667297', 'name': 'P. Echevarria'}, {'authorId': '2805840', 'name': 'U. Fladrich'}, {'authorId': '1404860587', 'name': 'R. Fuentes\u2010Franco'}, {'authorId': '52024757', 'name': 'M. Gr\u00f6ger'}, {'authorId': '2124322664', 'name': 'Jost v. Hardenberg'}, {'authorId': '92776659', 'name': 'Jenny Hieronymus'}, {'authorId': '49409509', 'name': 'M. Karami'}, {'authorId': '144578807', 'name': 'J. Keskinen'}, {'authorId': '70128047', 'name': 'T. Koenigk'}, {'authorId': '152217283', 'name': 'R. Makkonen'}, {'authorId': '8300829', 'name': 'F. Massonnet'}, {'authorId': '3682343', 'name': 'M. M\u00e9n\u00e9goz'}, {'authorId': '14120722', 'name': 'P. Miller'}, {'authorId': '1404835388', 'name': 'E. Moreno\u2010Chamarro'}, {'authorId': '2715521', 'name': 'L. Nieradzik'}, {'authorId': '4718738', 'name': 'T. van Noije'}, {'authorId': '79418754', 'name': 'P. Nolan'}, {'authorId': '1409890645', 'name': \"D. O'Donnell\"}, {'authorId': '70498289', 'name': 'P. Ollinaho'}, {'authorId': '134039680', 'name': 'G. V. D. van den Oord'}, {'authorId': '1753315568', 'name': 'P. Ortega'}, {'authorId': '69345766', 'name': 'Oriol Tint\u00f3 Prims'}, {'authorId': '2087284629', 'name': 'A. Ramos'}, {'authorId': '70549693', 'name': 'T. Reerink'}, {'authorId': '49580819', 'name': 'C. Rousset'}, {'authorId': '1399287695', 'name': 'Y. Ruprich\u2010Robert'}, {'authorId': '1688671060', 'name': 'Philipp Le Sager'}, {'authorId': '51331517', 'name': 'T. Schmith'}, {'authorId': '11324535', 'name': 'R. Schr\u00f6dner'}, {'authorId': '71069220', 'name': 'F. Serva'}, {'authorId': '13724059', 'name': 'V. Sicardi'}, {'authorId': '15871405', 'name': 'M. Sloth Madsen'}, {'authorId': '1417792690', 'name': 'Benjamin Smith'}, {'authorId': '48952011', 'name': 'T. Tian'}, {'authorId': '78718223', 'name': '\u00c9. Tourigny'}, {'authorId': '39109266', 'name': 'P. Uotila'}, {'authorId': '11839228', 'name': 'M. Vancoppenolle'}, {'authorId': '2109477527', 'name': 'Shiyu Wang'}, {'authorId': '4984570', 'name': 'D. W\u00e5rlind'}, {'authorId': '11415943', 'name': 'U. Will\u00e9n'}, {'authorId': '12229644', 'name': 'K. Wyser'}, {'authorId': '49080520', 'name': 'Shuting Yang'}, {'authorId': '2050574200', 'name': 'Xavier Yepes-Arb\u00f3s'}, {'authorId': '2108026677', 'name': 'Qiong Zhang'}]","107":"[{'authorId': '33499806', 'name': 'C. Gratton'}, {'authorId': '31275471', 'name': 'R. Coalson'}, {'authorId': '1403422168', 'name': 'A. Dworetsky'}, {'authorId': '3681453', 'name': 'B. Adeyemo'}, {'authorId': '2440512', 'name': 'Timothy O. Laumann'}, {'authorId': '145587736', 'name': 'G. Wig'}, {'authorId': '9487028', 'name': 'Tania S. Kong'}, {'authorId': '3337053', 'name': 'G. Gratton'}, {'authorId': '2718921', 'name': 'M. Fabiani'}, {'authorId': '2478230', 'name': 'D. Barch'}, {'authorId': '2467200', 'name': 'D. Tranel'}, {'authorId': '1390147912', 'name': '\u00d3. Miranda-Dom\u00ednguez'}, {'authorId': '35365511', 'name': 'D. Fair'}, {'authorId': '3133713', 'name': 'N. Dosenbach'}, {'authorId': '143908863', 'name': 'A. Snyder'}, {'authorId': '143747005', 'name': 'J. Perlmutter'}, {'authorId': '1878109', 'name': 'S. Petersen'}, {'authorId': '144236877', 'name': 'M. C. Campbell'}]","108":"[{'authorId': '1384709008', 'name': 'Xianhang Cheng'}, {'authorId': '48354614', 'name': 'Zhenzhong Chen'}]","109":"[{'authorId': '2026193813', 'name': 'Taiji Suzuki'}]","110":"[{'authorId': '2118767434', 'name': 'Nanyu Chen'}, {'authorId': '2112386216', 'name': 'Min Liu'}, {'authorId': '2110122263', 'name': 'Ya Xu'}]","111":"[{'authorId': '2495939', 'name': 'Michael A. Katell'}, {'authorId': '47533677', 'name': 'Meg Young'}, {'authorId': '1845779', 'name': 'Dharma Dailey'}, {'authorId': '11484361', 'name': 'Bernease Herman'}, {'authorId': '120844932', 'name': 'Vivian Guetler'}, {'authorId': '2070778588', 'name': 'Aaron Tam'}, {'authorId': '1451643713', 'name': 'Corinne Binz'}, {'authorId': '1451643902', 'name': 'Daniella Raz'}, {'authorId': '143782314', 'name': 'P. Krafft'}]","112":"[{'authorId': '36452482', 'name': 'Hashim A. Hashim'}]","113":"[{'authorId': '36294183', 'name': 'Benjamin Schiller'}, {'authorId': '1790638', 'name': 'Johannes Daxenberger'}, {'authorId': '1730400', 'name': 'Iryna Gurevych'}]","114":"[{'authorId': '1505462154', 'name': 'Aviram Bar-Haim'}, {'authorId': '48519520', 'name': 'L. Wolf'}]","115":"[{'authorId': '1491520578', 'name': 'Milagros Miceli'}, {'authorId': '1831833', 'name': 'Julian Posada'}, {'authorId': '1840070896', 'name': 'Tianling Yang'}]","116":"[{'authorId': '2086625174', 'name': 'Jon Leefmann'}]","117":"[{'authorId': '46450294', 'name': 'M. Coeckelbergh'}]","118":"[{'authorId': '1491520578', 'name': 'Milagros Miceli'}, {'authorId': '1831833', 'name': 'Julian Posada'}, {'authorId': '1840070896', 'name': 'Tianling Yang'}]","119":"[{'authorId': '104308565', 'name': 'A. Shadrova'}]","120":"[{'authorId': '51428797', 'name': 'M. Makhortykh'}, {'authorId': '1484797547', 'name': 'Aleksandra Urman'}, {'authorId': '1975336', 'name': 'R. Ulloa'}]","121":"[{'authorId': '2051252769', 'name': 'Michael F\u00e4rber'}, {'authorId': '30947879', 'name': 'Frederic Bartscherer'}]","122":"[]","123":"[{'authorId': '147225682', 'name': 'Keita Kurita'}, {'authorId': '47963068', 'name': 'Nidhi Vyas'}, {'authorId': '18081101', 'name': 'Ayush Pareek'}, {'authorId': '1690706', 'name': 'A. Black'}, {'authorId': '145317727', 'name': 'Yulia Tsvetkov'}]","124":"[{'authorId': '98173671', 'name': 'Baris Kirdemir'}, {'authorId': '1845898514', 'name': 'Joseph Kready'}, {'authorId': '50050425', 'name': 'Esther Mead'}, {'authorId': '26677596', 'name': 'Muhammad Nihal Hussain'}, {'authorId': '47631831', 'name': 'Nidhi Agarwal'}]","125":"[{'authorId': '51029829', 'name': 'Susan Leavy'}, {'authorId': '3403547', 'name': 'G. Meaney'}, {'authorId': '144507401', 'name': 'Karen Wade'}, {'authorId': '40199774', 'name': 'Derek Greene'}]","126":"[{'authorId': '2117326853', 'name': 'Fabian Haak'}, {'authorId': '34588911', 'name': 'Philipp Schaer'}]","127":"[{'authorId': '34865486', 'name': 'Toshihiro Kamishima'}, {'authorId': '143683998', 'name': 'S. Akaho'}, {'authorId': '2994688', 'name': 'Yukino Baba'}, {'authorId': '2785830', 'name': 'H. Kashima'}]","128":"[{'authorId': '2117318960', 'name': 'Francisco Gu\u00ed\u00f1ez'}, {'authorId': '143873892', 'name': 'Javier Ruiz'}, {'authorId': '2117080970', 'name': 'M. I. S\u00e1nchez'}]","129":"[{'authorId': '31125953', 'name': 'Joel Escud\u00e9 Font'}, {'authorId': '1398996347', 'name': 'M. Costa-juss\u00e0'}]","130":"[{'authorId': '2068408796', 'name': 'Simone Diniz Junqueira Barbosa'}, {'authorId': '40913232', 'name': 'Phoebe Chen'}, {'authorId': '145046124', 'name': 'A. Cuzzocrea'}, {'authorId': '46993406', 'name': 'Xiaoyong Du'}, {'authorId': '144408238', 'name': 'Orhun Kara'}, {'authorId': '145161755', 'name': 'Ting Liu'}, {'authorId': '1731022', 'name': 'K. Sivalingam'}, {'authorId': '145514740', 'name': 'D. \u015al\u0119zak'}, {'authorId': '1704749', 'name': 'T. Washio'}, {'authorId': '50031361', 'name': 'Xiaokang Yang'}, {'authorId': '145078769', 'name': 'Junsong Yuan'}, {'authorId': '1690892', 'name': 'R. Prates'}, {'authorId': '1824224', 'name': 'Ludovico Boratto'}, {'authorId': '1630492711', 'name': 'Stefano Faralli'}, {'authorId': '28922901', 'name': 'M. Marras'}, {'authorId': '1765155', 'name': 'G. Stilo'}]","131":"[{'authorId': '73312674', 'name': 'Christine Basta'}, {'authorId': '1398996347', 'name': 'M. Costa-juss\u00e0'}, {'authorId': '1794731', 'name': 'Noe Casas'}]","132":"[{'authorId': '1630500951', 'name': 'Giannis Konstantakis'}, {'authorId': '1811417244', 'name': 'Giannis Promponas'}, {'authorId': '1811417496', 'name': 'Manthos Dretakis'}, {'authorId': '2998829', 'name': 'P. Papadakos'}]","133":"[{'authorId': '153091253', 'name': 'Won Ik Cho'}, {'authorId': '47964255', 'name': 'Jiwon Kim'}, {'authorId': '2127354716', 'name': 'Seokhwan Kim'}, {'authorId': '1687497', 'name': 'N. Kim'}]","134":"[{'authorId': '151502827', 'name': 'Flavien Prost'}, {'authorId': '2665391', 'name': 'Nithum Thain'}, {'authorId': '2843215', 'name': 'Tolga Bolukbasi'}]","135":"[{'authorId': '1396196837', 'name': 'Yasmeen Hitti'}, {'authorId': '1379692479', 'name': 'Eunbee Jang'}, {'authorId': '47576563', 'name': 'I. Moreno'}, {'authorId': '2064166694', 'name': 'C. Pelletier'}]","136":"[{'authorId': '2662374', 'name': 'Jo\u00e3o Sedoc'}, {'authorId': '1412391493', 'name': 'L. Ungar'}]","137":"[{'authorId': '69045699', 'name': 'Nicholas Asher'}, {'authorId': '2331518', 'name': 'Soumya Paul'}, {'authorId': '2052380526', 'name': 'Chris Russell'}]","138":"[{'authorId': '2113643119', 'name': 'T. Nantsou'}, {'authorId': '133899636', 'name': 'E. Kapotis'}, {'authorId': '2833161', 'name': 'G. Tombras'}]","139":"[{'authorId': '2051747173', 'name': 'G. M. D. Nunzio'}, {'authorId': '35340264', 'name': 'Alessandro Fabris'}, {'authorId': '1508853659', 'name': 'Gianmaria Silvello'}, {'authorId': '3126083', 'name': 'Gian Antonio Susto'}]","140":"[{'authorId': '1405369173', 'name': 'Rajiv Movva'}]","141":"[{'authorId': '2089776510', 'name': 'Bin Han'}, {'authorId': '144797719', 'name': 'C. Shah'}, {'authorId': '2007656135', 'name': 'Daniel Saelid'}]","142":"[{'authorId': '1411408316', 'name': 'Joanna Misztal-Radecka'}, {'authorId': '1904554', 'name': 'B. Indurkhya'}]","143":"[{'authorId': '4322924', 'name': 'Nicholas Asher'}, {'authorId': '2331518', 'name': 'Soumya Paul'}, {'authorId': '2052380526', 'name': 'Chris Russell'}]","144":"[{'authorId': '1780214785', 'name': 'Sahil Verma'}, {'authorId': '2986776', 'name': 'Ruoyuan Gao'}, {'authorId': '144797716', 'name': 'C. Shah'}]","145":"[{'authorId': '35903921', 'name': 'E. Gerritse'}, {'authorId': '144509504', 'name': 'A. D. Vries'}]","146":"[{'authorId': '2068958502', 'name': 'W. Silva'}, {'authorId': '134477964', 'name': 'Marcos A. Spalenza'}, {'authorId': '32230107', 'name': 'Jean-R\u00e9mi Bourguet'}, {'authorId': '144469168', 'name': 'E. Oliveira'}]","147":"[{'authorId': '2118669575', 'name': 'Yinchuan Xu'}, {'authorId': '46478443', 'name': 'Junlin Yang'}]","148":"[{'authorId': '1380952930', 'name': 'Xingce Bao'}, {'authorId': '2058331569', 'name': 'Qianqian Qiao'}]","149":"[{'authorId': '147887099', 'name': 'Rakesh Chada'}]","150":"[{'authorId': '2064527991', 'name': 'Felipe Alfaro'}, {'authorId': '1398996347', 'name': 'M. Costa-juss\u00e0'}, {'authorId': '1779548', 'name': 'Jos\u00e9 A. R. Fonollosa'}]","151":"[{'authorId': '31640709', 'name': 'Tobias D. Krafft'}, {'authorId': '32674085', 'name': 'Marc P. Hauer'}, {'authorId': '1712415', 'name': 'K. Zweig'}]","152":"[{'authorId': '3378320', 'name': 'Dimitris Paraschakis'}, {'authorId': '1705462', 'name': 'Bengt J. Nilsson'}]","153":"[{'authorId': '65977783', 'name': 'J. Bhaskaran'}, {'authorId': '119208750', 'name': 'Isha Bhallamudi'}]","154":"[{'authorId': '115317198', 'name': 'A. Doyle'}]","155":"[{'authorId': '2129146', 'name': 'G. Origgi'}]","156":"[{'authorId': '2155440005', 'name': 'Bo Liu'}]","157":"[{'authorId': '3161763', 'name': 'Frank Soboczenski'}, {'authorId': '2947796', 'name': 'T. Trikalinos'}, {'authorId': '37912398', 'name': 'J. Kuiper'}, {'authorId': '1789999', 'name': 'R. Bias'}, {'authorId': '1912476', 'name': 'Byron C. Wallace'}, {'authorId': '1808775', 'name': 'I. Marshall'}]","158":"[{'authorId': '2058505917', 'name': 'Luca Russo'}, {'authorId': '48832947', 'name': 'S. Russo'}]","159":"[{'authorId': '4923854', 'name': 'Ramit Debnath'}, {'authorId': '144388959', 'name': 'Sarah C. Darby'}, {'authorId': '8605672', 'name': 'R. Bardhan'}, {'authorId': '66312620', 'name': 'Kamiar Mohaddes'}, {'authorId': '1401989531', 'name': 'Minna Sunikka-Blank'}]","160":"[{'authorId': '46547964', 'name': 'J. Kline'}, {'authorId': '2051654958', 'name': 'Avram Aelony'}, {'authorId': '2064025011', 'name': 'Brian Carpenter'}, {'authorId': '1917752', 'name': 'P. Barford'}]","161":"[{'authorId': '1752617585', 'name': 'Jonas Andersson Schwarz'}]","162":"[{'authorId': '81717057', 'name': 'Elija Perrier'}]","163":"[{'authorId': '8046474', 'name': 'Aida Rahmattalabi'}, {'authorId': '4990825', 'name': 'Alice Xiang'}]","164":"[{'authorId': '144802855', 'name': 'Freydis Vogel'}, {'authorId': '36069747', 'name': 'Heisawn Jeong'}, {'authorId': '34834708', 'name': 'Susan A. Yoon'}, {'authorId': '3039009', 'name': 'Stian H\u00e5klev'}, {'authorId': '40959639', 'name': 'L\u00e9onore V. Guillain'}, {'authorId': '145835641', 'name': 'N. Abassi'}, {'authorId': '31748637', 'name': 'S. Wan'}, {'authorId': '103713862', 'name': 'S. Wan'}, {'authorId': '89293431', 'name': 'Anika Radkowitsch'}, {'authorId': '1778666', 'name': 'F. Fischer'}, {'authorId': '1402023632', 'name': 'C. Hmelo\u2010Silver'}]","165":"[{'authorId': '3215719', 'name': 'R. Englert'}, {'authorId': '32671222', 'name': 'J\u00f6rg Muschiol'}]","166":"[{'authorId': '2117097772', 'name': 'Ziyi Chen'}, {'authorId': '2672180', 'name': 'Dilong Li'}, {'authorId': '2113534223', 'name': 'Wentao Fan'}, {'authorId': '21704078', 'name': 'H. Guan'}, {'authorId': '115877724', 'name': 'Cheng Wang'}, {'authorId': '2109043577', 'name': 'Jonathan Li'}]","167":"[{'authorId': '1406443102', 'name': 'Maria De-Arteaga'}, {'authorId': '145020546', 'name': 'Alexey Romanov'}, {'authorId': '1831395', 'name': 'H. Wallach'}, {'authorId': '1695997', 'name': 'J. Chayes'}, {'authorId': '1721812', 'name': 'C. Borgs'}, {'authorId': '2082393', 'name': 'A. Chouldechova'}, {'authorId': '6748971', 'name': 'S. C. Geyik'}, {'authorId': '1769861', 'name': 'K. Kenthapadi'}, {'authorId': '2186481', 'name': 'A. Kalai'}]","168":"[{'authorId': '4573107', 'name': 'Xenia Ohmer'}, {'authorId': '40089171', 'name': 'P. K\u00f6nig'}, {'authorId': '145075066', 'name': 'M. Franke'}]","169":"[{'authorId': '48881008', 'name': 'Tao Yu'}, {'authorId': '30340989', 'name': 'Chien-Sheng Wu'}, {'authorId': '143724481', 'name': 'Xi Victoria Lin'}, {'authorId': '5535859', 'name': 'Bailin Wang'}, {'authorId': '144787248', 'name': 'Y. Tan'}, {'authorId': '2150441485', 'name': 'Xinyi Yang'}, {'authorId': '1405531452', 'name': 'Dragomir Radev'}, {'authorId': '2166511', 'name': 'R. Socher'}, {'authorId': '2228109', 'name': 'Caiming Xiong'}]","170":"[{'authorId': '1852415', 'name': 'Zheng Zhang'}, {'authorId': '26951082', 'name': 'Luyao Liu'}, {'authorId': '150350159', 'name': 'Yadan Luo'}, {'authorId': '145622169', 'name': 'Zi Huang'}, {'authorId': '144618699', 'name': 'Fumin Shen'}, {'authorId': '1724393', 'name': 'H. Shen'}, {'authorId': '143911582', 'name': 'Guangming Lu'}]","171":"[{'authorId': '39878282', 'name': 'Jang Hyun Cho'}, {'authorId': '107979543', 'name': 'Utkarsh Mall'}, {'authorId': '144374926', 'name': 'K. Bala'}, {'authorId': '73710317', 'name': 'B. Hariharan'}]","172":"[{'authorId': '2053865518', 'name': 'Ruifei He'}, {'authorId': '47987749', 'name': 'Jihan Yang'}, {'authorId': '50844674', 'name': 'Xiaojuan Qi'}]","173":"[{'authorId': '1763181', 'name': 'Reza Azad'}, {'authorId': '20519879', 'name': 'A. Fayjie'}, {'authorId': '144854771', 'name': 'C. Kauffmann'}, {'authorId': '144019647', 'name': 'I. B. Ayed'}, {'authorId': '3048367', 'name': 'M. Pedersoli'}, {'authorId': '144702316', 'name': 'J. Dolz'}]","174":"[{'authorId': '2109795481', 'name': 'Dong Zhang'}, {'authorId': '5462268', 'name': 'Hanwang Zhang'}, {'authorId': '8053308', 'name': 'Jinhui Tang'}, {'authorId': '2053903039', 'name': 'Xiansheng Hua'}, {'authorId': '32222907', 'name': 'Qianru Sun'}]","175":"[{'authorId': '7247867', 'name': 'Ruibo Liu'}, {'authorId': '1727055797', 'name': 'Chenyan Jia'}, {'authorId': '2111343757', 'name': 'Jason Wei'}, {'authorId': '2007669250', 'name': 'Guangxuan Xu'}, {'authorId': '2117930921', 'name': 'Lili Wang'}, {'authorId': '1918441', 'name': 'Soroush Vosoughi'}]","176":"[{'authorId': '7788324', 'name': 'Jinyu Yang'}, {'authorId': '51166602', 'name': 'Weizhi An'}, {'authorId': '2151484950', 'name': 'Sheng Wang'}, {'authorId': '8361760', 'name': 'Xinliang Zhu'}, {'authorId': '7590092', 'name': 'Chao-chao Yan'}, {'authorId': '1768190', 'name': 'Junzhou Huang'}]","177":"[{'authorId': '2744372', 'name': 'Shaobo Min'}, {'authorId': '2222738', 'name': 'Hantao Yao'}, {'authorId': '143994657', 'name': 'Hongtao Xie'}, {'authorId': '2144555593', 'name': 'Chaoqun Wang'}, {'authorId': '143962510', 'name': 'Zhengjun Zha'}, {'authorId': '1699819', 'name': 'Yongdong Zhang'}]","178":"[{'authorId': None, 'name': 'Shuang Li'}, {'authorId': '2112817811', 'name': 'Mixue Xie'}, {'authorId': '2124763047', 'name': 'Fangrui Lv'}, {'authorId': '2144632579', 'name': 'Chi Harold Liu'}, {'authorId': '143932869', 'name': 'Jian Liang'}, {'authorId': '143771778', 'name': 'C. Qin'}, {'authorId': '2157338657', 'name': 'Wei Li'}]","179":"[{'authorId': '33524946', 'name': 'Jieyu Zhao'}, {'authorId': '1777140', 'name': 'Subhabrata Mukherjee'}, {'authorId': '2195458', 'name': 'Saghar Hosseini'}, {'authorId': '2782886', 'name': 'Kai-Wei Chang'}, {'authorId': '1977489', 'name': 'Ahmed Hassan Awadallah'}]","180":"[{'authorId': '31461304', 'name': 'Emily Dinan'}, {'authorId': '144270981', 'name': 'Angela Fan'}, {'authorId': '51183248', 'name': 'Ledell Yu Wu'}, {'authorId': '145183709', 'name': 'J. Weston'}, {'authorId': '1743722', 'name': 'Douwe Kiela'}, {'authorId': '81840293', 'name': 'Adina Williams'}]","181":"[{'authorId': '153152072', 'name': 'Aishan Liu'}, {'authorId': '2109618469', 'name': 'Jiakai Wang'}, {'authorId': '6820648', 'name': 'Xianglong Liu'}, {'authorId': '2072987637', 'name': 'Bowen Cao'}, {'authorId': '7923989', 'name': 'Chongzhi Zhang'}, {'authorId': '2110984200', 'name': 'Hang Yu'}]","182":"[{'authorId': '2592694', 'name': 'Haewoon Kwak'}, {'authorId': '2088546758', 'name': 'Jisun An'}, {'authorId': '2082915315', 'name': 'Elise Jing'}, {'authorId': '36663090', 'name': 'Yong-Yeol Ahn'}]","183":"[{'authorId': '1785372925', 'name': 'Tianlu Wang'}, {'authorId': '143724481', 'name': 'Xi Victoria Lin'}, {'authorId': '8937909', 'name': 'Nazneen Rajani'}, {'authorId': '2004053', 'name': 'Vicente Ordonez'}, {'authorId': '1576585374', 'name': 'Caimng Xiong'}]","184":"[{'authorId': '3460489', 'name': 'Amir Pouran Ben Veyseh'}, {'authorId': '150322649', 'name': 'Tuan Ngo Nguyen'}, {'authorId': '1811211', 'name': 'T. Nguyen'}]","185":"[{'authorId': '49968678', 'name': 'M. Hashemi'}, {'authorId': '29530794', 'name': 'M. Hall'}]","186":"[{'authorId': '2108470905', 'name': 'Weiwei Wang'}, {'authorId': '1753703441', 'name': 'Yuming Shen'}, {'authorId': '2605815', 'name': 'Haofeng Zhang'}, {'authorId': '2436931', 'name': 'Yazhou Yao'}, {'authorId': '40241836', 'name': 'Li Liu'}]","187":"[{'authorId': '3056500', 'name': 'N. Ousidhoum'}, {'authorId': '1809614', 'name': 'Yangqiu Song'}, {'authorId': '66427434', 'name': 'Dit-Yan Yeung'}]","188":"[{'authorId': '1388017711', 'name': 'Christoph Kamann'}, {'authorId': '3047741', 'name': 'Burkhard G\u00fcssefeld'}, {'authorId': '32038986', 'name': 'Robin Hutmacher'}, {'authorId': '2708564', 'name': 'J. H. Metzen'}, {'authorId': '1756036', 'name': 'C. Rother'}]","189":"[{'authorId': '2753987', 'name': 'Fengmao Lv'}, {'authorId': '2117956344', 'name': 'Haiyang Liu'}, {'authorId': '2116641647', 'name': 'Yichen Wang'}, {'authorId': '2109781936', 'name': 'Jiayi Zhao'}, {'authorId': '1805650', 'name': 'Guowu Yang'}]","190":"[{'authorId': '50991767', 'name': 'Sunipa Dev'}, {'authorId': '1795436', 'name': 'J. M. Phillips'}]","191":"[{'authorId': '3461253', 'name': 'Felix Hamborg'}]","192":"[{'authorId': '144618699', 'name': 'Fumin Shen'}, {'authorId': '50177639', 'name': 'Xiaoping Zhou'}, {'authorId': '2117884196', 'name': 'Jun Yu'}, {'authorId': '2152283122', 'name': 'Yang Yang'}, {'authorId': '49480212', 'name': 'Li Liu'}, {'authorId': '1724393', 'name': 'H. Shen'}]","193":"[{'authorId': '120296402', 'name': 'Seung-Jae Shin'}, {'authorId': '2490092', 'name': 'Kyungwoo Song'}, {'authorId': '91586945', 'name': 'Joonho Jang'}, {'authorId': '2155255295', 'name': 'Hyemi Kim'}, {'authorId': '67271599', 'name': 'Weonyoung Joo'}, {'authorId': '1729306', 'name': 'Il-Chul Moon'}]","194":"[{'authorId': '51214165', 'name': 'Muhammad Waleed Gondal'}, {'authorId': '36661824', 'name': 'Manuel W\u00fcthrich'}, {'authorId': '40220358', 'name': '\u00d0or\u00f0e Miladinovic'}, {'authorId': '9557137', 'name': 'Francesco Locatello'}, {'authorId': '2016068', 'name': 'M. Breidt'}, {'authorId': '23699290', 'name': 'V. Volchkov'}, {'authorId': '147016408', 'name': 'J. Akpo'}, {'authorId': '1936951', 'name': 'Olivier Bachem'}, {'authorId': '1707625', 'name': 'B. Sch\u00f6lkopf'}, {'authorId': '153125952', 'name': 'Stefan Bauer'}]","195":"[{'authorId': '2112713004', 'name': 'Jasdeep Singh'}, {'authorId': '143775536', 'name': 'Bryan McCann'}, {'authorId': '2166511', 'name': 'R. Socher'}, {'authorId': '2228109', 'name': 'Caiming Xiong'}]","196":"[{'authorId': '48927190', 'name': 'Akanksha Paul'}, {'authorId': '2503137', 'name': 'N. C. Krishnan'}, {'authorId': '102615578', 'name': 'Prateek Munjal'}]","197":"[{'authorId': '35593430', 'name': 'Mina Rezaei'}, {'authorId': '1688587', 'name': 'Haojin Yang'}, {'authorId': '1708312', 'name': 'C. Meinel'}]","198":"[{'authorId': '5535859', 'name': 'Bailin Wang'}, {'authorId': '144889265', 'name': 'Ivan Titov'}, {'authorId': '1747893', 'name': 'Mirella Lapata'}]","199":"[{'authorId': '83246531', 'name': 'Lukas Hoyer'}, {'authorId': '2067762722', 'name': 'Mauricio Mu\u00f1oz'}, {'authorId': '1853733', 'name': 'P. Katiyar'}, {'authorId': '145327993', 'name': 'A. Khoreva'}, {'authorId': '47092548', 'name': 'Volker Fischer'}]","200":"[{'authorId': '30462410', 'name': 'Shima Asaadi'}, {'authorId': '143880621', 'name': 'Saif M. Mohammad'}, {'authorId': '2886725', 'name': 'Svetlana Kiritchenko'}]","201":"[{'authorId': '2118154632', 'name': 'Siyao Li'}, {'authorId': '51924717', 'name': 'Deren Lei'}, {'authorId': '1937786', 'name': 'Pengda Qin'}, {'authorId': '1682479', 'name': 'William Yang Wang'}]","202":"[{'authorId': '1388056963', 'name': 'Chris J. M. Yoon'}, {'authorId': '3049056', 'name': 'G. Hamarneh'}, {'authorId': '51307114', 'name': 'Rafeef Garbi'}]","203":"[{'authorId': '2506727', 'name': 'Taylor R. Hayes'}, {'authorId': '144897958', 'name': 'J. Henderson'}]","204":"[{'authorId': '2910714', 'name': 'W. L. Cava'}, {'authorId': '152512193', 'name': 'Jason H. Moore'}]","205":"[{'authorId': '3461253', 'name': 'Felix Hamborg'}, {'authorId': '83302144', 'name': 'Anastasia Zhukova'}, {'authorId': '145151838', 'name': 'Bela Gipp'}]","206":"[{'authorId': '6845541', 'name': 'Alexa Tompary'}, {'authorId': '1398907287', 'name': 'S. Thompson-Schill'}]","207":"[{'authorId': '147132443', 'name': 'J. Pfau'}, {'authorId': '47973433', 'name': 'Albert T. Young'}, {'authorId': '31342816', 'name': 'Maria L. Wei'}, {'authorId': '2780351', 'name': 'Michael J. Keiser'}]","208":"[{'authorId': '2291858', 'name': 'Rakefet Ackerman'}, {'authorId': '70189402', 'name': 'A. Gal'}, {'authorId': '47125649', 'name': 'Tomer Sagi'}, {'authorId': '14398962', 'name': 'Roee Shraga'}]","209":"[{'authorId': '2079614268', 'name': 'A. Steiner'}, {'authorId': '144629422', 'name': 'Alexander Kolesnikov'}, {'authorId': '2743563', 'name': 'Xiaohua Zhai'}, {'authorId': '2113839396', 'name': 'Ross Wightman'}, {'authorId': '39328010', 'name': 'Jakob Uszkoreit'}, {'authorId': '39611591', 'name': 'L. Beyer'}]","210":"[{'authorId': '2108076606', 'name': 'Xudong Wang'}, {'authorId': '2054733874', 'name': 'Long Lian'}, {'authorId': '89139426', 'name': 'Zhongqi Miao'}, {'authorId': '2117940996', 'name': 'Ziwei Liu'}, {'authorId': '2107881808', 'name': 'Stella X. Yu'}]","211":"[{'authorId': '2112400', 'name': 'Jacob Andreas'}]","212":"[{'authorId': '1994268', 'name': 'Deven Santosh Shah'}, {'authorId': '145035129', 'name': 'H. A. Schwartz'}, {'authorId': '2022288', 'name': 'Dirk Hovy'}]","213":"[{'authorId': '23999143', 'name': 'Deng-Ping Fan'}, {'authorId': '2689358', 'name': 'Tengpeng Li'}, {'authorId': '2112752933', 'name': 'Zheng Lin'}, {'authorId': '94805190', 'name': 'Ge-Peng Ji'}, {'authorId': '39901030', 'name': 'Dingwen Zhang'}, {'authorId': '37535930', 'name': 'Ming-Ming Cheng'}, {'authorId': '1929093', 'name': 'H. Fu'}, {'authorId': '145953515', 'name': 'Jianbing Shen'}]","214":"[{'authorId': '49527724', 'name': 'Hongwei Wang'}, {'authorId': '2152527702', 'name': 'Miao Zhao'}, {'authorId': '144076239', 'name': 'Xing Xie'}, {'authorId': '50135338', 'name': 'Wenjie Li'}, {'authorId': '1697293', 'name': 'M. Guo'}]","215":"[{'authorId': '9370721', 'name': 'V. Guizilini'}, {'authorId': '2073312133', 'name': 'Rui Hou'}, {'authorId': '2155868565', 'name': 'Jie Li'}, {'authorId': '1829964', 'name': 'Rares Ambrus'}, {'authorId': '1799820', 'name': 'Adrien Gaidon'}]","216":"[{'authorId': '67146006', 'name': 'P. Kirichenko'}, {'authorId': '7991830', 'name': 'Pavel Izmailov'}, {'authorId': '145771261', 'name': 'A. G. Wilson'}]","217":"[{'authorId': '1954481', 'name': 'Dat T. Huynh'}, {'authorId': '47126776', 'name': 'Ehsan Elhamifar'}]","218":"[{'authorId': '1717107012', 'name': 'Dongnan Liu'}, {'authorId': '2109559435', 'name': 'Donghao Zhang'}, {'authorId': None, 'name': 'Yang Song'}, {'authorId': '144184856', 'name': 'Fan Zhang'}, {'authorId': '1398222646', 'name': \"L. O'Donnell\"}, {'authorId': '1748032', 'name': 'Heng Huang'}, {'authorId': '2108608250', 'name': 'Mei Chen'}, {'authorId': '122905659', 'name': 'Weidong (Tom) Cai'}]","219":"[{'authorId': '2107909505', 'name': 'Shiming Chen'}, {'authorId': '2146359889', 'name': 'Wenjie Wang'}, {'authorId': '1561145507', 'name': 'Beihao Xia'}, {'authorId': '2647338', 'name': 'Qinmu Peng'}, {'authorId': '1744228', 'name': 'Xinge You'}, {'authorId': '2057490886', 'name': 'Feng Zheng'}, {'authorId': '144082425', 'name': 'L. Shao'}]","220":"[{'authorId': '2135358934', 'name': 'Yicong Li'}, {'authorId': '1390538450', 'name': 'Xun Yang'}, {'authorId': '2444704', 'name': 'Xindi Shang'}, {'authorId': '144078686', 'name': 'Tat-Seng Chua'}]","221":"[{'authorId': '50991767', 'name': 'Sunipa Dev'}, {'authorId': '47387745', 'name': 'Tao Li'}, {'authorId': '1795436', 'name': 'J. M. Phillips'}, {'authorId': '3052879', 'name': 'Vivek Srikumar'}]","222":"[{'authorId': '38832570', 'name': 'Liang Zhao'}, {'authorId': '1958895984', 'name': 'Tao Yang'}, {'authorId': '2158723925', 'name': 'Jie Zhang'}, {'authorId': '1803933', 'name': 'Zhikui Chen'}, {'authorId': '2143685665', 'name': 'Yi Yang'}, {'authorId': '1859192', 'name': 'Z. J. Wang'}]","223":"[{'authorId': '144533942', 'name': 'Pengyu Cheng'}, {'authorId': '3314779', 'name': 'Weituo Hao'}, {'authorId': '2087092426', 'name': 'Siyang Yuan'}, {'authorId': '81065454', 'name': 'Shijing Si'}, {'authorId': '145006560', 'name': 'L. Carin'}]","224":"[{'authorId': '2057938837', 'name': 'R. Gao'}, {'authorId': '1837363', 'name': 'Xingsong Hou'}, {'authorId': '144411970', 'name': 'Jie Qin'}, {'authorId': '145905368', 'name': 'Jiaxin Chen'}, {'authorId': '40241836', 'name': 'Li Liu'}, {'authorId': '152506137', 'name': 'F. Zhu'}, {'authorId': '2156121278', 'name': 'Zhao Zhang'}, {'authorId': '144082425', 'name': 'L. Shao'}]","225":"[{'authorId': '1753703441', 'name': 'Yuming Shen'}, {'authorId': '144411970', 'name': 'Jie Qin'}, {'authorId': '1993660900', 'name': 'Lei Huang'}]","226":"[{'authorId': '23999143', 'name': 'Deng-Ping Fan'}, {'authorId': '2112752933', 'name': 'Zheng Lin'}, {'authorId': '94805190', 'name': 'Ge-Peng Ji'}, {'authorId': '39901030', 'name': 'Dingwen Zhang'}, {'authorId': '1929093', 'name': 'H. Fu'}, {'authorId': '37535930', 'name': 'Ming-Ming Cheng'}]","227":"[{'authorId': '90622954', 'name': 'B. Billot'}, {'authorId': '1827360', 'name': 'D. Greve'}, {'authorId': '1796114', 'name': 'K. Leemput'}, {'authorId': '145815766', 'name': 'B. Fischl'}, {'authorId': '1786793', 'name': 'J. E. Iglesias'}, {'authorId': '3046516', 'name': 'Adrian V. Dalca'}]","228":"[{'authorId': '153173943', 'name': 'Jin Ye'}, {'authorId': '1720735918', 'name': 'Junjun He'}, {'authorId': '1766837', 'name': 'Xiaojiang Peng'}, {'authorId': '50224945', 'name': 'Wenhao Wu'}, {'authorId': '145858545', 'name': 'Y. Qiao'}]","229":"[{'authorId': '24925751', 'name': 'Junnan Zhu'}, {'authorId': '2110631853', 'name': 'Yu Zhou'}, {'authorId': '38358352', 'name': 'Jiajun Zhang'}, {'authorId': '47893252', 'name': 'Haoran Li'}, {'authorId': '2423168', 'name': 'Chengqing Zong'}, {'authorId': '2348067', 'name': 'Changliang Li'}]","230":"[{'authorId': '2928777', 'name': 'Wenhu Chen'}, {'authorId': '1720246', 'name': 'Jianshu Chen'}, {'authorId': '1937786', 'name': 'Pengda Qin'}, {'authorId': '1740249', 'name': 'Xifeng Yan'}, {'authorId': '1682479', 'name': 'William Yang Wang'}]","231":"[{'authorId': '2118788278', 'name': 'Yujia Zhou'}, {'authorId': '1897235', 'name': 'Zhicheng Dou'}, {'authorId': '153693432', 'name': 'Ji-rong Wen'}]","232":"[{'authorId': '151170970', 'name': 'Peirong Ma'}, {'authorId': '47027390', 'name': 'Xiao Hu'}]","233":"[{'authorId': '1830436286', 'name': 'Vaibhav Kumar'}, {'authorId': '1736525810', 'name': 'Tenzin Singhay Bhotia'}, {'authorId': '144054829', 'name': 'Tanmoy Chakraborty'}]","234":"[{'authorId': '1396456007', 'name': 'Simone Conia'}, {'authorId': '1733928', 'name': 'R. Navigli'}]","235":"[{'authorId': '94845899', 'name': 'Qianyu Feng'}, {'authorId': '3374337', 'name': 'Guoliang Kang'}, {'authorId': '3446334', 'name': 'Hehe Fan'}, {'authorId': '7607499', 'name': 'Yezhou Yang'}]","236":"[{'authorId': '2791557', 'name': 'A. Pujari'}, {'authorId': '153726840', 'name': 'Ansh Mittal'}, {'authorId': '1492065906', 'name': 'Anshuman Padhi'}, {'authorId': '2116747941', 'name': 'Anshul Jain'}, {'authorId': '30091834', 'name': 'Mukesh K. Jadon'}, {'authorId': '2109446174', 'name': 'Vikas Kumar'}]","237":"[{'authorId': '2054105945', 'name': 'Nader Asadi'}, {'authorId': '29545186', 'name': 'M. Hosseinzadeh'}, {'authorId': '1879637', 'name': 'M. Eftekhari'}]","238":"[{'authorId': None, 'name': 'Meng Liu'}, {'authorId': '145410401', 'name': 'P. Thomas'}]","239":"[{'authorId': '2744372', 'name': 'Shaobo Min'}, {'authorId': '2222738', 'name': 'Hantao Yao'}, {'authorId': '143994657', 'name': 'Hongtao Xie'}, {'authorId': '143962510', 'name': 'Zhengjun Zha'}, {'authorId': '1699819', 'name': 'Yongdong Zhang'}]","240":"[{'authorId': '145123979', 'name': 'Ganesh Jawahar'}, {'authorId': '1679170', 'name': 'Djam\u00e9 Seddah'}]","241":"[{'authorId': '38759328', 'name': 'Peter Shaw'}, {'authorId': '1744179', 'name': 'Ming-Wei Chang'}, {'authorId': '2616463', 'name': 'Panupong Pasupat'}, {'authorId': '3259253', 'name': 'Kristina Toutanova'}]","242":"[{'authorId': '3203533', 'name': 'Rishabh Bhardwaj'}, {'authorId': '35122767', 'name': 'Navonil Majumder'}, {'authorId': '1746416', 'name': 'Soujanya Poria'}]","243":"[{'authorId': '101456890', 'name': 'Donghyeon Baek'}, {'authorId': '1564629398', 'name': 'Youngmin Oh'}, {'authorId': '38723538', 'name': 'Bumsub Ham'}]","244":"[{'authorId': '10200050', 'name': 'Fabio Cermelli'}, {'authorId': '38286801', 'name': 'Massimiliano Mancini'}, {'authorId': '2145174', 'name': 'S. R. Bul\u00f2'}, {'authorId': '40811261', 'name': 'E. Ricci'}, {'authorId': '3033284', 'name': 'B. Caputo'}]","245":"[{'authorId': '2151298960', 'name': 'Guangrui Li'}, {'authorId': '3374337', 'name': 'Guoliang Kang'}, {'authorId': '2117994649', 'name': 'Wu Liu'}, {'authorId': '49020088', 'name': 'Yunchao Wei'}, {'authorId': '7179962', 'name': 'Yi Yang'}]","246":"[{'authorId': '41079145', 'name': 'T. Radicioni'}, {'authorId': '34917281', 'name': 'E. Pavan'}, {'authorId': '2535806', 'name': 'T. Squartini'}, {'authorId': '2419880', 'name': 'F. Saracco'}]","247":"[{'authorId': '6274033', 'name': 'Shruti Jadon'}]","248":"[{'authorId': '2421691', 'name': 'Po-Sen Huang'}, {'authorId': '49723481', 'name': 'Huan Zhang'}, {'authorId': '35076395', 'name': 'Ray Jiang'}, {'authorId': '49860489', 'name': 'Robert Stanforth'}, {'authorId': '1851564', 'name': 'Johannes Welbl'}, {'authorId': '34269227', 'name': 'Jack W. Rae'}, {'authorId': '51965508', 'name': 'Vishal Maini'}, {'authorId': '1755465', 'name': 'Dani Yogatama'}, {'authorId': '143967473', 'name': 'Pushmeet Kohli'}]","249":"[{'authorId': '3372686', 'name': 'Nicolas Spatola'}, {'authorId': '3858139', 'name': 'Olga A. Wudarczyk'}]","250":"[{'authorId': '2108124330', 'name': 'Suhyeon Lee'}, {'authorId': '2246939', 'name': 'Junhyuk Hyun'}, {'authorId': '79755154', 'name': 'Hongje Seong'}, {'authorId': '1842453', 'name': 'Euntai Kim'}]","251":"[{'authorId': '144776615', 'name': 'L. E. Celis'}, {'authorId': '152276166', 'name': 'Anay Mehrotra'}, {'authorId': '1810064', 'name': 'Nisheeth K. Vishnoi'}]","252":"[{'authorId': '1430768604', 'name': 'Qi Han'}, {'authorId': '145341911', 'name': 'Kai Zhao'}, {'authorId': '145971173', 'name': 'Jun Xu'}, {'authorId': '1557350184', 'name': 'Mingg-Ming Cheng'}]","253":"[{'authorId': '2133312527', 'name': 'Timo Spinde'}, {'authorId': '2145258121', 'name': 'Christina Kreuter'}, {'authorId': '3077815', 'name': 'W. Gaissmaier'}, {'authorId': '2133299744', 'name': 'Felix Hamborg'}, {'authorId': '145151838', 'name': 'Bela Gipp'}, {'authorId': '5771775', 'name': 'H. Giese'}]","254":"[{'authorId': '2077527698', 'name': 'Zia Khan'}, {'authorId': '3151154', 'name': 'N. Yahya'}, {'authorId': '7450149', 'name': 'K. Alsaih'}, {'authorId': '1955345', 'name': 'S. Ali'}, {'authorId': '1744434', 'name': 'F. M\u00e9riaudeau'}]","255":"[{'authorId': '2155212771', 'name': 'Yubo Zhang'}, {'authorId': '47300698', 'name': 'Hao Tan'}, {'authorId': '143977268', 'name': 'Mohit Bansal'}]","256":"[{'authorId': '1476766004', 'name': 'Minghao Chen'}, {'authorId': '2511637', 'name': 'Hongyang Xue'}, {'authorId': '1724421', 'name': 'Deng Cai'}]","257":"[{'authorId': '41229153', 'name': 'Markus Nagel'}, {'authorId': '147409784', 'name': 'Mart van Baalen'}, {'authorId': '83133279', 'name': 'Tijmen Blankevoort'}, {'authorId': '1678311', 'name': 'M. Welling'}]","258":"[{'authorId': '2026652', 'name': 'Haim Dubossarsky'}, {'authorId': '3422512', 'name': 'Simon Hengchen'}, {'authorId': '1731960', 'name': 'Nina Tahmasebi'}, {'authorId': '3449121', 'name': 'Dominik Schlechtweg'}]","259":"[{'authorId': '2068229094', 'name': 'Bin Wen'}, {'authorId': '2116783388', 'name': 'Jie Luo'}, {'authorId': '6820648', 'name': 'Xianglong Liu'}, {'authorId': '2109138451', 'name': 'Lei Huang'}]","260":"[{'authorId': '33155962', 'name': 'Hossein ARABI'}, {'authorId': '3109880', 'name': 'Guodong Zeng'}, {'authorId': '144547625', 'name': 'Guoyan Zheng'}, {'authorId': '143958443', 'name': 'H. Zaidi'}]","261":"[{'authorId': '29348866', 'name': 'Lonesome Malambo'}, {'authorId': '49284242', 'name': 'S. Popescu'}, {'authorId': '40542048', 'name': 'N. Ku'}, {'authorId': '33234885', 'name': 'W. Rooney'}, {'authorId': '33316596', 'name': 'T. Zhou'}, {'authorId': '2113618211', 'name': 'S. Moore'}]","262":"[{'authorId': '46201207', 'name': 'M. Shahdloo'}, {'authorId': '81735116', 'name': 'Emin \u00c7elik'}, {'authorId': '3122940', 'name': 'T. \u00c7ukur'}]","263":"[{'authorId': '35175531', 'name': 'Patrick Esser'}, {'authorId': '1660819540', 'name': 'Robin Rombach'}, {'authorId': '1796707', 'name': 'B. Ommer'}]","264":"[{'authorId': '2109168016', 'name': 'Zhuang Liu'}, {'authorId': '2053590350', 'name': 'Hanzi Mao'}, {'authorId': '95426599', 'name': 'Chaozheng Wu'}, {'authorId': '2322150', 'name': 'Christoph Feichtenhofer'}, {'authorId': '1753210', 'name': 'Trevor Darrell'}, {'authorId': '1817030', 'name': 'Saining Xie'}]","265":"[{'authorId': '40894826', 'name': 'Muzammal Naseer'}, {'authorId': '48430646', 'name': 'Kanchana Ranasinghe'}, {'authorId': '152973423', 'name': 'S. Khan'}, {'authorId': '145684318', 'name': 'Munawar Hayat'}, {'authorId': '2358803', 'name': 'F. Khan'}, {'authorId': '37144787', 'name': 'Ming-Hsuan Yang'}]","266":"[{'authorId': '8804828', 'name': 'M. Schlichtkrull'}, {'authorId': '41019080', 'name': 'Nicola De Cao'}, {'authorId': '144889265', 'name': 'Ivan Titov'}]","267":"[{'authorId': '1912720', 'name': 'Yen-Chang Hsu'}, {'authorId': '1774780', 'name': 'Yilin Shen'}, {'authorId': '1705713', 'name': 'Hongxia Jin'}, {'authorId': '145276578', 'name': 'Z. Kira'}]","268":"[{'authorId': '2066060119', 'name': \"Santiago Ontan'on\"}, {'authorId': '1643737606', 'name': 'J. Ainslie'}, {'authorId': '3377849', 'name': 'V. Cvicek'}, {'authorId': '144211029', 'name': 'Zachary Kenneth Fisher'}]","269":"[{'authorId': '1748169', 'name': 'Kuansan Wang'}, {'authorId': '3303634', 'name': 'Zhihong Shen'}, {'authorId': '92605280', 'name': 'Chiyuan Huang'}, {'authorId': '153248481', 'name': 'Chieh-Han Wu'}, {'authorId': '2047998', 'name': 'Yuxiao Dong'}, {'authorId': '2035106', 'name': 'Anshul Kanakia'}]","270":"[{'authorId': '3240989', 'name': 'Md. Amirul Islam'}, {'authorId': '2065442325', 'name': 'M. Kowal'}, {'authorId': '35175531', 'name': 'Patrick Esser'}, {'authorId': '1805367', 'name': 'Sen Jia'}, {'authorId': '1796707', 'name': 'B. Ommer'}, {'authorId': '3150825', 'name': 'K. Derpanis'}, {'authorId': '2866780', 'name': 'Neil D. B. Bruce'}]","271":"[{'authorId': '119883573', 'name': 'J. Yu'}, {'authorId': '2056560007', 'name': 'Yuan Chai'}, {'authorId': '2108954687', 'name': 'Yue Hu'}, {'authorId': '1509240145', 'name': 'Qi Wu'}]","272":"[{'authorId': '22747364', 'name': 'V. Hellendoorn'}, {'authorId': '152549864', 'name': 'Charles Sutton'}, {'authorId': '50631599', 'name': 'Rishabh Singh'}, {'authorId': '2286904', 'name': 'Petros Maniatis'}, {'authorId': '3426307', 'name': 'David Bieber'}]","273":"[{'authorId': '2144836395', 'name': 'Yu Chen'}, {'authorId': '3008832', 'name': 'Lingfei Wu'}, {'authorId': '1693515', 'name': 'Mohammed J. Zaki'}]","274":"[{'authorId': '8742492', 'name': 'Arantxa Casanova'}, {'authorId': '2708655', 'name': 'Pedro H. O. Pinheiro'}, {'authorId': '2599281', 'name': 'Negar Rostamzadeh'}, {'authorId': '1972076', 'name': 'C. Pal'}]","275":"[{'authorId': '30888984', 'name': 'Dongling Xiao'}, {'authorId': '120811666', 'name': 'Han Zhang'}, {'authorId': '1710861', 'name': 'Yukun Li'}, {'authorId': '2117103617', 'name': 'Yu Sun'}, {'authorId': '50007795', 'name': 'Hao Tian'}, {'authorId': '40354707', 'name': 'Hua Wu'}, {'authorId': '144270731', 'name': 'Haifeng Wang'}]","276":"[{'authorId': '29891652', 'name': 'Anne Lauscher'}, {'authorId': '2472657', 'name': 'Goran Glavas'}, {'authorId': '1801255', 'name': 'Simone Paolo Ponzetto'}, {'authorId': '1747849', 'name': 'Ivan Vulic'}]","277":"[{'authorId': '1717107012', 'name': 'Dongnan Liu'}, {'authorId': '2109559435', 'name': 'Donghao Zhang'}, {'authorId': None, 'name': 'Yang Song'}, {'authorId': '144184856', 'name': 'Fan Zhang'}, {'authorId': '1398222646', 'name': \"L. O'Donnell\"}, {'authorId': '1748032', 'name': 'Heng Huang'}, {'authorId': '2108608250', 'name': 'Mei Chen'}, {'authorId': '122905659', 'name': 'Weidong (Tom) Cai'}]","278":"[{'authorId': '3408207', 'name': 'S. Z. Dadaneh'}, {'authorId': '2592556', 'name': 'Shahin Boluki'}, {'authorId': '13115663', 'name': 'Mingzhang Yin'}, {'authorId': '38026572', 'name': 'Mingyuan Zhou'}, {'authorId': '145616431', 'name': 'Xiaoning Qian'}]","279":"[{'authorId': '1864343242', 'name': 'W. La Cava'}, {'authorId': '152512193', 'name': 'Jason H. Moore'}]","280":"[{'authorId': '2112122873', 'name': 'Mingxing Zhang'}, {'authorId': '2152283122', 'name': 'Yang Yang'}, {'authorId': '5462268', 'name': 'Hanwang Zhang'}, {'authorId': '50006507', 'name': 'Yanli Ji'}, {'authorId': '1724393', 'name': 'H. Shen'}, {'authorId': '144078686', 'name': 'Tat-Seng Chua'}]","281":"[{'authorId': '51055350', 'name': 'Shuwen Xiao'}, {'authorId': '47122432', 'name': 'Zhou Zhao'}, {'authorId': '2116459561', 'name': 'Zijian Zhang'}, {'authorId': '1749272', 'name': 'Ziyu Guan'}, {'authorId': '1724421', 'name': 'Deng Cai'}]","282":"[{'authorId': '102609418', 'name': 'Sai Kumar Dwivedi'}, {'authorId': '1838218557', 'name': 'Vikram Gupta'}, {'authorId': '108057223', 'name': 'Rahul Mitra'}, {'authorId': '2109163113', 'name': 'Shuaib Ahmed'}, {'authorId': '49147969', 'name': 'Arjun Jain'}]","283":"[{'authorId': '51247075', 'name': 'Jaap Jumelet'}, {'authorId': '1787819', 'name': 'Willem H. Zuidema'}, {'authorId': '3449411', 'name': 'D. Hupkes'}]","284":"[{'authorId': '2108106092', 'name': 'Sunghyun Park'}, {'authorId': '1716415', 'name': 'Seung-won Hwang'}, {'authorId': '7243120', 'name': 'Fuxiang Chen'}, {'authorId': '1795455', 'name': 'J. Choo'}, {'authorId': '2577039', 'name': 'Jung-Woo Ha'}, {'authorId': '1787729', 'name': 'Sunghun Kim'}, {'authorId': '49841374', 'name': 'Jinyeong Yim'}]","285":"[{'authorId': '49950690', 'name': 'Debasmit Das'}, {'authorId': '145934505', 'name': 'C. S. G. Lee'}]","286":"[{'authorId': '40862084', 'name': 'Albert Zhao'}, {'authorId': '48748557', 'name': 'Tong He'}, {'authorId': '2141192339', 'name': 'Yitao Liang'}, {'authorId': '3119608', 'name': 'Haibin Huang'}, {'authorId': '1749506', 'name': 'Guy Van den Broeck'}, {'authorId': '1715959', 'name': 'Stefano Soatto'}]","287":"[{'authorId': '97767795', 'name': 'Daisuke Oba'}, {'authorId': '34849332', 'name': 'Naoki Yoshinaga'}, {'authorId': '8846453', 'name': 'Shoetsu Sato'}, {'authorId': '34819738', 'name': 'Satoshi Akasaki'}, {'authorId': '2361778', 'name': 'M. Toyoda'}]","288":"[{'authorId': '3234247', 'name': 'Senthil Purushwalkam'}, {'authorId': '1726095131', 'name': 'A. Gupta'}]","289":"[{'authorId': '152951058', 'name': 'Drew A. Hudson'}, {'authorId': '144783904', 'name': 'Christopher D. Manning'}]","290":"[{'authorId': '24835910', 'name': 'Jesse Mu'}, {'authorId': '2112400', 'name': 'Jacob Andreas'}]","291":"[{'authorId': '152951058', 'name': 'Drew A. Hudson'}, {'authorId': '144783904', 'name': 'Christopher D. Manning'}]","292":"[{'authorId': '38907975', 'name': 'Ning Xie'}, {'authorId': '1868193', 'name': 'Farley Lai'}, {'authorId': '2514295', 'name': 'Derek Doran'}, {'authorId': '2293919', 'name': 'Asim Kadav'}]","293":"[{'authorId': '1500384130', 'name': 'Hong-xiang Chen'}, {'authorId': '2115467299', 'name': 'Kunhong Li'}, {'authorId': '35487423', 'name': 'Zhiheng Fu'}, {'authorId': '1730228', 'name': 'Mengyi Liu'}, {'authorId': '2049680620', 'name': 'Zonghao Chen'}, {'authorId': '2985328', 'name': 'Yulan Guo'}]","294":"[{'authorId': '49773318', 'name': 'Min Zeng'}, {'authorId': '49140537', 'name': 'Min Li'}, {'authorId': '145391153', 'name': 'Fang-Xiang Wu'}, {'authorId': '2748057', 'name': 'Yaohang Li'}, {'authorId': '144680113', 'name': 'Yi Pan'}]","295":"[{'authorId': '2117097772', 'name': 'Ziyi Chen'}, {'authorId': '115877724', 'name': 'Cheng Wang'}, {'authorId': '2109043577', 'name': 'Jonathan Li'}, {'authorId': '2127958176', 'name': 'Nianci Xie'}, {'authorId': '2108807222', 'name': 'Yanyong Han'}, {'authorId': '1701928', 'name': 'Jixiang Du'}]","296":"[{'authorId': '121937604', 'name': 'Ziyi Yang'}, {'authorId': '2781059', 'name': 'Yinfei Yang'}, {'authorId': '46724030', 'name': 'Daniel Matthew Cer'}, {'authorId': '150151081', 'name': 'Jax Law'}, {'authorId': '3195327', 'name': 'Eric F Darve'}]","297":"[{'authorId': '115126020', 'name': 'Noah Arthurs'}, {'authorId': '1469416371', 'name': 'AJ Alvero'}]","298":"[{'authorId': '50381660', 'name': 'A. Wong'}, {'authorId': '46232059', 'name': 'Safa Cicek'}, {'authorId': '1715959', 'name': 'Stefano Soatto'}]","299":"[{'authorId': '1986859645', 'name': 'Chuan Qin'}, {'authorId': '1968806', 'name': 'Hengshu Zhu'}, {'authorId': '41157498', 'name': 'Tong Xu'}, {'authorId': '144469723', 'name': 'Chen Zhu'}, {'authorId': '2112663161', 'name': 'Chao Ma'}, {'authorId': '144378760', 'name': 'Enhong Chen'}, {'authorId': '2093122576', 'name': 'Hui Xiong'}]","300":"[{'authorId': '67100504', 'name': 'Christopher Thomas'}, {'authorId': '1770205', 'name': 'Adriana Kovashka'}]","301":"[{'authorId': '1643961315', 'name': 'Jingtao Zhan'}, {'authorId': '1644047628', 'name': 'Jiaxin Mao'}, {'authorId': '1783406', 'name': 'Yiqun Liu'}, {'authorId': '38898636', 'name': 'Min Zhang'}, {'authorId': '8093158', 'name': 'Shaoping Ma'}]","302":"[{'authorId': '47659905', 'name': 'Liang Qiu'}, {'authorId': '2109831678', 'name': 'Yizhou Zhao'}, {'authorId': '8299781', 'name': 'Weiyan Shi'}, {'authorId': '1390525037', 'name': 'Yuan Liang'}, {'authorId': '122710522', 'name': 'Feng Shi'}, {'authorId': '153825264', 'name': 'Tao Yuan'}, {'authorId': '1564034697', 'name': 'Zhou Yu'}, {'authorId': '145380991', 'name': 'Song-Chun Zhu'}]","303":"[{'authorId': '2124993', 'name': 'Rocco Tripodi'}, {'authorId': '2210986', 'name': 'M. Warglien'}, {'authorId': '2091691550', 'name': 'S. Sullam'}, {'authorId': '2075187961', 'name': 'Deborah Paci'}]","304":"[{'authorId': '1388790625', 'name': 'Mustafa Sercan Amac'}, {'authorId': '40387200', 'name': 'Semih Yagcioglu'}, {'authorId': '14364286', 'name': 'Aykut Erdem'}, {'authorId': '152330322', 'name': 'Erkut Erdem'}]","305":"[{'authorId': '101434104', 'name': 'S. Sajedi'}, {'authorId': '97764437', 'name': 'Xiao Liang'}]","306":"[{'authorId': '2139059234', 'name': 'Zhou Yang'}, {'authorId': '1626115661', 'name': 'Muhammad Hilmi Asyrofi'}, {'authorId': '143960553', 'name': 'D. Lo'}]","307":"[{'authorId': '3009037', 'name': 'G. Dimauro'}, {'authorId': '143985074', 'name': 'L. Simone'}]","308":"[{'authorId': '2005440168', 'name': 'Wuyang Chen'}, {'authorId': '1751019', 'name': 'Zhiding Yu'}, {'authorId': '24817039', 'name': 'Shalini De Mello'}, {'authorId': '2391885', 'name': 'Sifei Liu'}, {'authorId': '2974008', 'name': 'J. \u00c1lvarez'}, {'authorId': '2969311', 'name': 'Zhangyang Wang'}, {'authorId': '2047844', 'name': 'Anima Anandkumar'}]","309":"[{'authorId': '46924234', 'name': 'Eunjin Chun'}, {'authorId': '2873952', 'name': 'E. Kaan'}]","310":"[{'authorId': '2188643', 'name': 'Shengwei An'}, {'authorId': '50631599', 'name': 'Rishabh Singh'}, {'authorId': '1704478', 'name': 'Sasa Misailovic'}, {'authorId': '2010700', 'name': 'R. Samanta'}]","311":"[{'authorId': '1576481811', 'name': 'Zichun Su'}, {'authorId': '2149532105', 'name': 'Jialin Jiang'}]","312":"[{'authorId': '147132443', 'name': 'J. Pfau'}, {'authorId': '47973433', 'name': 'Albert T. Young'}, {'authorId': '2111338254', 'name': 'Jerome Wei'}, {'authorId': '31342816', 'name': 'Maria L. Wei'}, {'authorId': '2780351', 'name': 'Michael J. Keiser'}]","313":"[{'authorId': '2108805827', 'name': 'Xinpeng Li'}, {'authorId': '2109979241', 'name': 'Dan Zhang'}, {'authorId': '2064962363', 'name': 'Mao Ye'}, {'authorId': '2116383449', 'name': 'Xue Li'}, {'authorId': '145530076', 'name': 'Q. Dou'}, {'authorId': '2099677220', 'name': 'Qiao Lv'}]","314":"[{'authorId': '143780023', 'name': 'Zhong Ji'}, {'authorId': '104008470', 'name': 'Biying Cui'}, {'authorId': '50133856', 'name': 'Yunlong Yu'}, {'authorId': '145134722', 'name': 'Yanwei Pang'}, {'authorId': '1720488', 'name': 'Zhongfei Zhang'}]","315":"[{'authorId': '1500404926', 'name': 'Gengwei Zhang'}, {'authorId': '3374337', 'name': 'Guoliang Kang'}, {'authorId': '49020088', 'name': 'Yunchao Wei'}, {'authorId': '7179962', 'name': 'Yi Yang'}]","316":"[{'authorId': '31444437', 'name': 'Ahram Song'}, {'authorId': '7629811', 'name': 'Jaewan Choi'}]","317":"[{'authorId': '2117425254', 'name': 'Zili Wang'}]","318":"[{'authorId': '2109967617', 'name': 'Jiabo Huang'}, {'authorId': '2152797548', 'name': 'Yang Liu'}, {'authorId': '144784813', 'name': 'S. Gong'}, {'authorId': '41151701', 'name': 'Hailin Jin'}]","319":"[{'authorId': '38526293', 'name': 'T. Lindsey'}, {'authorId': '2108513147', 'name': 'Jin-Ju Lee'}]","320":"[{'authorId': '1942197948', 'name': 'Luoqiu Li'}, {'authorId': '2143735911', 'name': 'Xiang Chen'}, {'authorId': '40463748', 'name': 'Hongbin Ye'}, {'authorId': '2059276046', 'name': 'Zhen Bi'}, {'authorId': '152931849', 'name': 'Shumin Deng'}, {'authorId': '2153010067', 'name': 'Ningyu Zhang'}, {'authorId': '49178307', 'name': 'Huajun Chen'}]","321":"[{'authorId': '48379966', 'name': 'Y. Zhang'}, {'authorId': '3238613', 'name': 'Zilei Wang'}]","322":"[{'authorId': '2061470075', 'name': 'Lucas O. Teixeira'}, {'authorId': '21194405', 'name': 'R. M. Pereira'}, {'authorId': '2096543', 'name': 'Diego Bertolini'}, {'authorId': '144925520', 'name': 'Luiz Oliveira'}, {'authorId': '1804258', 'name': 'L. Nanni'}, {'authorId': '38686411', 'name': 'Yandre M. G. Costa'}]","323":"[{'authorId': '7641396', 'name': 'Sarim Zafar'}, {'authorId': '2093196225', 'name': 'Muhammad Zubair Malik'}, {'authorId': '10100364', 'name': 'G. Walia'}]","324":"[{'authorId': '3235013', 'name': 'M. Virgolin'}, {'authorId': '3151583', 'name': 'T. Alderliesten'}, {'authorId': '1735401', 'name': 'C. Witteveen'}, {'authorId': '1704785', 'name': 'P. Bosman'}]","325":"[{'authorId': '33585083', 'name': 'Melvin Wevers'}, {'authorId': '1781703', 'name': 'M. Koolen'}]","326":"[{'authorId': '2118847803', 'name': 'Liang Hu'}, {'authorId': '2108244733', 'name': 'Gang Wu'}, {'authorId': '2072728282', 'name': 'Yongheng Xing'}, {'authorId': '2108635929', 'name': 'Feng Wang'}]","327":"[{'authorId': '2115874501', 'name': 'Shuai Lin'}, {'authorId': '2109890021', 'name': 'Pan Zhou'}, {'authorId': '2111189521', 'name': 'Zi-Yuan Hu'}, {'authorId': '2117011532', 'name': 'Shuojia Wang'}, {'authorId': '2567863', 'name': 'Ruihui Zhao'}, {'authorId': '2145273405', 'name': 'Yefeng Zheng'}, {'authorId': '1737218', 'name': 'Liang Lin'}, {'authorId': '143977260', 'name': 'E. Xing'}, {'authorId': '40250403', 'name': 'Xiaodan Liang'}]","328":"[{'authorId': '1411252544', 'name': 'L. Machado'}, {'authorId': '1399452704', 'name': 'Renato Rocha Souza'}, {'authorId': '2065936899', 'name': 'Maria da Gra\u00e7a de Melo Sim\u00f5es'}]","329":"[{'authorId': '147115675', 'name': 'J. Minot'}, {'authorId': '2065992515', 'name': 'Nicholas Cheney'}, {'authorId': '1733462', 'name': 'Marc E. Maier'}, {'authorId': '5823186', 'name': 'Danne C. Elbers'}, {'authorId': '2310860', 'name': 'C. Danforth'}, {'authorId': '2660575', 'name': 'P. Dodds'}]","330":"[{'authorId': '144605807', 'name': 'Maoguo Gong'}, {'authorId': '5248284', 'name': 'Xiangming Jiang'}, {'authorId': '2152297783', 'name': 'Hao Li'}, {'authorId': '1707078', 'name': 'K. Tan'}]","331":"[{'authorId': '40896023', 'name': 'P. Schramowski'}, {'authorId': '13671251', 'name': 'Cigdem Turan'}, {'authorId': '151209594', 'name': 'Sophie F. Jentzsch'}, {'authorId': '3249046', 'name': 'C. Rothkopf'}, {'authorId': '1746871', 'name': 'K. Kersting'}]","332":"[{'authorId': '7898385', 'name': 'Jianhong Wang'}, {'authorId': '11860201', 'name': 'Yuan Zhang'}, {'authorId': '2110993733', 'name': 'Tae-Kyun Kim'}, {'authorId': '2977076', 'name': 'Yunjie Gu'}]","333":"[{'authorId': '47509360', 'name': 'Shir Gur'}, {'authorId': '2112239702', 'name': 'Ameen Ali'}, {'authorId': '48519520', 'name': 'L. Wolf'}]","334":"[{'authorId': '2144555593', 'name': 'Chaoqun Wang'}, {'authorId': '40941551', 'name': 'Xuejin Chen'}, {'authorId': '2744372', 'name': 'Shaobo Min'}, {'authorId': '2145200611', 'name': 'Xiaoyan Sun'}, {'authorId': '2144406784', 'name': 'Houqiang Li'}]","335":"[{'authorId': '49164404', 'name': 'P. Dimmock'}]","336":"[{'authorId': '144667749', 'name': 'Massimo Stella'}]","337":"[{'authorId': '3139858', 'name': 'Apoorv Khandelwal'}, {'authorId': '20745881', 'name': 'Luca Weihs'}, {'authorId': '3012475', 'name': 'R. Mottaghi'}, {'authorId': '2684226', 'name': 'Aniruddha Kembhavi'}]","338":"[{'authorId': '1491233100', 'name': 'Pranav Agarwal'}, {'authorId': '145086911', 'name': 'Alejandro Betancourt'}, {'authorId': '1594025086', 'name': 'V. Panagiotou'}, {'authorId': '2058921025', 'name': 'Natalia D\u00edaz Rodr\u00edguez'}]","339":"[{'authorId': '46618542', 'name': 'Jiawei Zhou'}, {'authorId': '2524647', 'name': 'Tahira Naseem'}, {'authorId': '3394760', 'name': 'Ram\u00f3n Fern\u00e1ndez Astudillo'}, {'authorId': '1707117', 'name': 'Radu Florian'}]","340":"[{'authorId': '145326496', 'name': 'Rafael Felix'}, {'authorId': '38777725', 'name': 'Ben Harwood'}, {'authorId': '47725086', 'name': 'M. Sasdelli'}, {'authorId': '145575177', 'name': 'G. Carneiro'}]","341":"[{'authorId': '47942148', 'name': 'Poorya Zaremoodi'}, {'authorId': '2561045', 'name': 'Gholamreza Haffari'}]","342":"[{'authorId': '3097148', 'name': 'Melissa Ailem'}, {'authorId': '3047890', 'name': 'Bowen Zhang'}, {'authorId': '145757665', 'name': 'Fei Sha'}]","343":"[{'authorId': '120777041', 'name': 'Shrey Desai'}, {'authorId': '2057450366', 'name': 'Ahmed Aly'}]","344":"[{'authorId': '2121686730', 'name': 'Gengcong Yang'}, {'authorId': '2108122973', 'name': 'Jingyi Zhang'}, {'authorId': '2144289260', 'name': 'Yong Zhang'}, {'authorId': '143905981', 'name': 'Baoyuan Wu'}, {'authorId': '3001727', 'name': 'Yujiu Yang'}]","345":"[{'authorId': '46395705', 'name': 'Ying Da Wang'}, {'authorId': '11051167', 'name': 'Mehdi Shabaninejad'}, {'authorId': '48408621', 'name': 'R. Armstrong'}, {'authorId': '3548245', 'name': 'P. Mostaghimi'}]","346":"[{'authorId': '52418142', 'name': 'L. Ismailova'}, {'authorId': '47601888', 'name': 'S. Kosikov'}, {'authorId': '143771788', 'name': 'K. Zinchenko'}, {'authorId': '3164427', 'name': 'Viacheslav Wolfengagen'}]","347":"[{'authorId': '48241944', 'name': 'Zhanming Guan'}, {'authorId': '145965599', 'name': 'Bin Wu'}, {'authorId': '1735282', 'name': 'Bai Wang'}, {'authorId': '51003086', 'name': 'Hezi Liu'}]","348":"[{'authorId': '66916694', 'name': 'Xinyu Xiao'}, {'authorId': '2151976048', 'name': 'Lingfeng Wang'}, {'authorId': '33969294', 'name': 'Kun Ding'}, {'authorId': '1683738', 'name': 'Shiming Xiang'}, {'authorId': '144809241', 'name': 'Chunhong Pan'}]","349":"[{'authorId': '1390533012', 'name': 'Ruiyi Zhang'}, {'authorId': '1752041', 'name': 'Changyou Chen'}, {'authorId': '144702900', 'name': 'Zhe Gan'}, {'authorId': '39761651', 'name': 'Zheng Wen'}, {'authorId': '2900282', 'name': 'Wenlin Wang'}, {'authorId': '145006560', 'name': 'L. Carin'}]","350":"[{'authorId': '2096571748', 'name': 'M. Aurnague'}, {'authorId': '2076356941', 'name': 'D. Stosic'}]","351":"[{'authorId': '2608639', 'name': 'Ningyu Zhang'}, {'authorId': '1942197948', 'name': 'Luoqiu Li'}, {'authorId': '152931849', 'name': 'Shumin Deng'}, {'authorId': '2119316118', 'name': 'Haiyang Yu'}, {'authorId': '2110251893', 'name': 'Xu Cheng'}, {'authorId': '2155468731', 'name': 'Wei Zhang'}, {'authorId': '49178307', 'name': 'Huajun Chen'}]","352":"[{'authorId': '35593430', 'name': 'Mina Rezaei'}, {'authorId': '1688587', 'name': 'Haojin Yang'}, {'authorId': '24003853', 'name': 'Konstantin Harmuth'}, {'authorId': '1708312', 'name': 'C. Meinel'}]","353":"[{'authorId': '1995357461', 'name': 'Rinu Chacko'}, {'authorId': '103943916', 'name': 'D. Jain'}, {'authorId': '34326205', 'name': 'Manasi S. Patwardhan'}, {'authorId': '1995116127', 'name': 'Abhishek Puri'}, {'authorId': '2973267', 'name': 'Shirish S. Karande'}, {'authorId': '34892487', 'name': 'B. Rai'}]","354":"[{'authorId': '2110410048', 'name': 'Jiamin Wu'}, {'authorId': '2146331327', 'name': 'Tianzhu Zhang'}, {'authorId': '143962510', 'name': 'Zhengjun Zha'}, {'authorId': '33642939', 'name': 'Jiebo Luo'}, {'authorId': '1699819', 'name': 'Yongdong Zhang'}, {'authorId': '1684705122', 'name': 'Feng Wu'}]","355":"[{'authorId': '2067103717', 'name': 'William Thong'}, {'authorId': '145404204', 'name': 'Cees G. M. Snoek'}]","356":"[{'authorId': '2000278193', 'name': 'Laura Oberl\u00e4nder'}, {'authorId': '1904099596', 'name': 'K. Reich'}, {'authorId': '66339110', 'name': 'Roman Klinger'}]","357":"[{'authorId': '52215803', 'name': 'Yaza Wainakh'}, {'authorId': '1382579961', 'name': 'Moiz Rauf'}, {'authorId': '1884064', 'name': 'Michael Pradel'}]","358":"[{'authorId': '35713454', 'name': 'M\u00e1t\u00e9 \u00c1kos T\u00fcndik'}, {'authorId': '70456844', 'name': 'Val\u00e9r Kasz\u00e1s'}, {'authorId': '3071937', 'name': 'Gy\u00f6rgy Szasz\u00e1k'}]","359":"[{'authorId': '1738701878', 'name': 'Andr\u00e9 Ferreira Cruz'}, {'authorId': '40192974', 'name': 'Gil Rocha'}, {'authorId': '35114153', 'name': 'Henrique Lopes Cardoso'}]","360":"[{'authorId': '48387106', 'name': 'Xianyou Zhu'}, {'authorId': '2108601694', 'name': 'X. Wang'}, {'authorId': '145773394', 'name': 'Haochen Zhao'}, {'authorId': '3258090', 'name': 'Tingrui Pei'}, {'authorId': '144893369', 'name': 'Linai Kuang'}, {'authorId': '2152506844', 'name': 'Lei Wang'}]","361":"[{'authorId': '3458687', 'name': 'Manoj Reddy Dareddy'}, {'authorId': '40308435', 'name': 'Mahashweta Das'}, {'authorId': '2115537541', 'name': 'Hao Yang'}]","362":"[{'authorId': '2151459740', 'name': 'Han-Jia Ye'}, {'authorId': '1721819', 'name': 'De-Chuan Zhan'}, {'authorId': '2192443', 'name': 'Yuan Jiang'}, {'authorId': '145624000', 'name': 'Zhi-Hua Zhou'}]","363":"[{'authorId': '2113664446', 'name': 'Yang Hu'}, {'authorId': '9725901', 'name': 'Guihua Wen'}, {'authorId': '144030084', 'name': 'Adriane P. Chapman'}, {'authorId': '144599541', 'name': 'Pei Yang'}, {'authorId': '51149455', 'name': 'Mingnan Luo'}, {'authorId': '48615798', 'name': 'Yingxue Xu'}, {'authorId': '46925647', 'name': 'Dan Dai'}, {'authorId': '152252333', 'name': 'Wendy Hall'}]","364":"[{'authorId': '3130527', 'name': 'Rohan Padhye'}, {'authorId': '1794524593', 'name': 'Caroline Lemieux'}, {'authorId': '145741786', 'name': 'Koushik Sen'}, {'authorId': '37766916', 'name': 'Mike Papadakis'}, {'authorId': '47681863', 'name': 'Y. L. Traon'}]","365":"[{'authorId': '152229386', 'name': 'Arka Sadhu'}, {'authorId': '2118439352', 'name': 'Kan Chen'}, {'authorId': '1694832', 'name': 'R. Nevatia'}]","366":"[{'authorId': '1382532296', 'name': 'Jacob Russin'}, {'authorId': '35005710', 'name': 'Jason Jo'}, {'authorId': '1390067049', 'name': 'R. O\u2019Reilly'}, {'authorId': '1865800402', 'name': 'Y. Bengio'}]","367":"[{'authorId': '34952384', 'name': 'Mohammad Darwich'}, {'authorId': '2480890', 'name': 'S. Noah'}, {'authorId': '143999897', 'name': 'N. Omar'}, {'authorId': '2852042', 'name': 'Nurul Aida Osman'}, {'authorId': '2059011445', 'name': 'Ibrahim Said'}, {'authorId': '2057407915', 'name': 'Ahmad'}]","368":"[{'authorId': '1576299780', 'name': 'Xiangxi Jiang'}, {'authorId': '2117199647', 'name': 'Liqiang Ding'}, {'authorId': '2203743', 'name': 'Mohammad Havaei'}, {'authorId': '14343042', 'name': 'A. Jesson'}, {'authorId': '1749003', 'name': 'S. Matwin'}]","369":"[{'authorId': '151471590', 'name': 'Binyuan Hui'}, {'authorId': '9706609', 'name': 'Ruiying Geng'}, {'authorId': '2054858849', 'name': 'Qiyu Ren'}, {'authorId': '66200440', 'name': 'Binhua Li'}, {'authorId': '1527090216', 'name': 'Yongbin Li'}, {'authorId': '2152147863', 'name': 'Jian Sun'}, {'authorId': '143857288', 'name': 'Fei Huang'}, {'authorId': '2059080424', 'name': 'Luo Si'}, {'authorId': '145463313', 'name': 'Pengfei Zhu'}, {'authorId': '150345740', 'name': 'Xiaodan Zhu'}]","370":"[{'authorId': '2107909505', 'name': 'Shiming Chen'}, {'authorId': '100965035', 'name': 'Ziming Hong'}, {'authorId': '2152797548', 'name': 'Yang Liu'}, {'authorId': '3057896', 'name': 'Guosen Xie'}, {'authorId': '2033539', 'name': 'Baigui Sun'}, {'authorId': '1706574', 'name': 'Hao Li'}, {'authorId': '2647338', 'name': 'Qinmu Peng'}, {'authorId': '2153781775', 'name': 'Ke Lu'}, {'authorId': '1744228', 'name': 'Xinge You'}]","371":"[{'authorId': '2157511237', 'name': 'Jiwen Tang'}, {'authorId': '2148905158', 'name': 'Zheng Zhang'}, {'authorId': '49608162', 'name': 'Lijun Zhao'}, {'authorId': '91436383', 'name': 'P. Tang'}]","372":"[{'authorId': '2066256691', 'name': 'Saurabh Kulshreshtha'}, {'authorId': '1787607', 'name': 'Jos\u00e9 Luis Redondo Garc\u00eda'}, {'authorId': '1728955', 'name': 'Ching-Yun Chang'}]","373":"[{'authorId': '83246531', 'name': 'Lukas Hoyer'}, {'authorId': '1778526', 'name': 'Dengxin Dai'}, {'authorId': '1681236', 'name': 'L. Gool'}]","374":"[{'authorId': '2222738', 'name': 'Hantao Yao'}, {'authorId': '2744372', 'name': 'Shaobo Min'}, {'authorId': '1699819', 'name': 'Yongdong Zhang'}, {'authorId': '145194969', 'name': 'Changsheng Xu'}]","375":"[{'authorId': '150898486', 'name': 'Arjun D Desai'}, {'authorId': '46781653', 'name': 'Francesco Caliv\u00e1'}, {'authorId': '31645725', 'name': 'C. Iriondo'}, {'authorId': '3451652', 'name': 'Naji Khosravan'}, {'authorId': '14487370', 'name': 'Aliasghar Mortazi'}, {'authorId': '3313734', 'name': 'S. Jambawalikar'}, {'authorId': '2036825', 'name': 'D. Torigian'}, {'authorId': '1661217429', 'name': 'J. Ellerman'}, {'authorId': '3307984', 'name': 'M. Ak\u00e7akaya'}, {'authorId': '1717161', 'name': 'U. Bagci'}, {'authorId': '122351350', 'name': 'R. Tibrewala'}, {'authorId': '1585444659', 'name': 'I. Flament'}, {'authorId': '2055848945', 'name': 'Matthew S Obrien'}, {'authorId': '145346586', 'name': 'S. Majumdar'}, {'authorId': '117451694', 'name': 'Mathias Perslev'}, {'authorId': '1792577', 'name': 'A. Pai'}, {'authorId': '1748824', 'name': 'C. Igel'}, {'authorId': '49831508', 'name': 'E. Dam'}, {'authorId': '3386805', 'name': 'S. Gaj'}, {'authorId': '152170060', 'name': 'Mingrui Yang'}, {'authorId': '1612990608', 'name': 'Kunio Nakamura'}, {'authorId': '47058252', 'name': 'Xiaojuan Li'}, {'authorId': '6106608', 'name': 'C. Deniz'}, {'authorId': '4915630', 'name': 'V. Juras'}, {'authorId': '2089502', 'name': 'R. Regatte'}, {'authorId': '6588156', 'name': 'G. Gold'}, {'authorId': '2735749', 'name': 'B. Hargreaves'}, {'authorId': '2319990', 'name': 'V. Pedoia'}, {'authorId': '31072467', 'name': 'A. Chaudhari'}]","376":"[{'authorId': '48418960', 'name': 'Madeleine Y. Stepper'}, {'authorId': '2869174', 'name': 'B. Rolke'}, {'authorId': '6643336', 'name': 'Elisabeth Hein'}]","377":"[{'authorId': '2148023', 'name': 'Jianmo Ni'}, {'authorId': '34607455', 'name': 'Chun-Nan Hsu'}, {'authorId': '48383460', 'name': 'Amilcare Gentili'}, {'authorId': '35660011', 'name': 'Julian McAuley'}]","378":"[{'authorId': '1649996134', 'name': 'Jeroen van Doorenmalen'}, {'authorId': '2266428', 'name': 'Vlado Menkovski'}]","379":"[{'authorId': '80200948', 'name': 'Sajad Norouzi'}, {'authorId': '1995851674', 'name': 'Keyi Tang'}, {'authorId': '2125469779', 'name': 'Yanshuai Cao'}]","380":"[{'authorId': '93768810', 'name': 'Xiaogang Wang'}, {'authorId': '32222907', 'name': 'Qianru Sun'}, {'authorId': '144078686', 'name': 'Tat-Seng Chua'}, {'authorId': '2315714', 'name': 'M. Ang'}]","381":"[{'authorId': '2144042552', 'name': 'Lulu Zhao'}, {'authorId': '2069640466', 'name': 'Weihao Zeng'}, {'authorId': '1753096', 'name': 'Weiran Xu'}, {'authorId': '2117223099', 'name': 'Jun Guo'}]","382":"[{'authorId': '48324873', 'name': 'Xiaoyan Jiang'}, {'authorId': '2642847', 'name': 'Yongbin Gao'}, {'authorId': '35301080', 'name': 'Zhijun Fang'}, {'authorId': '2155300820', 'name': 'Peng Wang'}, {'authorId': '2110606700', 'name': 'Bo Huang'}]","383":"[{'authorId': '49071560', 'name': 'Alex Lamb'}, {'authorId': '1391126980', 'name': 'Di He'}, {'authorId': '1996705', 'name': 'Anirudh Goyal'}, {'authorId': '35286545', 'name': 'Guolin Ke'}, {'authorId': '11398954', 'name': 'Chien-Feng Liao'}, {'authorId': '34924498', 'name': 'M. Ravanelli'}, {'authorId': '1751762', 'name': 'Yoshua Bengio'}]","384":"[{'authorId': '31664866', 'name': 'G. Franchi'}, {'authorId': '3364768', 'name': 'Nacim Belkhir'}, {'authorId': '32199099', 'name': 'Mai Lan Ha'}, {'authorId': '2112324775', 'name': 'Yufei Hu'}, {'authorId': '3056236', 'name': 'Andrei Bursuc'}, {'authorId': '2880906', 'name': 'V. Blanz'}, {'authorId': '144031869', 'name': 'Angela Yao'}]","385":"[{'authorId': '2112119367', 'name': 'Mingjie Li'}, {'authorId': '2115096576', 'name': 'Fuyu Wang'}, {'authorId': '144950946', 'name': 'Xiaojun Chang'}, {'authorId': '13246332', 'name': 'Xiaodan Liang'}]","386":"[{'authorId': '2109762507', 'name': 'Youngtaek Oh'}, {'authorId': '2155570010', 'name': 'Dong-jin Kim'}, {'authorId': '98758720', 'name': 'I. Kweon'}]","387":"[{'authorId': '144653901', 'name': 'Daniel Loureiro'}, {'authorId': '1667035673', 'name': 'Kiamehr Rezaee'}, {'authorId': '1717641', 'name': 'Mohammad Taher Pilehvar'}, {'authorId': '1387447871', 'name': 'Jos\u00e9 Camacho-Collados'}]","388":"[{'authorId': '152754428', 'name': 'Yoav Levine'}, {'authorId': '69978543', 'name': 'Noam Wies'}, {'authorId': '2090357207', 'name': 'Daniel Jannai'}, {'authorId': '3515397', 'name': 'D. Navon'}, {'authorId': '2126490970', 'name': 'Yedid Hoshen'}, {'authorId': '3140335', 'name': 'A. Shashua'}]","389":"[{'authorId': '2115763618', 'name': 'Xinyao Ma'}, {'authorId': '2729164', 'name': 'Maarten Sap'}, {'authorId': '2516777', 'name': 'Hannah Rashkin'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]","390":"[{'authorId': '51997673', 'name': 'Ninareh Mehrabi'}, {'authorId': '2775559', 'name': 'Fred Morstatter'}, {'authorId': '51884035', 'name': 'N. Saxena'}, {'authorId': '1782658', 'name': 'Kristina Lerman'}, {'authorId': '143728483', 'name': 'A. Galstyan'}]","391":"[{'authorId': '145481919', 'name': 'J. Sterne'}, {'authorId': '5566390', 'name': 'J. Savovi\u0107'}, {'authorId': '37175314', 'name': 'M. Page'}, {'authorId': '4869735', 'name': 'R. Elbers'}, {'authorId': '5239568', 'name': 'N. Blencowe'}, {'authorId': '4282797', 'name': 'I. Boutron'}, {'authorId': '4597347', 'name': 'C. Cates'}, {'authorId': '47413516', 'name': 'Hung-Yuan Cheng'}, {'authorId': '50221925', 'name': 'M. Corbett'}, {'authorId': '2714935', 'name': 'S. Eldridge'}, {'authorId': '5029279', 'name': 'J. Emberson'}, {'authorId': '40362338', 'name': 'M. Hern\u00e1n'}, {'authorId': '3357884', 'name': 'S. Hopewell'}, {'authorId': '6528578', 'name': 'A. Hr\u00f5bjartsson'}, {'authorId': '4778505', 'name': 'D. Junqueira'}, {'authorId': '8530606', 'name': 'P. J\u00fcni'}, {'authorId': '35219091', 'name': 'J. Kirkham'}, {'authorId': '3946342', 'name': 'T. Lasserson'}, {'authorId': '32425009', 'name': 'Tianjing Li'}, {'authorId': '3803482', 'name': 'A. McAleenan'}, {'authorId': '3645103', 'name': 'B. Reeves'}, {'authorId': '145965711', 'name': 'S. Shepperd'}, {'authorId': '3241622', 'name': 'I. Shrier'}, {'authorId': '5467017', 'name': 'L. Stewart'}, {'authorId': '2098167816', 'name': 'K. Tilling'}, {'authorId': '2120605', 'name': 'I. White'}, {'authorId': '145419831', 'name': 'P. Whiting'}, {'authorId': '27367111', 'name': 'J. Higgins'}]","392":"[{'authorId': '2729164', 'name': 'Maarten Sap'}, {'authorId': '35540755', 'name': 'Dallas Card'}, {'authorId': '119902504', 'name': 'Saadia Gabriel'}, {'authorId': '1699545', 'name': 'Yejin Choi'}, {'authorId': '144365875', 'name': 'Noah A. Smith'}]","393":"[{'authorId': '150031890', 'name': 'Nicole Shadowen'}]","394":"[{'authorId': '35444249', 'name': 'Aki Koivula'}, {'authorId': '34624150', 'name': 'P. R\u00e4s\u00e4nen'}, {'authorId': '22576428', 'name': 'Outi Sarpila'}]","395":"[{'authorId': '50991767', 'name': 'Sunipa Dev'}, {'authorId': '47387745', 'name': 'Tao Li'}, {'authorId': '1795436', 'name': 'J. M. Phillips'}, {'authorId': '3052879', 'name': 'Vivek Srikumar'}]","396":"[{'authorId': '52033331', 'name': 'M. Borovcnik'}]","397":"[{'authorId': '50385831', 'name': 'H. Kumar'}, {'authorId': '145640829', 'name': 'B. Harish'}, {'authorId': '66906193', 'name': 'H. Darshan'}]","398":"[{'authorId': '31055170', 'name': 'S. Karve'}, {'authorId': '1717822', 'name': 'Lyle Ungar'}, {'authorId': '2662374', 'name': 'Jo\u00e3o Sedoc'}]","399":"[{'authorId': '144499041', 'name': 'P. Rochat'}]","400":"[{'authorId': '47014055', 'name': 'Sandeep Attree'}]","401":"[{'authorId': '50487261', 'name': 'Chan Young Park'}, {'authorId': '10719786', 'name': 'Xinru Yan'}, {'authorId': '49713890', 'name': 'Anjalie Field'}, {'authorId': '145317727', 'name': 'Yulia Tsvetkov'}]","402":"[{'authorId': '153170239', 'name': 'Chris. Miller'}, {'authorId': '2019717782', 'name': 'M. Poston'}]","403":"[{'authorId': '1557324013', 'name': 'Pei Zhou'}, {'authorId': '3040379', 'name': 'Weijia Shi'}, {'authorId': '2110117732', 'name': 'Jieyu Zhao'}, {'authorId': '3137324', 'name': 'Kuan-Hao Huang'}, {'authorId': '1998918', 'name': 'Muhao Chen'}, {'authorId': '1750769', 'name': 'Ryan Cotterell'}, {'authorId': '2782886', 'name': 'Kai-Wei Chang'}]","404":"[{'authorId': '9316362', 'name': 'Prasetya Ajie Utama'}, {'authorId': '2182290', 'name': 'N. Moosavi'}, {'authorId': '1730400', 'name': 'Iryna Gurevych'}]","405":"[{'authorId': '3109339', 'name': 'Mihaela Vorvoreanu'}, {'authorId': '48570857', 'name': 'Lingyi Zhang'}, {'authorId': '4113230', 'name': 'Yun-Han Huang'}, {'authorId': '3913620', 'name': 'C. Hilderbrand'}, {'authorId': '1411347600', 'name': 'Zoe Steine-Hanson'}, {'authorId': '1737204', 'name': 'M. Burnett'}]","406":"[{'authorId': '143997772', 'name': 'Christopher Clark'}, {'authorId': '2064210', 'name': 'Mark Yatskar'}, {'authorId': '1982950', 'name': 'Luke Zettlemoyer'}]","407":"[{'authorId': '144119930', 'name': 'Jochen Sieg'}, {'authorId': '3363652', 'name': 'Florian Flachsenberg'}, {'authorId': '3232100', 'name': 'M. Rarey'}]","408":"[{'authorId': '2066152579', 'name': 'Nan Xi'}, {'authorId': '2113508764', 'name': 'Di Ma'}, {'authorId': '1414796571', 'name': 'Marcus Liou'}, {'authorId': '1398679323', 'name': 'Zachary C. Steinert-Threlkeld'}, {'authorId': '39656686', 'name': 'Jason Anastasopoulos'}, {'authorId': '1834047', 'name': 'Jungseock Joo'}]","409":"[{'authorId': '3490018', 'name': 'R. Baly'}, {'authorId': '34086979', 'name': 'Giovanni Da San Martino'}, {'authorId': '145898106', 'name': 'James R. Glass'}, {'authorId': '1683562', 'name': 'Preslav Nakov'}]","410":"[{'authorId': '3490018', 'name': 'R. Baly'}, {'authorId': '48764610', 'name': 'Georgi Karadzhov'}, {'authorId': '145826863', 'name': 'Abdelrhman Saleh'}, {'authorId': '145898106', 'name': 'James R. Glass'}, {'authorId': '1683562', 'name': 'Preslav Nakov'}]","411":"[{'authorId': '102319456', 'name': 'Julie Jiang'}, {'authorId': '2149473678', 'name': 'Xiang Ren'}, {'authorId': '2082804692', 'name': 'Emilio Ferrara'}]","412":"[{'authorId': '2054613690', 'name': 'Fabian Baumann'}, {'authorId': '1414918071', 'name': 'Philipp Lorenz-Spreen'}, {'authorId': '2142164', 'name': 'I. Sokolov'}, {'authorId': '2081249', 'name': 'M. Starnini'}]","413":"[{'authorId': '102319456', 'name': 'Julie Jiang'}, {'authorId': '145201124', 'name': 'Xiang Ren'}, {'authorId': '48898287', 'name': 'Emilio Ferrara'}]","414":"[{'authorId': '2169215', 'name': 'Daejin Choi'}, {'authorId': '40917208', 'name': 'Selin Chun'}, {'authorId': '2105614711', 'name': 'H. Oh'}, {'authorId': '2304380', 'name': 'Jinyoung Han'}, {'authorId': '1688374', 'name': 'T. Kwon'}]","415":"[{'authorId': '152988336', 'name': 'Yingqiang Ge'}, {'authorId': '2111307684', 'name': 'Shuyang Zhao'}, {'authorId': '3450095', 'name': 'H. Zhou'}, {'authorId': '3438562', 'name': 'Changhua Pei'}, {'authorId': '143770118', 'name': 'Fei Sun'}, {'authorId': '10336865', 'name': 'Wenwu Ou'}, {'authorId': '1739818', 'name': 'Yongfeng Zhang'}]","416":"[{'authorId': '1742226337', 'name': 'Federico Cinus'}, {'authorId': '2067355150', 'name': 'Marco Minici'}, {'authorId': '47286020', 'name': 'Corrado Monti'}, {'authorId': '1705764', 'name': 'F. Bonchi'}]","417":"[{'authorId': '2143840223', 'name': 'Rui Luo'}, {'authorId': '30113760', 'name': 'Buddhika Nettasinghe'}, {'authorId': '144951190', 'name': 'V. Krishnamurthy'}]","418":"[{'authorId': '2036355404', 'name': 'Bohan Jiang'}, {'authorId': '145084368', 'name': 'Mansooreh Karami'}, {'authorId': '144842921', 'name': 'Lu Cheng'}, {'authorId': '2073993343', 'name': 'T. Black'}, {'authorId': '145896397', 'name': 'Huan Liu'}]","419":"[{'authorId': '1990773491', 'name': 'F. Alatawi'}, {'authorId': '2140175677', 'name': 'Lu Cheng'}, {'authorId': '133671993', 'name': 'Anique Tahir'}, {'authorId': '145084368', 'name': 'Mansooreh Karami'}, {'authorId': '2036355404', 'name': 'Bohan Jiang'}, {'authorId': '2073993343', 'name': 'T. Black'}, {'authorId': '145896397', 'name': 'Huan Liu'}]","420":"[{'authorId': '3468616', 'name': 'Matteo Cinelli'}, {'authorId': '35168570', 'name': 'G. D. F. Morales'}, {'authorId': '30978073', 'name': 'Alessandro Galeazzi'}, {'authorId': '1728390', 'name': 'Walter Quattrociocchi'}, {'authorId': '2081249', 'name': 'M. Starnini'}]","421":"[{'authorId': '2153689012', 'name': 'Xin Wang'}, {'authorId': '2720462', 'name': 'Shaoting Tang'}, {'authorId': '145155258', 'name': 'Zhiming Zheng'}, {'authorId': '49471480', 'name': 'Feng Fu'}]","422":"[{'authorId': '3481339', 'name': 'Shelley Boulianne'}, {'authorId': '1401672879', 'name': 'Karolina Koc-Michalska'}, {'authorId': '1940819', 'name': 'Bruce Bimber'}]","423":"[{'authorId': '2904268', 'name': 'Brent Kitchens'}, {'authorId': '143799789', 'name': 'Steven L. Johnson'}, {'authorId': '2052932402', 'name': 'Peter Gray'}]","424":"[{'authorId': '13901928', 'name': 'S. Gadarian'}]","425":"[{'authorId': '48630717', 'name': 'Xiaohui Wang'}, {'authorId': '1927682', 'name': 'Yunya Song'}]","426":"[{'authorId': '144008442', 'name': 'Jonathan Bright'}, {'authorId': '1491046516', 'name': 'Nahema Marchal'}, {'authorId': '36838735', 'name': 'B. Ganesh'}, {'authorId': '2815960', 'name': 'S. Rudinac'}]","427":"[{'authorId': '1435240859', 'name': 'Christopher Torres-Lugo'}, {'authorId': '31014271', 'name': 'Kai-Cheng Yang'}, {'authorId': '143653472', 'name': 'F. Menczer'}]","428":"[{'authorId': '52221360', 'name': 'I. Kozitsin'}, {'authorId': '50813891', 'name': 'A. Chkhartishvili'}]","429":"[{'authorId': '2071266140', 'name': 'Gabriel Martinez'}, {'authorId': '119255749', 'name': 'N. Tenev'}]","430":"[{'authorId': '1676136686', 'name': 'B. Phillips'}, {'authorId': '2736592', 'name': 'C. Bauch'}]","431":"[{'authorId': '30563513', 'name': 'E. Noordeh'}, {'authorId': '40543637', 'name': 'Roman Levin'}, {'authorId': '2052890330', 'name': 'Ruochen Jiang'}, {'authorId': '2007758740', 'name': 'Harris Shadmany'}]","432":"[{'authorId': '2378569', 'name': 'Homa Hosseinmardi'}, {'authorId': '2896291', 'name': 'Amir Ghasemian'}, {'authorId': '1978989', 'name': 'A. Clauset'}, {'authorId': '145792941', 'name': 'David M. Rothschild'}, {'authorId': '2402406', 'name': 'M. Mobius'}, {'authorId': '1783914', 'name': 'D. Watts'}]","433":"[{'authorId': '35168570', 'name': 'G. D. F. Morales'}, {'authorId': '47286020', 'name': 'Corrado Monti'}, {'authorId': '2081249', 'name': 'M. Starnini'}]","434":"[{'authorId': '1928964', 'name': 'K. Sasahara'}, {'authorId': '2111884170', 'name': 'Wen Chen'}, {'authorId': '2138443791', 'name': 'Hao Peng'}, {'authorId': '1683012', 'name': 'G. Ciampaglia'}, {'authorId': '1769960', 'name': 'A. Flammini'}, {'authorId': '143653472', 'name': 'F. Menczer'}]","435":"[{'authorId': '1928964', 'name': 'K. Sasahara'}, {'authorId': '2111884170', 'name': 'Wen Chen'}, {'authorId': '2138443791', 'name': 'Hao Peng'}, {'authorId': '1683012', 'name': 'G. Ciampaglia'}, {'authorId': '1769960', 'name': 'A. Flammini'}, {'authorId': '143653472', 'name': 'F. Menczer'}]","436":"[{'authorId': '153841419', 'name': 'Mina Young Pedersen'}, {'authorId': '1737695', 'name': 'S. Smets'}, {'authorId': '3283957', 'name': 'Thomas \u00c5gotnes'}]","437":"[{'authorId': '1394484621', 'name': 'Nikita Duseja'}, {'authorId': '2006291', 'name': 'Harsh Jhamtani'}]","438":"[{'authorId': '2764521', 'name': 'Marten Risius'}, {'authorId': '7825356', 'name': 'Okan Ayding\u00fcl'}, {'authorId': '50817412', 'name': 'Maximilian Haug'}]","439":"[{'authorId': '2137235502', 'name': 'Jiyoung Han'}, {'authorId': '2109246592', 'name': 'Youngin Lee'}, {'authorId': '46663293', 'name': 'Junbum Lee'}, {'authorId': '1775511', 'name': 'M. Cha'}]","440":"[{'authorId': '35445565', 'name': 'Moritz Markgraf'}, {'authorId': '2096255130', 'name': 'Manfred Schoch'}]","441":"[{'authorId': '36162262', 'name': 'Emanuele Brugnoli'}, {'authorId': '3468616', 'name': 'Matteo Cinelli'}, {'authorId': '40016674', 'name': 'Fabiana Zollo'}, {'authorId': '1728390', 'name': 'Walter Quattrociocchi'}, {'authorId': '143604617', 'name': 'A. Scala'}]","442":"[{'authorId': '2101279430', 'name': 'Yves Costa Netto'}, {'authorId': '2443880', 'name': 'A. Ma\u00e7ada'}]","443":"[{'authorId': '89146795', 'name': 'Nynke M. D. Niezink'}]","444":"[{'authorId': '2061493427', 'name': 'A. Peruzzi'}, {'authorId': '40016674', 'name': 'Fabiana Zollo'}, {'authorId': '2131958054', 'name': 'Ana Luc\u00eda Schmidt'}, {'authorId': '1728390', 'name': 'Walter Quattrociocchi'}]","445":"[{'authorId': '2078464034', 'name': 'Alessandro Cossard'}, {'authorId': '35168570', 'name': 'G. D. F. Morales'}, {'authorId': '145519038', 'name': 'Kyriaki Kalimeri'}, {'authorId': '3329961', 'name': 'Yelena Mejova'}, {'authorId': '2504674', 'name': 'D. Paolotti'}, {'authorId': '2081249', 'name': 'M. Starnini'}]","446":"[{'authorId': '2051973162', 'name': 'Kuan-Chieh Lo'}, {'authorId': '3400291', 'name': 'Shih-Chieh Dai'}, {'authorId': '2156155', 'name': 'Aiping Xiong'}, {'authorId': '2118241443', 'name': 'Jing Jiang'}, {'authorId': '1746959', 'name': 'Lun-Wei Ku'}]","447":"[{'authorId': '51039404', 'name': 'Youngseung Jeon'}, {'authorId': '51043444', 'name': 'Bogoan Kim'}, {'authorId': '2156155', 'name': 'Aiping Xiong'}, {'authorId': '37585620', 'name': 'Dongwon Lee'}, {'authorId': '35655049', 'name': 'Kyungsik Han'}]","448":"[{'authorId': '2907656', 'name': 'Tim Donkers'}, {'authorId': '145758499', 'name': 'J. Ziegler'}]","449":"[{'authorId': '3049771', 'name': 'Antonela Tommasel'}, {'authorId': '50388356', 'name': 'J. M. Rodr\u00edguez'}, {'authorId': '145525472', 'name': 'D. Godoy'}]","450":"[{'authorId': '1869835702', 'name': 'Virginia Morini'}, {'authorId': '28956425', 'name': 'Laura Pollacci'}, {'authorId': '37340414', 'name': 'Giulio Rossetti'}]","451":"[{'authorId': '2124029874', 'name': 'Giacomo Villa'}, {'authorId': '145645971', 'name': 'G. Pasi'}, {'authorId': '40449696', 'name': 'Marco Viviani'}]","452":"[{'authorId': '80108223', 'name': 'Matan Orbach'}, {'authorId': '2911299', 'name': 'Yonatan Bilu'}, {'authorId': '35874066', 'name': 'Assaf Toledo'}, {'authorId': '1396093833', 'name': 'D. Lahav'}, {'authorId': '2697312', 'name': 'Michal Jacovi'}, {'authorId': '48361424', 'name': 'R. Aharonov'}, {'authorId': '1766595', 'name': 'N. Slonim'}]","453":"[{'authorId': '5460357', 'name': 'W. Cota'}, {'authorId': '2150565225', 'name': 'Silvio C. Ferreira'}, {'authorId': '1397426946', 'name': 'R. Pastor-Satorras'}, {'authorId': '2081249', 'name': 'M. Starnini'}]","454":"[{'authorId': '32667074', 'name': 'An Nguyen'}, {'authorId': '145193206', 'name': 'H. Vu'}]","455":"[{'authorId': '89552478', 'name': 'Duilio Balsamo'}, {'authorId': '150331411', 'name': 'Valeria Gelardi'}, {'authorId': '146373399', 'name': 'Chengyuan Han'}, {'authorId': '114115435', 'name': 'D. Rama'}, {'authorId': '52135517', 'name': 'Abhishek Samantray'}, {'authorId': '150068440', 'name': 'C. Zucca'}, {'authorId': '2081249', 'name': 'M. Starnini'}]","456":"[{'authorId': '2030916236', 'name': 'Henrique Ferraz de Arruda'}, {'authorId': '114830687', 'name': 'Alexandre Benatti'}, {'authorId': '2106621774', 'name': 'Filipi Nascimento Silva'}, {'authorId': '2327749', 'name': 'C. H. Comin'}, {'authorId': '80994511', 'name': 'L. da Fontoura Costa'}]","457":"[{'authorId': '121629061', 'name': 'Renee Bowen'}, {'authorId': '2020212467', 'name': 'Danil Dmitriev'}, {'authorId': '2773368', 'name': 'S. Galperti'}]","458":"[{'authorId': '7247867', 'name': 'Ruibo Liu'}, {'authorId': '2117930921', 'name': 'Lili Wang'}, {'authorId': '1727055797', 'name': 'Chenyan Jia'}, {'authorId': '1918441', 'name': 'Soroush Vosoughi'}]","459":"[{'authorId': '52023534', 'name': 'Rohit Kumar Kaliyar'}, {'authorId': '71989499', 'name': 'Anurag Goswami'}, {'authorId': '3120689', 'name': 'Pratik Narang'}]","460":"[{'authorId': '41079145', 'name': 'T. Radicioni'}, {'authorId': '2535806', 'name': 'T. Squartini'}, {'authorId': '34917281', 'name': 'E. Pavan'}, {'authorId': '2419880', 'name': 'F. Saracco'}]","461":"[{'authorId': '9029894', 'name': 'Uthsav Chitra'}, {'authorId': '2767340', 'name': 'C. Musco'}]","462":"[{'authorId': '1774514', 'name': 'Francesco Pierri'}, {'authorId': '2601281', 'name': 'C. Piccardi'}, {'authorId': '144161686', 'name': 'S. Ceri'}]","463":"[{'authorId': '52023534', 'name': 'Rohit Kumar Kaliyar'}, {'authorId': '71989499', 'name': 'Anurag Goswami'}, {'authorId': '3120689', 'name': 'Pratik Narang'}]","464":"[{'authorId': '4476840', 'name': 'R. P. Curiel'}, {'authorId': '2058483961', 'name': \"Humberto Gonz'alez Ram'irez\"}]","465":"[{'authorId': '34962733', 'name': 'Siqi Wu'}, {'authorId': '144741762', 'name': 'P. Resnick'}]","466":"[{'authorId': '2004215224', 'name': 'D. Lauer'}]","467":"[{'authorId': '120076217', 'name': 'Ho-Chun Herbert Chang'}, {'authorId': '2000893055', 'name': 'Emily Chen'}, {'authorId': '2145176897', 'name': 'Meiqing Zhang'}, {'authorId': '7255575', 'name': 'Goran Muri\u0107'}, {'authorId': '48898287', 'name': 'Emilio Ferrara'}]","468":"[{'authorId': '2543788', 'name': 'Dimitris Kalimeris'}, {'authorId': '1738297', 'name': 'Smriti Bhagat'}, {'authorId': '40413877', 'name': 'Shankar Kalyanaraman'}, {'authorId': '2714236', 'name': 'Udi Weinsberg'}]","469":"[{'authorId': '1573738676', 'name': 'Lisa Oswald'}, {'authorId': '144008442', 'name': 'Jonathan Bright'}]","470":"[{'authorId': '35076395', 'name': 'Ray Jiang'}, {'authorId': '48880818', 'name': 'S. Chiappa'}, {'authorId': '2989692', 'name': 'Tor Lattimore'}, {'authorId': '145350541', 'name': 'A. Gy\u00f6rgy'}, {'authorId': '143967473', 'name': 'Pushmeet Kohli'}]","471":"[{'authorId': '52186442', 'name': 'H. Prasetya'}, {'authorId': '1702484', 'name': 'T. Murata'}]","472":"[{'authorId': '143964310', 'name': 'Tian Yang'}, {'authorId': '1402573847', 'name': 'S\u00edlvia Maj\u00f3-V\u00e1zquez'}, {'authorId': '2212978', 'name': 'R. Nielsen'}, {'authorId': '1404609254', 'name': 'Sandra Gonz\u00e1lez-Bail\u00f3n'}]","473":"[{'authorId': '143733378', 'name': 'Yan Xia'}, {'authorId': '92104193', 'name': 'T. H. Chen'}, {'authorId': '1846839', 'name': 'Mikko Kivel\u00e4'}]","474":"[{'authorId': '4797155', 'name': 'Dana McKay'}, {'authorId': '1716766', 'name': 'S. Makri'}, {'authorId': '1560489979', 'name': 'M. Gutierrez-Lopez'}, {'authorId': '143811409', 'name': 'A. MacFarlane'}, {'authorId': '2018752', 'name': 'S. Missaoui'}, {'authorId': '92477588', 'name': 'Colin Porlezza'}, {'authorId': '48603039', 'name': 'Glenda Cooper'}]","475":"[{'authorId': '5960787', 'name': 'C. Blex'}, {'authorId': '1985987', 'name': 'T. Yasseri'}]","476":"[{'authorId': '32150489', 'name': 'Longzhao Liu'}, {'authorId': '2153689012', 'name': 'Xin Wang'}, {'authorId': '3104053', 'name': 'Yihui Zheng'}, {'authorId': '3120145', 'name': 'Wenyi Fang'}, {'authorId': '2720462', 'name': 'Shaoting Tang'}, {'authorId': '145155258', 'name': 'Zhiming Zheng'}]","477":"[{'authorId': '144626725', 'name': 'Huyen T. Le'}, {'authorId': '114443948', 'name': 'Raven S. Maragh'}, {'authorId': '2597086', 'name': 'Brian Ekdale'}, {'authorId': '2871894', 'name': 'Andrew C. High'}, {'authorId': '3172469', 'name': 'T. Havens'}, {'authorId': '34616778', 'name': 'Zubair Shafiq'}]","478":"[{'authorId': '1470600809', 'name': 'Stefano Guarino'}, {'authorId': '119054185', 'name': 'Noemi Trino'}, {'authorId': '40572046', 'name': 'Alessandro Celestini'}, {'authorId': '3063377', 'name': 'A. Chessa'}, {'authorId': '2863073', 'name': 'Gianni Riotta'}]","479":"[{'authorId': '1581883920', 'name': 'Daniel R\u00f6chert'}, {'authorId': '2668730', 'name': 'German Neubaum'}, {'authorId': '26234127', 'name': 'Bj\u00f6rn Ross'}, {'authorId': '19179786', 'name': 'Florian Brachten'}, {'authorId': '2423134', 'name': 'Stefan Stieglitz'}]","480":"[{'authorId': '16413762', 'name': 'K. Allison'}, {'authorId': '40521107', 'name': 'K. Bussey'}]","481":"[{'authorId': '2111884170', 'name': 'Wen Chen'}, {'authorId': '144795888', 'name': 'D. Pacheco'}, {'authorId': '31014271', 'name': 'Kai-Cheng Yang'}, {'authorId': '143653472', 'name': 'F. Menczer'}]","482":"[{'authorId': '114830687', 'name': 'Alexandre Benatti'}, {'authorId': '1903282', 'name': 'H. F. D. Arruda'}, {'authorId': '145827334', 'name': 'F. N. Silva'}, {'authorId': '2327749', 'name': 'C. H. Comin'}, {'authorId': '145882236', 'name': 'L. D. Costa'}]","483":"[{'authorId': '34543844', 'name': 'A. Shahin'}, {'authorId': '31810658', 'name': 'Sultan Almotairi'}]","484":"[{'authorId': '1730531', 'name': 'T. Abdelzaher'}, {'authorId': '2072976571', 'name': 'Heng Ji'}, {'authorId': '2124948781', 'name': 'Jinyang Li'}, {'authorId': '51166038', 'name': 'Chaoqi Yang'}, {'authorId': '1607112868', 'name': 'John Dellaverson'}, {'authorId': '2144156375', 'name': 'Lixian Zhang'}, {'authorId': '2004428678', 'name': 'Chao Xu'}, {'authorId': '144133315', 'name': 'B. Szymanski'}]","485":"[{'authorId': '114936934', 'name': 'Lukas Schwengerer'}]","486":"[{'authorId': '2252904', 'name': 'L. Fell'}, {'authorId': '2052950786', 'name': 'A. Gibson'}, {'authorId': '1755431', 'name': 'P. Bruza'}, {'authorId': '1396900119', 'name': 'Pamela Hoyte'}]","487":"[{'authorId': '1447144401', 'name': 'Inayathullah Ghori'}, {'authorId': '153881820', 'name': 'Debaditya Roy'}, {'authorId': '145057697', 'name': 'R. John'}, {'authorId': '4759148', 'name': 'Krishna Mohan Chalavadi'}]","488":"[{'authorId': '2053279508', 'name': 'E. Kang'}, {'authorId': '1562166541', 'name': 'Cin Young Hur'}, {'authorId': '47634928', 'name': 'Yong Soon Choi'}]","489":"[{'authorId': '2082074150', 'name': 'Dimitar Nikolov'}, {'authorId': '1769960', 'name': 'A. Flammini'}, {'authorId': '143653472', 'name': 'F. Menczer'}]","490":"[{'authorId': '2061106122', 'name': 'Benjamin D. Horne'}, {'authorId': '90031160', 'name': 'Jeppe N\u00f8rregaard'}, {'authorId': '3139418', 'name': 'Sibel Adali'}]","491":"[{'authorId': '25184870', 'name': 'Anders Edelbo Lillie'}, {'authorId': '150092537', 'name': 'Emil Refsgaard Middelboe'}]","492":"[{'authorId': '27670260', 'name': 'Urbano Reviglio'}]","493":"[{'authorId': '7660878', 'name': 'A. Dash'}, {'authorId': '33392067', 'name': 'Animesh Mukherjee'}, {'authorId': '143841814', 'name': 'Saptarshi Ghosh'}]","494":"[{'authorId': '144019696', 'name': 'Yong Min'}, {'authorId': '1406059692', 'name': 'Tingjun Jiang'}, {'authorId': '2114039158', 'name': 'Cheng Jin'}, {'authorId': '2108646557', 'name': 'Qu Li'}, {'authorId': '50562484', 'name': 'Xiaogang Jin'}]","495":"[{'authorId': '32615664', 'name': 'Neil Thurman'}]","496":"[{'authorId': '39507908', 'name': 'Wenjun Mei'}, {'authorId': '1793883', 'name': 'F. Bullo'}, {'authorId': '2116388731', 'name': 'Ge Chen'}, {'authorId': '2121967', 'name': 'F. D\u00f6rfler'}]","497":"[{'authorId': '47690104', 'name': 'Thomas H\u00e4ussler'}]","498":"[{'authorId': '144227173', 'name': 'A. Bagavathi'}, {'authorId': '75140402', 'name': 'Pedram Bashiri'}, {'authorId': '50380410', 'name': 'S. Reid'}, {'authorId': '2070364557', 'name': 'Matthew Phillips'}, {'authorId': '14317484', 'name': 'S. Krishnan'}]","499":"[{'authorId': '3364109', 'name': 'Alexis M. Elder'}]","500":"[{'authorId': '32259840', 'name': 'A. Abdi'}, {'authorId': '144777949', 'name': 'T. Tsang'}, {'authorId': '2427371', 'name': 'P. Abolmaesumi'}]","501":"[{'authorId': None, 'name': 'Wei Li'}, {'authorId': '2092075591', 'name': 'Xu Tan'}]","502":"[{'authorId': '3076440', 'name': 'W. Dutton'}, {'authorId': '2871500', 'name': 'Bianca C. Reisdorf'}, {'authorId': '47443814', 'name': 'Grant Blank'}, {'authorId': '47782014', 'name': 'Elizabeth Dubois'}, {'authorId': '39769695', 'name': 'Laleah Fernandez'}]","503":"[{'authorId': '123893736', 'name': 'S. Engel'}, {'authorId': '1405174380', 'name': 'Linda Lee-Davies'}]","504":"[{'authorId': '1774514', 'name': 'Francesco Pierri'}, {'authorId': '2601281', 'name': 'C. Piccardi'}, {'authorId': '144161686', 'name': 'S. Ceri'}]","505":"[{'authorId': '2067992879', 'name': 'Shayan A. Tabrizi'}, {'authorId': '2887988', 'name': 'A. Shakery'}]","506":"[{'authorId': '1760642', 'name': 'Dimitris Sacharidis'}]","507":"[{'authorId': '2437582', 'name': 'Timotheus Kampik'}, {'authorId': '2297347', 'name': 'A. Najjar'}]","508":"[{'authorId': '2325707', 'name': 'R. Bierig'}, {'authorId': '2452441', 'name': 'Simon Caton'}]","509":"[{'authorId': '2059413126', 'name': 'Rob Walton'}, {'authorId': '1708123', 'name': 'D. D. Roure'}]","510":"[{'authorId': '1695689', 'name': 'Geoffrey E. Hinton'}]","511":"[{'authorId': '144438218', 'name': 'F. Santos'}, {'authorId': '46567426', 'name': 'Yphtach Lelkes'}, {'authorId': '2112147237', 'name': 'S. Levin'}]","512":"[{'authorId': '143897867', 'name': 'A. F. Peralta'}, {'authorId': '2093483117', 'name': \"J'anos Kert'esz\"}, {'authorId': '40527549', 'name': 'G. I\u00f1iguez'}]","513":"[{'authorId': '36581135', 'name': 'Marialisa Scat\u00e0'}, {'authorId': '29819517', 'name': 'Alessandro Di Stefano'}, {'authorId': '2078988166', 'name': 'Aurelio La Corte'}, {'authorId': '144269589', 'name': 'P. Lio\u2019'}]","514":"[{'authorId': '3468616', 'name': 'Matteo Cinelli'}, {'authorId': '36162262', 'name': 'Emanuele Brugnoli'}, {'authorId': '39976743', 'name': 'A. L. Schmidt'}, {'authorId': '40016674', 'name': 'Fabiana Zollo'}, {'authorId': '1728390', 'name': 'Walter Quattrociocchi'}, {'authorId': '143604617', 'name': 'A. Scala'}]","515":"[{'authorId': '48898287', 'name': 'Emilio Ferrara'}, {'authorId': '2116152428', 'name': 'Herbert Chang'}, {'authorId': '2000893055', 'name': 'Emily Chen'}, {'authorId': '7255575', 'name': 'Goran Muri\u0107'}, {'authorId': '2070427337', 'name': 'Jaimin Patel'}]","516":"[{'authorId': '103427559', 'name': 'Heather Z. Brooks'}, {'authorId': '2554498', 'name': 'M. Porter'}]","517":"[{'authorId': '37873464', 'name': 'Hilah Geva'}, {'authorId': '1399088307', 'name': 'Gal Oestreicher-Singer'}, {'authorId': '1388405043', 'name': 'M. Saar-Tsechansky'}]","518":"[{'authorId': '2110618947', 'name': 'Jie Gao'}, {'authorId': '1710013', 'name': 'G. Schoenebeck'}, {'authorId': '34405310', 'name': 'Fang-Yi Yu'}]","519":"[{'authorId': '51955992', 'name': 'R. Luzsa'}, {'authorId': '3096362', 'name': 'S. Mayr'}]","520":"[{'authorId': '1388724736', 'name': 'Echo Ho'}, {'authorId': '13073628', 'name': 'A. D. Campo'}, {'authorId': '98182421', 'name': 'H. Hoelzl'}]","521":"[{'authorId': '2119849076', 'name': 'Cedric Waterschoot'}, {'authorId': '153030757', 'name': 'A. V. D. Bosch'}, {'authorId': '81094050', 'name': 'E. Hemel'}]","522":"[{'authorId': '84224473', 'name': 'M. Saadatmand'}, {'authorId': '2007906109', 'name': 'Elham Fathipour'}, {'authorId': '30951587', 'name': 'Alireza Noei Sarcheshmeh'}]","523":"[{'authorId': '2146695726', 'name': 'Amin Mekacher'}, {'authorId': '9207147', 'name': 'Antonis Papasavva'}]","524":"[{'authorId': '3033269', 'name': 'Nika Haghtalab'}, {'authorId': '1724913', 'name': 'M. Jackson'}, {'authorId': '1689184', 'name': 'Ariel D. Procaccia'}]","525":"[{'authorId': '40650641', 'name': 'Mehwish Nasim'}, {'authorId': '2056850278', 'name': 'Derek Weber'}, {'authorId': '148243135', 'name': 'Tobin South'}, {'authorId': '8676452', 'name': 'Simon Jonathan Tuke'}, {'authorId': '1738558', 'name': 'N. Bean'}, {'authorId': '34787071', 'name': 'Lucia Falzon'}, {'authorId': '13568600', 'name': 'Lewis Mitchell'}]","526":"[{'authorId': '150007688', 'name': 'A. Bracci'}]","527":"[{'authorId': '97586640', 'name': 'Michele Travierso'}]","528":"[{'authorId': '2111130689', 'name': 'Yan Xia'}, {'authorId': '92104193', 'name': 'T. H. Chen'}, {'authorId': '1846839', 'name': 'Mikko Kivel\u00e4'}]","529":"[{'authorId': '1454375179', 'name': 'Dawoud Al Kindi'}, {'authorId': '31776961', 'name': 'M. Househ'}, {'authorId': '49164594', 'name': 'T. Alam'}, {'authorId': '2052725797', 'name': 'Zubair Shah'}]","530":"[{'authorId': '144124714', 'name': 'Joseph L. Clarke'}]","531":"[{'authorId': '2423134', 'name': 'Stefan Stieglitz'}]","532":"[{'authorId': '1435240859', 'name': 'Christopher Torres-Lugo'}, {'authorId': '31014271', 'name': 'Kai-Cheng Yang'}, {'authorId': '143653472', 'name': 'F. Menczer'}]","533":"[{'authorId': '40973999', 'name': 'Sebastian Schams'}, {'authorId': '2644626', 'name': 'Jan Hauffa'}, {'authorId': '144314168', 'name': 'Maximilian Schmidt'}, {'authorId': '1711829', 'name': 'Georg Groh'}]","534":"[{'authorId': '2112655298', 'name': 'Niccol\u00f2 Di Marco'}, {'authorId': '3468616', 'name': 'Matteo Cinelli'}, {'authorId': '1728390', 'name': 'Walter Quattrociocchi'}]","535":"[{'authorId': '2841005', 'name': 'Amy Perfors'}, {'authorId': '145968398', 'name': 'D. Navarro'}]","536":"[{'authorId': '122534807', 'name': 'Muhammad Al Atiqi'}, {'authorId': '87640969', 'name': 'Shuang Chang'}, {'authorId': '144336989', 'name': 'H. Deguchi'}]","537":"[{'authorId': '143660688', 'name': 'N. Tkachenko'}, {'authorId': '50054955', 'name': 'Weisi Guo'}]","538":"[{'authorId': '2153708171', 'name': 'Jacques Bara'}, {'authorId': '145295207', 'name': 'Omer Lev'}, {'authorId': '1820012', 'name': 'P. Turrini'}]","539":"[{'authorId': '48815577', 'name': 'J. Shine'}, {'authorId': '1792909', 'name': 'M. Breakspear'}, {'authorId': '2780753', 'name': 'P. Bell'}, {'authorId': '5853686', 'name': 'K. E. Ehgoetz Martens'}, {'authorId': '153730460', 'name': 'R. Shine'}, {'authorId': '143812875', 'name': 'O. Koyejo'}, {'authorId': '1694232', 'name': 'O. Sporns'}, {'authorId': '145625277', 'name': 'R. Poldrack'}]","540":"[{'authorId': '2065740541', 'name': 'Emily Wall'}, {'authorId': '1691661', 'name': 'J. Stasko'}, {'authorId': '3200296', 'name': 'A. Endert'}]","541":"[{'authorId': '2304083', 'name': 'Evanthia Dimara'}, {'authorId': '1836170', 'name': 'S. Franconeri'}, {'authorId': '1764846', 'name': 'C. Plaisant'}, {'authorId': '34790289', 'name': 'A. Bezerianos'}, {'authorId': '3297322', 'name': 'Pierre Dragicevic'}]","542":"[{'authorId': '1794884', 'name': 'A. Caraban'}, {'authorId': '1766666', 'name': 'E. Karapanos'}, {'authorId': '145583003', 'name': 'Daniel Gon\u00e7alves'}, {'authorId': '145495484', 'name': 'Pedro F. Campos'}]","543":"[{'authorId': '36784255', 'name': 'M. Kinsey'}, {'authorId': '145956407', 'name': 'S. Gwynne'}, {'authorId': '4789972', 'name': 'E. Kuligowski'}, {'authorId': '2728602', 'name': 'M. Kinateder'}]","544":"[{'authorId': '1909948', 'name': 'Bryan Dosono'}, {'authorId': '3356301', 'name': 'Bryan C. Semaan'}]","545":"[{'authorId': '3250103', 'name': 'Peiyang Li'}, {'authorId': '2146396846', 'name': 'Huan Liu'}, {'authorId': '2473106', 'name': 'Yajing Si'}, {'authorId': '153227949', 'name': 'Cunbo Li'}, {'authorId': '2999471', 'name': 'Fali Li'}, {'authorId': '2132408', 'name': 'Xuyang Zhu'}, {'authorId': '4685138', 'name': 'Xiaoye Huang'}, {'authorId': '50233652', 'name': 'Yin Zeng'}, {'authorId': '50496953', 'name': 'D. Yao'}, {'authorId': '1794006', 'name': 'Yangsong Zhang'}, {'authorId': '145612636', 'name': 'Peng Xu'}]","546":"[{'authorId': '51112001', 'name': 'Jernej Mihelj'}, {'authorId': '48379914', 'name': 'Y. Zhang'}, {'authorId': '2708176', 'name': 'A. Kos'}, {'authorId': '2851263', 'name': 'Urban Sedlar'}]","547":"[{'authorId': '34845167', 'name': 'Antino Kim'}, {'authorId': '52202443', 'name': 'Patricia L. Moravec'}, {'authorId': '1718617', 'name': 'A. Dennis'}]","548":"[{'authorId': '1411076398', 'name': 'Lenin Guaya-Delgado'}, {'authorId': '1404607038', 'name': 'E. Pallar\u00e8s-Segarra'}, {'authorId': '2471561', 'name': 'A. M. Mezher'}, {'authorId': '2226660', 'name': 'J. Forn\u00e9'}]","549":"[{'authorId': '143911967', 'name': 'M. Gerosa'}, {'authorId': '2381447', 'name': 'I. Wiese'}, {'authorId': '1859526', 'name': 'Bianca Trinkenreich'}, {'authorId': '2854197', 'name': 'Georg J. P. Link'}, {'authorId': '143684601', 'name': 'G. Robles'}, {'authorId': '1685418', 'name': 'Christoph Treude'}, {'authorId': '2091414', 'name': 'Igor Steinmacher'}, {'authorId': '2805449', 'name': 'A. Sarma'}]","550":"[{'authorId': '48377962', 'name': 'Yasir Hussain'}, {'authorId': '46378344', 'name': 'Huang Zhiqiu'}, {'authorId': '32584448', 'name': 'M. Akbar'}, {'authorId': '31197943', 'name': 'Ahmed Alsanad'}, {'authorId': '2325376', 'name': 'A. Alsanad'}, {'authorId': '48907802', 'name': 'Asif Nawaz'}, {'authorId': '49525434', 'name': 'I. A. Khan'}, {'authorId': '49412931', 'name': 'Z. Khan'}]","551":"[{'authorId': '2037649', 'name': 'Marios Kokkodis'}, {'authorId': '1987564', 'name': 'Theodoros Lappas'}]","552":"[{'authorId': '1403733152', 'name': 'Ana Reyes-Menendez'}, {'authorId': '32179627', 'name': 'Jos\u00e9 Ram\u00f3n Saura'}, {'authorId': '1413687450', 'name': 'J. Mart\u00ednez\u2010Naval\u00f3n'}]","553":"[{'authorId': '143643872', 'name': 'Jie Cui'}, {'authorId': '2133401299', 'name': 'Xiaoyu Zhang'}, {'authorId': '32256751', 'name': 'Hong Zhong'}, {'authorId': '3436314', 'name': 'Zuobin Ying'}, {'authorId': '2145287019', 'name': 'Lu Liu'}]","554":"[{'authorId': '35342324', 'name': 'A. Cartwright'}, {'authorId': '144267098', 'name': 'E. Cartwright'}]","555":"[{'authorId': '38825289', 'name': 'I. Howley'}, {'authorId': '2072549567', 'name': 'Gaurav Tomar'}, {'authorId': '1751511', 'name': 'Oliver Ferschke'}, {'authorId': '35959897', 'name': 'C. Ros\u00e9'}]","556":"[{'authorId': '3110752', 'name': 'Sadika Amreen'}, {'authorId': '98524776', 'name': 'Andrey Karnauch'}, {'authorId': '1702551', 'name': 'A. Mockus'}]","557":"[{'authorId': '145224489', 'name': 'A. Alami'}, {'authorId': '27820949', 'name': 'M. Cohn'}, {'authorId': '1723400', 'name': 'A. Wasowski'}]","558":"[{'authorId': '2016795', 'name': 'Thomas Morstyn'}, {'authorId': '143969598', 'name': 'M. Mcculloch'}]","559":"[{'authorId': '24821875', 'name': 'Haoyan Sun'}, {'authorId': '145104983', 'name': 'Ming Fan'}, {'authorId': '144176421', 'name': 'Yong Tan'}]","560":"[{'authorId': '3073122', 'name': 'Gary E. Bolton'}, {'authorId': '23204247', 'name': 'D. Kusterer'}, {'authorId': '116027152', 'name': 'J. Mans'}]","561":"[{'authorId': '66289573', 'name': 'Liviu-Adrian Hirtan'}, {'authorId': '143649293', 'name': 'C. Dobre'}, {'authorId': '1397951978', 'name': 'H. Gonz\u00e1lez-V\u00e9lez'}]","562":"[{'authorId': '47008023', 'name': 'Zhou Su'}, {'authorId': '2735832', 'name': 'Qifan Qi'}, {'authorId': '1908622', 'name': 'Qichao Xu'}, {'authorId': '144123438', 'name': 'Song Guo'}, {'authorId': '2108201889', 'name': 'Xiaowei Wang'}]","563":"[{'authorId': '5943146', 'name': 'S. Slussarenko'}, {'authorId': '4049282', 'name': 'G. Pryde'}]","564":"[{'authorId': '47008023', 'name': 'Zhou Su'}, {'authorId': '2108901244', 'name': 'Yuntao Wang'}, {'authorId': '1908622', 'name': 'Qichao Xu'}, {'authorId': '143750306', 'name': 'M. Fei'}, {'authorId': '1777602', 'name': 'Yu-Chu Tian'}, {'authorId': '2153009389', 'name': 'Ning Zhang'}]","565":"[{'authorId': '2146027601', 'name': 'Li Chen'}, {'authorId': '66693998', 'name': 'S. Yao'}, {'authorId': '2543684', 'name': 'Kaijie Zhu'}]","566":"[{'authorId': '1701119', 'name': 'Dapeng Tao'}, {'authorId': '2112570628', 'name': 'Jun Cheng'}, {'authorId': '1760581', 'name': 'Zhengtao Yu'}, {'authorId': '145611284', 'name': 'Kun Yue'}, {'authorId': '151502331', 'name': 'Lizhen Wang'}]","567":"[{'authorId': '48634318', 'name': 'Farhan Ullah'}, {'authorId': '9101428', 'name': 'Hamad Naeem'}, {'authorId': '1844196', 'name': 'Sohail Jabbar'}, {'authorId': '144665620', 'name': 'S. Khalid'}, {'authorId': '143680427', 'name': 'M. Latif'}, {'authorId': '1410064789', 'name': 'F. Al-turjman'}, {'authorId': '2860068', 'name': 'L. Mostarda'}]","568":"[{'authorId': '51137512', 'name': 'T. Rasool'}, {'authorId': '2962670', 'name': 'Wasi Haider Butt'}, {'authorId': '3258043', 'name': 'A. Shaukat'}, {'authorId': '1749722', 'name': 'M. Akram'}]","569":"[{'authorId': '2049963', 'name': 'Junting Ye'}, {'authorId': '1721948', 'name': 'S. Skiena'}]","570":"[{'authorId': '122138264', 'name': 'Adamu Sani Yahaya'}, {'authorId': '1685054', 'name': 'N. Javaid'}, {'authorId': '24463293', 'name': 'M. Javed'}, {'authorId': '145232527', 'name': 'M. Shafiq'}, {'authorId': '27421950', 'name': 'W. Z. Khan'}, {'authorId': '1693895', 'name': 'M. Aalsalem'}]","571":"[{'authorId': '1410451728', 'name': 'Affaf Shahid'}, {'authorId': '69005233', 'name': 'Umair Sarfraz'}, {'authorId': '1600334602', 'name': 'Muhammad Waseem Malik'}, {'authorId': '1411531480', 'name': 'Muhammad Sohaib Iftikhar'}, {'authorId': '5983145', 'name': 'A. Jamal'}, {'authorId': '1685054', 'name': 'N. Javaid'}]","572":"[{'authorId': '50821700', 'name': 'Leonard Przybilla'}, {'authorId': '1867435361', 'name': 'Maxi Rahn'}, {'authorId': '2248993', 'name': 'Manuel Wiesche'}, {'authorId': '1712422', 'name': 'H. Krcmar'}]","573":"[{'authorId': '1921691', 'name': 'S. Mahmood'}, {'authorId': '108327393', 'name': 'Anwar Ghani'}, {'authorId': '2117656857', 'name': 'Ali Daud'}, {'authorId': '1925224', 'name': 'S. Shamshirband'}]","574":"[{'authorId': '144611259', 'name': 'B. Khan'}, {'authorId': '2019098', 'name': 'F. Anwar'}, {'authorId': '9255543', 'name': 'R. F. Olanrewaju'}, {'authorId': '73364397', 'name': 'Bisma Rasool Pampori'}, {'authorId': '2833169', 'name': 'R. Mir'}]","575":"[{'authorId': '87133830', 'name': 'Atia Javaid'}, {'authorId': '144163870', 'name': 'M. Zahid'}, {'authorId': '3052749', 'name': 'Ishtiaq Ali'}, {'authorId': '49107159', 'name': 'R. U. Khan'}, {'authorId': '92082919', 'name': 'Zainib Noshad'}, {'authorId': '1685054', 'name': 'N. Javaid'}]","576":"[{'authorId': '46989536', 'name': 'M. Careem'}, {'authorId': '46967382', 'name': 'A. Dutta'}]","577":"[{'authorId': '153585587', 'name': 'Chunyuan Yuan'}, {'authorId': '1500398963', 'name': 'Qianwen Ma'}, {'authorId': '1388837278', 'name': 'W. Zhou'}, {'authorId': '47179764', 'name': 'Jizhong Han'}, {'authorId': '40845069', 'name': 'Songlin Hu'}]","578":"[{'authorId': '1971083', 'name': 'Gene M. Alarcon'}, {'authorId': '144238205', 'name': 'Anthony M. Gibson'}, {'authorId': '145874287', 'name': 'Charles Walter'}, {'authorId': '145331095', 'name': 'R. Gamble'}, {'authorId': '39403126', 'name': 'Tyler J. Ryan'}, {'authorId': '12376885', 'name': 'Sarah A. Jessup'}, {'authorId': '2072070268', 'name': 'Brian Boyd'}, {'authorId': '4057262', 'name': 'August A. Capiola'}]","579":"[{'authorId': '143920050', 'name': 'Zhen Shao'}, {'authorId': '49813865', 'name': 'Yue Guo'}, {'authorId': '50079713', 'name': 'Xiaotong Li'}, {'authorId': '50744223', 'name': 'S. Barnes'}]","580":"[{'authorId': '40379784', 'name': 'Ryan Kennedy'}, {'authorId': '51895628', 'name': 'Philip D. Waggoner'}, {'authorId': '50498034', 'name': 'M. Ward'}]","581":"[{'authorId': '2776924', 'name': 'Davide Ceolin'}, {'authorId': '2614511', 'name': 'G. Primiero'}]","582":"[{'authorId': '1396960751', 'name': 'Aikaterini Soumelidou'}, {'authorId': '2554433', 'name': 'A. Tsohou'}]","583":"[{'authorId': '145478138', 'name': 'Jiao Sun'}, {'authorId': '3157053', 'name': 'Nanyun Peng'}]","584":"[{'authorId': '3442017', 'name': 'Himan Abdollahpouri'}, {'authorId': '3437010', 'name': 'M. Mansoury'}, {'authorId': '1747150', 'name': 'R. Burke'}, {'authorId': '1684679', 'name': 'B. Mobasher'}]","585":"[{'authorId': '5222015', 'name': 'R. Sloan'}, {'authorId': '145782984', 'name': 'Richard Warner'}]","586":"[{'authorId': '3461253', 'name': 'Felix Hamborg'}, {'authorId': '2067413924', 'name': 'Anastasia Zhukova'}, {'authorId': '2488381', 'name': 'K. Donnay'}, {'authorId': '145151838', 'name': 'Bela Gipp'}]","587":"[{'authorId': '14343042', 'name': 'A. Jesson'}, {'authorId': '32777162', 'name': 'S. Mindermann'}, {'authorId': '2681954', 'name': 'Y. Gal'}, {'authorId': '2304764', 'name': 'Uri Shalit'}]","588":"[{'authorId': '71360738', 'name': 'A. Bierema'}, {'authorId': '34612639', 'name': 'Anne-Marie Hoskinson'}, {'authorId': '6076883', 'name': 'R. Moscarella'}, {'authorId': '1572220335', 'name': 'Alex Lyford'}, {'authorId': '4097419', 'name': 'Kevin C. Haudek'}, {'authorId': '21289631', 'name': 'John E. Merrill'}, {'authorId': '1389222465', 'name': 'M. Urban-Lurain'}]","589":"[{'authorId': '6015978', 'name': 'Gabriel Mittag'}, {'authorId': '19382329', 'name': 'Saman Zadtootaghaj'}, {'authorId': '145305039', 'name': 'Thilo Michael'}, {'authorId': '2488813', 'name': 'Babak Naderi'}, {'authorId': '145733288', 'name': 'S. M\u00f6ller'}]","590":"[{'authorId': '2123355312', 'name': 'Meric Altug Gemalmaz'}, {'authorId': '2053888438', 'name': 'M. Yin'}]","591":"[{'authorId': '22176560', 'name': 'Daniel B. Dodgson'}, {'authorId': '1869263', 'name': 'J. Raymond'}]","592":"[{'authorId': '144563237', 'name': 'Ahsan Mahmood'}, {'authorId': '34987718', 'name': 'H. Khan'}, {'authorId': '1517028233', 'name': 'Muhammad Ramzan'}]","593":"[{'authorId': '3442017', 'name': 'Himan Abdollahpouri'}, {'authorId': '3437010', 'name': 'M. Mansoury'}, {'authorId': '1747150', 'name': 'R. Burke'}, {'authorId': '1684679', 'name': 'B. Mobasher'}]","594":"[{'authorId': '79417324', 'name': 'Victor M. van Santen'}, {'authorId': '1894736', 'name': 'H. Amrouch'}, {'authorId': '144271439', 'name': 'J. Henkel'}]","595":"[{'authorId': '2011378', 'name': 'Zuohui Fu'}, {'authorId': '2885287', 'name': 'Yikun Xian'}, {'authorId': '2986776', 'name': 'Ruoyuan Gao'}, {'authorId': '33524946', 'name': 'Jieyu Zhao'}, {'authorId': '48185960', 'name': 'Qiaoying Huang'}, {'authorId': '152988336', 'name': 'Yingqiang Ge'}, {'authorId': '145670447', 'name': 'Shuyuan Xu'}, {'authorId': '1947101', 'name': 'Shijie Geng'}, {'authorId': '144797716', 'name': 'C. Shah'}, {'authorId': '1739818', 'name': 'Yongfeng Zhang'}, {'authorId': '144608002', 'name': 'Gerard de Melo'}]","596":"[{'authorId': '2119301078', 'name': 'Ke Yang'}, {'authorId': '2110784332', 'name': 'Biao Huang'}, {'authorId': '1682824', 'name': 'Julia Stoyanovich'}, {'authorId': '2180399', 'name': 'Sebastian Schelter'}]","597":"[{'authorId': '50853559', 'name': 'Feiyang Pan'}, {'authorId': '48480626', 'name': 'Xiang Ao'}, {'authorId': '34198278', 'name': 'Pingzhong Tang'}, {'authorId': '2149494300', 'name': 'Min Lu'}, {'authorId': '2144413415', 'name': 'Dapeng Liu'}, {'authorId': '2110394629', 'name': 'Lei Xiao'}, {'authorId': '2158548', 'name': 'Qing He'}]","598":"[{'authorId': '2105646417', 'name': 'Xinyi Dai'}, {'authorId': '2115103111', 'name': 'Jiawei Hou'}, {'authorId': '2116621589', 'name': 'Qing Liu'}, {'authorId': '2056826850', 'name': 'Yunjia Xi'}, {'authorId': '2824766', 'name': 'Ruiming Tang'}, {'authorId': '2108309275', 'name': 'Weinan Zhang'}, {'authorId': '1996703', 'name': 'Xiuqiang He'}, {'authorId': '39055225', 'name': 'Jun Wang'}, {'authorId': '1811427', 'name': 'Yong Yu'}]","599":"[{'authorId': '2122826069', 'name': 'Sheng Hu'}, {'authorId': '47009264', 'name': 'Yuqing Ma'}, {'authorId': '6820648', 'name': 'Xianglong Liu'}, {'authorId': '1492178649', 'name': 'Yanlu Wei'}, {'authorId': '151475528', 'name': 'Shihao Bai'}]","600":"[{'authorId': '7026794', 'name': 'Sudhir K. Satpathy'}, {'authorId': '2131367', 'name': 'S. Mathew'}, {'authorId': '2107921471', 'name': 'Raghavan Kumar'}, {'authorId': '38070985', 'name': 'Vikram B. Suresh'}, {'authorId': '143794851', 'name': 'M. Anders'}, {'authorId': '1703398', 'name': 'H. Kaul'}, {'authorId': '144728257', 'name': 'A. Agarwal'}, {'authorId': '1681504', 'name': 'S. Hsu'}, {'authorId': '1721155', 'name': 'R. Krishnamurthy'}, {'authorId': '145146098', 'name': 'V. De'}]","601":"[{'authorId': '1400347769', 'name': 'T. Glushkova'}, {'authorId': '36259430', 'name': 'Chrysoula Zerva'}, {'authorId': '15631652', 'name': 'Ricardo Rei'}, {'authorId': '2069905347', 'name': 'Andr\u00e9 Martins'}]","602":"[{'authorId': '48084733', 'name': 'M. Cordel'}, {'authorId': '2087470', 'name': 'Shaojing Fan'}, {'authorId': '2111639168', 'name': 'Zhiqi Shen'}, {'authorId': '1744045', 'name': 'M. Kankanhalli'}]","603":"[{'authorId': '3070188', 'name': 'N. Gkanatsios'}, {'authorId': '1738119', 'name': 'Vassilis Pitsikalis'}, {'authorId': '1750686', 'name': 'P. Maragos'}]","604":"[{'authorId': '104322179', 'name': 'D. Molinari'}, {'authorId': '87302591', 'name': 'A. R. Scorzini'}, {'authorId': '143824956', 'name': 'C. Arrighi'}, {'authorId': '103518704', 'name': 'F. Carisi'}, {'authorId': '2969740', 'name': 'F. Castelli'}, {'authorId': '51159865', 'name': 'A. Domeneghetti'}, {'authorId': '118450414', 'name': 'Alice Gallazzi'}, {'authorId': '1573954204', 'name': 'M. Galliani'}, {'authorId': '3014581', 'name': 'F. Grelot'}, {'authorId': '88288202', 'name': 'P. Kellermann'}, {'authorId': '50347076', 'name': 'H. Kreibich'}, {'authorId': '67222308', 'name': 'G. Mohor'}, {'authorId': '3121881', 'name': 'Markus Mosimann'}, {'authorId': '4123160', 'name': 'S. Natho'}, {'authorId': '88062963', 'name': 'Claire Richert'}, {'authorId': '1970930', 'name': 'K. Schroeter'}, {'authorId': '3229538', 'name': 'A. Thieken'}, {'authorId': '144813394', 'name': 'A. Zischg'}, {'authorId': '1930586', 'name': 'F. Ballio'}]","605":"[{'authorId': '2522915', 'name': 'Heba Khdr'}, {'authorId': '1894736', 'name': 'H. Amrouch'}, {'authorId': '144271439', 'name': 'J. Henkel'}]","606":"[{'authorId': '2593082', 'name': 'Ananth Balashankar'}, {'authorId': '49982610', 'name': 'Alyssa Lees'}, {'authorId': '143778120', 'name': 'Chris Welty'}, {'authorId': '1710917', 'name': 'L. Subramanian'}]","607":"[{'authorId': '143823700', 'name': 'R. P\u00f3voa'}, {'authorId': '144389200', 'name': 'N. Louren\u00e7o'}, {'authorId': '144264776', 'name': 'R. Martins'}, {'authorId': '2959152', 'name': 'A. Canelas'}, {'authorId': '1678956', 'name': 'N. Horta'}, {'authorId': '144409329', 'name': 'J. Goes'}]","608":"[{'authorId': '144829605', 'name': 'Woojoo Lee'}, {'authorId': '2118292681', 'name': 'Tae-Wook Kang'}, {'authorId': '2108395522', 'name': 'Jae-Jin Lee'}, {'authorId': '3007734', 'name': 'Kyuseung Han'}, {'authorId': '46454449', 'name': 'Joongheon Kim'}, {'authorId': '1691311', 'name': 'Massoud Pedram'}]","609":"[{'authorId': '2064234221', 'name': 'An Yan'}, {'authorId': '1686294', 'name': 'Bill Howe'}]","610":"[{'authorId': '48423943', 'name': 'Wenlong Sun'}, {'authorId': '12801406', 'name': 'Sami Khenissi'}, {'authorId': '2423522', 'name': 'O. Nasraoui'}, {'authorId': '3210220', 'name': 'Patrick Shafto'}]","611":"[{'authorId': '144204231', 'name': 'Lin Gu'}, {'authorId': '2081217', 'name': 'Deze Zeng'}, {'authorId': '2054576280', 'name': 'Sheng Tao'}, {'authorId': '144123438', 'name': 'Song Guo'}, {'authorId': '145914256', 'name': 'Hai Jin'}, {'authorId': '9392149', 'name': 'Albert Y. Zomaya'}, {'authorId': '143887379', 'name': 'W. Zhuang'}]","612":"[{'authorId': '79326405', 'name': 'Samuel Tuhkanen'}, {'authorId': '144040475', 'name': 'J. Pekkanen'}, {'authorId': '7578793', 'name': 'E. Lehtonen'}, {'authorId': '1975758', 'name': 'Otto Lappi'}]","613":"[{'authorId': '39666236', 'name': 'Jesperi Rantanen'}, {'authorId': '1894036', 'name': 'L. Ruotsalainen'}, {'authorId': '1403872425', 'name': 'M. Kirkko-Jaakkola'}, {'authorId': '46227974', 'name': 'M. M\u00e4kel\u00e4'}]","614":"[{'authorId': '16132631', 'name': 'Ziyi Kou'}, {'authorId': '2145953897', 'name': 'Yang Zhang'}, {'authorId': '65855502', 'name': 'Lanyu Shang'}, {'authorId': '2152686930', 'name': 'Dong Wang'}]","615":"[{'authorId': '121517184', 'name': 'Marina Dabic'}, {'authorId': '39662409', 'name': 'Timothy Kiessling'}]","616":"[{'authorId': '2112895644', 'name': 'Yuxuan Han'}, {'authorId': '2109732576', 'name': 'Jiaolong Yang'}, {'authorId': '143728560', 'name': 'Ying Fu'}]","617":"[{'authorId': '1413577591', 'name': 'Jacob Hadnett-Hunter'}, {'authorId': '2105800009', 'name': 'George Nicolaou'}, {'authorId': '1400661573', 'name': \"E. O'Neill\"}, {'authorId': '2042456', 'name': 'M. Proulx'}]","618":"[{'authorId': '1403916480', 'name': 'M. O\u2019Driscoll'}, {'authorId': '2000441382', 'name': 'C. Harry'}, {'authorId': '31534251', 'name': 'C. Donnelly'}, {'authorId': '2120479', 'name': 'A. Cori'}, {'authorId': '3940600', 'name': 'I. Dorigatti'}]","619":"[{'authorId': '39060459', 'name': 'L. Quaglietta'}, {'authorId': '87087630', 'name': 'M. Porto'}]","620":"[{'authorId': '50686568', 'name': 'Abdalla Abdelrahman'}, {'authorId': '35725657', 'name': 'H. Hassanein'}, {'authorId': '8739091', 'name': 'N. Ali'}]","621":"[{'authorId': '143820870', 'name': 'Vidhisha Balachandran'}, {'authorId': '51152502', 'name': 'Artidoro Pagnoni'}, {'authorId': '11073942', 'name': 'Jay Yoon Lee'}, {'authorId': '1801149', 'name': 'Dheeraj Rajagopal'}, {'authorId': '143712374', 'name': 'J. Carbonell'}, {'authorId': '145317727', 'name': 'Yulia Tsvetkov'}]","622":"[{'authorId': '21805084', 'name': 'Minghong Cai'}, {'authorId': '2745642', 'name': 'Jinghua Zhu'}]","623":"[{'authorId': '1733466994', 'name': 'Andrew Thirlwell'}, {'authorId': '46837178', 'name': 'Ognjen Arandjelov\u00edc'}]","624":"[{'authorId': '1404586776', 'name': 'Emma Beauxis-Aussalet'}]","625":"[{'authorId': '144260020', 'name': 'Rahim Khan'}, {'authorId': '19270859', 'name': 'M. Zakarya'}, {'authorId': '120636643', 'name': 'Zhiyuan Tan'}, {'authorId': '66805060', 'name': 'Muhammad Usman'}, {'authorId': '2015986', 'name': 'M. Jan'}, {'authorId': '2109202281', 'name': 'Mukhtaj Khan'}]","626":"[{'authorId': '98904107', 'name': 'Katarina Kosteli\u0107'}]","627":"[{'authorId': '116109895', 'name': 'Laura Schelenz'}]","628":"[{'authorId': '2119552000', 'name': 'M. Alipour'}, {'authorId': '1399083912', 'name': 'Sophie Dupuy-Chessa'}, {'authorId': '103964109', 'name': 'Eline Jongmans'}]","629":"[{'authorId': '2140486783', 'name': 'Maurilio Monsu'}, {'authorId': '1782340', 'name': 'M. Comin'}]","630":"[{'authorId': '46363540', 'name': 'S. Ravichandran'}, {'authorId': '1922932670', 'name': 'Drona Khurana'}, {'authorId': '153441561', 'name': 'B. Venkatesh'}, {'authorId': '2451136', 'name': 'N. U. Edakunni'}]","631":"[{'authorId': '1450761997', 'name': 'Guillermo Ant\u00fanez-Calistro'}, {'authorId': '90410420', 'name': 'Mariana Siniscalchi'}, {'authorId': '145510482', 'name': 'F. Silveira'}, {'authorId': '1404579003', 'name': 'Conrado Rossi-Aicardi'}]","632":"[{'authorId': '2118580089', 'name': 'Jie Yang'}, {'authorId': '145382786', 'name': 'Chao-Kai Wen'}, {'authorId': '145824256', 'name': 'Shi Jin'}, {'authorId': '145440737', 'name': 'Xiao Li'}]","633":"[{'authorId': '1987279', 'name': 'Shaoyang Men'}, {'authorId': '2763730', 'name': 'P. Charg\u00e9'}, {'authorId': '1698643', 'name': 'Yide Wang'}, {'authorId': '2109113125', 'name': 'Jianzhong Li'}]","634":"[{'authorId': '3202750', 'name': 'Falk Lieder'}, {'authorId': '1799860', 'name': 'T. Griffiths'}]","635":"[{'authorId': '31118130', 'name': 'Hesameddin Mokhtarzadeh'}, {'authorId': '1393929004', 'name': 'Amirhossein Taherpour'}, {'authorId': '1746911', 'name': 'A. Taherpour'}, {'authorId': '1681402', 'name': 'S. Gazor'}]","636":"[{'authorId': '116302891', 'name': 'Ouhao Chen'}, {'authorId': '2305406', 'name': 'Slava Kalyuga'}]","637":"[{'authorId': '102412642', 'name': 'Xin Liu'}, {'authorId': '2130045998', 'name': 'Xueyan Zhang'}]","638":"[{'authorId': '89121677', 'name': 'Xin Liu'}, {'authorId': '47929092', 'name': 'H. Ding'}, {'authorId': '145062831', 'name': 'Su Hu'}]","639":"[{'authorId': '19179786', 'name': 'Florian Brachten'}, {'authorId': '9534043', 'name': 'Felix Br\u00fcnker'}, {'authorId': '72529929', 'name': 'Nicholas R. J. Frick'}, {'authorId': '26234127', 'name': 'Bj\u00f6rn Ross'}, {'authorId': '2423134', 'name': 'Stefan Stieglitz'}]","640":"[{'authorId': '49481130', 'name': 'Ke Zhang'}, {'authorId': '4926792', 'name': 'S. Leng'}, {'authorId': '2115815081', 'name': 'Xin Peng'}, {'authorId': '2114094665', 'name': 'Li Pan'}, {'authorId': '2461792', 'name': 'Sabita Maharjan'}, {'authorId': '2152819646', 'name': 'Yan Zhang'}]","641":"[{'authorId': '9459356', 'name': 'Zhiqun Song'}, {'authorId': '2153690115', 'name': 'Xin Wang'}, {'authorId': '152891734', 'name': 'Yutao Liu'}, {'authorId': '2249346', 'name': 'Zhongzhao Zhang'}]","642":"[{'authorId': '51128405', 'name': 'Woping Xu'}, {'authorId': '8428743', 'name': 'Runhe Qiu'}, {'authorId': '150344047', 'name': 'Xueqin Jiang'}]","643":"[{'authorId': '47655624', 'name': 'Boyang Liu'}, {'authorId': '2143718806', 'name': 'Jin Wang'}, {'authorId': '2046978401', 'name': 'Shuai Ma'}, {'authorId': '3311360', 'name': 'Fuhui Zhou'}, {'authorId': '2109237233', 'name': 'Yujiao Ma'}, {'authorId': '1804026', 'name': 'G. Lu'}]","644":"[{'authorId': '2758671', 'name': 'Rami Halloush'}, {'authorId': '2253043', 'name': 'Mohammed D. Halloush'}, {'authorId': '2742225', 'name': 'Islam T. Almalkawi'}, {'authorId': '144731477', 'name': 'A. Musa'}, {'authorId': '1726369', 'name': 'H. Salameh'}]","645":"[{'authorId': '8278933', 'name': 'Christine Salahub'}, {'authorId': '6561324', 'name': 'Holly A. Lockhart'}, {'authorId': '31463299', 'name': 'Blaire Dube'}, {'authorId': '1398827516', 'name': 'Naseem Al-Aidroos'}, {'authorId': '2943407', 'name': 'Stephen M. Emrich'}]","646":"[{'authorId': '10661884', 'name': 'I. A. Sohu'}, {'authorId': '88726397', 'name': 'Asif Ahmed Rahimoon'}, {'authorId': '88727535', 'name': 'Amjad Ali Junejo'}, {'authorId': '88727694', 'name': 'Arsalan Ahmed Sohu'}, {'authorId': '66211755', 'name': 'Sadam Hussain Junejo'}]","647":"[{'authorId': '8278933', 'name': 'Christine Salahub'}, {'authorId': '6561324', 'name': 'Holly A. Lockhart'}, {'authorId': '31463299', 'name': 'Blaire Dube'}, {'authorId': '1398827516', 'name': 'Naseem Al-Aidroos'}, {'authorId': '2943407', 'name': 'Stephen M. Emrich'}]","648":"[{'authorId': '2157677056', 'name': 'Ryan Smith'}, {'authorId': '70438543', 'name': 'K. Friston'}, {'authorId': '2058398020', 'name': 'Christopher Whyte'}]","649":"[{'authorId': '2251210', 'name': 'K. Denecke'}, {'authorId': '89073076', 'name': 'Sayan Vaaheesan'}, {'authorId': '89810749', 'name': 'Aaganya Arulnathan'}]","650":"[{'authorId': '5865209', 'name': 'D. Do'}, {'authorId': '81417361', 'name': 'M. V. Nguyen'}, {'authorId': '144331984', 'name': 'Furqan Jameel'}, {'authorId': '1767008', 'name': 'R. J\u00e4ntti'}, {'authorId': '1781673', 'name': 'I. S. Ansari'}]","651":"[{'authorId': '2543534', 'name': 'Mark K. Ho'}, {'authorId': '152422014', 'name': 'David Abel'}, {'authorId': '153564781', 'name': 'Jonathan D. Cohen'}, {'authorId': '144885169', 'name': 'M. Littman'}, {'authorId': '1799860', 'name': 'T. Griffiths'}]","652":"[{'authorId': '8760717', 'name': 'S. Ladouce'}, {'authorId': '2828022', 'name': 'D. Donaldson'}, {'authorId': '143801375', 'name': 'P. Dudchenko'}, {'authorId': '6088500', 'name': 'M. Ietswaart'}]","653":"[{'authorId': '1430657367', 'name': 'Neda Afzaliseresht'}, {'authorId': '2086798954', 'name': 'Yuan Miao'}, {'authorId': None, 'name': 'Sandra Michalska'}, {'authorId': '2116620685', 'name': 'Qing Liu'}, {'authorId': '2135474577', 'name': 'Hua Wang'}]","654":"[{'authorId': '144652877', 'name': 'Liangtian Wan'}, {'authorId': '2110784587', 'name': 'Lu Sun'}, {'authorId': '2123270', 'name': 'Xiangjie Kong'}, {'authorId': '91152071', 'name': 'Yuyuan Yuan'}, {'authorId': '2113849716', 'name': 'Keyi Sun'}, {'authorId': '9704074', 'name': 'Feng Xia'}]","655":"[{'authorId': '118680136', 'name': 'Miguel Ramlatchan'}]","656":"[{'authorId': '1411385142', 'name': 'Ahmed Al-Tahmeesschi'}, {'authorId': '1397286739', 'name': 'Miguel L\u00f3pez-Ben\u00edtez'}, {'authorId': '144906937', 'name': 'Dhaval K. Patel'}, {'authorId': '145524513', 'name': 'Janne J. Lehtom\u00e4ki'}, {'authorId': '1758291', 'name': 'K. Umebayashi'}]","657":"[{'authorId': '67022972', 'name': 'Zhijin Qin'}, {'authorId': '35035273', 'name': 'Xiangwei Zhou'}, {'authorId': '2143834998', 'name': 'Lin Zhang'}, {'authorId': '2109218825', 'name': 'Yue Gao'}, {'authorId': '144791622', 'name': 'Ying-Chang Liang'}, {'authorId': '1410112765', 'name': 'Geoffrey Y. Li'}]","658":"[{'authorId': '7374360', 'name': 'Sebastian Musslick'}, {'authorId': '34927843', 'name': 'Andrew M. Saxe'}, {'authorId': '52222367', 'name': 'A. N. Hoskin'}, {'authorId': '7240083', 'name': 'Daniel Reichman'}, {'authorId': '153564781', 'name': 'Jonathan D. Cohen'}]","659":"[{'authorId': '2496636', 'name': 'A. Baddeley'}, {'authorId': '2615428', 'name': 'G. Hitch'}, {'authorId': '143913722', 'name': 'R. Allen'}]","660":"[{'authorId': '2055638228', 'name': 'A. Owens'}, {'authorId': '144956527', 'name': 'C. Ballard'}, {'authorId': '3475982', 'name': 'M. Beigi'}, {'authorId': '51114241', 'name': 'C. Kalafatis'}, {'authorId': '6295704', 'name': 'H. Brooker'}, {'authorId': '46998233', 'name': 'G. Lavelle'}, {'authorId': '13810069', 'name': 'K. Br\u00f8nnick'}, {'authorId': '145481689', 'name': 'J. Sauer'}, {'authorId': '50369072', 'name': 'S. Boddington'}, {'authorId': '48123860', 'name': 'Latha Velayudhan'}, {'authorId': '8558876', 'name': 'D. Aarsland'}]","661":"[{'authorId': '40384830', 'name': 'Spencer Frazier'}, {'authorId': '2757194', 'name': 'Mark O. Riedl'}]","662":"[{'authorId': '51922896', 'name': 'Giancarlo Kerg'}, {'authorId': '40974715', 'name': 'Bhargav Kanuparthi'}, {'authorId': '151354678', 'name': 'Anirudh Goyal'}, {'authorId': '51008424', 'name': 'Kyle Goyette'}, {'authorId': '1751762', 'name': 'Yoshua Bengio'}, {'authorId': '49921594', 'name': 'Guillaume Lajoie'}]","663":"[{'authorId': '98858396', 'name': 'T. Haid'}, {'authorId': '144305657', 'name': 'P. Federolf'}]","664":"[{'authorId': '34729699', 'name': 'F. Tang'}, {'authorId': '2118172888', 'name': 'Long Chen'}, {'authorId': '2116326736', 'name': 'Xu Li'}, {'authorId': '1690341', 'name': 'L. Yang'}, {'authorId': '1922573', 'name': 'Luoyi Fu'}]","665":"[{'authorId': '147478215', 'name': 'Mononito Goswami'}, {'authorId': '2115385407', 'name': 'Lujie Chen'}, {'authorId': '144292541', 'name': 'A. Dubrawski'}]","666":"[{'authorId': '8426739', 'name': 'Peyman Toreini'}, {'authorId': '47065438', 'name': 'Moritz Langner'}, {'authorId': '1806905', 'name': 'A. Maedche'}]","667":"[{'authorId': '2455758', 'name': 'V. R. Bejjanki'}, {'authorId': '3065843', 'name': 'R. Aslin'}]","668":"[{'authorId': '36604089', 'name': 'Justus Robertson'}, {'authorId': '145256430', 'name': 'A. Kokkinakis'}, {'authorId': '144778816', 'name': 'J. Hook'}, {'authorId': '38204674', 'name': 'B. Kirman'}, {'authorId': '144793645', 'name': 'Florian Block'}, {'authorId': '1733725', 'name': 'M. Ursu'}, {'authorId': '1752006159', 'name': 'Sagarika Patra'}, {'authorId': '8164959', 'name': 'Simon Demediuk'}, {'authorId': '3329979', 'name': 'Anders Drachen'}, {'authorId': '1752398910', 'name': 'Oluseyi Olarewaju'}]","669":"[{'authorId': '89510974', 'name': 'Patricia L\u00f3pez de Frutos'}, {'authorId': '2113499149', 'name': 'R. Rodr\u00edguez'}, {'authorId': '10711797', 'name': 'Danlin Zhang'}, {'authorId': '2111073167', 'name': 'Shutao Zheng'}, {'authorId': '2767133', 'name': 'J. Ca\u00f1as'}, {'authorId': '1419490231', 'name': 'Enrique Mu\u00f1oz-de-Escalona'}]","670":"[{'authorId': '29891208', 'name': 'Oscar J. Romero'}]","671":"[{'authorId': '2848211', 'name': 'A. S. Nobandegani'}, {'authorId': '35483804', 'name': 'Kevin da Silva Castanheira'}, {'authorId': '1692007159', 'name': \"Timothy O'Donnell\"}, {'authorId': '2852732', 'name': 'T. Shultz'}]","672":"[{'authorId': '1401845875', 'name': 'Rub\u00e9n Moreno-Bote'}, {'authorId': '2065502438', 'name': 'J. Ram\u00edrez-Ruiz'}, {'authorId': '2980740', 'name': 'Jan Drugowitsch'}, {'authorId': '4284038', 'name': 'B. Hayden'}]","673":"[{'authorId': '29891208', 'name': 'Oscar J. Romero'}]","674":"[{'authorId': '37973115', 'name': 'M. Gaafar'}, {'authorId': '2208688', 'name': 'M. Shaghaghi'}, {'authorId': '9346468', 'name': 'R. Adve'}, {'authorId': '144096418', 'name': 'Z. Ding'}]","675":"[{'authorId': '71951498', 'name': 'B. Wu'}, {'authorId': '7341262', 'name': 'Murat Cubuktepe'}, {'authorId': '22697629', 'name': 'Suda Bharadwaj'}, {'authorId': '3199888', 'name': 'U. Topcu'}]","676":"[{'authorId': '1571574252', 'name': 'Hemant Purohit'}, {'authorId': '2065333595', 'name': 'C. Castillo'}, {'authorId': '1571603655', 'name': 'Rahul Pandey'}]","677":"[{'authorId': '83988101', 'name': 'A. Joykutty'}, {'authorId': '41028251', 'name': 'B. Baranidharan'}]","678":"[{'authorId': '6846615', 'name': 'Hector Palada'}, {'authorId': '145567494', 'name': 'A. Neal'}, {'authorId': '11160676', 'name': 'D. Strayer'}, {'authorId': '39599711', 'name': 'T. Ballard'}, {'authorId': '3238523', 'name': 'A. Heathcote'}]","679":"[{'authorId': '2157677056', 'name': 'Ryan Smith'}, {'authorId': '2815441', 'name': 'P. Schwartenbeck'}, {'authorId': '47363526', 'name': 'Thomas Parr'}, {'authorId': '1737497', 'name': 'Karl J. Friston'}]","680":"[{'authorId': '2157677056', 'name': 'Ryan Smith'}, {'authorId': '2815441', 'name': 'P. Schwartenbeck'}, {'authorId': '47363526', 'name': 'Thomas Parr'}, {'authorId': '1737497', 'name': 'Karl J. Friston'}]","681":"[{'authorId': '123807764', 'name': 'Carlos Correa'}, {'authorId': '2543534', 'name': 'Mark K. Ho'}, {'authorId': '17026067', 'name': 'Frederick Callaway'}, {'authorId': '1799860', 'name': 'T. Griffiths'}]","682":"[{'authorId': '2044612', 'name': 'D. Jaiswal'}, {'authorId': '39831306', 'name': 'Arijit Chowdhury'}, {'authorId': '49686644', 'name': 'Tanushree Banerjee'}, {'authorId': '2658638', 'name': 'D. Chatterjee'}]","683":"[{'authorId': '144576599', 'name': 'M. Imani'}, {'authorId': '2082353756', 'name': 'Zhuowen Zou'}, {'authorId': '1471845793', 'name': 'Samuel Bosch'}, {'authorId': '2109494092', 'name': 'Sanjay Anantha Rao'}, {'authorId': '10763948', 'name': 'Sahand Salamat'}, {'authorId': '2112124352', 'name': 'Venkatesh Kumar'}, {'authorId': '2140071418', 'name': 'Yeseong Kim'}, {'authorId': '3560620', 'name': 'T. Simunic'}]","684":"[{'authorId': '2108860848', 'name': 'Xiaodi Liu'}, {'authorId': '8721011', 'name': 'Zengwen Wang'}, {'authorId': '1702317', 'name': 'Shitao Zhang'}, {'authorId': '2136179887', 'name': 'Jiashu Liu'}]","685":"[{'authorId': '108413994', 'name': 'Ma\u0142gorzata Wasilewska'}, {'authorId': '3000983', 'name': 'H. Bogucka'}]","686":"[{'authorId': '31727175', 'name': 'Alexander P. Christensen'}, {'authorId': '3000599', 'name': 'Yoed N. Kenett'}]","687":"[{'authorId': '1767495', 'name': 'K. Lloyd'}, {'authorId': '2353715', 'name': 'Adam N. Sanborn'}, {'authorId': '2061666358', 'name': 'David Leslie'}, {'authorId': '2573193', 'name': 'S. Lewandowsky'}]","688":"[{'authorId': '122990697', 'name': 'Ashish Sharma'}, {'authorId': '143990839', 'name': 'M. Choudhury'}, {'authorId': '1745524', 'name': 'Tim Althoff'}, {'authorId': '144676398', 'name': 'Amit Sharma'}]","689":"[{'authorId': '2051228927', 'name': 'Avani Agarwal'}, {'authorId': '2022422378', 'name': 'Sahil Sharma'}, {'authorId': '2116341413', 'name': 'Vijay Kumar'}, {'authorId': '49650872', 'name': 'M. Kaur'}]","690":"[{'authorId': '2285483', 'name': 'Yaguang Lin'}, {'authorId': '47119330', 'name': 'Xiaoming Wang'}, {'authorId': '2105562387', 'name': 'Fei Hao'}, {'authorId': '34681128', 'name': 'Yichuan Jiang'}, {'authorId': '2947357', 'name': 'Yulei Wu'}, {'authorId': '145896559', 'name': 'G. Min'}, {'authorId': '1776387', 'name': 'Daojing He'}, {'authorId': '1712616', 'name': 'Sencun Zhu'}, {'authorId': '144876292', 'name': 'Wei Zhao'}]","691":"[{'authorId': '1573897866', 'name': 'Lada Kohoutov\u00e1'}, {'authorId': '2053276921', 'name': 'Juyeon Heo'}, {'authorId': '34352481', 'name': 'Sungmin Cha'}, {'authorId': '2108097854', 'name': 'Sungwoo Lee'}, {'authorId': '4842965', 'name': 'Taesup Moon'}, {'authorId': '2549424', 'name': 'T. Wager'}, {'authorId': '38550277', 'name': 'Choong-Wan Woo'}]","692":"[{'authorId': '2152209789', 'name': 'Ping Wang'}, {'authorId': '3439372', 'name': 'Luobing Dong'}, {'authorId': '2227410', 'name': 'Yueshen Xu'}, {'authorId': '2157221967', 'name': 'Wei Liu'}, {'authorId': '2066999422', 'name': 'Ningning Jing'}]","693":"[{'authorId': '37125611', 'name': 'M. McCaul'}, {'authorId': '8647509', 'name': 'D. Ernstzen'}, {'authorId': '5349961', 'name': 'H. Temmingh'}, {'authorId': '6709377', 'name': 'B. Draper'}, {'authorId': '50430046', 'name': 'M. Galloway'}, {'authorId': '5468487', 'name': 'T. Kredo'}]","694":"[{'authorId': '100621949', 'name': 'Daniel Pimentel'}, {'authorId': '69576531', 'name': 'Maxwell Foxman'}, {'authorId': '100979536', 'name': 'Donna Z. Davis'}, {'authorId': '145013056', 'name': 'David M. Markowitz'}]","695":"[{'authorId': '153399276', 'name': 'J. A. Garc\u00eda'}, {'authorId': '1398595158', 'name': 'R. Rodr\u00edguez-S\u00e1nchez'}, {'authorId': '1405387187', 'name': 'J. Fdez-Valdivia'}]","696":"[{'authorId': '123437034', 'name': 'Tianyi Zhang'}, {'authorId': '24277779', 'name': 'Felix Wu'}, {'authorId': '2199597', 'name': 'Arzoo Katiyar'}, {'authorId': '7446832', 'name': 'Kilian Q. Weinberger'}, {'authorId': '3167681', 'name': 'Yoav Artzi'}]","697":"[{'authorId': '2115650487', 'name': 'D. Y. Lee'}, {'authorId': '4337713', 'name': 'Jeffrey R. Harring'}, {'authorId': '49754622', 'name': 'L. Stapleton'}]","698":"[{'authorId': '1825773', 'name': 'Terrence D. Hill'}, {'authorId': '48424395', 'name': 'A. Davis'}, {'authorId': '8961931', 'name': 'J. M. Roos'}, {'authorId': '2243079', 'name': 'M. French'}]","699":"[{'authorId': '46854801', 'name': 'S. Pohl'}, {'authorId': '2064484279', 'name': 'Benjamin Becker'}]","700":"[{'authorId': '1405234144', 'name': '\u00c1. Fern\u00e1ndez-Carrillo'}, {'authorId': '41031375', 'name': 'Zdenek Patocka'}, {'authorId': '86955803', 'name': 'L. Dobrovoln\u00fd'}, {'authorId': '1409223225', 'name': 'A. Franco-Nieto'}, {'authorId': '1398935172', 'name': 'B. Revilla-Romero'}]","701":"[{'authorId': '48908513', 'name': 'M. G\u00f6tz'}, {'authorId': '1397951928', 'name': 'Klaus Maier-Hein'}]","702":"[{'authorId': '35588059', 'name': 'Sahith N. Dambekodi'}, {'authorId': '40384830', 'name': 'Spencer Frazier'}, {'authorId': '19179135', 'name': 'Prithviraj Ammanabrolu'}, {'authorId': '2757194', 'name': 'Mark O. Riedl'}]","703":"[{'authorId': '49955418', 'name': 'D. Elms'}]","704":"[{'authorId': '10803637', 'name': 'Martin Krucek'}, {'authorId': '27559167', 'name': 'Kamil Kr\u00e1l'}, {'authorId': '47171797', 'name': 'K. Cushman'}, {'authorId': '1996145748', 'name': 'Azim Missarov'}, {'authorId': '34835691', 'name': 'J. Kellner'}]","705":"[{'authorId': '48974005', 'name': 'E. Graf'}, {'authorId': '1868362', 'name': 'A. Theakston'}, {'authorId': '2707563', 'name': 'D. Freudenthal'}, {'authorId': '144155750', 'name': 'E. Lieven'}]","706":"[{'authorId': '120133626', 'name': 'Laura Blattner'}, {'authorId': '35576802', 'name': 'Scott Nelson'}, {'authorId': '47281276', 'name': 'Jann Spiess'}]","707":"[{'authorId': '2503523', 'name': 'Shangtong Zhang'}, {'authorId': '144100820', 'name': 'R. Laroche'}, {'authorId': '1748153', 'name': 'H. V. Seijen'}, {'authorId': '1766767', 'name': 'S. Whiteson'}, {'authorId': '15032777', 'name': 'R\u00e9mi Tachet des Combes'}]","708":"[{'authorId': '1781190265', 'name': 'Sara Javadi'}, {'authorId': '1879019', 'name': 'A. Bahrampour'}, {'authorId': '144765919', 'name': 'M. M. Saber'}, {'authorId': '4332123', 'name': 'B. Garrusi'}, {'authorId': '7666356', 'name': 'M. Baneshi'}]","709":"[{'authorId': '2061356847', 'name': 'Ming Qian'}, {'authorId': '2108346218', 'name': 'Jessie Liu'}, {'authorId': '2150357925', 'name': 'Chaofeng Li'}, {'authorId': '1396364242', 'name': 'Liming Pals'}]","710":"[{'authorId': '1795953', 'name': 'M. Cummings'}, {'authorId': '2819753', 'name': 'Songpo Li'}]","711":"[{'authorId': '2110350428', 'name': 'Panpan Zhang'}, {'authorId': '3061296', 'name': 'L. Bao'}, {'authorId': '46296931', 'name': 'Dongmei Guo'}, {'authorId': '47767739', 'name': 'Lin Wu'}, {'authorId': '2108274473', 'name': 'Qianqian Li'}, {'authorId': '49957841', 'name': 'Hui Liu'}, {'authorId': '47752023', 'name': 'Zhixin Xue'}, {'authorId': '2109660887', 'name': 'Zhicai Li'}]","712":"[{'authorId': '2060487732', 'name': 'Robert E Kelly'}, {'authorId': '2766223', 'name': 'M. Hoptman'}, {'authorId': '2444847', 'name': 'G. Alexopoulos'}, {'authorId': '3568698', 'name': 'F. Gunning'}, {'authorId': '1711848', 'name': 'M. McKeown'}]","713":"[{'authorId': '72538102', 'name': 'Max J. Pachali'}, {'authorId': '40116223', 'name': 'P. Kurz'}, {'authorId': '1811532', 'name': 'Thomas Otter'}]","714":"[{'authorId': '2125141539', 'name': 'M. Jo'}, {'authorId': '3135325', 'name': 'B. Osmanoglu'}]","715":"[{'authorId': '2606408', 'name': 'Douglas Zytko'}, {'authorId': '108557591', 'name': 'Leanne DeVreugd'}]","716":"[{'authorId': '46854801', 'name': 'S. Pohl'}, {'authorId': '2064484279', 'name': 'Benjamin Becker'}]","717":"[{'authorId': '153936479', 'name': 'Esther van den Berg'}, {'authorId': '1686341', 'name': 'K. Markert'}]","718":"[{'authorId': '33524946', 'name': 'Jieyu Zhao'}, {'authorId': '1785372925', 'name': 'Tianlu Wang'}, {'authorId': '2064210', 'name': 'Mark Yatskar'}, {'authorId': '1750769', 'name': 'Ryan Cotterell'}, {'authorId': '2004053', 'name': 'Vicente Ordonez'}, {'authorId': '2782886', 'name': 'Kai-Wei Chang'}]","719":"[{'authorId': '143902495', 'name': 'M. Tschannen'}, {'authorId': '2941141', 'name': 'Josip Djolonga'}, {'authorId': '48159426', 'name': 'Paul K. Rubenstein'}, {'authorId': '1802148', 'name': 'S. Gelly'}, {'authorId': '34302129', 'name': 'Mario Lucic'}]","720":"[{'authorId': '51453887', 'name': 'Jiaming Song'}, {'authorId': '2490652', 'name': 'S. Ermon'}]","721":"[{'authorId': '16443937', 'name': 'Ben Poole'}, {'authorId': '1955694', 'name': 'Sherjil Ozair'}, {'authorId': '3422336', 'name': 'A\u00e4ron van den Oord'}, {'authorId': '122113652', 'name': 'Alexander A. Alemi'}, {'authorId': '145499435', 'name': 'G. Tucker'}]","722":"[{'authorId': '1821892', 'name': 'Hila Gonen'}, {'authorId': '2089067', 'name': 'Yoav Goldberg'}]","723":"[{'authorId': '48620767', 'name': 'R. Hughes'}, {'authorId': '47951202', 'name': 'J. Heron'}, {'authorId': '145481919', 'name': 'J. Sterne'}, {'authorId': '2098167816', 'name': 'K. Tilling'}]","724":"[{'authorId': '7535126', 'name': 'R\u00e9mi Cad\u00e8ne'}, {'authorId': '41020827', 'name': 'Corentin Dancette'}, {'authorId': '1405301761', 'name': 'H. Ben-younes'}, {'authorId': '51021910', 'name': 'M. Cord'}, {'authorId': '153432684', 'name': 'Devi Parikh'}]","725":"[{'authorId': '2056908', 'name': 'Jesse Vig'}, {'authorId': '3159346', 'name': 'Sebastian Gehrmann'}, {'authorId': '2083259', 'name': 'Y. Belinkov'}, {'authorId': '30413267', 'name': 'Sharon Qian'}, {'authorId': '32609652', 'name': 'D. Nevo'}, {'authorId': '1778763', 'name': 'Yaron Singer'}, {'authorId': '1692491', 'name': 'S. Shieber'}]","726":"[{'authorId': '11254155', 'name': 'Cynthia L. Foronda'}, {'authorId': '1423316039', 'name': 'Margo Fernandez-Burgos'}, {'authorId': '1557723114', 'name': 'Catherine Nadeau'}, {'authorId': '1491584569', 'name': 'Courtney N Kelley'}, {'authorId': '87662791', 'name': 'Myrthle N Henry'}]","727":"[{'authorId': '2029237287', 'name': 'Priyanka Nanayakkara'}, {'authorId': '3159918', 'name': 'J. Hullman'}, {'authorId': '2943892', 'name': 'N. Diakopoulos'}]","728":"[{'authorId': '3422038', 'name': 'Su Lin Blodgett'}, {'authorId': '2881033', 'name': 'Solon Barocas'}, {'authorId': '2065041692', 'name': \"Hal Daum'e\"}, {'authorId': '1831395', 'name': 'H. Wallach'}]","729":"[{'authorId': '1845794923', 'name': 'Timo Spinde'}, {'authorId': '2068169039', 'name': 'L. Rudnitckaia'}, {'authorId': '2070406913', 'name': 'K. Sinha'}, {'authorId': '145151838', 'name': 'Bela Gipp'}, {'authorId': '1845794923', 'name': 'Timo Spinde'}, {'authorId': '2068169039', 'name': 'L. Rudnitckaia'}, {'authorId': '2070406913', 'name': 'K. Sinha'}, {'authorId': '3461253', 'name': 'Felix Hamborg'}, {'authorId': '145151838', 'name': 'Bela Gipp'}, {'authorId': '2488381', 'name': 'K. Donnay'}]","730":"[{'authorId': '72793550', 'name': 'P. Terhorst'}, {'authorId': '1491747775', 'name': 'J. Kolf'}, {'authorId': '1516862195', 'name': 'Marco Huber'}, {'authorId': '2178720', 'name': 'Florian Kirchbuchner'}, {'authorId': '2265721', 'name': 'N. Damer'}, {'authorId': '144083995', 'name': 'A. Morales'}, {'authorId': '1701431', 'name': 'Julian Fierrez'}, {'authorId': '145307900', 'name': 'Arjan Kuijper'}]","731":"[{'authorId': '3035222', 'name': 'Walid Krichene'}, {'authorId': '2843982', 'name': 'Steffen Rendle'}]","732":"[{'authorId': '1700031', 'name': 'Adnan Darwiche'}, {'authorId': '1500720692', 'name': 'Auguste Hirth'}]","733":"[{'authorId': '3445334', 'name': 'Kevin Roitero'}, {'authorId': '51006308', 'name': 'Michael Soprano'}, {'authorId': '1696683650', 'name': 'Shaoyang Fan'}, {'authorId': '1630446247', 'name': 'Damiano Spina'}, {'authorId': '1726978', 'name': 'S. Mizzaro'}, {'authorId': '1694274', 'name': 'Gianluca Demartini'}]","734":"[{'authorId': '46185703', 'name': 'Erenay Dayanik'}, {'authorId': '1708581', 'name': 'Sebastian Pad\u00f3'}]","735":"[{'authorId': '46537606', 'name': 'Harini Suresh'}, {'authorId': '1724429', 'name': 'J. Guttag'}]","736":"[{'authorId': '2109929634', 'name': 'Hui Jin'}, {'authorId': '1784667', 'name': 'Guido Mont\u00fafar'}]","737":"[{'authorId': '2134880', 'name': 'R. Auksztulewicz'}, {'authorId': '145590468', 'name': 'N. Myers'}, {'authorId': '51215972', 'name': 'J. Schnupp'}, {'authorId': '1692729', 'name': 'A. Nobre'}]","738":"[{'authorId': '2108919537', 'name': 'Wei-Fan Chen'}, {'authorId': '2248209', 'name': 'Khalid Al Khatib'}, {'authorId': '1405867539', 'name': 'Benno Stein'}, {'authorId': '2626599', 'name': 'Henning Wachsmuth'}]","739":"[{'authorId': '145263196', 'name': 'Y. Ho'}]","740":"[{'authorId': '51511926', 'name': 'Navoneel Chakrabarty'}, {'authorId': '2150473007', 'name': 'Sanket Biswas'}]","741":"[{'authorId': '4453862', 'name': 'C. Arg\u00fcelles'}, {'authorId': '93037920', 'name': 'A. Schneider'}, {'authorId': '145373873', 'name': 'T. Yuan'}]","742":"[{'authorId': '23923796', 'name': 'Emily Sheng'}, {'authorId': '2054031596', 'name': 'Josh Arnold'}, {'authorId': '1564034697', 'name': 'Zhou Yu'}, {'authorId': '2782886', 'name': 'Kai-Wei Chang'}, {'authorId': '3157053', 'name': 'Nanyun Peng'}]","743":"[{'authorId': '35268756', 'name': 'Stefania Bracci'}, {'authorId': '144219339', 'name': 'J. Ritchie'}, {'authorId': '6631331', 'name': 'Ioannis Kalfas'}, {'authorId': '1766192', 'name': 'H. P. Op de Beeck'}]","744":"[{'authorId': '91112285', 'name': 'Sabine Wehnert'}, {'authorId': '34430751', 'name': 'Sayed Anisul Hoque'}, {'authorId': '2652957', 'name': 'W. Fenske'}, {'authorId': '1746173', 'name': 'G. Saake'}]","745":"[{'authorId': '5945772', 'name': 'Nikolaos Ignatiadis'}, {'authorId': '3160667', 'name': 'Stefan Wager'}]","746":"[{'authorId': '1557324013', 'name': 'Pei Zhou'}, {'authorId': '1885282', 'name': 'Rahul Khanna'}, {'authorId': '51583409', 'name': 'Bill Yuchen Lin'}, {'authorId': '2056458351', 'name': 'Daniel Ho'}, {'authorId': '2634786', 'name': 'J. Pujara'}, {'authorId': '1384550891', 'name': 'Xiang Ren'}]","747":"[{'authorId': '145769448', 'name': 'Liang Wang'}, {'authorId': '2108379899', 'name': 'Jinlong Liu'}, {'authorId': '49721664', 'name': 'Jingming Liu'}]","748":"[{'authorId': '2076432154', 'name': 'Neelakshi Sarma'}, {'authorId': '2125278877', 'name': 'Ranbir Sanasam Singh'}, {'authorId': '145550931', 'name': 'D. Goswami'}]","749":"[{'authorId': '1596865887', 'name': 'Gun Hee Cho'}, {'authorId': '2154073365', 'name': 'Y. Choi'}]","750":"[{'authorId': '2992999', 'name': 'Ananya'}, {'authorId': '134526250', 'name': 'N. Parthasarthi'}, {'authorId': '34650964', 'name': 'Sameer Singh'}]","751":"[{'authorId': '2108841625', 'name': 'Yiwei Wang'}, {'authorId': '1998918', 'name': 'Muhao Chen'}, {'authorId': '2203076', 'name': 'Wenxuan Zhou'}, {'authorId': '1928716951', 'name': 'Yujun Cai'}, {'authorId': '3431194', 'name': 'Yuxuan Liang'}, {'authorId': '2004587660', 'name': 'Dayiheng Liu'}, {'authorId': '21299583', 'name': 'Baosong Yang'}, {'authorId': '2108378854', 'name': 'Juncheng Liu'}, {'authorId': '2019961', 'name': 'Bryan Hooi'}]","752":"[{'authorId': '2119028179', 'name': 'Shanshan Li'}, {'authorId': '30715522', 'name': 'Canhua Qiu'}, {'authorId': '2152156571', 'name': 'Mingming Jiang'}]","753":"[{'authorId': '1406062858', 'name': 'Shang Gao'}, {'authorId': '2091889530', 'name': 'M. Alawad'}, {'authorId': '103259720', 'name': 'Noah Schaefferkoetter'}, {'authorId': '144203902', 'name': 'Lynne Penberthy'}, {'authorId': '2154602619', 'name': 'Xiao-Cheng Wu'}, {'authorId': '3742715', 'name': 'E. Durbin'}, {'authorId': '9587918', 'name': 'Linda Coyle'}, {'authorId': '46431693', 'name': 'A. Ramanathan'}, {'authorId': '1783513', 'name': 'G. Tourassi'}]","754":"[{'authorId': '88739501', 'name': 'Shikha Bordia'}, {'authorId': '3644767', 'name': 'Samuel R. Bowman'}]","755":"[{'authorId': '134894281', 'name': 'Yusu Qian'}, {'authorId': '3375824', 'name': 'Urwa Muaz'}, {'authorId': '2117774606', 'name': 'Ben Zhang'}, {'authorId': '2058870034', 'name': 'J. Hyun'}]","756":"[{'authorId': '49713890', 'name': 'Anjalie Field'}, {'authorId': '145317727', 'name': 'Yulia Tsvetkov'}]","757":"[{'authorId': '3422912', 'name': 'Zihang Dai'}, {'authorId': '2109512754', 'name': 'Zhilin Yang'}, {'authorId': '35729970', 'name': 'Yiming Yang'}, {'authorId': '143712374', 'name': 'J. Carbonell'}, {'authorId': '2827616', 'name': 'Quoc V. Le'}, {'authorId': '145124475', 'name': 'R. Salakhutdinov'}]","758":"[{'authorId': '47120498', 'name': 'Xinyu Wang'}, {'authorId': '2118476056', 'name': 'Yong Jiang'}, {'authorId': '144756231', 'name': 'Nguyen Bach'}, {'authorId': '143988955', 'name': 'Tao Wang'}, {'authorId': '2109670639', 'name': 'Zhongqiang Huang'}, {'authorId': '143857288', 'name': 'Fei Huang'}, {'authorId': '40341553', 'name': 'Kewei Tu'}]","759":"[{'authorId': '2170235', 'name': 'Filipo Sharevski'}, {'authorId': '34113448', 'name': 'Amy Devine'}, {'authorId': '2031906180', 'name': 'Emma Pieroni'}, {'authorId': '1388057930', 'name': 'Peter Jachim'}]","760":"[{'authorId': '3768491', 'name': 'G. Fosgate'}]","761":"[{'authorId': '87465347', 'name': 'Lalitha Kameswari'}, {'authorId': '2082277520', 'name': 'Dama Sravani'}, {'authorId': '1829635', 'name': 'R. Mamidi'}]","762":"[{'authorId': '144142360', 'name': 'Rui Zhang'}, {'authorId': '48881008', 'name': 'Tao Yu'}, {'authorId': '100520099', 'name': 'H. Er'}, {'authorId': '134758914', 'name': 'Sungrok Shim'}, {'authorId': '153858201', 'name': 'Eric Xue'}, {'authorId': '143724481', 'name': 'Xi Victoria Lin'}, {'authorId': '2929835', 'name': 'Tianze Shi'}, {'authorId': '2228109', 'name': 'Caiming Xiong'}, {'authorId': '2166511', 'name': 'R. Socher'}, {'authorId': '9215251', 'name': 'Dragomir R. Radev'}]","763":"[{'authorId': '35570245', 'name': 'Ali Furkan Biten'}, {'authorId': '51231577', 'name': 'Llu\u00eds G\u00f3mez'}, {'authorId': '143823474', 'name': 'Mar\u00e7al Rusi\u00f1ol'}, {'authorId': '1694974', 'name': 'Dimosthenis Karatzas'}]","764":"[{'authorId': '25598028', 'name': 'Courtney Mansfield'}, {'authorId': '145739668', 'name': 'Ming Sun'}, {'authorId': '152669131', 'name': 'Ming Sun'}, {'authorId': '2108218661', 'name': 'Yuzong Liu'}, {'authorId': '36881920', 'name': 'Ankur Gandhe'}, {'authorId': '145878402', 'name': 'Bj\u00f6rn Hoffmeister'}]","765":"[{'authorId': '1515856441', 'name': 'M.A. Dibitso'}, {'authorId': '21504196', 'name': 'P. Owolawi'}, {'authorId': '2066076645', 'name': 'S. Ojo'}]","766":"[{'authorId': '3102551', 'name': 'Carmen De Maio'}, {'authorId': '2721973', 'name': 'G. Fenza'}, {'authorId': '18755547', 'name': 'Mariacristina Gallo'}, {'authorId': '1689838', 'name': 'V. Loia'}, {'authorId': '1768764330', 'name': 'Alberto Volpe'}]","767":"[{'authorId': '2149236756', 'name': 'Zhen Xu'}, {'authorId': '2486992', 'name': 'Albert D. Ritzhaupt'}, {'authorId': '11908148', 'name': 'Feng-shou Tian'}, {'authorId': '3220155', 'name': 'K. Umapathy'}]","768":"[{'authorId': '3475586', 'name': 'J. Dhamala'}, {'authorId': '1516120843', 'name': 'Tony Sun'}, {'authorId': '40574366', 'name': 'Varun Kumar'}, {'authorId': '1387484410', 'name': 'Satyapriya Krishna'}, {'authorId': '100984698', 'name': 'Yada Pruksachatkun'}, {'authorId': '2782886', 'name': 'Kai-Wei Chang'}, {'authorId': '2139538015', 'name': 'Rahul Gupta'}]","769":"[{'authorId': '2067975964', 'name': 'Pedro L. Rodriguez'}, {'authorId': '22267378', 'name': 'A. Spirling'}]","770":"[{'authorId': '144447820', 'name': 'Yi Tay'}, {'authorId': '2057663102', 'name': 'V. Tran'}, {'authorId': '2884561', 'name': 'Sebastian Ruder'}, {'authorId': '143702064', 'name': 'Jai Gupta'}, {'authorId': '3351938', 'name': 'Hyung Won Chung'}, {'authorId': '11774695', 'name': 'Dara Bahri'}, {'authorId': '145144957', 'name': 'Zhen Qin'}, {'authorId': '2054255425', 'name': 'Simon Baumgartner'}, {'authorId': '82737548', 'name': 'Cong Yu'}, {'authorId': '47193990', 'name': 'Donald Metzler'}]","771":"[{'authorId': '31099365', 'name': 'Aparna Garimella'}, {'authorId': '2121347719', 'name': 'Akhash Amarnath'}, {'authorId': '2110632520', 'name': 'K. Kumar'}, {'authorId': '2121368400', 'name': 'Akash Pramod Yalla'}, {'authorId': '3365985', 'name': 'Anandhavelu Natarajan'}, {'authorId': '2954043', 'name': 'Niyati Chhaya'}, {'authorId': '2881425', 'name': 'Balaji Vasan Srinivasan'}]","772":"[{'authorId': '31728436', 'name': 'Niklas Rach'}, {'authorId': '1752551237', 'name': 'Klaus Weber'}, {'authorId': '2108802126', 'name': 'Yuchi Yang'}, {'authorId': '2295429', 'name': 'Stefan Ultes'}, {'authorId': '1742930', 'name': 'E. Andr\u00e9'}, {'authorId': '1720942', 'name': 'W. Minker'}]","773":"[{'authorId': '144877076', 'name': 'J. Xie'}, {'authorId': '138700031', 'name': 'Renato Ferreira Pinto Junior'}, {'authorId': '145036961', 'name': 'Graeme Hirst'}, {'authorId': '1698958205', 'name': 'Yang Xu'}]","774":"[{'authorId': '2064873282', 'name': \"Filip Grali'nski\"}, {'authorId': '1822665', 'name': 'Tomasz Stanislawek'}, {'authorId': '2065175441', 'name': \"Anna Wr'oblewska\"}, {'authorId': '2055968344', 'name': \"Dawid Lipi'nski\"}, {'authorId': '2064187520', 'name': 'Agnieszka Kaliska'}, {'authorId': '2066303178', 'name': 'Paulina Rosalska'}, {'authorId': '11016367', 'name': 'Bartosz Topolski'}, {'authorId': '144356944', 'name': 'P. Biecek'}]","775":"[{'authorId': '143621743', 'name': 'Jianfei Yu'}, {'authorId': '144924128', 'name': 'Jing Jiang'}, {'authorId': None, 'name': 'Li Yang'}, {'authorId': '1491639587', 'name': 'Rui Xia'}]","776":"[{'authorId': '28735341', 'name': 'W. Guo'}, {'authorId': '144537437', 'name': 'Aylin Caliskan'}]","777":"[{'authorId': '2108335211', 'name': 'Ye Liu'}, {'authorId': '20851195', 'name': 'Kazuma Hashimoto'}, {'authorId': '2118860628', 'name': 'Yingbo Zhou'}, {'authorId': '3014143', 'name': 'Semih Yavuz'}, {'authorId': '2054594326', 'name': 'Caiming Xiong'}, {'authorId': '152297693', 'name': 'Philip S. Yu'}]","778":"[{'authorId': '2116490937', 'name': 'Fangsheng Wu'}, {'authorId': '3432460', 'name': 'Mengnan Du'}, {'authorId': '1490931604', 'name': 'Chao Fan'}, {'authorId': '2057059798', 'name': 'Ruixiang Tang'}, {'authorId': '2152917003', 'name': 'Yang Yang'}, {'authorId': '48813438', 'name': 'A. Mostafavi'}, {'authorId': '2123553641', 'name': 'Xia Hu'}]","779":"[{'authorId': '98868399', 'name': 'Chandler May'}, {'authorId': '144906624', 'name': 'Alex Wang'}, {'authorId': '88739501', 'name': 'Shikha Bordia'}, {'authorId': '3644767', 'name': 'Samuel R. Bowman'}, {'authorId': '2034613', 'name': 'Rachel Rudinger'}]","780":"[{'authorId': '2403712', 'name': 'A. Akbik'}, {'authorId': '2077245166', 'name': 'Tanja Bergmann'}, {'authorId': '2742129', 'name': 'Roland Vollgraf'}]","781":"[{'authorId': '143655216', 'name': 'Masahiro Kaneko'}, {'authorId': '2075356592', 'name': 'D. Bollegala'}]","782":"[{'authorId': '6583232', 'name': 'Angana Chakraborty'}, {'authorId': '1735074', 'name': 'B. Morgenstern'}, {'authorId': '82752795', 'name': 'S. Bandyopadhyay'}]","783":"[{'authorId': '144787248', 'name': 'Y. Tan'}, {'authorId': '144776615', 'name': 'L. E. Celis'}]","784":"[{'authorId': '2108769177', 'name': 'Hainan Zhang'}, {'authorId': '37510256', 'name': 'Yanyan Lan'}, {'authorId': '48537499', 'name': 'Liang Pang'}, {'authorId': '1777025', 'name': 'J. Guo'}, {'authorId': '1717004', 'name': 'Xueqi Cheng'}]","785":"[{'authorId': '26755024', 'name': 'Sara Giuliani'}, {'authorId': '150114725', 'name': 'Giuseppe Romana'}, {'authorId': '1382587433', 'name': 'Massimiliano Rossi'}]","786":"[{'authorId': '2854297', 'name': 'Xingdi Yuan'}, {'authorId': '49252800', 'name': 'Jie Fu'}, {'authorId': '40638665', 'name': 'Marc-Alexandre C\u00f4t\u00e9'}, {'authorId': '144447820', 'name': 'Yi Tay'}, {'authorId': '1972076', 'name': 'C. Pal'}, {'authorId': '3382568', 'name': 'Adam Trischler'}]","787":"[{'authorId': '144101734', 'name': 'Xuhui Zhou'}, {'authorId': '1591125925', 'name': 'Yue Zhang'}, {'authorId': '152496687', 'name': 'Leyang Cui'}, {'authorId': '2110409012', 'name': 'Dandan Huang'}]","788":"[{'authorId': '47043446', 'name': 'A. Bruguier'}, {'authorId': '2557391', 'name': 'Rohit Prabhavalkar'}, {'authorId': '2779415', 'name': 'G. Pundak'}, {'authorId': '1784851', 'name': 'T. Sainath'}]","789":"[{'authorId': '23923796', 'name': 'Emily Sheng'}, {'authorId': '2782886', 'name': 'Kai-Wei Chang'}, {'authorId': '145603129', 'name': 'P. Natarajan'}, {'authorId': '3157053', 'name': 'Nanyun Peng'}]","790":"[{'authorId': '40896023', 'name': 'P. Schramowski'}, {'authorId': '13671251', 'name': 'Cigdem Turan'}, {'authorId': '151209594', 'name': 'Sophie F. Jentzsch'}, {'authorId': '3249046', 'name': 'C. Rothkopf'}, {'authorId': '1746871', 'name': 'K. Kersting'}]","791":"[{'authorId': '152973423', 'name': 'S. Khan'}, {'authorId': '40894826', 'name': 'Muzammal Naseer'}, {'authorId': '145684318', 'name': 'Munawar Hayat'}, {'authorId': '3323621', 'name': 'Syed Waqas Zamir'}, {'authorId': '2358803', 'name': 'F. Khan'}, {'authorId': '145103012', 'name': 'M. Shah'}]","792":"[{'authorId': '1557300901', 'name': 'Mingshuang Luo'}, {'authorId': '2132170578', 'name': 'Shuang Yang'}, {'authorId': '145455919', 'name': 'S. Shan'}, {'authorId': '46772547', 'name': 'Xilin Chen'}]","793":"[{'authorId': '1745337', 'name': 'Lora Aroyo'}, {'authorId': '2065639113', 'name': 'Lucas Dixon'}, {'authorId': '2665391', 'name': 'Nithum Thain'}, {'authorId': '90784578', 'name': 'Olivia Redfield'}, {'authorId': '38326911', 'name': 'R. Rosen'}]","794":"[{'authorId': '24025563', 'name': 'Vikas Raunak'}, {'authorId': '35186886', 'name': 'Siddharth Dalmia'}, {'authorId': '46346053', 'name': 'Vivek Gupta'}, {'authorId': '1740721', 'name': 'Florian Metze'}]","795":"[{'authorId': '49917731', 'name': 'F. K\u00fcnzler'}, {'authorId': '2432048', 'name': 'Varun Mishra'}, {'authorId': '31052098', 'name': 'Jan-Niklas Kramer'}, {'authorId': '143980068', 'name': 'D. Kotz'}, {'authorId': '2801545', 'name': 'E. Fleisch'}, {'authorId': '1793743', 'name': 'T. Kowatsch'}]","796":"[{'authorId': '3460960', 'name': 'Yassien Shaalan'}, {'authorId': '1821099', 'name': 'Xiuzhen Zhang'}, {'authorId': '123784590', 'name': 'Jeffrey Chan'}, {'authorId': '39044014', 'name': 'Mahsa Salehi'}]","797":"[{'authorId': '40896023', 'name': 'P. Schramowski'}, {'authorId': '13671251', 'name': 'Cigdem Turan'}, {'authorId': '2026607179', 'name': 'Nico Andersen'}, {'authorId': '3249046', 'name': 'C. Rothkopf'}, {'authorId': '2066493115', 'name': 'K. Kersting'}]","798":"[{'authorId': '1776627', 'name': 'L. Burnard'}]","799":"[{'authorId': '145748852', 'name': 'S. Veer'}, {'authorId': '3832823', 'name': 'L. Riste'}, {'authorId': '1399312935', 'name': 'S. Cheraghi-Sohi'}, {'authorId': '2444164', 'name': 'D. Phipps'}, {'authorId': '10312102', 'name': 'M. Tully'}, {'authorId': '40832643', 'name': 'Kyle Bozentko'}, {'authorId': '2122343327', 'name': 'Sarah Atwood'}, {'authorId': '2122341481', 'name': 'Alex Hubbard'}, {'authorId': '2122341374', 'name': 'Carl Wiper'}, {'authorId': '5300031', 'name': 'M. Oswald'}, {'authorId': '1718890', 'name': 'N. Peek'}]","800":"[{'authorId': '51444591', 'name': 'Yuwei Fang'}, {'authorId': '2419809', 'name': 'S. Sun'}, {'authorId': '144702900', 'name': 'Zhe Gan'}, {'authorId': '2128387353', 'name': 'R. Pillai'}, {'authorId': '2992833', 'name': 'Shuohang Wang'}, {'authorId': '46700348', 'name': 'Jingjing Liu'}]","801":"[{'authorId': '2545335', 'name': 'Rowan Zellers'}, {'authorId': '14487640', 'name': 'Ari Holtzman'}, {'authorId': '2516777', 'name': 'Hannah Rashkin'}, {'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '143787583', 'name': 'Ali Farhadi'}, {'authorId': '3268360', 'name': 'Franziska Roesner'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]","802":"[{'authorId': '51065712', 'name': 'Martina Scholger'}]","803":"[{'authorId': '1710392', 'name': 'A. Johri'}]","804":"[{'authorId': '2117787471', 'name': 'Yanping Fu'}, {'authorId': '2118113473', 'name': 'Yun Liu'}, {'authorId': '2880050', 'name': 'Sheng-Lung Peng'}]","805":"[{'authorId': '16936789', 'name': 'Mun Kit Ho'}, {'authorId': '2411859', 'name': 'S. Tatinati'}, {'authorId': '1807572', 'name': 'Andy W. H. Khong'}]","806":"[{'authorId': '143623207', 'name': 'Tiago Santos'}, {'authorId': '2101037', 'name': 'F. Lemmerich'}, {'authorId': '1743043', 'name': 'M. Strohmaier'}, {'authorId': '1747800', 'name': 'D. Helic'}]","807":"[{'authorId': '1403082631', 'name': 'J. G\u00f3mez-P\u00e9rez'}, {'authorId': '2213589', 'name': 'R. Denaux'}, {'authorId': '1401950156', 'name': 'Andres Garcia-Silva'}]","808":"[{'authorId': '40803555', 'name': 'Sajib Sen'}, {'authorId': '1710856', 'name': 'D. Dasgupta'}, {'authorId': '29314088', 'name': 'Kishor Datta Gupta'}]","809":"[{'authorId': '2112768206', 'name': 'Kaiyu Huang'}, {'authorId': '3251187', 'name': 'Keli Xiao'}, {'authorId': '2007643794', 'name': 'Fengran Mo'}, {'authorId': '144732658', 'name': 'Bo Jin'}, {'authorId': '46271578', 'name': 'Zhuang Liu'}, {'authorId': '2610330', 'name': 'Degen Huang'}]","810":"[{'authorId': '2108540349', 'name': 'Wen Zhang'}, {'authorId': '34208320', 'name': 'Lean Yu'}, {'authorId': '153274225', 'name': 'Taketoshi Yoshida'}, {'authorId': '40326638', 'name': 'Qing Wang'}]","811":"[{'authorId': '2444056', 'name': 'Alexander Junge'}, {'authorId': '2214567', 'name': 'L. Jensen'}]","812":"[{'authorId': '40896023', 'name': 'P. Schramowski'}, {'authorId': '13671251', 'name': 'Cigdem Turan'}, {'authorId': '2026607179', 'name': 'Nico Andersen'}, {'authorId': '3249046', 'name': 'C. Rothkopf'}, {'authorId': '1746871', 'name': 'K. Kersting'}]","813":"[{'authorId': '49339371', 'name': 'Yong Zhao'}, {'authorId': '1500653659', 'name': 'Tianyan Zhou'}, {'authorId': '145718850', 'name': 'Zhuo Chen'}, {'authorId': '2115902507', 'name': 'Jian Wu'}]","814":"[{'authorId': '2118960911', 'name': 'Hanmeng Liu'}, {'authorId': '152496687', 'name': 'Leyang Cui'}, {'authorId': '2150168584', 'name': 'Jian Liu'}, {'authorId': '1591125925', 'name': 'Yue Zhang'}]","815":"[{'authorId': '50774742', 'name': 'Jun He'}, {'authorId': '2108908160', 'name': 'Liqun Wang'}, {'authorId': '2117958137', 'name': 'Liu Liu'}, {'authorId': '1406031975', 'name': 'Jiao Feng'}, {'authorId': '30566977', 'name': 'Hao Wu'}]","816":"[{'authorId': '50086584', 'name': 'Haiyan Yin'}, {'authorId': '34377382', 'name': 'Dingcheng Li'}, {'authorId': '2116327105', 'name': 'Xu Li'}, {'authorId': '2420746', 'name': 'P. Li'}]","817":"[{'authorId': '49721680', 'name': 'Jingang Liu'}, {'authorId': '2056988799', 'name': 'Chunhe Xia'}, {'authorId': '48506966', 'name': 'Haihua Yan'}, {'authorId': '7654102', 'name': 'Zhipu Xie'}, {'authorId': '2110956901', 'name': 'Jie Sun'}]","818":"[{'authorId': '38755520', 'name': 'Kaiming Nie'}, {'authorId': '1658864968', 'name': 'Wanbin Zha'}, {'authorId': '2119202826', 'name': 'Xiaolin Shi'}, {'authorId': '2109401377', 'name': 'Jiawen Li'}, {'authorId': '1788399', 'name': 'Jiangtao Xu'}, {'authorId': '2146393070', 'name': 'Jianguo Ma'}]","819":"[{'authorId': '93386308', 'name': 'Yiwei Zhu'}, {'authorId': '2999987', 'name': 'Shilin Wang'}, {'authorId': '1390799037', 'name': 'Zheng Huang'}, {'authorId': '72387933', 'name': 'Kai Chen'}]","820":"[{'authorId': '2023987348', 'name': 'Shi-Qiu Guo'}, {'authorId': '1796651', 'name': 'Kenny Q. Zhu'}]","821":"[{'authorId': '46911248', 'name': 'A. Varghese'}, {'authorId': '2066928424', 'name': 'Tao Hong'}, {'authorId': '2053129573', 'name': 'Chelsea Hunter'}, {'authorId': '1411605821', 'name': 'George Agyeman-Badu'}, {'authorId': '1411611262', 'name': 'Michelle Cawley'}]","822":"[{'authorId': '2149086998', 'name': 'Shenggang Hu'}, {'authorId': '1412632844', 'name': 'Jabir Alshehabi Al-Ani'}, {'authorId': '103936158', 'name': 'K. Hughes'}, {'authorId': '39558957', 'name': 'Nicole Denier'}, {'authorId': '113296328', 'name': 'Alla Konnikov'}, {'authorId': '1878824772', 'name': 'Lei Ding'}, {'authorId': '2153624090', 'name': 'Jinhan Xie'}, {'authorId': '2155855183', 'name': 'Yang Hu'}, {'authorId': '144336221', 'name': 'Monideepa Tarafdar'}, {'authorId': '2080003952', 'name': 'Bei'}, {'authorId': '2086634492', 'name': 'Jiang'}, {'authorId': '2515229', 'name': 'Linglong Kong'}, {'authorId': '47958298', 'name': 'Hongsheng Dai'}]","823":"[{'authorId': '2116734918', 'name': 'Liang Zhao'}, {'authorId': '2114857066', 'name': 'Hexin Cao'}, {'authorId': '2118524497', 'name': 'Yunsong Zhao'}]","824":"[{'authorId': '2152519291', 'name': 'Li Lu'}, {'authorId': '36908613', 'name': 'L. Deng'}, {'authorId': '46172167', 'name': 'J. Ke'}, {'authorId': '9123018', 'name': 'Congwei Liao'}, {'authorId': '51493738', 'name': 'Shengxiang Huang'}]","825":"[{'authorId': '1879114403', 'name': 'Luigi Fassio'}, {'authorId': '3340326', 'name': 'Longyang Lin'}, {'authorId': '118203671', 'name': 'R. De Rose'}, {'authorId': '2397620', 'name': 'M. Lanuzza'}, {'authorId': '2734878', 'name': 'F. Crupi'}, {'authorId': '145466806', 'name': 'M. Alioto'}]","826":"[{'authorId': '1403267720', 'name': 'Anas El-Alem'}, {'authorId': '1782957', 'name': 'K. Chokmani'}, {'authorId': '3300100', 'name': 'I. Laurion'}, {'authorId': '2101336597', 'name': 'Salah E. El-Adlouni'}, {'authorId': '47386496', 'name': 'S. Raymond'}, {'authorId': '1404347206', 'name': 'C. Ratte-Fortin'}]","827":"[{'authorId': '90391228', 'name': 'N. Bajwa'}, {'authorId': '1725004', 'name': 'Cornelius J. K\u00f6nig'}]","828":"[{'authorId': '35856546', 'name': 'Jan Kinne'}, {'authorId': '81017548', 'name': 'Janna Axenbeck'}]","829":"[{'authorId': '29891652', 'name': 'Anne Lauscher'}, {'authorId': '152357481', 'name': 'B. Ko'}, {'authorId': '2003338023', 'name': 'Bailey Kuehl'}, {'authorId': '1406046265', 'name': 'Sophie Johnson'}, {'authorId': '3046220', 'name': 'David Jurgens'}, {'authorId': '2527954', 'name': 'Arman Cohan'}, {'authorId': '46258841', 'name': 'Kyle Lo'}]","830":"[{'authorId': '48414237', 'name': 'S. Ghorbani'}, {'authorId': '2334648', 'name': 'Yashesh Gaur'}, {'authorId': '1844953096', 'name': 'Yu Shi'}, {'authorId': '152319568', 'name': 'Jinyu Li'}]","831":"[{'authorId': '2154458114', 'name': 'Yi Wang'}]","832":"[{'authorId': '151401628', 'name': 'Nuhil Mehdy'}, {'authorId': '2061232', 'name': 'C. Kennington'}, {'authorId': '2396156', 'name': 'Hoda Mehrpouyan'}]","833":"[{'authorId': '1805991958', 'name': 'Zden\u011bk Kasner'}, {'authorId': '2738095', 'name': 'Simon Mille'}, {'authorId': '2544049', 'name': 'Ondrej Dusek'}]","834":"[{'authorId': '2142365411', 'name': 'Yimin Huang'}, {'authorId': '2999987', 'name': 'Shilin Wang'}, {'authorId': '2152112109', 'name': 'Cheng-Yu Gu'}, {'authorId': '1390799037', 'name': 'Zheng Huang'}, {'authorId': '2157740684', 'name': 'Kai Chen'}]","835":"[{'authorId': '144394770', 'name': 'Guixian Xu'}, {'authorId': '81948844', 'name': 'Y. Meng'}, {'authorId': '2027160668', 'name': 'Xiaokai Zhou'}, {'authorId': '9276757', 'name': 'Ziheng Yu'}, {'authorId': '2117921454', 'name': 'Xu Wu'}, {'authorId': '2143383260', 'name': 'Lijun Zhang'}]","836":"[{'authorId': '1774514', 'name': 'Francesco Pierri'}, {'authorId': '2601281', 'name': 'C. Piccardi'}, {'authorId': '144161686', 'name': 'S. Ceri'}]","837":"[{'authorId': '2108711165', 'name': 'Xi Liu'}, {'authorId': '51199131', 'name': 'Gaojing Zhou'}, {'authorId': '2118403836', 'name': 'Rui Zhang'}, {'authorId': '49141839', 'name': 'Xiaolin Wei'}]","838":"[{'authorId': '36212180', 'name': 'Sawan Kumar'}, {'authorId': '150171281', 'name': 'Kalpit Dixit'}, {'authorId': '39888194', 'name': 'Kashif Shah'}]","839":"[{'authorId': '51264673', 'name': 'Jaesung Bae'}, {'authorId': '2115953251', 'name': 'Taejun Bak'}, {'authorId': '3052252', 'name': 'Young-Sun Joo'}, {'authorId': '9460727', 'name': 'Hoon-Young Cho'}]","840":"[{'authorId': '2058866904', 'name': 'Daniel Loureiro'}, {'authorId': '1667035673', 'name': 'Kiamehr Rezaee'}, {'authorId': '1717641', 'name': 'Mohammad Taher Pilehvar'}, {'authorId': '1387447871', 'name': 'Jos\u00e9 Camacho-Collados'}]","841":"[{'authorId': '2108281590', 'name': 'Longyin Zhang'}, {'authorId': '47425794', 'name': 'Fang Kong'}, {'authorId': '143740945', 'name': 'Guodong Zhou'}]","842":"[{'authorId': '2678268', 'name': 'Peng Wu'}, {'authorId': '153003087', 'name': 'Xiangteng He'}, {'authorId': '1391123823', 'name': 'Mingqian Tang'}, {'authorId': '2075456784', 'name': 'Yiliang Lv'}, {'authorId': '2163063860', 'name': 'Jing Liu'}]","843":"[{'authorId': '49226685', 'name': 'N. Fay'}, {'authorId': '2150915447', 'name': 'B. Walker'}, {'authorId': '1996561', 'name': 'Y. Kashima'}, {'authorId': '2005906112', 'name': 'Andrew Perfors'}]","844":"[{'authorId': '49969982', 'name': 'Zhichao Li'}, {'authorId': '1424365262', 'name': 'H. Gurgel'}, {'authorId': '3816695', 'name': 'N. Dessay'}, {'authorId': '2144596253', 'name': 'Luojia Hu'}, {'authorId': '2109329691', 'name': 'Lei Xu'}, {'authorId': '144039260', 'name': 'Peng Gong'}]","845":"[{'authorId': '145984543', 'name': 'L. Salekhova'}, {'authorId': '114112540', 'name': 'A. Danilov'}, {'authorId': '2046618362', 'name': 'N. Spiridonova'}, {'authorId': '2629384', 'name': 'N. Anyameluhor'}]","846":"[{'authorId': '3331311', 'name': 'Youhyun Shin'}, {'authorId': '73124469', 'name': 'Sang-goo Lee'}]","847":"[{'authorId': '1401875317', 'name': 'O. Berger\u2010Tal'}, {'authorId': '143829064', 'name': 'B. B. M. Wong'}, {'authorId': '4189684', 'name': 'U. Candolin'}, {'authorId': '18747749', 'name': 'J. Barber'}]","848":"[{'authorId': '114304906', 'name': 'Caiwei Ma'}, {'authorId': '144666293', 'name': 'N. Au'}, {'authorId': '3610671', 'name': 'Lianping Ren'}]","849":"[{'authorId': '3162861', 'name': 'Burak Ayd\u0131n'}, {'authorId': '3226861', 'name': 'J. Algina'}]","850":"[{'authorId': '2022788741', 'name': 'Ritu Bibyan'}, {'authorId': '40599103', 'name': 'Sameer Anand'}, {'authorId': '2141351789', 'name': 'Ajay Jaiswal'}]","851":"[{'authorId': '2116713003', 'name': 'Qianlong Wang'}, {'authorId': '46606181', 'name': 'Jiangtao Ren'}]","852":"[{'authorId': '144214068', 'name': 'Guangyao Pang'}, {'authorId': '2070276430', 'name': 'Keda Lu'}, {'authorId': '145629492', 'name': 'Xiaoying Zhu'}, {'authorId': '2109654559', 'name': 'Jie He'}, {'authorId': '9250525', 'name': 'Zhiyi Mo'}, {'authorId': '153001545', 'name': 'Zizhen Peng'}, {'authorId': '2123357434', 'name': 'Baoxing Pu'}]","853":"[{'authorId': '50617505', 'name': 'Junjie Pan'}, {'authorId': '2152558639', 'name': 'Lin Wu'}, {'authorId': '145158503', 'name': 'Xiang Yin'}, {'authorId': '2115616711', 'name': 'Pengfei Wu'}, {'authorId': '2153078700', 'name': 'Chenchang Xu'}, {'authorId': '2919563', 'name': 'Zejun Ma'}]","854":"[{'authorId': '144160450', 'name': 'I. Salman'}, {'authorId': '2037650533', 'name': 'Pilar Rodr\u00edguez'}, {'authorId': '145973228', 'name': 'Burak Turhan'}, {'authorId': '49659397', 'name': 'Ayse Tosun'}, {'authorId': '11042599', 'name': 'Arda Gureller'}]","855":"[{'authorId': '52185502', 'name': 'N. Jain'}, {'authorId': '2487502', 'name': 'Maja Popovic'}, {'authorId': '39366957', 'name': 'Declan Groves'}, {'authorId': '32380598', 'name': 'Eva Vanmassenhove'}]","856":"[{'authorId': '51000113', 'name': 'Lixue Zou'}, {'authorId': '2140091968', 'name': 'Xiwen Liu'}, {'authorId': '70219052', 'name': 'Wray L. Buntine'}, {'authorId': '2108203099', 'name': 'Yanli Liu'}]","857":"[{'authorId': '38859145', 'name': 'A. Hayden'}, {'authorId': '38761190', 'name': 'Sarah Elaine Eaton'}, {'authorId': '75144711', 'name': 'Katherine Crossman'}, {'authorId': '81710944', 'name': 'L. Penaluna'}, {'authorId': '116191594', 'name': 'Bartlomiej A. Lenart'}]","858":"[{'authorId': '51284866', 'name': 'Tao Wang'}, {'authorId': '3491973', 'name': 'Jiangyan Yi'}, {'authorId': '3418514', 'name': 'Ruibo Fu'}, {'authorId': '37670752', 'name': 'J. Tao'}, {'authorId': '1718662', 'name': 'Zhengqi Wen'}]","859":"[{'authorId': '119546640', 'name': 'Doruk Kilitcioglu'}, {'authorId': '1763613', 'name': 'Serdar Kadioglu'}]","860":"[{'authorId': '2148899355', 'name': 'Jiaqi Guo'}, {'authorId': '2121301653', 'name': 'Ziliang Si'}, {'authorId': '47196158', 'name': 'Yu Wang'}, {'authorId': '1409707585', 'name': 'Qian Liu'}, {'authorId': '153441905', 'name': 'Ming Fan'}, {'authorId': '153249455', 'name': 'Jian-Guang Lou'}, {'authorId': '1752757', 'name': 'Z. Yang'}, {'authorId': '144003898', 'name': 'Ting Liu'}]","861":"[{'authorId': '40080808', 'name': 'Joe Barrow'}, {'authorId': '39878379', 'name': 'R. Jain'}, {'authorId': '102031958', 'name': 'N. Lipka'}, {'authorId': '2075390842', 'name': 'Franck Dernoncourt'}, {'authorId': '2852035', 'name': 'Vlad I. Morariu'}, {'authorId': '1977256', 'name': 'Varun Manjunatha'}, {'authorId': '1737250', 'name': 'D. Oard'}, {'authorId': '1680292', 'name': 'P. Resnik'}, {'authorId': '2007652833', 'name': 'Henning Wachsmuth'}]","862":"[{'authorId': '2145421216', 'name': 'Chang Li'}]","863":"[{'authorId': '2106411510', 'name': 'Adithya Renduchintala'}, {'authorId': '2036504384', 'name': 'Denise D\u00edaz'}, {'authorId': '1702066', 'name': 'Kenneth Heafield'}, {'authorId': '2116235416', 'name': 'Xian Li'}, {'authorId': '1700007', 'name': 'Mona T. Diab'}]","864":"[{'authorId': '1712115555', 'name': 'Taichi Murayama'}, {'authorId': '1824142', 'name': 'Shoko Wakamiya'}, {'authorId': '3182818', 'name': 'E. Aramaki'}]","865":"[{'authorId': '1492180700', 'name': 'Tanvi Dadu'}, {'authorId': '1384359611', 'name': 'Kartikey Pant'}, {'authorId': '1829635', 'name': 'R. Mamidi'}]","866":"[{'authorId': '1500520681', 'name': 'Tianyu Liu'}, {'authorId': '1430762233', 'name': 'Xin Zheng'}, {'authorId': '7267809', 'name': 'Baobao Chang'}, {'authorId': '3335836', 'name': 'Zhifang Sui'}]","867":"[{'authorId': '2122901065', 'name': 'Tao Yang'}, {'authorId': '7304193', 'name': 'Rujing Yao'}, {'authorId': '2057789213', 'name': 'Qing Yin'}, {'authorId': '1875827017', 'name': 'Qiang Tian'}, {'authorId': '1720110', 'name': 'Ou Wu'}]","868":"[{'authorId': '3370111', 'name': 'Todd R Ferretti'}, {'authorId': '145811519', 'name': 'K. McRae'}]","869":"[{'authorId': '144743946', 'name': 'Yuanqing Gu'}, {'authorId': '3239692', 'name': 'Hidehito Honda'}, {'authorId': '2617800', 'name': 'T. Matsuka'}, {'authorId': '145201934', 'name': 'K. Ueda'}]","870":"[{'authorId': '90820729', 'name': 'Lanna Lima'}, {'authorId': '1766601', 'name': 'V. Furtado'}, {'authorId': '1755605', 'name': 'E. Furtado'}, {'authorId': '2068335060', 'name': 'V. Almeida'}]","871":"[{'authorId': '3441331', 'name': 'Yugang Ji'}, {'authorId': '144123161', 'name': 'C. Shi'}, {'authorId': '1799525', 'name': 'Fuzhen Zhuang'}, {'authorId': '144019071', 'name': 'Philip S. Yu'}]","872":"[{'authorId': '1564589559', 'name': 'Maria Krommyda'}, {'authorId': '2915174', 'name': 'A. Rigos'}, {'authorId': '2104179248', 'name': 'Kostas Bouklas'}, {'authorId': '2046146', 'name': 'A. Amditis'}]","873":"[{'authorId': '2129454749', 'name': 'Matan Halevy'}, {'authorId': '2146887091', 'name': 'Camille Harris'}, {'authorId': '143709703', 'name': 'A. Bruckman'}, {'authorId': '2143919864', 'name': 'Diyi Yang'}, {'authorId': '145065293', 'name': 'A. Howard'}]","874":"[{'authorId': '97609914', 'name': 'Ibrahim Abu Farha'}, {'authorId': '1745226', 'name': 'Walid Magdy'}]","875":"[{'authorId': '2285178', 'name': 'Nitish Gupta'}, {'authorId': '34650964', 'name': 'Sameer Singh'}, {'authorId': '40642935', 'name': 'Matt Gardner'}]","876":"[{'authorId': '143644345', 'name': 'Zheng Zhang'}, {'authorId': '2109890021', 'name': 'Pan Zhou'}]","877":"[{'authorId': '49835220', 'name': 'M. Han'}, {'authorId': '2152288750', 'name': 'Linhao Dong'}, {'authorId': '1491085705', 'name': 'Zhenlin Liang'}, {'authorId': '2052052102', 'name': 'Meng Cai'}, {'authorId': '1661008937', 'name': 'Shiyu Zhou'}, {'authorId': '2919563', 'name': 'Zejun Ma'}, {'authorId': '1998966583', 'name': 'Bo Xu'}]","878":"[{'authorId': '73621142', 'name': 'Julia Suter'}, {'authorId': '2144883228', 'name': 'Letitia Parcalabescu'}, {'authorId': '143876555', 'name': 'A. Frank'}]","879":"[{'authorId': '2174964', 'name': 'Jiuxiang Gu'}, {'authorId': '7574699', 'name': 'Handong Zhao'}, {'authorId': '145527707', 'name': 'Zhe L. Lin'}, {'authorId': '39541577', 'name': 'Sheng Li'}, {'authorId': '1688642', 'name': 'Jianfei Cai'}, {'authorId': '2059515', 'name': 'Mingyang Ling'}]","880":"[{'authorId': '2261457', 'name': 'Eni Mustafaraj'}, {'authorId': '122583224', 'name': 'Emma Lurie'}, {'authorId': '1491522257', 'name': 'Claire Devine'}]","881":"[{'authorId': '1392982175', 'name': 'Eliza M. Grames'}, {'authorId': '48897344', 'name': 'Andrew N. Stillman'}, {'authorId': '6348771', 'name': 'M. Tingley'}, {'authorId': '2371015', 'name': 'C. Elphick'}]","882":"[{'authorId': '5231070', 'name': 'Kathryn Bousquet'}, {'authorId': '2250958', 'name': 'T. Swaab'}, {'authorId': '2265709', 'name': 'D. Long'}]","883":"[{'authorId': '1745899', 'name': 'Chris Dyer'}, {'authorId': '94303026', 'name': 'G\u00e1bor Melis'}, {'authorId': '1685771', 'name': 'P. Blunsom'}]","884":"[{'authorId': '50152545', 'name': 'Shulin Liu'}, {'authorId': '98177814', 'name': 'Y. Li'}, {'authorId': '47190894', 'name': 'F. Zhang'}, {'authorId': '2122901214', 'name': 'Tao Yang'}, {'authorId': '3005633', 'name': 'Xinpeng Zhou'}]","885":"[{'authorId': '89780350', 'name': 'Saeed Najafipour'}, {'authorId': '77397689', 'name': 'S. Hosseini'}, {'authorId': '144051547', 'name': 'Wen Hua'}, {'authorId': '144114389', 'name': 'M. Kangavari'}, {'authorId': '48667278', 'name': 'Xiaofang Zhou'}]","886":"[{'authorId': '2149217402', 'name': 'Michael S. Lin'}, {'authorId': '2117876104', 'name': 'Yun Liang'}, {'authorId': '2153235728', 'name': 'Joanne X. Xue'}, {'authorId': '89916774', 'name': 'B. Pan'}, {'authorId': '145880134', 'name': 'Ashley Schroeder'}]","887":"[{'authorId': '1846519', 'name': 'Helen Ngo'}, {'authorId': '119166278', 'name': 'Cooper D. Raterink'}, {'authorId': '145564780', 'name': \"J. Ara'ujo\"}, {'authorId': '1965882673', 'name': 'Ivan Zhang'}, {'authorId': '2109064358', 'name': 'Carol Chen'}, {'authorId': '1833773702', 'name': 'Adrien Morisot'}, {'authorId': '8207080', 'name': 'Nick Frosst'}]","888":"[{'authorId': '48448113', 'name': 'A. Evtushenko'}, {'authorId': '3371403', 'name': 'J. Kleinberg'}]","889":"[{'authorId': '3422202', 'name': 'Dong Huk Park'}, {'authorId': '2300366', 'name': 'Samaneh Azadi'}, {'authorId': '46522599', 'name': 'Xihui Liu'}, {'authorId': '1753210', 'name': 'Trevor Darrell'}, {'authorId': '34721166', 'name': 'Anna Rohrbach'}]","890":"[{'authorId': '2108262811', 'name': 'Xinyang Zhang'}, {'authorId': '2047145237', 'name': 'Chenwei Zhang'}, {'authorId': '2031471015', 'name': 'Xin Dong'}, {'authorId': '2884976', 'name': 'Jingbo Shang'}, {'authorId': '153034701', 'name': 'Jiawei Han'}]","891":"[{'authorId': '1475670743', 'name': 'Alissa Ostapenko'}, {'authorId': '2524073', 'name': 'S. Wintner'}, {'authorId': '40635326', 'name': 'Melinda Fricke'}, {'authorId': '145317727', 'name': 'Yulia Tsvetkov'}]","892":"[{'authorId': '2144616015', 'name': 'Hao Zhang'}, {'authorId': '2146041600', 'name': 'Jie Wang'}]","893":"[{'authorId': '37852874', 'name': 'Wuwei Lan'}, {'authorId': '145755239', 'name': 'Chao Jiang'}, {'authorId': '145738420', 'name': 'Wei Xu'}]","894":"[{'authorId': '2721029', 'name': 'Sheikh Muhammad Sarwar'}, {'authorId': '143798603', 'name': 'Felipe Moraes'}, {'authorId': '1730464', 'name': 'Jiepu Jiang'}, {'authorId': '144890574', 'name': 'James Allan'}]","895":"[{'authorId': '3358418', 'name': 'M. Song'}, {'authorId': '144889532', 'name': 'L. Jing'}, {'authorId': '2149552149', 'name': 'Lin Xiao'}]","896":"[{'authorId': '2108919537', 'name': 'Wei-Fan Chen'}, {'authorId': '18417916', 'name': 'S. Syed'}, {'authorId': '1405867539', 'name': 'Benno Stein'}, {'authorId': '145072133', 'name': 'Matthias Hagen'}, {'authorId': '3046200', 'name': 'Martin Potthast'}]","897":"[{'authorId': '47783130', 'name': 'Ding Zhao'}, {'authorId': '1784851', 'name': 'T. Sainath'}, {'authorId': '1743961', 'name': 'David Rybach'}, {'authorId': '51301830', 'name': 'Pat Rondon'}, {'authorId': '2055505691', 'name': 'Deepti Bhatia'}, {'authorId': '143771569', 'name': 'Bo Li'}, {'authorId': '34320634', 'name': 'Ruoming Pang'}]","898":"[{'authorId': '143857244', 'name': 'Alexander Martin'}, {'authorId': '2000772489', 'name': 'A. Holtz'}, {'authorId': '52039074', 'name': 'K. Abels'}, {'authorId': '4390470', 'name': 'D. Adger'}, {'authorId': '2852263', 'name': 'Jennifer Culbertson'}]","899":"[{'authorId': '2717484', 'name': 'Asaf Cidon'}, {'authorId': '2064122', 'name': 'Lior Gavish'}, {'authorId': '1395039711', 'name': 'Itay Bleier'}, {'authorId': '1395039714', 'name': 'Nadia Korshun'}, {'authorId': '1381199611', 'name': 'M. Schweighauser'}, {'authorId': '2069778805', 'name': 'Alexey Tsitkin'}]","900":"[{'authorId': '1996123', 'name': 'M. Corley'}, {'authorId': '25973828', 'name': 'S. Haywood'}]","901":"[{'authorId': '32095595', 'name': 'M. Markus'}]","902":"[{'authorId': '98337167', 'name': 'X. Zu'}, {'authorId': '2054584421', 'name': 'Fei Xie'}, {'authorId': '2110963267', 'name': 'Xiaojian Liu'}]","903":"[{'authorId': '34132063', 'name': 'D. Filimonov'}, {'authorId': '51909876', 'name': 'R. Gadde'}, {'authorId': '3070896', 'name': 'A. Rastrow'}]","904":"[{'authorId': '52182406', 'name': 'Mahjabeen Akter'}, {'authorId': '2107441566', 'name': 'M. S. Rahman'}, {'authorId': '2069560919', 'name': 'M. Z. Iqbal'}, {'authorId': '2056409968', 'name': 'M. R. Selim'}]","905":"[{'authorId': '2852263', 'name': 'Jennifer Culbertson'}, {'authorId': '3370565', 'name': 'M. Schouwstra'}, {'authorId': '145679294', 'name': 'S. Kirby'}]","906":"[{'authorId': '10690309', 'name': 'Maria Kyriacou'}, {'authorId': '36915012', 'name': 'K. Conklin'}, {'authorId': '153364510', 'name': 'Dominic Thompson'}]","907":"[{'authorId': '143766740', 'name': 'V. Solovyev'}, {'authorId': '46173549', 'name': 'Marina I. Solnyshkina'}, {'authorId': '72145692', 'name': 'E. Gafiyatova'}, {'authorId': '1801516', 'name': 'D. McNamara'}, {'authorId': '47616409', 'name': 'Vladimir Ivanov'}]","908":"[{'authorId': '3456331', 'name': 'Jianri Li'}, {'authorId': '2108480753', 'name': 'Jae-whan Lee'}, {'authorId': '3033707', 'name': 'Woosang Song'}, {'authorId': '2112789995', 'name': 'Ki-young Shin'}, {'authorId': '152353926', 'name': 'Byung-Hyun Go'}]","909":"[{'authorId': '1403601484', 'name': 'S. Yanisky-Ravid'}, {'authorId': '1410373153', 'name': 'C. Martens'}]","910":"[{'authorId': '123108102', 'name': 'Jesse A Harris'}]","911":"[{'authorId': '1832969', 'name': 'A. Ram'}, {'authorId': '1909396', 'name': 'Kurt P. Eiselt'}]","912":"[{'authorId': '40238128', 'name': 'Abdulrahman Alatawi'}, {'authorId': '47210195', 'name': 'Weifeng Xu'}, {'authorId': '1706387', 'name': 'Dianxiang Xu'}]","913":"[{'authorId': '2143784502', 'name': 'Bojana Ristic'}, {'authorId': '2047921934', 'name': 'S. Mancini'}, {'authorId': '1713794', 'name': 'Nicola Molinaro'}]","914":"[{'authorId': '52013156', 'name': 'Suzanne Petryk'}, {'authorId': '151088535', 'name': 'Lisa Dunlap'}, {'authorId': '2114436811', 'name': 'Keyan Nasseri'}, {'authorId': '49988044', 'name': 'Joseph E. Gonzalez'}, {'authorId': '1753210', 'name': 'Trevor Darrell'}, {'authorId': '34721166', 'name': 'Anna Rohrbach'}]","915":"[{'authorId': '2144686058', 'name': 'Xiaoqiang Wang'}, {'authorId': '2108086973', 'name': 'Yanqing Liu'}, {'authorId': '152319568', 'name': 'Jinyu Li'}, {'authorId': '2156930507', 'name': 'Veljko Miljanic'}, {'authorId': '47601191', 'name': 'Sheng Zhao'}, {'authorId': '145478726', 'name': 'H. Khalil'}]","916":"[{'authorId': '150215211', 'name': 'Matei Ionita'}, {'authorId': '2153701', 'name': 'Yury Kashnitsky'}, {'authorId': '150174292', 'name': 'Ken Krige'}, {'authorId': '2067164053', 'name': 'Vladimir Larin'}, {'authorId': '2064130334', 'name': 'Denis Logvinenko'}, {'authorId': '2063953501', 'name': 'Atanas Atanasov'}]","917":"[{'authorId': '150054634', 'name': 'Cas W. Coopmans'}, {'authorId': '150121370', 'name': 'Helen de Hoop'}, {'authorId': '2030986747', 'name': 'K. Kaushik'}, {'authorId': '2608476', 'name': 'P. Hagoort'}, {'authorId': '2157214768', 'name': 'Andrea E. Martin'}]","918":"[{'authorId': '1690448', 'name': 'T. Bickmore'}, {'authorId': '50196275', 'name': 'Dhaval Parmar'}, {'authorId': '3489930', 'name': 'Everlyne Kimani'}, {'authorId': '9079939', 'name': 'S. \u00d3lafsson'}]","919":"[{'authorId': '2108793987', 'name': 'Yi Ting Huang'}, {'authorId': '3512469', 'name': 'Zoe Ovans'}]","920":"[{'authorId': '3338985', 'name': 'Ke Wu'}, {'authorId': '2297426', 'name': 'Gilad Asharov'}, {'authorId': '1726246', 'name': 'E. Shi'}]","921":"[{'authorId': '2115404023', 'name': 'Jinghui Lu'}, {'authorId': '2145500840', 'name': 'Linyi Yang'}, {'authorId': '7616304', 'name': 'Brian Mac Namee'}, {'authorId': '39939186', 'name': 'Yue Zhang'}]","922":"[{'authorId': '2061829', 'name': 'B. McSkimming'}, {'authorId': '2146731987', 'name': 'Sean Mackay'}, {'authorId': '144469423', 'name': 'Adrienne Decker'}]","923":"[{'authorId': '2108607714', 'name': 'Yiheng Huang'}, {'authorId': '49160066', 'name': 'Liqiang He'}, {'authorId': '2112661282', 'name': 'Lei Han'}, {'authorId': '2221935', 'name': 'Guangsen Wang'}, {'authorId': '144610227', 'name': 'Dan Su'}]","924":"[{'authorId': '1398890675', 'name': 'Yeslam Al\u2010Saggaf'}]","925":"[{'authorId': '1666206198', 'name': \"James O'Neill\"}, {'authorId': '2617185', 'name': 'Polina Rozenshtein'}, {'authorId': '9924480', 'name': 'Ryuichi Kiryo'}, {'authorId': '2075373151', 'name': 'Motoko Kubota'}, {'authorId': '2075356592', 'name': 'D. Bollegala'}]","926":"[{'authorId': '51250894', 'name': 'Aditi Chaudhary'}, {'authorId': '38599655', 'name': 'Zaid A. W. Sheikh'}, {'authorId': '3407646', 'name': 'David R. Mortensen'}, {'authorId': '49513989', 'name': 'Antonios Anastasopoulos'}, {'authorId': '2075395906', 'name': 'Graham Neubig'}]","927":"[{'authorId': '37655342', 'name': 'A. Varol'}, {'authorId': '2008821796', 'name': 'Veysel Kocaman'}, {'authorId': '73097272', 'name': 'Hasham Ul Haq'}, {'authorId': '1761395', 'name': 'David Talby'}]","928":"[{'authorId': '2138301112', 'name': 'Amanda Bertsch'}, {'authorId': '2105138', 'name': 'Steven Bethard'}]","929":"[{'authorId': '1438945178', 'name': 'Charlotte Rochereau'}, {'authorId': '2075036', 'name': 'B. Sagot'}, {'authorId': '2202008', 'name': 'Emmanuel Dupoux'}]","930":"[{'authorId': '118187689', 'name': 'Andrew Chia'}]","931":"[{'authorId': '2134770444', 'name': 'Yiyun Zhao'}, {'authorId': '119076558', 'name': 'Jian Gang Ngui'}, {'authorId': '2138532771', 'name': 'Lucy Hall Hartley'}, {'authorId': '2105138', 'name': 'Steven Bethard'}]","932":"[{'authorId': '103202968', 'name': 'Ashok Thillaisundaram'}]","933":"[{'authorId': '2042704087', 'name': 'A. Perera'}, {'authorId': '2387149', 'name': 'A. Aleti'}, {'authorId': '1957122', 'name': 'C. Tantithamthavorn'}, {'authorId': '3269086', 'name': 'Jirayus Jiarpakdee'}, {'authorId': '145973228', 'name': 'Burak Turhan'}, {'authorId': '2161103852', 'name': 'Lisa Kuhn'}, {'authorId': '2161128508', 'name': 'Katie Walker'}]","934":"[{'authorId': '82105675', 'name': 'Xiaohan Lan'}, {'authorId': '48009996', 'name': 'Yitian Yuan'}, {'authorId': '2153687490', 'name': 'Xin Wang'}, {'authorId': '143891667', 'name': 'Long Chen'}, {'authorId': '2135451624', 'name': 'Zhi Wang'}, {'authorId': '2115503059', 'name': 'Lin Ma'}, {'authorId': '2156154955', 'name': 'Wenwu Zhu'}]","935":"[{'authorId': '12782489', 'name': 'Shuo Wang'}, {'authorId': '2909321', 'name': 'Zhaopeng Tu'}, {'authorId': '3468510', 'name': 'Zhixing Tan'}, {'authorId': '2072684668', 'name': 'Shuming Shi'}, {'authorId': '1753344', 'name': 'Maosong Sun'}, {'authorId': '2152797839', 'name': 'Yang Liu'}]","936":"[{'authorId': '1491626939', 'name': 'Yu Bai'}, {'authorId': '2068869988', 'name': 'Song Mei'}, {'authorId': '2113268674', 'name': 'Huan Wang'}, {'authorId': '2228109', 'name': 'Caiming Xiong'}]","937":"[{'authorId': '2886004', 'name': 'Yuan-Jyue Chen'}, {'authorId': '35479753', 'name': 'Christopher N. Takahashi'}, {'authorId': '23757022', 'name': 'Lee Organick'}, {'authorId': '1729912945', 'name': 'Callista Bee'}, {'authorId': '29865576', 'name': 'S. Ang'}, {'authorId': '120860510', 'name': 'P. Weiss'}, {'authorId': '1770271879', 'name': 'Bill J Peck'}, {'authorId': '49997612', 'name': 'G. Seelig'}, {'authorId': '1717411', 'name': 'L. Ceze'}, {'authorId': '145033446', 'name': 'K. Strauss'}]","938":"[{'authorId': '30910987', 'name': 'Vishnu Vardhan Chetlur'}, {'authorId': '1780194', 'name': 'Harpreet S. Dhillon'}]","939":"[{'authorId': '3442017', 'name': 'Himan Abdollahpouri'}, {'authorId': '1747150', 'name': 'R. Burke'}, {'authorId': '1684679', 'name': 'B. Mobasher'}]","940":"[{'authorId': '3442017', 'name': 'Himan Abdollahpouri'}, {'authorId': '3437010', 'name': 'M. Mansoury'}, {'authorId': '1747150', 'name': 'R. Burke'}, {'authorId': '1684679', 'name': 'B. Mobasher'}]","941":"[{'authorId': '1824224', 'name': 'Ludovico Boratto'}, {'authorId': '40433308', 'name': 'G. Fenu'}, {'authorId': '28922901', 'name': 'M. Marras'}]","942":"[{'authorId': '3461253', 'name': 'Felix Hamborg'}, {'authorId': '83302144', 'name': 'Anastasia Zhukova'}, {'authorId': '145151838', 'name': 'Bela Gipp'}]","943":"[{'authorId': '2886004', 'name': 'Yuan-Jyue Chen'}, {'authorId': '35479753', 'name': 'Christopher N. Takahashi'}, {'authorId': '23757022', 'name': 'Lee Organick'}, {'authorId': '145966834', 'name': 'Kendall Stewart'}, {'authorId': '29865576', 'name': 'S. Ang'}, {'authorId': '120860510', 'name': 'P. Weiss'}, {'authorId': '1770271879', 'name': 'Bill J Peck'}, {'authorId': '49997612', 'name': 'G. Seelig'}, {'authorId': '1717411', 'name': 'L. Ceze'}, {'authorId': '145033446', 'name': 'K. Strauss'}]","944":"[{'authorId': '39844137', 'name': 'A. Keil'}, {'authorId': '1892714', 'name': 'J. Buckley'}, {'authorId': '89757355', 'name': 'K. O\u2019Brien'}, {'authorId': '5406192', 'name': 'K. Ferguson'}, {'authorId': '152836797', 'name': 'Shanshan Zhao'}, {'authorId': '6874085', 'name': 'A. White'}]","945":"[{'authorId': '47652495', 'name': 'Liangyuan Hu'}]","946":"[{'authorId': '48631777', 'name': 'Xiaozhi Wang'}, {'authorId': '48506411', 'name': 'Xu Han'}, {'authorId': '49293587', 'name': 'Zhiyuan Liu'}, {'authorId': '1753344', 'name': 'Maosong Sun'}, {'authorId': '144326610', 'name': 'Peng Li'}]","947":"[{'authorId': '1402912902', 'name': 'B. Bauer-Marschallinger'}, {'authorId': '65882962', 'name': 'V. Freeman'}, {'authorId': '38165997', 'name': 'S. Cao'}, {'authorId': '2988660', 'name': 'C. Paulik'}, {'authorId': '66345422', 'name': 'S. Schaufler'}, {'authorId': '66704075', 'name': 'Tobias Stachl'}, {'authorId': '51159881', 'name': 'S. Modanesi'}, {'authorId': '2094136', 'name': 'C. Massari'}, {'authorId': '3369758', 'name': 'L. Ciabatta'}, {'authorId': '2235623', 'name': 'L. Brocca'}, {'authorId': '144530757', 'name': 'W. Wagner'}]","948":"[{'authorId': '3150523', 'name': 'J. Kattge'}, {'authorId': '6098953', 'name': 'G. B\u00f6nisch'}, {'authorId': '144203256', 'name': 'S. D\u00edaz'}, {'authorId': '4687927', 'name': 'S. Lavorel'}, {'authorId': '51915849', 'name': 'I. Prentice'}, {'authorId': '4856898', 'name': 'P. Leadley'}, {'authorId': '3488389', 'name': 'S. Tautenhahn'}, {'authorId': '28766374', 'name': 'G. D. Werner'}, {'authorId': '3709128', 'name': 'T. Aakala'}, {'authorId': '4693314', 'name': 'M. Abedi'}, {'authorId': '4532639', 'name': 'A. Acosta'}, {'authorId': '5774096', 'name': 'G. Adamidis'}, {'authorId': '108078010', 'name': 'Kairi Adamson'}, {'authorId': '50448193', 'name': 'Masahiro Aiba'}, {'authorId': '144823568', 'name': 'C. Albert'}, {'authorId': '105039782', 'name': 'J. Alc\u00e1ntara'}, {'authorId': '1471904323', 'name': 'Carolina Alc\u00e1zar C'}, {'authorId': '118291916', 'name': 'Izabela Aleixo'}, {'authorId': '108438823', 'name': 'Hamada E. Ali'}, {'authorId': '5914260', 'name': 'Bernard Amiaud'}, {'authorId': '4325875', 'name': 'C. Ammer'}, {'authorId': '21481106', 'name': 'M. Amoroso'}, {'authorId': '145459348', 'name': 'M. Anand'}, {'authorId': '49852511', 'name': 'C. Anderson'}, {'authorId': '143927786', 'name': 'N. Anten'}, {'authorId': '35679346', 'name': 'J. Antos'}, {'authorId': '145453174', 'name': 'D. Apgaua'}, {'authorId': '50144175', 'name': 'T. Ashman'}, {'authorId': '108344347', 'name': 'Degi Harja Asmara'}, {'authorId': '145976126', 'name': 'G. Asner'}, {'authorId': '5289420', 'name': 'Michael J. Aspinwall'}, {'authorId': '5886162', 'name': 'O. Atkin'}, {'authorId': '6583573', 'name': 'I. Aubin'}, {'authorId': '1411482168', 'name': 'L. Baastrup\u2010Spohr'}, {'authorId': '1471904520', 'name': 'Khadijeh Bahalkeh'}, {'authorId': '2428288', 'name': 'M. Bahn'}, {'authorId': '40622085', 'name': 'T. Baker'}, {'authorId': '48622044', 'name': 'W. Baker'}, {'authorId': '48920815', 'name': 'J. Bakker'}, {'authorId': '3098010', 'name': 'D. Baldocchi'}, {'authorId': '46970112', 'name': 'J. Baltzer'}, {'authorId': '144205696', 'name': 'A. Banerjee'}, {'authorId': '5029957', 'name': 'A. Baranger'}, {'authorId': '50387533', 'name': 'J. Barlow'}, {'authorId': '5492896', 'name': 'D. R. Barneche'}, {'authorId': '38937844', 'name': 'Z. Baruch'}, {'authorId': '30125122', 'name': 'D. Bastianelli'}, {'authorId': '2655910', 'name': 'J. Battles'}, {'authorId': '5804141', 'name': 'W. Bauerle'}, {'authorId': '3926308', 'name': 'M. Bauters'}, {'authorId': '2082656029', 'name': 'E. Bazzato'}, {'authorId': '48953245', 'name': 'Michael Beckmann'}, {'authorId': '6772280', 'name': 'H. Beeckman'}, {'authorId': '5741227', 'name': 'C. Beierkuhnlein'}, {'authorId': '144762815', 'name': 'R. Bekker'}, {'authorId': '1471931669', 'name': 'Gavin Belfry'}, {'authorId': '1656935861', 'name': 'M. Belluau'}, {'authorId': '66479656', 'name': 'Mirela Beloiu'}, {'authorId': '46898298', 'name': 'R. Benavides'}, {'authorId': '4607769', 'name': 'Lahcen Benomar'}, {'authorId': '1403412666', 'name': 'Mary Lee Berdugo-Lattke'}, {'authorId': '5543597', 'name': 'E. Berenguer'}, {'authorId': '3999099', 'name': 'R. Bergamin'}, {'authorId': '39111863', 'name': 'Joana Bergmann'}, {'authorId': '1471901053', 'name': 'Marcos Bergmann Carlucci'}, {'authorId': '3612294', 'name': 'L. Berner'}, {'authorId': '1398012397', 'name': 'M. Bernhardt\u2010R\u00f6mermann'}, {'authorId': '3922014', 'name': 'C. Bigler'}, {'authorId': '34805531', 'name': 'Anne D. Bjorkman'}, {'authorId': '40556293', 'name': 'Chris J. Blackman'}, {'authorId': '48724230', 'name': 'C. Blanco'}, {'authorId': '4756850', 'name': 'B. Blonder'}, {'authorId': '27089237', 'name': 'D. Blumenthal'}, {'authorId': '1422513781', 'name': 'Kelly T Bocanegra-Gonz\u00e1lez'}, {'authorId': '4591569', 'name': 'P. Boeckx'}, {'authorId': '3415991', 'name': 'S. Bohlman'}, {'authorId': '1397357368', 'name': 'K. B\u00f6hning\u2010Gaese'}, {'authorId': '1438361688', 'name': 'L. Boisvert\u2010Marsh'}, {'authorId': '143903401', 'name': 'W. Bond'}, {'authorId': '1422519120', 'name': 'B. Bond\u2010Lamberty'}, {'authorId': '48472244', 'name': 'A. Boom'}, {'authorId': '1470601110', 'name': 'C. Boonman'}, {'authorId': '90556589', 'name': 'Kauane Bordin'}, {'authorId': '6603947', 'name': 'E. Boughton'}, {'authorId': '49614006', 'name': 'V. Boukili'}, {'authorId': '144594762', 'name': 'D. Bowman'}, {'authorId': '2068774379', 'name': 'S. Bravo'}, {'authorId': '40795969', 'name': 'Marco R. Brendel'}, {'authorId': '5471474', 'name': 'M. Broadley'}, {'authorId': '144823323', 'name': 'K. Brown'}, {'authorId': '6881322', 'name': 'H. Bruelheide'}, {'authorId': '137470220', 'name': 'F. Brumnich'}, {'authorId': '144274335', 'name': 'H. H. Bruun'}, {'authorId': '52172475', 'name': 'David Bruy'}, {'authorId': '144131252', 'name': 'S. Buchanan'}, {'authorId': '32778652', 'name': 'S. F. Bucher'}, {'authorId': '2039226', 'name': 'N. Buchmann'}, {'authorId': '3738099', 'name': 'R. Buitenwerf'}, {'authorId': '5690742', 'name': 'D. Bunker'}, {'authorId': '31835949', 'name': 'Jana B\u00fcrger'}, {'authorId': '4916515', 'name': 'S. Burrascano'}, {'authorId': '5157109', 'name': 'D. Burslem'}, {'authorId': '2989996', 'name': 'B. Butterfield'}, {'authorId': '13147335', 'name': 'Chaeho Byun'}, {'authorId': '37151086', 'name': 'M. Marques'}, {'authorId': '4430568', 'name': 'M. Scalon'}, {'authorId': '6122521', 'name': 'M. Caccianiga'}, {'authorId': '144733030', 'name': 'M. Cadotte'}, {'authorId': '4135424', 'name': 'M. Cailleret'}, {'authorId': '6456360', 'name': 'James S. Camac'}, {'authorId': '2359553', 'name': 'J. Camarero'}, {'authorId': '5194216', 'name': 'C. Campany'}, {'authorId': '5750945', 'name': 'G. Campetella'}, {'authorId': '49385412', 'name': 'J. A. Campos'}, {'authorId': '1471904755', 'name': 'Laura V. Cano-Arboleda'}, {'authorId': '5895429', 'name': 'R. Canullo'}, {'authorId': '5364291', 'name': 'M. Carbognani'}, {'authorId': '84590660', 'name': 'Fabio Carvalho'}, {'authorId': '6782828', 'name': 'F. Casanoves'}, {'authorId': '4888367', 'name': 'B. Castagneyrol'}, {'authorId': '40341364', 'name': 'J. Catford'}, {'authorId': '1398054936', 'name': 'J. Cavender-Bares'}, {'authorId': '3739855', 'name': 'B. Cerabolini'}, {'authorId': '32822844', 'name': 'M. Cervellini'}, {'authorId': '1422383334', 'name': 'Eduardo Chac\u00f3n\u2010Madrigal'}, {'authorId': '5790566', 'name': 'K. Chapin'}, {'authorId': '46601508', 'name': 'F. Chapin'}, {'authorId': '5811117', 'name': 'S. Chelli'}, {'authorId': '50357736', 'name': 'Si\u2010Chong Chen'}, {'authorId': '48162950', 'name': 'Anping Chen'}, {'authorId': '1947602', 'name': 'P. Cherubini'}, {'authorId': '2078438', 'name': 'F. Chianucci'}, {'authorId': '4409939', 'name': 'B. Choat'}, {'authorId': '87176567', 'name': 'Kyong-Sook Chung'}, {'authorId': '88224102', 'name': 'M. Chytr\u00fd'}, {'authorId': '4883692', 'name': 'D. Ciccarelli'}, {'authorId': '49574911', 'name': 'L. Coll'}, {'authorId': '27388136', 'name': 'Courtney G Collins'}, {'authorId': '40141429', 'name': 'L. Conti'}, {'authorId': '3243360', 'name': 'D. Coomes'}, {'authorId': '143995477', 'name': 'J. Cornelissen'}, {'authorId': '3031444', 'name': 'W. Cornwell'}, {'authorId': '46715424', 'name': 'P. Corona'}, {'authorId': '6377611', 'name': 'M. Coyea'}, {'authorId': '3166884', 'name': 'J. Craine'}, {'authorId': '40390376', 'name': 'D. Craven'}, {'authorId': '145249929', 'name': 'J. Cromsigt'}, {'authorId': '66362949', 'name': 'Anik\u00f3 Csecserits'}, {'authorId': '5586111', 'name': 'K. \u010cufar'}, {'authorId': '46726374', 'name': 'M. Cuntz'}, {'authorId': '50148198', 'name': 'A. C. da Silva'}, {'authorId': '21668859', 'name': 'K. Dahlin'}, {'authorId': '2468388', 'name': 'M. Dainese'}, {'authorId': '5273016', 'name': 'I. Dalke'}, {'authorId': '1471904473', 'name': 'M. Dalle Fratte'}, {'authorId': '1438498250', 'name': 'Anh Tuan Dang-Le'}, {'authorId': '3310957', 'name': 'J. Danihelka'}, {'authorId': '5090405', 'name': 'M. Dannoura'}, {'authorId': '36485455', 'name': 'Samantha K. Dawson'}, {'authorId': '1471904684', 'name': 'Arend Jacobus de Beer'}, {'authorId': '47617237', 'name': 'A. D. de Frutos'}, {'authorId': '50604739', 'name': 'J. R. De Long'}, {'authorId': '22426017', 'name': 'Benjamin Dechant'}, {'authorId': '5473656', 'name': 'S. Delagrange'}, {'authorId': '6796500', 'name': 'N. Delpierre'}, {'authorId': '31778564', 'name': 'G. Derroire'}, {'authorId': '46809304', 'name': 'A. S. Dias'}, {'authorId': '1413707292', 'name': 'Milton H. D\u00edaz-Toribio'}, {'authorId': '39750691', 'name': 'P. Dimitrakopoulos'}, {'authorId': '13838975', 'name': 'M. Dobrowolski'}, {'authorId': '2106380', 'name': 'D. Doktor'}, {'authorId': '2076971790', 'name': 'P. D\u0159evojan'}, {'authorId': '145803288', 'name': 'N. Dong'}, {'authorId': '50523261', 'name': 'J. Dransfield'}, {'authorId': '2020119102', 'name': 'S. Dressler'}, {'authorId': '3481159', 'name': 'L. Duarte'}, {'authorId': '2006495917', 'name': '\u00c9. Ducouret'}, {'authorId': '6399755', 'name': 'S. Dullinger'}, {'authorId': '143801495', 'name': 'W. Durka'}, {'authorId': '4307379', 'name': 'R. Duursma'}, {'authorId': '3566765', 'name': 'O. Dymova'}, {'authorId': '1405024787', 'name': 'A. E\u2010Vojtk\u00f3'}, {'authorId': '47873587', 'name': 'R. L. Eckstein'}, {'authorId': '5822979', 'name': 'H. Ejtehadi'}, {'authorId': '2265657', 'name': 'J. Elser'}, {'authorId': '3874085', 'name': 'T. Emilio'}, {'authorId': '35560412', 'name': 'K. Engemann'}, {'authorId': '122250748', 'name': 'Mohammad Bagher Erfanian'}, {'authorId': '4775327', 'name': 'Alexandra Erfmeier'}, {'authorId': '1401953045', 'name': 'Adriane Esquivel\u2010Muelbert'}, {'authorId': '102376403', 'name': 'G. Esser'}, {'authorId': '92457648', 'name': 'M. Estiarte'}, {'authorId': '4384828', 'name': 'T. Domingues'}, {'authorId': '143683589', 'name': 'W. Fagan'}, {'authorId': '47455485', 'name': 'J. Fag\u00fandez'}, {'authorId': '6009953', 'name': 'D. Falster'}, {'authorId': '49411439', 'name': 'Ying Fan'}, {'authorId': '47469926', 'name': 'Jingyun Fang'}, {'authorId': '145514438', 'name': 'E. Farris'}, {'authorId': '8674031', 'name': 'Fatih Fazlioglu'}, {'authorId': '8061412', 'name': 'Yanhao Feng'}, {'authorId': '1398490212', 'name': 'F. Fernandez-Mendez'}, {'authorId': '19781533', 'name': 'C. Ferrara'}, {'authorId': '30407329', 'name': 'J. Ferreira'}, {'authorId': '144910931', 'name': 'A. Fidelis'}, {'authorId': '49218094', 'name': 'B. Finegan'}, {'authorId': '3941019', 'name': 'J. Firn'}, {'authorId': '1925956', 'name': 'T. Flowers'}, {'authorId': '39933854', 'name': 'D. Flynn'}, {'authorId': '46906670', 'name': 'V. Fontana'}, {'authorId': '4072869', 'name': 'E. Forey'}, {'authorId': '3834368', 'name': 'Cristiane Forgiarini'}, {'authorId': '49243711', 'name': 'L. Fran\u00e7ois'}, {'authorId': '114344604', 'name': 'Marcelo Frangipani'}, {'authorId': '37646231', 'name': 'D. Frank'}, {'authorId': '1438435298', 'name': 'C\u00e9dric Frenette-Dussault'}, {'authorId': '6755255', 'name': 'G. T. Freschet'}, {'authorId': '20943771', 'name': 'Ellen L. Fry'}, {'authorId': '5734433', 'name': 'N. Fyllas'}, {'authorId': '87459776', 'name': 'G. G. Mazzochini'}, {'authorId': '3109629', 'name': 'S. Gachet'}, {'authorId': '4703963', 'name': 'R. Gallagher'}, {'authorId': '5339529', 'name': 'G. Ganade'}, {'authorId': '1471901882', 'name': 'Francesca Ganga'}, {'authorId': '1397970337', 'name': 'P. Garc\u00eda\u2010Palacios'}, {'authorId': '4588036', 'name': 'V. Gargaglione'}, {'authorId': '144690078', 'name': 'E. Garnier'}, {'authorId': '145958371', 'name': 'J. Garrido'}, {'authorId': '133583466', 'name': 'A. L. de Gasper'}, {'authorId': '1399424810', 'name': 'G. Gea\u2010Izquierdo'}, {'authorId': '145207629', 'name': 'D. Gibson'}, {'authorId': '5234600', 'name': 'A. Gillison'}, {'authorId': '4340197', 'name': 'A. Giroldo'}, {'authorId': '91365007', 'name': 'Mary-Claire Glasenhardt'}, {'authorId': '29584140', 'name': 'S. Gleason'}, {'authorId': '1471900293', 'name': 'Mariana Gliesch'}, {'authorId': '144797118', 'name': 'E. Goldberg'}, {'authorId': '13592014', 'name': 'Bastian G\u00f6ldel'}, {'authorId': '1384229158', 'name': 'E. Gonzalez-Akre'}, {'authorId': '1398617184', 'name': 'J. Gonz\u00e1lez-And\u00fajar'}, {'authorId': '1404539257', 'name': 'Andr\u00e9s Gonz\u00e1lez-Melo'}, {'authorId': '1405048779', 'name': 'A. Gonz\u00e1lez-Robles'}, {'authorId': '4398432', 'name': 'B. Graae'}, {'authorId': '4555826', 'name': 'E. Granda'}, {'authorId': '4480444', 'name': 'Sarah J. Graves'}, {'authorId': '90096292', 'name': 'W. Green'}, {'authorId': '46273619', 'name': 'T. Gregor'}, {'authorId': '35349703', 'name': 'N. Gross'}, {'authorId': '49063011', 'name': 'G. Guerin'}, {'authorId': '1405894124', 'name': 'A. G\u00fcnther'}, {'authorId': '152729684', 'name': '\u00c1. Guti\u00e9rrez'}, {'authorId': '1471904342', 'name': 'Lillie Haddock'}, {'authorId': '145897891', 'name': 'Anna L. Haines'}, {'authorId': '144923151', 'name': 'Jefferson S. Hall'}, {'authorId': '5617136', 'name': 'A. Hambuckers'}, {'authorId': '38542842', 'name': 'W. Han'}, {'authorId': '40334344', 'name': 'S. Harrison'}, {'authorId': '30020997', 'name': 'W. Hattingh'}, {'authorId': '5166588', 'name': 'J. Hawes'}, {'authorId': '1880265', 'name': 'Tianhua He'}, {'authorId': '2112512470', 'name': 'Pengcheng He'}, {'authorId': '145792341', 'name': 'J. M. Heberling'}, {'authorId': '144365865', 'name': 'A. Helm'}, {'authorId': '2229822', 'name': 'S. Hempel'}, {'authorId': '5999513', 'name': 'J. Hentschel'}, {'authorId': '3342894', 'name': 'B. H\u00e9rault'}, {'authorId': '120914797', 'name': 'A. Here\u0219'}, {'authorId': '29871013', 'name': 'K. Herz'}, {'authorId': '6116067', 'name': 'M. Heuertz'}, {'authorId': '3995829', 'name': 'T. Hickler'}, {'authorId': '4435204', 'name': 'P. Hietz'}, {'authorId': '2089154780', 'name': 'P. Higuchi'}, {'authorId': '2331805', 'name': 'A. Hipp'}, {'authorId': '51310560', 'name': 'A. Hirons'}, {'authorId': '145519106', 'name': 'M. Hock'}, {'authorId': '31894831', 'name': 'J. Hogan'}, {'authorId': '34956007', 'name': 'K. Holl'}, {'authorId': '1849258', 'name': 'O. Honnay'}, {'authorId': '114404843', 'name': 'Daniel Hornstein'}, {'authorId': '4882061', 'name': 'E. Hou'}, {'authorId': '1399190266', 'name': 'Nate Hough-Snee'}, {'authorId': '8765490', 'name': 'K. Hovstad'}, {'authorId': '3372723', 'name': 'T. Ichie'}, {'authorId': '3864086', 'name': 'B. Igi\u0107'}, {'authorId': '152819979', 'name': 'E. Illa'}, {'authorId': '5922671', 'name': 'M. Isaac'}, {'authorId': '3022011', 'name': 'M. Ishihara'}, {'authorId': '145377792', 'name': 'L. Ivanov'}, {'authorId': '2105838180', 'name': 'Larissa Ivanova'}, {'authorId': '2483992', 'name': 'C. Iversen'}, {'authorId': '2058233464', 'name': 'J. Izquierdo'}, {'authorId': '145293035', 'name': 'R. B. Jackson'}, {'authorId': '32144221', 'name': 'B. Jackson'}, {'authorId': '3688486', 'name': 'H. Jactel'}, {'authorId': '2322653', 'name': 'A. Jagodzi\u0144ski'}, {'authorId': '29859002', 'name': 'Ute Jandt'}, {'authorId': '144476289', 'name': 'S. Jansen'}, {'authorId': '153133784', 'name': 'T. Jenkins'}, {'authorId': '2426600', 'name': 'A. Jentsch'}, {'authorId': '1471901462', 'name': 'J. R. P. Jespersen'}, {'authorId': '4047609', 'name': 'Guo-Feng Jiang'}, {'authorId': '51211603', 'name': 'Jesper Liengaard Johansen'}, {'authorId': '2150444788', 'name': 'David Johnson'}, {'authorId': '4005118', 'name': 'E. Jokela'}, {'authorId': '34863763', 'name': 'C. Joly'}, {'authorId': '31804019', 'name': 'G. Jordan'}, {'authorId': '103814655', 'name': 'G. Joseph'}, {'authorId': '51213736', 'name': 'D. Junaedi'}, {'authorId': '6628274', 'name': 'R. Junker'}, {'authorId': '2963271', 'name': 'E. Justes'}, {'authorId': '6386229', 'name': 'R. Kabzems'}, {'authorId': '143882193', 'name': 'J. Kane'}, {'authorId': '4632060', 'name': 'Z. Kaplan'}, {'authorId': '2617037', 'name': 'T. Kattenborn'}, {'authorId': '117370321', 'name': 'L. Kavelenova'}, {'authorId': '4345306', 'name': 'E. Kearsley'}, {'authorId': '5694700', 'name': 'Anne Kempel'}, {'authorId': '6527558', 'name': 'T. Kenzo'}, {'authorId': '40229183', 'name': 'A. Kerkhoff'}, {'authorId': '1401130045', 'name': 'Mohammed Ibrahim Khalil'}, {'authorId': '65739171', 'name': 'N. Kinlock'}, {'authorId': '144366400', 'name': 'W. D. Kissling'}, {'authorId': '4486479', 'name': 'K. Kitajima'}, {'authorId': '5700151', 'name': 'T. Kitzberger'}, {'authorId': '1401553647', 'name': 'R. Kj\u00f8ller'}, {'authorId': '39634456', 'name': 'T. Klein'}, {'authorId': '88684180', 'name': 'M. Kleyer'}, {'authorId': '5814560', 'name': 'J. Klime\u0161ov\u00e1'}, {'authorId': '2086553652', 'name': 'Joice Klipel'}, {'authorId': '2261324', 'name': 'B. Kloeppel'}, {'authorId': '145743168', 'name': 'S. Klotz'}, {'authorId': '145267598', 'name': 'J. Knops'}, {'authorId': '34666299', 'name': 'T. Kohyama'}, {'authorId': '4017428', 'name': 'F. Koike'}, {'authorId': '3338268', 'name': 'J. Kollmann'}, {'authorId': '3528399', 'name': 'B. Komac'}, {'authorId': '151075880', 'name': 'K. Komatsu'}, {'authorId': '143633956', 'name': 'C. K\u00f6nig'}, {'authorId': '40544934', 'name': 'Nathan J B Kraft'}, {'authorId': '145128020', 'name': 'K. Kramer'}, {'authorId': '2871866', 'name': 'H. Kreft'}, {'authorId': '39240989', 'name': 'I. K\u00fchn'}, {'authorId': '14912006', 'name': 'D. Kumarathunge'}, {'authorId': '7006712', 'name': 'J. Kuppler'}, {'authorId': '2356714', 'name': 'H. Kurokawa'}, {'authorId': '90671005', 'name': 'Y. Kurosawa'}, {'authorId': '4555783', 'name': 'Shem Kuyah'}, {'authorId': '87627642', 'name': 'J. Laclau'}, {'authorId': '39975277', 'name': 'Benoit Lafleur'}, {'authorId': '1471904615', 'name': 'E. Lallai'}, {'authorId': '3943532', 'name': 'E. Lamb'}, {'authorId': '17362191', 'name': 'A. Lamprecht'}, {'authorId': '34863075', 'name': 'D. Larkin'}, {'authorId': '3084356', 'name': 'D. Laughlin'}, {'authorId': '1399166713', 'name': 'Y. Le Bagousse-Pinguet'}, {'authorId': '134015548', 'name': 'G. le Maire'}, {'authorId': '46819040', 'name': 'P. C. le Roux'}, {'authorId': '114837672', 'name': 'E. le Roux'}, {'authorId': '2110642233', 'name': 'Tali D. Lee'}, {'authorId': '4309890', 'name': 'F. Lens'}, {'authorId': '3890299', 'name': 'S. Lewis'}, {'authorId': '2221748', 'name': 'B. Lhotsky'}, {'authorId': '2110486794', 'name': 'Yuanzhi Li'}, {'authorId': '7824369', 'name': \"Xin'e Li\"}, {'authorId': '3978515', 'name': 'J. Lichstein'}, {'authorId': '46776946', 'name': 'Mario Liebergesell'}, {'authorId': '49719277', 'name': 'J. Y. Lim'}, {'authorId': '7892845', 'name': 'Yan-Shih Lin'}, {'authorId': '50682696', 'name': 'J. Linares'}, {'authorId': '1915896', 'name': 'Chunjiang Liu'}, {'authorId': '14212578', 'name': 'Daijun Liu'}, {'authorId': '4512798', 'name': 'Udayangani Liu'}, {'authorId': '15517296', 'name': 'Stuart W. Livingstone'}, {'authorId': '6364523', 'name': 'J. Llusi\u00e0'}, {'authorId': '88917543', 'name': 'Madelon Lohbeck'}, {'authorId': '1439112596', 'name': '\u00c1lvaro L\u00f3pez-Garc\u00eda'}, {'authorId': '1380697522', 'name': 'G. Lopez-Gonzalez'}, {'authorId': '3691860', 'name': 'Zde\u0148ka Lososov\u00e1'}, {'authorId': '4883302', 'name': 'F. Louault'}, {'authorId': '49799762', 'name': 'B. Luk\u00e1cs'}, {'authorId': '2933411', 'name': 'P. Luke\u0161'}, {'authorId': '48001724', 'name': 'Yunjian Luo'}, {'authorId': '89607249', 'name': 'M. Lussu'}, {'authorId': '33383105', 'name': 'Siyan Ma'}, {'authorId': '1471905356', 'name': 'Camilla Maciel Rabelo Pereira'}, {'authorId': '144712452', 'name': 'M. Mack'}, {'authorId': '2077858', 'name': 'V. Maire'}, {'authorId': '145814603', 'name': 'A. M\u00e4kel\u00e4'}, {'authorId': '3134315', 'name': 'H. M\u00e4kinen'}, {'authorId': '1835146', 'name': 'A. C. M. Malhado'}, {'authorId': '37594808', 'name': 'A. Mallik'}, {'authorId': '115444519', 'name': 'P. Manning'}, {'authorId': '40410284', 'name': 'S. Manzoni'}, {'authorId': '87258631', 'name': 'Z. Marchetti'}, {'authorId': '90161515', 'name': 'L. Marchino'}, {'authorId': '1405018096', 'name': 'Vin\u00edcius Marcilio-Silva'}, {'authorId': '50615511', 'name': 'Eric Marcon'}, {'authorId': '40157508', 'name': 'M. Marignani'}, {'authorId': '3922166', 'name': 'Lars Markesteijn'}, {'authorId': '2157215225', 'name': 'Adam R. Martin'}, {'authorId': '1403951114', 'name': 'C. Mart\u00ednez-Garza'}, {'authorId': '1398482212', 'name': 'J. Mart\u00ednez\u2010Vilalta'}, {'authorId': '51146177', 'name': 'T. Ma\u0161kov\u00e1'}, {'authorId': '40480212', 'name': 'Kelly E. Mason'}, {'authorId': '39816397', 'name': 'N. Mason'}, {'authorId': '4301568', 'name': 'T. Massad'}, {'authorId': '47824460', 'name': 'J. Masse'}, {'authorId': '2785090', 'name': 'I. Mayrose'}, {'authorId': '2104308101', 'name': 'James K McCarthy'}, {'authorId': '39124401', 'name': 'M. L. McCormack'}, {'authorId': '4104463', 'name': 'K. McCulloh'}, {'authorId': '65878153', 'name': 'Ian R. McFadden'}, {'authorId': '2357130', 'name': 'B. McGill'}, {'authorId': '81940199', 'name': 'M. McPartland'}, {'authorId': '2295523', 'name': 'J. Medeiros'}, {'authorId': '4582588', 'name': 'B. Medlyn'}, {'authorId': '40591032', 'name': 'P. Meerts'}, {'authorId': '5124169', 'name': 'Z. Mehrabi'}, {'authorId': '144938923', 'name': 'P. Meir'}, {'authorId': '19168759', 'name': 'F. Melo'}, {'authorId': '4457448', 'name': 'Maurizio Mencuccini'}, {'authorId': '5934410', 'name': 'C. Meredieu'}, {'authorId': '47402644', 'name': 'J. Messier'}, {'authorId': '36847271', 'name': 'I. M\u00e9sz\u00e1ros'}, {'authorId': '4145431', 'name': 'J. Metsaranta'}, {'authorId': '4073878', 'name': 'S. Michaletz'}, {'authorId': '15262203', 'name': 'Chrysanthi Michelaki'}, {'authorId': '6015192', 'name': 'S. Migalina'}, {'authorId': '6518156', 'name': 'R. Milla'}, {'authorId': '51159976', 'name': 'Jesse E. D. Miller'}, {'authorId': '50685138', 'name': 'V. Minden'}, {'authorId': '144994897', 'name': 'R. Ming'}, {'authorId': '6338094', 'name': 'K. Mokany'}, {'authorId': '152483579', 'name': 'A. Moles'}, {'authorId': '145098440', 'name': 'A. Moln\u00e1r'}, {'authorId': '5202944', 'name': 'J. Molofsky'}, {'authorId': '89583003', 'name': 'Martin Molz'}, {'authorId': '23708706', 'name': 'R. Montgomery'}, {'authorId': '6633814', 'name': 'A. Monty'}, {'authorId': '6027604', 'name': 'L. Moravcov\u00e1'}, {'authorId': '1401991063', 'name': '\u00c1lvaro Moreno-Mart\u00ednez'}, {'authorId': '145045957', 'name': 'M. Moretti'}, {'authorId': '65875606', 'name': 'A. Mori'}, {'authorId': '17070467', 'name': 'S. Mori'}, {'authorId': '50413065', 'name': 'D. Morris'}, {'authorId': '2048639946', 'name': 'J. Morrison'}, {'authorId': '5272131', 'name': 'L. Mucina'}, {'authorId': '50544305', 'name': 'Sandra Mueller'}, {'authorId': '3380957', 'name': 'C. Muir'}, {'authorId': '12610357', 'name': 'S. M\u00fcller'}, {'authorId': '143930869', 'name': 'F. Munoz'}, {'authorId': '1398968975', 'name': 'I. Myers-Smith'}, {'authorId': '6215094', 'name': 'R. Myster'}, {'authorId': '40009028', 'name': 'M. Nagano'}, {'authorId': '32373985', 'name': 'S. Naidu'}, {'authorId': '30811730', 'name': 'Ayyappan Narayanan'}, {'authorId': '2023609437', 'name': 'Balachandran Natesan'}, {'authorId': '89358325', 'name': 'Luka Negoita'}, {'authorId': '143752163', 'name': 'A. Nelson'}, {'authorId': '6751355', 'name': 'E. Neuschulz'}, {'authorId': '144406080', 'name': 'J. Ni'}, {'authorId': '1797103', 'name': 'G. Niedrist'}, {'authorId': '144208071', 'name': 'Jhon Nieto'}, {'authorId': '4316676', 'name': '\u00dc. Niinemets'}, {'authorId': '50391625', 'name': 'R. Nolan'}, {'authorId': '48425863', 'name': 'H. Nottebrock'}, {'authorId': '2575445', 'name': 'Y. Nouvellon'}, {'authorId': '3164477', 'name': 'A. Novakovskiy'}, {'authorId': '2366245', 'name': 'K. Nystuen'}, {'authorId': '1399131508', 'name': \"A. O'Grady\"}, {'authorId': '52247833', 'name': 'K. O\u2019Hara'}, {'authorId': '1402144895', 'name': 'A. O\u2019Reilly-Nugent'}, {'authorId': '3579492', 'name': 'S. Oakley'}, {'authorId': '4926798', 'name': 'W. Oberhuber'}, {'authorId': '49573263', 'name': 'T. Ohtsuka'}, {'authorId': '153714436', 'name': 'R. Oliveira'}, {'authorId': '15539009', 'name': 'Kinga \u00d6llerer'}, {'authorId': '7425921', 'name': 'M. Olson'}, {'authorId': '5283502', 'name': 'V. Onipchenko'}, {'authorId': '5638423', 'name': 'Y. Onoda'}, {'authorId': '14187723', 'name': 'Renske E. Onstein'}, {'authorId': '27540187', 'name': 'J. Ordo\u00f1ez'}, {'authorId': '34791159', 'name': 'N. Osada'}, {'authorId': '4254890', 'name': 'I. Ostonen'}, {'authorId': '35375933', 'name': 'G. Ottaviani'}, {'authorId': '1836426', 'name': 'S. Otto'}, {'authorId': '50232654', 'name': 'G. Overbeck'}, {'authorId': '4949184', 'name': 'W. Ozinga'}, {'authorId': '9811180', 'name': 'A. Pahl'}, {'authorId': '144165742', 'name': 'C. E. T. Paine'}, {'authorId': '5133353', 'name': 'R. Pakeman'}, {'authorId': '144131483', 'name': 'A. Papageorgiou'}, {'authorId': '1471902078', 'name': 'Evgeniya Parfionova'}, {'authorId': '2373976', 'name': 'M. P\u00e4rtel'}, {'authorId': '83854581', 'name': 'Marco Patacca'}, {'authorId': '40097048', 'name': 'S. Paula'}, {'authorId': '6102164', 'name': 'Juraj Paule'}, {'authorId': '145795937', 'name': 'H. Pauli'}, {'authorId': '3177876', 'name': 'J. Pausas'}, {'authorId': '6089548', 'name': 'B. Peco'}]","949":"[{'authorId': '2052212417', 'name': 'Ning Yu'}, {'authorId': '49243436', 'name': 'Ke Li'}, {'authorId': '2113325955', 'name': 'Peng Zhou'}, {'authorId': '153652147', 'name': 'J. Malik'}, {'authorId': '2069321324', 'name': 'Larry Davis'}, {'authorId': '1739548', 'name': 'Mario Fritz'}]","950":"[{'authorId': '1576480073', 'name': 'Fabrice Harel-Canada'}, {'authorId': '2151976110', 'name': 'Lingxiao Wang'}, {'authorId': '33828413', 'name': 'Muhammad Ali Gulzar'}, {'authorId': '9937103', 'name': 'Quanquan Gu'}, {'authorId': '35710133', 'name': 'Miryung Kim'}]","951":"[{'authorId': '152644758', 'name': 'Ling Liu'}, {'authorId': '5855965', 'name': 'Yiqing Zhou'}, {'authorId': '143887379', 'name': 'W. Zhuang'}, {'authorId': '143910093', 'name': 'Jinhong Yuan'}, {'authorId': '144580742', 'name': 'Lin Tian'}]","952":"[{'authorId': '51006560', 'name': 'Damian Szklarczyk'}, {'authorId': '40833431', 'name': 'Annika L. Gable'}, {'authorId': '3974904', 'name': 'Katerina C. Nastou'}, {'authorId': '2059127322', 'name': 'D. Lyon'}, {'authorId': '34981869', 'name': 'Rebecca Kirsch'}, {'authorId': '1708916', 'name': 'Sampo Pyysalo'}, {'authorId': '50391572', 'name': 'N. Doncheva'}, {'authorId': '2699077', 'name': 'M. Legeay'}, {'authorId': '2057025915', 'name': 'T. Fang'}, {'authorId': '3534315', 'name': 'P. Bork'}, {'authorId': '2214567', 'name': 'L. Jensen'}, {'authorId': '2544559', 'name': 'C. V. Mering'}]","953":"[{'authorId': '19203468', 'name': 'Ali Jahanian'}, {'authorId': '51322829', 'name': 'Lucy Chai'}, {'authorId': '2094770', 'name': 'Phillip Isola'}]","954":"[{'authorId': '2342592', 'name': 'N. Lenssen'}, {'authorId': '37931449', 'name': 'G. Schmidt'}, {'authorId': '1723191', 'name': 'J. Hansen'}, {'authorId': '40006660', 'name': 'M. Menne'}, {'authorId': '133646586', 'name': 'Avraham Persin'}, {'authorId': '40686158', 'name': 'R. Ruedy'}, {'authorId': '133868747', 'name': 'Daniel Zyss'}]","955":"[{'authorId': '2072080518', 'name': 'Joshua Feldman'}, {'authorId': '48776237', 'name': 'Joe Davison'}, {'authorId': '2531268', 'name': 'Alexander M. Rush'}]","956":"[{'authorId': '36915272', 'name': 'C. Blanco'}, {'authorId': '40236121', 'name': 'Evan Janzen'}, {'authorId': '50782844', 'name': 'Abe Pressman'}, {'authorId': '3487521', 'name': 'R. Saha'}, {'authorId': '144775593', 'name': 'I. Chen'}]","957":"[{'authorId': '144683061', 'name': 'S. M. Moosavi'}, {'authorId': '36554532', 'name': 'A. Nandy'}, {'authorId': '134251468', 'name': 'K. Jablonka'}, {'authorId': '17711197', 'name': 'D. Ongari'}, {'authorId': '49898352', 'name': 'J. Janet'}, {'authorId': '8775508', 'name': 'Peter G. Boyd'}, {'authorId': '2145416165', 'name': 'Yongjin Lee'}, {'authorId': '144189527', 'name': 'B. Smit'}, {'authorId': '3434648', 'name': 'H. Kulik'}]","958":"[{'authorId': '48577290', 'name': 'Amanda Coston'}, {'authorId': '2820009', 'name': 'Neel Guha'}, {'authorId': '100964532', 'name': 'Derek Ouyang'}, {'authorId': '2152517945', 'name': 'L. Lu'}, {'authorId': '2082393', 'name': 'A. Chouldechova'}, {'authorId': '40688328', 'name': 'Daniel E. Ho'}]","959":"[{'authorId': '6033796', 'name': 'V. Steen'}, {'authorId': '2371015', 'name': 'C. Elphick'}, {'authorId': '6348771', 'name': 'M. Tingley'}]","960":"[{'authorId': '2848828', 'name': 'Zhongjun (Mark) Jin'}, {'authorId': '2110683475', 'name': 'Mengjing Xu'}, {'authorId': '1726046634', 'name': 'Chenkai Sun'}, {'authorId': '1717283', 'name': 'Abolfazl Asudeh'}, {'authorId': '1394934985', 'name': 'H. V. Jagadish'}]","961":"[{'authorId': '2117033724', 'name': 'Yin Lin'}, {'authorId': '148390943', 'name': 'Yifan Guan'}, {'authorId': '1717283', 'name': 'Abolfazl Asudeh'}, {'authorId': '1394934985', 'name': 'H. V. Jagadish'}]","962":"[{'authorId': '2146652203', 'name': 'Jie Liu'}, {'authorId': '145837716', 'name': 'Xiao Yan'}, {'authorId': '81329448', 'name': 'XINYAN DAI'}, {'authorId': '2109623846', 'name': 'Zhirong Li'}, {'authorId': '1717691', 'name': 'James Cheng'}, {'authorId': '2150427580', 'name': 'Ming Yang'}]","963":"[{'authorId': '2034354321', 'name': 'Shubham Sharma'}, {'authorId': '2108127520', 'name': 'Yunfeng Zhang'}, {'authorId': '1491594309', 'name': 'J. Aliaga'}, {'authorId': '1744675', 'name': 'Djallel Bouneffouf'}, {'authorId': '46761645', 'name': 'Vinod Muthusamy'}, {'authorId': '1712865', 'name': 'K. Varshney'}]","964":"[{'authorId': '2373965', 'name': 'Zhi Da'}, {'authorId': '3377448', 'name': 'Umit G. Gurun'}, {'authorId': '46708279', 'name': 'B. Li'}, {'authorId': '1856468', 'name': 'M. Warachka'}]","965":"[{'authorId': '78427612', 'name': 'Sebastian Anzinger'}, {'authorId': '50170441', 'name': 'Christian Bretthauer'}, {'authorId': '153022242', 'name': 'J. Manz'}, {'authorId': '2345918', 'name': 'U. Krumbein'}, {'authorId': '3122909', 'name': 'A. Dehe'}]","966":"[{'authorId': '2065740541', 'name': 'Emily Wall'}, {'authorId': '1471443568', 'name': 'Arup Arcalgud'}, {'authorId': '2066789564', 'name': 'Kuhu Gupta'}, {'authorId': '2064142802', 'name': 'Andrew Jo'}]","967":"[{'authorId': '8274439', 'name': 'Guiming Zhang'}]","968":"[{'authorId': '1381900594', 'name': 'Yizhu Jiao'}, {'authorId': '33629364', 'name': 'Yun Xiong'}, {'authorId': '1718428', 'name': 'Jiawei Zhang'}, {'authorId': '49889358', 'name': 'Yao Zhang'}, {'authorId': '2146332011', 'name': 'Tianqi Zhang'}, {'authorId': '8247706', 'name': 'Yangyong Zhu'}]","969":"[{'authorId': '2756380', 'name': 'Felix Beierle'}, {'authorId': '2067019123', 'name': 'T. Eichinger'}]","970":"[{'authorId': '39496312', 'name': 'A. S\u00eerbu'}, {'authorId': '1693341', 'name': 'D. Pedreschi'}, {'authorId': '1685102', 'name': 'F. Giannotti'}, {'authorId': '3141455', 'name': 'J. Kert\u00e9sz'}]","971":"[{'authorId': '48426386', 'name': 'H. Takeuchi'}, {'authorId': '30978801', 'name': 'K. Yoshikawa'}, {'authorId': '32402180', 'name': 'Y. Takei'}, {'authorId': '50164466', 'name': 'Y. Oki'}, {'authorId': '48742628', 'name': 'S. Kikuchi'}, {'authorId': '47969458', 'name': 'H. Ikeda'}, {'authorId': '39224235', 'name': 'S. Soldini'}, {'authorId': '46326062', 'name': 'N. Ogawa'}, {'authorId': '2953898', 'name': 'Y. Mimasu'}, {'authorId': '86944698', 'name': 'G. Ono'}, {'authorId': '2298771', 'name': 'F. Terui'}, {'authorId': '144005464', 'name': 'N. Sakatani'}, {'authorId': '52464988', 'name': 'M. Yamada'}, {'authorId': '38390863', 'name': 'T. Kouyama'}, {'authorId': '23405975', 'name': 'S. Kameda'}, {'authorId': '145196261', 'name': 'T. Saiki'}, {'authorId': '3069465', 'name': 'Y. Tsuda'}]","972":"[{'authorId': '2107445405', 'name': 'M. S. Rahman'}, {'authorId': '145478828', 'name': 'J. Yau'}]","973":"[{'authorId': '34980535', 'name': 'Doug J. Chung'}, {'authorId': '12484312', 'name': 'Byungyeon Kim'}, {'authorId': '2111272272', 'name': 'Byoung G. Park'}]","974":"[{'authorId': '7236454', 'name': 'Suhyeong Choi'}, {'authorId': '144224500', 'name': 'Seongbo Shim'}, {'authorId': '143869968', 'name': 'Youngsoo Shin'}]","975":"[{'authorId': '51045236', 'name': 'Zohreh Ovaisi'}, {'authorId': '40757149', 'name': 'Ragib Ahsan'}, {'authorId': '2108463891', 'name': 'Yifan Zhang'}, {'authorId': '8067930', 'name': 'K. Vasilaky'}, {'authorId': '2392370', 'name': 'E. Zheleva'}]","976":"[{'authorId': '2115013', 'name': 'Yae Jee Cho'}, {'authorId': '30880777', 'name': 'Jianyu Wang'}, {'authorId': '144225970', 'name': 'Gauri Joshi'}]","977":"[{'authorId': '48634137', 'name': 'Zhe Zhao'}, {'authorId': '2217278', 'name': 'Lichan Hong'}, {'authorId': '2113554448', 'name': 'Li Wei'}, {'authorId': '2144168512', 'name': 'Jilin Chen'}, {'authorId': '3046228', 'name': 'A. Nath'}, {'authorId': '2054883439', 'name': 'Shawn Andrews'}, {'authorId': '1394490096', 'name': 'Aditee Kumthekar'}, {'authorId': '3221924', 'name': 'M. Sathiamoorthy'}, {'authorId': '2838461', 'name': 'Xinyang Yi'}, {'authorId': '2226805', 'name': 'Ed H. Chi'}]","978":"[{'authorId': '2716643', 'name': 'D. Darriba'}, {'authorId': '143610178', 'name': 'D. Posada'}, {'authorId': '48086053', 'name': 'Alexey M. Kozlov'}, {'authorId': '143958048', 'name': 'A. Stamatakis'}, {'authorId': '1388149436', 'name': 'Benoit Morel'}, {'authorId': '3357808', 'name': 'T. Flouri'}]","979":"[{'authorId': '153741783', 'name': 'T. Papakonstantinou'}, {'authorId': '3921629', 'name': 'A. Nikolakopoulou'}, {'authorId': '27367111', 'name': 'J. Higgins'}, {'authorId': '46915081', 'name': 'M. Egger'}, {'authorId': '5186748', 'name': 'G. Salanti'}]","980":"[{'authorId': '22472831', 'name': 'Yuchi Tian'}, {'authorId': '30188141', 'name': 'Ziyuan Zhong'}, {'authorId': '2004053', 'name': 'Vicente Ordonez'}, {'authorId': '1694056', 'name': 'G. Kaiser'}, {'authorId': '31631000', 'name': 'Baishakhi Ray'}]","981":"[{'authorId': '151112226', 'name': 'Michael F\u00e4rber'}, {'authorId': '1774986', 'name': 'A. Jatowt'}]","982":"[{'authorId': '2026545715', 'name': 'Preslav Nakov'}, {'authorId': '1772206', 'name': 'H. Sencar'}, {'authorId': '40660541', 'name': 'Jisun An'}, {'authorId': '2592694', 'name': 'Haewoon Kwak'}]","983":"[{'authorId': '1456009348', 'name': 'Chenguang Zhu'}, {'authorId': '2155459391', 'name': 'Ziyi Yang'}, {'authorId': '2983603', 'name': 'R. Gmyr'}, {'authorId': '48262024', 'name': 'Michael Zeng'}, {'authorId': '144531812', 'name': 'Xuedong Huang'}]","984":"[{'authorId': '1380259269', 'name': 'Jamell Dacon'}, {'authorId': '2143856455', 'name': 'Haochen Liu'}]","985":"[{'authorId': '2087122322', 'name': 'Jingwei Yi'}, {'authorId': '2397264', 'name': 'Fangzhao Wu'}, {'authorId': '2118839668', 'name': 'Chuhan Wu'}, {'authorId': '2141309833', 'name': 'Qifei Li'}, {'authorId': '39109247', 'name': 'Guang-zhong Sun'}, {'authorId': '144076239', 'name': 'Xing Xie'}]","986":"[{'authorId': '1845794923', 'name': 'Timo Spinde'}, {'authorId': '3461253', 'name': 'Felix Hamborg'}, {'authorId': '145151838', 'name': 'Bela Gipp'}]","987":"[{'authorId': '2061106122', 'name': 'Benjamin D. Horne'}, {'authorId': '1770033', 'name': 'Dorit Nevo'}, {'authorId': '120372931', 'name': \"J. O'Donovan\"}, {'authorId': '2779190', 'name': 'Jin-Hee Cho'}, {'authorId': '3139418', 'name': 'Sibel Adali'}]","988":"[{'authorId': '41135268', 'name': 'Rama Rohit Reddy Gangula'}, {'authorId': '150294927', 'name': 'Suma Reddy Duggenpudi'}, {'authorId': '1829635', 'name': 'R. Mamidi'}]","989":"[{'authorId': '8652308', 'name': 'Chenguang Zhu'}, {'authorId': '2155459391', 'name': 'Ziyi Yang'}, {'authorId': '2983603', 'name': 'R. Gmyr'}, {'authorId': '48262024', 'name': 'Michael Zeng'}, {'authorId': '144531812', 'name': 'Xuedong Huang'}]","990":"[{'authorId': '15132048', 'name': 'Marco Morik'}, {'authorId': '2872310', 'name': 'Ashudeep Singh'}, {'authorId': '2110641603', 'name': 'Jessica Hong'}, {'authorId': '1680188', 'name': 'T. Joachims'}]","991":"[{'authorId': '2111884170', 'name': 'Wen Chen'}, {'authorId': '38844751', 'name': 'Diogo Pacheco'}, {'authorId': '31014271', 'name': 'Kai-Cheng Yang'}, {'authorId': '143653472', 'name': 'F. Menczer'}]","992":"[{'authorId': '33585083', 'name': 'Melvin Wevers'}]","993":"[{'authorId': '15161448', 'name': 'Chuhan Wu'}, {'authorId': '2397264', 'name': 'Fangzhao Wu'}, {'authorId': '2108045320', 'name': 'Xiting Wang'}, {'authorId': '1731776', 'name': 'Yongfeng Huang'}, {'authorId': '144076239', 'name': 'Xing Xie'}]","994":"[{'authorId': '133801460', 'name': 'Calum Thornhill'}, {'authorId': '134614216', 'name': 'Quentin Meeus'}, {'authorId': '47854580', 'name': 'J. Peperkamp'}, {'authorId': '2990203', 'name': 'Bettina Berendt'}]","995":"[{'authorId': '1845794923', 'name': 'Timo Spinde'}]","996":"[{'authorId': '8729899', 'name': 'Yingtong Dou'}, {'authorId': '145800151', 'name': 'Kai Shu'}, {'authorId': '1850373603', 'name': 'Congyin Xia'}, {'authorId': '144019071', 'name': 'Philip S. Yu'}, {'authorId': '49755259', 'name': 'Lichao Sun'}]","997":"[{'authorId': '2105675738', 'name': 'Jihyung Moon'}, {'authorId': '153091253', 'name': 'Won Ik Cho'}, {'authorId': '46663293', 'name': 'Junbum Lee'}]","998":"[{'authorId': '101217602', 'name': 'So-jeong Lim'}, {'authorId': '1774986', 'name': 'A. Jatowt'}, {'authorId': '151112226', 'name': 'Michael F\u00e4rber'}, {'authorId': '1740865', 'name': 'M. Yoshikawa'}]","999":"[{'authorId': '90031160', 'name': 'Jeppe N\u00f8rregaard'}, {'authorId': '2061106122', 'name': 'Benjamin D. Horne'}, {'authorId': '3139418', 'name': 'Sibel Adali'}]","1000":"[{'authorId': '34845167', 'name': 'Antino Kim'}, {'authorId': '1718617', 'name': 'A. Dennis'}]","1001":"[{'authorId': '52202443', 'name': 'Patricia L. Moravec'}, {'authorId': '3255946', 'name': 'Randall K. Minas'}, {'authorId': '1718617', 'name': 'A. Dennis'}]","1002":"[{'authorId': '10726253', 'name': 'Lia Bozarth'}, {'authorId': '1759771', 'name': 'Ceren Budak'}]","1003":"[{'authorId': '2848024', 'name': 'Yotam Shmargad'}, {'authorId': '35174214', 'name': 'Samara Klar'}]","1004":"[{'authorId': '51961836', 'name': 'Marina Danchovsky Ibrishimova'}, {'authorId': '6763090', 'name': 'K. F. Li'}]","1005":"[{'authorId': '46952961', 'name': 'Federica Lago'}, {'authorId': '7856141', 'name': 'Quoc-Tin Phan'}, {'authorId': '2430707', 'name': 'G. Boato'}]","1006":"[{'authorId': '22176776', 'name': 'Mahak Goindani'}, {'authorId': '144050371', 'name': 'Jennifer Neville'}]","1007":"[{'authorId': '3312309', 'name': 'Yonatan Bisk'}, {'authorId': '2545335', 'name': 'Rowan Zellers'}, {'authorId': '39227408', 'name': 'Ronan Le Bras'}, {'authorId': '48441311', 'name': 'Jianfeng Gao'}, {'authorId': '1699545', 'name': 'Yejin Choi'}]","1008":"[{'authorId': '145137850', 'name': 'Katherine A. Keith'}, {'authorId': '2057064256', 'name': 'David D. Jensen'}, {'authorId': '1401020033', 'name': 'Brendan O\u2019Connor'}]","1009":"[{'authorId': '1741815151', 'name': 'Rava Azeredo da Silveira'}, {'authorId': '38203896', 'name': 'Yeji Sung'}, {'authorId': '4887754', 'name': 'M. Woodford'}]","1010":"[{'authorId': '97638739', 'name': 'Taehee Jung'}, {'authorId': '48493368', 'name': 'Dongyeop Kang'}, {'authorId': '3422652', 'name': 'L. Mentch'}, {'authorId': '144547315', 'name': 'E. Hovy'}]","1011":"[{'authorId': '1379925776', 'name': 'Yoan Dinkov'}, {'authorId': '2141768778', 'name': 'Ahmed Ali'}, {'authorId': '52553663', 'name': 'Ivan Koychev'}, {'authorId': '1683562', 'name': 'Preslav Nakov'}]","1012":"[{'authorId': '50329599', 'name': 'Tao Qi'}, {'authorId': '2397264', 'name': 'Fangzhao Wu'}, {'authorId': '2118839668', 'name': 'Chuhan Wu'}, {'authorId': '1731776', 'name': 'Yongfeng Huang'}]","1013":"[{'authorId': '32271841', 'name': 'M. A. Britt'}, {'authorId': '2489083', 'name': 'J. Rouet'}, {'authorId': '2034108', 'name': 'Dylan Blaum'}, {'authorId': '1777817', 'name': 'K. Millis'}]","1014":"[{'authorId': '41190798', 'name': 'Franziska Zimmer'}, {'authorId': '51060517', 'name': 'Katrin Scheibe'}, {'authorId': '32003132', 'name': 'M. Stock'}, {'authorId': '2477051', 'name': 'Wolfgang G. Stock'}]","1015":"[{'authorId': '153401328', 'name': 'Yijun Duan'}, {'authorId': '1774986', 'name': 'A. Jatowt'}]","1016":"[{'authorId': '51439912', 'name': 'Ye Ma'}, {'authorId': '48373979', 'name': 'Lu Zong'}, {'authorId': '2142549235', 'name': 'Yikang Yang'}, {'authorId': '40233076', 'name': 'Jionglong Su'}]","1017":"[{'authorId': '113796187', 'name': 'Shaina Raza'}, {'authorId': '144835980', 'name': 'Chen Ding'}]","1018":"[{'authorId': '3243116', 'name': 'Weichang Wu'}, {'authorId': '2313243', 'name': 'Huanxi Liu'}, {'authorId': '2108584373', 'name': 'Xiaohu Zhang'}, {'authorId': '2146402774', 'name': 'Yu Liu'}, {'authorId': '145203884', 'name': 'H. Zha'}]","1019":"[{'authorId': '49683525', 'name': 'Kirsten E. Martin'}]","1020":"[{'authorId': '101222809', 'name': 'S. Kucinskas'}, {'authorId': '1738550597', 'name': 'Florian S. Peters'}]","1021":"[{'authorId': '29891652', 'name': 'Anne Lauscher'}, {'authorId': '2007649680', 'name': 'Rafik Takieddin'}, {'authorId': '1801255', 'name': 'Simone Paolo Ponzetto'}, {'authorId': '2472657', 'name': 'Goran Glavas'}]","1022":"[{'authorId': '1380203356', 'name': 'Fantahun Gereme'}, {'authorId': '145517018', 'name': 'William Zhu'}]","1023":"[{'authorId': '49687960', 'name': 'Galen Cassebeer Weld'}, {'authorId': '2046282', 'name': 'M. Glenski'}, {'authorId': '1745524', 'name': 'Tim Althoff'}]","1024":"[{'authorId': '49549996', 'name': 'Miguel A. Alonso'}, {'authorId': '3259155', 'name': 'David Vilares'}, {'authorId': '1388759404', 'name': 'C. G\u00f3mez-Rodr\u00edguez'}, {'authorId': '3252869', 'name': 'Jes\u00fas Vilares'}]","1025":"[{'authorId': '2157945536', 'name': 'Ruey-Cheng Chen'}, {'authorId': '144922928', 'name': 'Qingyao Ai'}, {'authorId': '2438393', 'name': 'Gaya K. Jayasinghe'}, {'authorId': '144456145', 'name': 'W. Bruce Croft'}]","1026":"[{'authorId': '2097949114', 'name': 'Matt Grenander'}, {'authorId': '49265991', 'name': 'Yue Dong'}, {'authorId': '3159752', 'name': 'J. C. Cheung'}, {'authorId': '1767336', 'name': 'Annie Louis'}]","1027":"[{'authorId': '25568009', 'name': 'M. Behroozi'}, {'authorId': '1765101', 'name': 'Chris Parnin'}, {'authorId': '1686613', 'name': 'Titus Barik'}]","1028":"[{'authorId': '2391370', 'name': 'Elissa M. Redmiles'}, {'authorId': '2630296', 'name': 'Sean Kross'}, {'authorId': '37176218', 'name': 'Michelle L. Mazurek'}]","1029":"[{'authorId': '121937604', 'name': 'Ziyi Yang'}, {'authorId': '8652308', 'name': 'Chenguang Zhu'}, {'authorId': '2983603', 'name': 'R. Gmyr'}, {'authorId': '48262024', 'name': 'Michael Zeng'}, {'authorId': '144531812', 'name': 'Xuedong Huang'}]","1030":"[{'authorId': '52381343', 'name': 'Anu Shrestha'}, {'authorId': '1794160', 'name': 'Francesca Spezzano'}]","1031":"[{'authorId': '1775511', 'name': 'M. Cha'}, {'authorId': '145816335', 'name': 'Wei Gao'}, {'authorId': '2144231489', 'name': 'Cheng-Te Li'}]","1032":"[{'authorId': '5182072', 'name': 'Ana-Andreea Stoica'}, {'authorId': '1643347009', 'name': 'Jessy Xinyi Han'}, {'authorId': '2775909', 'name': 'A. Chaintreau'}]","1033":"[{'authorId': '145066132', 'name': 'Bin Guo'}, {'authorId': '151260226', 'name': 'Yasan Ding'}, {'authorId': '1789944', 'name': 'Yueheng Sun'}, {'authorId': '47325834', 'name': 'Shuai Ma'}, {'authorId': '2149142384', 'name': 'Ke Li'}]","1034":"[{'authorId': '26913292', 'name': 'A. S. C. Melo'}, {'authorId': '1739660', 'name': 'L. Marinho'}, {'authorId': '1685147', 'name': 'Adriano Veloso'}]","1035":"[{'authorId': '144724775', 'name': 'Vivek K. Singh'}, {'authorId': '3247454', 'name': 'M. Chayko'}, {'authorId': '1454196769', 'name': 'Raj Inamdar'}, {'authorId': '51167132', 'name': 'Diana Floegel'}]","1036":"[{'authorId': '36560654', 'name': 'T. G. van der Meer'}, {'authorId': '25646210', 'name': 'M. Hameleers'}]","1037":"[{'authorId': '143683394', 'name': 'Svitlana Volkova'}, {'authorId': '27558137', 'name': 'Ellyn Ayton'}, {'authorId': '1832594', 'name': 'Dustin L. Arendt'}, {'authorId': '10742505', 'name': 'Zhuanyi Huang'}, {'authorId': '144156036', 'name': 'Brian Hutchinson'}]","1038":"[{'authorId': '34574116', 'name': 'Marija Stanojevic'}, {'authorId': '151041487', 'name': 'Jumanah Alshehri'}, {'authorId': '1825318', 'name': 'Eduard Constantin Dragut'}, {'authorId': '3844766', 'name': 'Z. Obradovic'}]","1039":"[{'authorId': '145826863', 'name': 'Abdelrhman Saleh'}, {'authorId': '3490018', 'name': 'R. Baly'}, {'authorId': '1397442049', 'name': 'Alberto Barr\u00f3n-Cede\u00f1o'}, {'authorId': '34086979', 'name': 'Giovanni Da San Martino'}, {'authorId': '1754057', 'name': 'Mitra Mohtarami'}, {'authorId': '1683562', 'name': 'Preslav Nakov'}, {'authorId': '145898106', 'name': 'James R. Glass'}]","1040":"[{'authorId': '1410926560', 'name': 'Hani Al-Omari'}, {'authorId': '19265487', 'name': 'Malak Abdullah'}, {'authorId': '1453623335', 'name': 'Ola Altiti'}, {'authorId': '145102721', 'name': 'Samira Shaikh'}]","1041":"[{'authorId': '2502685', 'name': 'Xinzhi Wang'}, {'authorId': '2005310540', 'name': 'Luyao Kou'}, {'authorId': '1802251', 'name': 'V. Sugumaran'}, {'authorId': '2167614', 'name': 'Xiangfeng Luo'}, {'authorId': '2153729460', 'name': 'Hui Zhang'}]","1042":"[{'authorId': '1753737512', 'name': 'Jaynil Gaglani'}, {'authorId': '1753737863', 'name': 'Yash Gandhi'}, {'authorId': '1753737760', 'name': 'Shubham Gogate'}, {'authorId': '51439323', 'name': 'Aparna Halbe'}]","1043":"[{'authorId': '2059894216', 'name': 'James McInerney'}, {'authorId': '2001134027', 'name': 'B. Brost'}, {'authorId': '2667305', 'name': 'Praveen Chandar'}, {'authorId': '39718171', 'name': 'Rishabh Mehrotra'}, {'authorId': '1750995', 'name': 'Ben Carterette'}]","1044":"[{'authorId': '2133312527', 'name': 'Timo Spinde'}, {'authorId': '2135030875', 'name': 'Manuel Plank'}, {'authorId': '2140442370', 'name': 'Jan-David Krieger'}, {'authorId': '8837621', 'name': 'Terry Ruas'}, {'authorId': '145151838', 'name': 'Bela Gipp'}, {'authorId': '1705519', 'name': 'Akiko Aizawa'}]","1045":"[{'authorId': '72615265', 'name': 'S. KrishnapriyaK.'}, {'authorId': '72322690', 'name': 'K. Vangara'}, {'authorId': '143922787', 'name': 'Michael C. King'}, {'authorId': '51261315', 'name': 'V\u00edtor Albiero'}, {'authorId': '143759604', 'name': 'K. Bowyer'}]","1046":"[{'authorId': '2162344', 'name': 'Eduardo M. Hargreaves'}, {'authorId': '51152896', 'name': 'C. Agosti'}, {'authorId': '1735876', 'name': 'D. Menasch\u00e9'}, {'authorId': '1715333', 'name': 'G. Neglia'}, {'authorId': '2625269', 'name': 'Alexandre Reiffers'}, {'authorId': '143665732', 'name': 'E. Altman'}]","1047":"[{'authorId': '103923952', 'name': 'S. Ganguly'}, {'authorId': '2709512', 'name': 'Juhi Kulshrestha'}, {'authorId': '40660541', 'name': 'Jisun An'}, {'authorId': '2592694', 'name': 'Haewoon Kwak'}]","1048":"[{'authorId': '12061312', 'name': 'Brendan Spillane'}, {'authorId': '1809790', 'name': 'S. Lawless'}, {'authorId': '1715807', 'name': 'V. Wade'}]","1049":"[{'authorId': '79828215', 'name': 'Ali H\u00fcrriyeto\u01e7lu'}, {'authorId': '2185304', 'name': 'Hristo Tanev'}, {'authorId': '2481036', 'name': 'Vanni Zavarella'}, {'authorId': '1678833', 'name': 'J. Piskorski'}, {'authorId': '2819613', 'name': 'R. Yeniterzi'}, {'authorId': '2808366', 'name': 'Deniz Yuret'}, {'authorId': '145585242', 'name': 'Aline Villavicencio'}]","1050":"[{'authorId': '8652308', 'name': 'Chenguang Zhu'}, {'authorId': '121937604', 'name': 'Ziyi Yang'}, {'authorId': '2983603', 'name': 'R. Gmyr'}, {'authorId': '48262024', 'name': 'Michael Zeng'}, {'authorId': '144531812', 'name': 'Xuedong Huang'}]","1051":"[{'authorId': '3418860', 'name': 'Lukas Gebhard'}, {'authorId': '3461253', 'name': 'Felix Hamborg'}]","1052":"[{'authorId': '1781993', 'name': 'E. Pitoura'}, {'authorId': '1680709', 'name': 'G. Koutrika'}, {'authorId': '12619004', 'name': 'K. Stefanidis'}]","1053":"[{'authorId': '22220222', 'name': 'Pinelopi Papalampidi'}, {'authorId': '1393020635', 'name': 'Frank Keller'}, {'authorId': '2875615', 'name': 'Lea Frermann'}, {'authorId': '1747893', 'name': 'Mirella Lapata'}]","1054":"[{'authorId': '145238384', 'name': 'Thomas Nygren'}, {'authorId': '2739130', 'name': 'J. Folkeryd'}, {'authorId': '2629153', 'name': 'Caroline Liberg'}, {'authorId': '2733333', 'name': 'Mona Guath'}]","1055":"[{'authorId': '2070535332', 'name': 'A. Pandey'}, {'authorId': '9221453', 'name': 'V. Tikkiwal'}]","1056":"[{'authorId': '1656712698', 'name': \"Samantha D'Alonzo\"}, {'authorId': '2011933', 'name': 'Max Tegmark'}]","1057":"[{'authorId': '2639305', 'name': 'Marzieh Mozafari'}, {'authorId': '2633697', 'name': 'R. Farahbakhsh'}, {'authorId': '145107973', 'name': 'N. Crespi'}]","1058":"[{'authorId': '20985588', 'name': 'O. Papakyriakopoulos'}, {'authorId': '13641047', 'name': 'J. M. Serrano'}, {'authorId': '3403284', 'name': 'Simon Hegelich'}]","1059":"[{'authorId': '35337798', 'name': 'P. Drozdowski'}, {'authorId': '2005394', 'name': 'C. Rathgeb'}, {'authorId': '3299530', 'name': 'A. Dantcheva'}, {'authorId': '2265721', 'name': 'N. Damer'}, {'authorId': '46347050', 'name': 'C. Busch'}]","1060":"[{'authorId': '2054378953', 'name': 'Thomas Davidson'}, {'authorId': '2052797388', 'name': 'Debasmita Bhattacharya'}, {'authorId': '1684687', 'name': 'Ingmar Weber'}]","1061":"[{'authorId': '20985588', 'name': 'O. Papakyriakopoulos'}, {'authorId': '3403284', 'name': 'Simon Hegelich'}, {'authorId': '13641047', 'name': 'J. M. Serrano'}, {'authorId': '2065062787', 'name': 'Fabienne Marco'}]","1062":"[{'authorId': '10357841', 'name': 'Pinkesh Badjatiya'}, {'authorId': '46722320', 'name': 'Manish Gupta'}, {'authorId': '1704709', 'name': 'Vasudeva Varma'}]","1063":"[{'authorId': '152860987', 'name': 'P. Stefanov'}, {'authorId': '143758717', 'name': 'Kareem Darwish'}, {'authorId': '2063953501', 'name': 'Atanas Atanasov'}, {'authorId': '1683562', 'name': 'Preslav Nakov'}]","1064":"[{'authorId': '145558696', 'name': 'Pascal J\u00fcrgens'}, {'authorId': '1844292960', 'name': 'Birgit Stark'}, {'authorId': '2065495870', 'name': 'M. Magin'}]","1065":"[{'authorId': '2110418636', 'name': 'Yiyi Li'}, {'authorId': '2012752481', 'name': 'Ying Xie'}]","1066":"[{'authorId': '50219006', 'name': 'Zijian Wang'}, {'authorId': '1801223', 'name': 'Scott A. Hale'}, {'authorId': '2518906', 'name': 'David Ifeoluwa Adelani'}, {'authorId': '1907673', 'name': 'Przemyslaw A. Grabowicz'}, {'authorId': '2105567264', 'name': 'Timo Hartmann'}, {'authorId': '1724463', 'name': 'Fabian Fl\u00f6ck'}, {'authorId': '3046220', 'name': 'David Jurgens'}]","1067":"[{'authorId': '2295436', 'name': 'S. Ernala'}, {'authorId': '40124031', 'name': 'M. Birnbaum'}, {'authorId': '38757983', 'name': 'Kristin A. Candan'}, {'authorId': '8055639', 'name': 'A. Rizvi'}, {'authorId': '1945863208', 'name': 'W. A. Sterling'}, {'authorId': '48728447', 'name': 'J. Kane'}, {'authorId': '2583473', 'name': 'M. Choudhury'}]","1068":"[{'authorId': '3362324', 'name': 'Binny Mathew'}, {'authorId': '48480843', 'name': 'Punyajoy Saha'}, {'authorId': '3084761', 'name': 'Seid Muhie Yimam'}, {'authorId': '31565315', 'name': 'Chris Biemann'}, {'authorId': '2111980452', 'name': 'P. Goyal'}, {'authorId': '33392067', 'name': 'Animesh Mukherjee'}]","1069":"[{'authorId': '152446909', 'name': 'Yigal Godler'}, {'authorId': '32040297', 'name': 'Zvi Reich'}, {'authorId': '18440557', 'name': 'Boaz Miller'}]","1070":"[{'authorId': '2510840', 'name': 'Stevie Chancellor'}, {'authorId': '40124031', 'name': 'M. Birnbaum'}, {'authorId': '6831208', 'name': 'E. Caine'}, {'authorId': '1729668', 'name': 'V. Silenzio'}, {'authorId': '2583473', 'name': 'M. Choudhury'}]","1071":"[{'authorId': '69342047', 'name': 'Quentin J. Leclerc'}, {'authorId': '1454212121', 'name': 'Naomi M. Fuller'}, {'authorId': '1805985917', 'name': 'Lisa E. Knight'}, {'authorId': '2262177', 'name': 'S. Funk'}, {'authorId': '1965244', 'name': 'G. Knight'}]","1072":"[{'authorId': '51303224', 'name': 'Jakob Ohme'}, {'authorId': '145398035', 'name': 'T. Araujo'}, {'authorId': '51913730', 'name': 'C. D. De Vreese'}, {'authorId': '31799264', 'name': 'J. Piotrowski'}]","1073":"[{'authorId': '23180033', 'name': 'Y. Gerrard'}, {'authorId': '27740362', 'name': 'H. Thornham'}]","1074":"[{'authorId': '1729547', 'name': 'S. Vaudenay'}]","1075":"[{'authorId': '12619623', 'name': 'K. Saha'}, {'authorId': '153831662', 'name': 'A. Bayraktaroglu'}, {'authorId': '1690035', 'name': 'A. Campbell'}, {'authorId': '144539424', 'name': 'N. Chawla'}, {'authorId': '2583473', 'name': 'M. Choudhury'}, {'authorId': '1383996606', 'name': 'S. D\u2019Mello'}, {'authorId': '144021446', 'name': 'A. Dey'}, {'authorId': '2084530289', 'name': 'Ge Gao'}, {'authorId': '145448811', 'name': 'Julie M. Gregg'}, {'authorId': '3127277', 'name': 'Krithika Jagannath'}, {'authorId': '143750317', 'name': 'G. Mark'}, {'authorId': '143750085', 'name': 'Gonzalo J. Mart\u00ednez'}, {'authorId': '50655657', 'name': 'Stephen M. Mattingly'}, {'authorId': '118204336', 'name': 'E. Moskal'}, {'authorId': '112891427', 'name': 'Anusha Sirigiri'}, {'authorId': '144244615', 'name': 'A. Striegel'}, {'authorId': '117844934', 'name': 'Dong Whi Yoo'}]","1076":"[{'authorId': '1840894', 'name': 'T. Hellstr\u00f6m'}, {'authorId': '71343039', 'name': 'V. Dignum'}, {'authorId': '15618794', 'name': 'Suna Bensch'}]","1077":"[{'authorId': '1485959722', 'name': 'Daniela Jaramillo-Dent'}, {'authorId': '1450387624', 'name': 'M. A. P\u00e9rez-Rodr\u00edguez'}]","1078":"[{'authorId': '2110905214', 'name': 'Jae Yeon Kim'}, {'authorId': '2056889597', 'name': 'Carlos Ortiz'}, {'authorId': '6014565', 'name': 'S. Nam'}, {'authorId': '2070361702', 'name': 'Sarah Santiago'}, {'authorId': '2070936764', 'name': 'Vivek Datta'}]","1079":"[{'authorId': '34086979', 'name': 'Giovanni Da San Martino'}, {'authorId': '2063950160', 'name': \"A. Barr'on-Cedeno\"}, {'authorId': '2626599', 'name': 'Henning Wachsmuth'}, {'authorId': '2065869784', 'name': 'R. Petrov'}, {'authorId': '1683562', 'name': 'Preslav Nakov'}]","1080":"[{'authorId': '46188821', 'name': 'Bilal Ghanem'}, {'authorId': '143752702', 'name': 'Paolo Rosso'}, {'authorId': '133975199', 'name': 'Francisco Rangel'}]","1081":"[{'authorId': '145035467', 'name': 'Xin Du'}, {'authorId': '6830931', 'name': 'Kumiko Tanaka-Ishii'}]","1082":"[{'authorId': '3466801', 'name': 'Prafulla Kumar Choubey'}, {'authorId': '2116043027', 'name': 'A. Lee'}, {'authorId': '40372969', 'name': 'Ruihong Huang'}, {'authorId': '2153518220', 'name': 'Lu Wang'}]","1083":"[{'authorId': '3170717', 'name': 'Aytu\u011f Onan'}, {'authorId': '3058942', 'name': 'Mansur Alp To\u00e7o\u011flu'}]","1084":"[{'authorId': '3235960', 'name': 'Beakcheol Jang'}, {'authorId': '2344096', 'name': 'Inhwan Kim'}, {'authorId': '2145246865', 'name': 'Jong Wook Kim'}]","1085":"[{'authorId': '89545127', 'name': 'Charlotte Rudnik'}, {'authorId': '102836004', 'name': 'Thibault Ehrhart'}, {'authorId': '1679133', 'name': 'Olivier Ferret'}, {'authorId': '35548096', 'name': 'Denis Teyssou'}, {'authorId': '1684267', 'name': 'Raphael Troncy'}, {'authorId': '2404850', 'name': 'Xavier Tannier'}]","1086":"[{'authorId': '2108942', 'name': 'Roshni Chakraborty'}, {'authorId': '7797235', 'name': 'Maitry Bhavsar'}, {'authorId': '1755054', 'name': 'Sourav Kumar Dandapat'}, {'authorId': '39700170', 'name': 'Joydeep Chandra'}]","1087":"[{'authorId': '3461253', 'name': 'Felix Hamborg'}, {'authorId': '2587724', 'name': 'Corinna Breitinger'}, {'authorId': '145151838', 'name': 'Bela Gipp'}]","1088":"[{'authorId': '2111008120', 'name': 'A. Singh'}, {'authorId': '144078801', 'name': 'M. Shashi'}]","1089":"[{'authorId': '123088926', 'name': 'Soonh Taj'}, {'authorId': '88728415', 'name': 'Baby Bakhtawer Shaikh'}, {'authorId': '88729447', 'name': 'Areej Fatemah Meghji'}]","1090":"[{'authorId': '84238312', 'name': 'T. Traylor'}, {'authorId': '82959715', 'name': 'Jerey Straub'}, {'authorId': '66855633', 'name': 'Gurmeet'}, {'authorId': '81915434', 'name': 'Nicholas Snell'}]","1091":"[{'authorId': '1403059899', 'name': 'Anne Oeldorf-Hirsch'}, {'authorId': '2007386', 'name': 'Mike Schmierbach'}, {'authorId': '2741842', 'name': 'A. Appelman'}, {'authorId': '2057315674', 'name': 'Michael P. Boyle'}]","1092":"[{'authorId': '1579818535', 'name': 'P. Patwa'}, {'authorId': '1491627343', 'name': 'Shivam Sharma'}, {'authorId': '1866316662', 'name': 'Srinivas Pykl'}, {'authorId': '1724549065', 'name': 'V. Guptha'}, {'authorId': '2084322185', 'name': 'G. Kumari'}, {'authorId': '46815454', 'name': 'Md. Shad Akhtar'}, {'authorId': '1734904', 'name': 'Asif Ekbal'}, {'authorId': '47295571', 'name': 'A. Das'}, {'authorId': '144054829', 'name': 'Tanmoy Chakraborty'}]","1093":"[{'authorId': '39848715', 'name': 'Wei Li'}, {'authorId': '47883245', 'name': 'Jingjing Xu'}, {'authorId': '49990515', 'name': 'Yancheng He'}, {'authorId': '1892671885', 'name': 'Shengli Yan'}, {'authorId': '2477658', 'name': 'Yunfang Wu'}, {'authorId': '11774802', 'name': 'Xu Sun'}]","1094":"[{'authorId': '2118839668', 'name': 'Chuhan Wu'}, {'authorId': '2397264', 'name': 'Fangzhao Wu'}, {'authorId': '50329599', 'name': 'Tao Qi'}, {'authorId': '1731776', 'name': 'Yongfeng Huang'}]","1095":"[{'authorId': '2397264', 'name': 'Fangzhao Wu'}, {'authorId': '2056923187', 'name': 'Ying Qiao'}, {'authorId': '33926030', 'name': 'Jiun-Hung Chen'}, {'authorId': '15161448', 'name': 'Chuhan Wu'}, {'authorId': '50329599', 'name': 'Tao Qi'}, {'authorId': '2813328', 'name': 'Jianxun Lian'}, {'authorId': '2822590', 'name': 'Danyang Liu'}, {'authorId': '144076239', 'name': 'Xing Xie'}, {'authorId': '1800422', 'name': 'Jianfeng Gao'}, {'authorId': '2110027452', 'name': 'Winnie Wu'}, {'authorId': '143849609', 'name': 'M. Zhou'}]","1096":"[{'authorId': '46188821', 'name': 'Bilal Ghanem'}, {'authorId': '1801255', 'name': 'Simone Paolo Ponzetto'}, {'authorId': '143752702', 'name': 'Paolo Rosso'}, {'authorId': '133975199', 'name': 'Francisco Rangel'}]","1097":"[{'authorId': '9054180', 'name': 'Vivek Kumar Singh'}, {'authorId': '25729116', 'name': 'Isha Ghosh'}, {'authorId': '1721001174', 'name': 'Darshan Sonagara'}]","1098":"[{'authorId': '3376145', 'name': 'Gautam Kishore Shahi'}, {'authorId': '39206055', 'name': 'D. Nandini'}]","1099":"[{'authorId': '1490776655', 'name': 'Xinyi Zhou'}, {'authorId': '72018607', 'name': 'Apurva Mulay'}, {'authorId': '48898287', 'name': 'Emilio Ferrara'}, {'authorId': '2281410', 'name': 'R. Zafarani'}]","1100":"[{'authorId': '1490776655', 'name': 'Xinyi Zhou'}, {'authorId': '46365795', 'name': 'Jindi Wu'}, {'authorId': '2281410', 'name': 'R. Zafarani'}]","1101":"[{'authorId': '46255971', 'name': 'Alexander R. Fabbri'}, {'authorId': '46331602', 'name': 'Irene Li'}, {'authorId': '2106009217', 'name': 'Tianwei She'}, {'authorId': '50341789', 'name': 'Suyi Li'}, {'authorId': '9215251', 'name': 'Dragomir R. Radev'}]","1102":"[{'authorId': '2115793087', 'name': 'Yaqing Wang'}, {'authorId': '2117043884', 'name': 'Weifeng Yang'}, {'authorId': '2988239', 'name': 'Fenglong Ma'}, {'authorId': '2110639436', 'name': 'Jin Xu'}, {'authorId': '2061200345', 'name': 'Bin Zhong'}, {'authorId': '2056197580', 'name': 'Qiang Deng'}, {'authorId': '144407304', 'name': 'Jing Gao'}]","1103":"[{'authorId': '34086979', 'name': 'Giovanni Da San Martino'}, {'authorId': '1885974', 'name': 'Seunghak Yu'}, {'authorId': '1397442049', 'name': 'Alberto Barr\u00f3n-Cede\u00f1o'}, {'authorId': '2065869784', 'name': 'R. Petrov'}, {'authorId': '1683562', 'name': 'Preslav Nakov'}]","1104":"[{'authorId': '1792599', 'name': 'T. Ruokolainen'}, {'authorId': '47053843', 'name': 'Pekka Kauppinen'}, {'authorId': '2614548', 'name': 'Miikka Silfverberg'}, {'authorId': '13206584', 'name': 'Krister Lind\u00e9n'}]","1105":"[{'authorId': '2822590', 'name': 'Danyang Liu'}, {'authorId': '2813328', 'name': 'Jianxun Lian'}, {'authorId': '50695615', 'name': 'Shiyin Wang'}, {'authorId': '2056923187', 'name': 'Ying Qiao'}, {'authorId': '33926030', 'name': 'Jiun-Hung Chen'}, {'authorId': '39109247', 'name': 'Guang-zhong Sun'}, {'authorId': '144076239', 'name': 'Xing Xie'}]","1106":"[{'authorId': '2319272', 'name': 'Dhruv Khattar'}, {'authorId': '88840103', 'name': 'Jaipal Singh Goud'}, {'authorId': '46722320', 'name': 'Manish Gupta'}, {'authorId': '1704709', 'name': 'Vasudeva Varma'}]","1107":"[{'authorId': '1840075', 'name': 'Johannes Kiesel'}, {'authorId': '144040598', 'name': 'Maria Mestre'}, {'authorId': '121293845', 'name': 'Rishabh Shukla'}, {'authorId': '2035263593', 'name': 'Emmanuel Vincent'}, {'authorId': '9568703', 'name': 'Payam Adineh'}, {'authorId': '3347130', 'name': 'D. Corney'}, {'authorId': '144146081', 'name': 'Benno Stein'}, {'authorId': '3046200', 'name': 'Martin Potthast'}]","1108":"[{'authorId': '50329599', 'name': 'Tao Qi'}, {'authorId': '2397264', 'name': 'Fangzhao Wu'}, {'authorId': '15161448', 'name': 'Chuhan Wu'}, {'authorId': '1731776', 'name': 'Yongfeng Huang'}, {'authorId': '144076239', 'name': 'Xing Xie'}]","1109":"[{'authorId': '9120924', 'name': 'Shivangi Singhal'}, {'authorId': '1735001746', 'name': 'Anubha Kabra'}, {'authorId': '2110360195', 'name': 'Mohit Sharma'}, {'authorId': '1753278', 'name': 'R. Shah'}, {'authorId': '144054829', 'name': 'Tanmoy Chakraborty'}, {'authorId': '1734731', 'name': 'P. Kumaraguru'}]","1110":"[{'authorId': '15161448', 'name': 'Chuhan Wu'}, {'authorId': '2397264', 'name': 'Fangzhao Wu'}, {'authorId': '92701189', 'name': 'Mingxiao An'}, {'authorId': '50535300', 'name': 'Jianqiang Huang'}, {'authorId': '1731776', 'name': 'Yongfeng Huang'}, {'authorId': '144076239', 'name': 'Xing Xie'}]","1111":"[{'authorId': '49167336', 'name': 'Nguyen Vo'}, {'authorId': '2848353', 'name': 'Kyumin Lee'}]","1112":"[{'authorId': '7407022', 'name': 'Anastasia Giahanou'}, {'authorId': '1380215996', 'name': 'E. R\u00edssola'}, {'authorId': '46188821', 'name': 'Bilal Ghanem'}, {'authorId': '145876066', 'name': 'F. Crestani'}, {'authorId': '143752702', 'name': 'Paolo Rosso'}]","1113":"[{'authorId': '2085389970', 'name': 'Heng-Shiou Sheu'}, {'authorId': '2153698893', 'name': 'Sheng Li'}]","1114":"[{'authorId': '7787721', 'name': 'Xiaotao Gu'}, {'authorId': '3375249', 'name': 'Yuning Mao'}, {'authorId': '153034701', 'name': 'Jiawei Han'}, {'authorId': '2746747', 'name': 'Jialu Liu'}, {'authorId': '40244451', 'name': 'Hongkun Yu'}, {'authorId': '1557391861', 'name': 'You Wu'}, {'authorId': '82737548', 'name': 'Cong Yu'}, {'authorId': '1490886761', 'name': 'Daniel Finnie'}, {'authorId': '48017650', 'name': 'Jiaqi Zhai'}, {'authorId': '1490887487', 'name': 'Nicholas Zukoski'}]","1115":"[{'authorId': '3253084', 'name': 'Siva Charan Reddy Gangireddy'}, {'authorId': '1803913519', 'name': 'D. P'}, {'authorId': '2073609384', 'name': 'Cheng Long'}, {'authorId': '144054829', 'name': 'Tanmoy Chakraborty'}]","1116":"[{'authorId': '3447293', 'name': 'Savvas Zannettou'}, {'authorId': '2165346', 'name': 'Mai ElSherief'}, {'authorId': '1397933253', 'name': 'E. Belding-Royer'}, {'authorId': '2267110', 'name': 'Shirin Nilizadeh'}, {'authorId': '2350947', 'name': 'G. Stringhini'}]","1117":"[{'authorId': '113145194', 'name': 'Christiaan Burggraaff'}, {'authorId': '10721627', 'name': 'D. Trilling'}]","1118":"[{'authorId': '1596725015', 'name': 'Hamid Karimi'}, {'authorId': '1736632', 'name': 'Jiliang Tang'}]","1119":"[{'authorId': '1394478017', 'name': 'Fatemeh Torabi Asr'}, {'authorId': '145522054', 'name': 'M. Taboada'}]","1120":"[{'authorId': '2146463849', 'name': 'Saloni Mohan'}, {'authorId': '1394159949', 'name': 'Sahitya Mullapudi'}, {'authorId': '1395349889', 'name': 'Sudheer Sammeta'}, {'authorId': '1396843867', 'name': 'Parag Vijayvergia'}, {'authorId': '2079573', 'name': 'D. Anastasiu'}]","1121":"[{'authorId': '34884946', 'name': 'F. Salem'}, {'authorId': '147901200', 'name': 'Roaa Al Feel'}, {'authorId': '1863248', 'name': 'Shady Elbassuoni'}, {'authorId': '31512093', 'name': 'Mohamad Jaber'}, {'authorId': '2065679414', 'name': 'May Farah'}]","1122":"[{'authorId': '1397442049', 'name': 'Alberto Barr\u00f3n-Cede\u00f1o'}, {'authorId': '34086979', 'name': 'Giovanni Da San Martino'}, {'authorId': '40446918', 'name': 'Israa Jaradat'}, {'authorId': '1683562', 'name': 'Preslav Nakov'}]","1123":"[{'authorId': '51914476', 'name': 'Sameer Dhoju'}, {'authorId': '9949334', 'name': 'Md Main Uddin Rony'}, {'authorId': '3207804', 'name': 'M. A. Kabir'}, {'authorId': '2789540', 'name': 'Naeemul Hassan'}]","1124":"[{'authorId': '117489784', 'name': 'Sonia Castelo'}, {'authorId': '2055150260', 'name': 'Thais G. Almeida'}, {'authorId': '2697663', 'name': 'Anas Elghafari'}, {'authorId': '3154815', 'name': 'A\u00e9cio Santos'}, {'authorId': '145318862', 'name': 'Kien Pham'}, {'authorId': '49324558', 'name': 'E. Nakamura'}, {'authorId': '144162611', 'name': 'J. Freire'}]","1125":"[{'authorId': '3249675', 'name': 'W. Souma'}, {'authorId': '2566697', 'name': 'I. Vodenska'}, {'authorId': '11466616', 'name': 'H. Aoyama'}]","1126":"[{'authorId': '1418098184', 'name': 'Adrien Benamira'}, {'authorId': '1415110072', 'name': 'Benjamin Devillers'}, {'authorId': '1418100032', 'name': 'Etienne Lesot'}, {'authorId': '2064770009', 'name': 'Ayush Ray'}, {'authorId': '1412752599', 'name': 'Manal Saadi'}, {'authorId': '2817467', 'name': 'Fragkiskos D. Malliaros'}]","1127":"[{'authorId': '2067570060', 'name': 'Kevin Joseph'}, {'authorId': '36357862', 'name': 'Hui Jiang'}]","1128":"[{'authorId': '150025901', 'name': 'Archita Pathak'}, {'authorId': '1748081', 'name': 'R. Srihari'}]","1129":"[{'authorId': '1782426', 'name': 'Bogdan Gliwa'}, {'authorId': '103241417', 'name': 'Iwona Mochol'}, {'authorId': '2065251929', 'name': 'Maciej Biesek'}, {'authorId': '1744393', 'name': 'Aleksander Wawer'}]","1130":"[{'authorId': '151271136', 'name': 'Zeynep Akkalyoncu Yilmaz'}, {'authorId': '144205313', 'name': 'Wei Yang'}, {'authorId': '9184695', 'name': 'Haotian Zhang'}, {'authorId': '145580839', 'name': 'Jimmy J. Lin'}]","1131":"[{'authorId': '37863838', 'name': 'Sara Ahmadian'}, {'authorId': '3356743', 'name': 'Alessandro Epasto'}, {'authorId': '2144045240', 'name': 'Ravi Kumar'}, {'authorId': '145967611', 'name': 'Mohammad Mahdian'}]","1132":"[{'authorId': '2117056217', 'name': 'Gurinder Singh'}, {'authorId': '33477755', 'name': 'Bhawna Kumar'}, {'authorId': '40099305', 'name': 'Loveleen Gaur'}, {'authorId': '50703033', 'name': 'Ankur Tyagi'}]","1133":"[{'authorId': '144579978', 'name': 'Chong Feng'}, {'authorId': '2109189996', 'name': 'Muzammil Khan'}, {'authorId': '2032219', 'name': 'Arif Ur Rahman'}, {'authorId': '2111120623', 'name': 'Arshad Ahmad'}]","1134":"[{'authorId': '1387983862', 'name': 'Nisan Stiennon'}, {'authorId': '31793034', 'name': 'Long Ouyang'}, {'authorId': '49387725', 'name': 'Jeff Wu'}, {'authorId': '2052152920', 'name': 'Daniel M. Ziegler'}, {'authorId': '49407415', 'name': 'Ryan J. Lowe'}, {'authorId': '153387869', 'name': 'Chelsea Voss'}, {'authorId': '38909097', 'name': 'Alec Radford'}, {'authorId': '2698777', 'name': 'Dario Amodei'}, {'authorId': '145370786', 'name': 'Paul Christiano'}]","1135":"[{'authorId': '2875615', 'name': 'Lea Frermann'}, {'authorId': '2393075', 'name': 'A. Klementiev'}]","1136":"[{'authorId': '1751098996', 'name': 'Saravanapriya Manoharan'}, {'authorId': '145862298', 'name': 'R. Senthilkumar'}]","1137":"[{'authorId': '1815604', 'name': 'M. Schonlau'}, {'authorId': '151197773', 'name': 'Rosie Yuyan Zou'}]","1138":"[{'authorId': '2114057147', 'name': 'Yunan Ye'}, {'authorId': '146922081', 'name': 'Hengzhi Pei'}, {'authorId': '51454501', 'name': 'Boxin Wang'}, {'authorId': '153191489', 'name': 'Pin-Yu Chen'}, {'authorId': '24018646', 'name': 'Yada Zhu'}, {'authorId': '145974111', 'name': 'Jun Xiao'}, {'authorId': '1490934734', 'name': 'Bo Li'}]","1139":"[{'authorId': '2108482646', 'name': 'Xinyi Li'}, {'authorId': '47002988', 'name': 'Yinchuan Li'}, {'authorId': '1504453822', 'name': 'Hongyang Yang'}, {'authorId': '2119061550', 'name': 'Liuqing Yang'}, {'authorId': '4029028', 'name': 'Xiao-Yang Liu'}]","1140":"[{'authorId': '2918378', 'name': 'K. Kousha'}, {'authorId': '1701298', 'name': 'M. Thelwall'}]","1141":"[{'authorId': '143887653', 'name': 'Duc Minh Nguyen'}, {'authorId': '31981971', 'name': 'T. Do'}, {'authorId': '144003733', 'name': 'A. Calderbank'}, {'authorId': '1782042', 'name': 'N. Deligiannis'}]","1142":"[{'authorId': '2822590', 'name': 'Danyang Liu'}, {'authorId': '143831387', 'name': 'Ting Bai'}, {'authorId': '2813328', 'name': 'Jianxun Lian'}, {'authorId': '39109247', 'name': 'Guang-zhong Sun'}, {'authorId': '2542603', 'name': 'Wayne Xin Zhao'}, {'authorId': '153693432', 'name': 'Ji-rong Wen'}, {'authorId': '144076239', 'name': 'Xing Xie'}]","1143":"[{'authorId': '1396383488', 'name': 'Bhavika Bhutani'}, {'authorId': '2065983997', 'name': 'Neha Rastogi'}, {'authorId': '1382666315', 'name': 'Priyanshu Sehgal'}, {'authorId': '34992369', 'name': 'Archana Purwar'}]","1144":"[{'authorId': '1774514', 'name': 'Francesco Pierri'}, {'authorId': '150892645', 'name': 'Alessandro Artoni'}, {'authorId': '144161686', 'name': 'S. Ceri'}]","1145":"[{'authorId': '1391072008', 'name': 'Sneh Kalra'}, {'authorId': '31606196', 'name': 'J. S. Prasad'}]","1146":"[{'authorId': '2142435826', 'name': 'Ritika Singh'}, {'authorId': '2047358865', 'name': 'Satwinder Singh'}]","1147":"[{'authorId': '151398120', 'name': 'G. Brena'}, {'authorId': '2112146631', 'name': 'M. Brambilla'}, {'authorId': '144161686', 'name': 'S. Ceri'}, {'authorId': '49474509', 'name': 'Marco Di Giovanni'}, {'authorId': '1774514', 'name': 'Francesco Pierri'}, {'authorId': '144763838', 'name': 'Giorgia Ramponi'}]","1148":"[{'authorId': '3314639', 'name': 'Panayiotis Smeros'}, {'authorId': '2065333595', 'name': 'C. Castillo'}, {'authorId': '1751802', 'name': 'K. Aberer'}]","1149":"[{'authorId': '153586604', 'name': 'Dongwhan Kim'}, {'authorId': '1959755', 'name': 'Joonhwan Lee'}]","1150":"[{'authorId': '1452348515', 'name': 'Leen Al Qadi'}, {'authorId': '1452347873', 'name': 'Hozayfa El Rifai'}, {'authorId': '104148079', 'name': 'Safa Obaid'}, {'authorId': '145973534', 'name': 'Ashraf Elnagar'}]","1151":"[{'authorId': '3376145', 'name': 'Gautam Kishore Shahi'}]","1152":"[{'authorId': '1741091586', 'name': 'Bastian von Beschwitz'}, {'authorId': '1689367', 'name': 'Donald B. Keim'}, {'authorId': '31997394', 'name': 'M. Massa'}]","1153":"[{'authorId': '1570445417', 'name': 'Sunidhi Sharma'}, {'authorId': '1921825', 'name': 'D. Sharma'}]","1154":"[{'authorId': '101014769', 'name': 'Pranav Bharadwaj'}, {'authorId': '81241455', 'name': 'Zongru Shao'}]","1155":"[{'authorId': '10330863', 'name': 'Yiangos Papanastasiou'}]","1156":"[{'authorId': '3361240', 'name': 'Manling Li'}, {'authorId': '1490467781', 'name': 'Lingyu Zhang'}, {'authorId': '144016781', 'name': 'Heng Ji'}, {'authorId': '1772337', 'name': 'R. Radke'}]","1157":"[{'authorId': '51017310', 'name': 'Jan Christian Blaise Cruz'}, {'authorId': '1382569223', 'name': 'J. A. Tan'}, {'authorId': '1973047', 'name': 'C. Cheng'}]","1158":"[{'authorId': '147856060', 'name': 'Philine Widmer'}, {'authorId': '152195449', 'name': 'Elliott Ash'}, {'authorId': '118781847', 'name': 'S. Galletta'}, {'authorId': '118781847', 'name': 'S. Galletta'}]","1159":"[{'authorId': '48837352', 'name': 'M. Mosleh'}, {'authorId': '153085268', 'name': 'Cameron Martel'}, {'authorId': '1996878', 'name': 'Dean Eckles'}, {'authorId': '2157480', 'name': 'David G. Rand'}]","1160":"[{'authorId': '116825227', 'name': 'Shiri Melumad'}, {'authorId': '35029435', 'name': 'R. Meyer'}, {'authorId': '2117904379', 'name': 'Yoon Duk Kim'}]","1161":"[{'authorId': '143913286', 'name': 'Stephen Bradshaw'}, {'authorId': '1398007078', 'name': \"C. O'Riordan\"}, {'authorId': '2028218150', 'name': 'Riad Cheikh'}]","1162":"[{'authorId': '1471447346', 'name': 'M. Ledwich'}, {'authorId': '2070146083', 'name': 'Anna Zaitsev'}]","1163":"[{'authorId': '2109670823', 'name': 'Ankur Sharma'}, {'authorId': '48931441', 'name': 'N. Kaur'}, {'authorId': '2906658', 'name': 'Anirban Sen'}, {'authorId': '1775627', 'name': 'Aaditeshwar Seth'}]","1164":"[{'authorId': '2133299744', 'name': 'Felix Hamborg'}, {'authorId': '2133312527', 'name': 'Timo Spinde'}, {'authorId': '2133299779', 'name': 'Kim Heinser'}, {'authorId': '2488381', 'name': 'K. Donnay'}, {'authorId': '145151838', 'name': 'Bela Gipp'}]","1165":"[{'authorId': '2133299744', 'name': 'Felix Hamborg'}, {'authorId': '2133299779', 'name': 'Kim Heinser'}, {'authorId': '83302144', 'name': 'Anastasia Zhukova'}, {'authorId': '2488381', 'name': 'K. Donnay'}, {'authorId': '145151838', 'name': 'Bela Gipp'}]","1166":"[{'authorId': '1704511', 'name': 'L. A. Hemaspaandra'}]","1167":"[{'authorId': '1413032419', 'name': 'Felix H\u00f6hne'}, {'authorId': '1468571086', 'name': 'S\u00f6ren Schmitt'}, {'authorId': '1807342', 'name': 'R. V. Stee'}]","1168":"[{'authorId': '1704511', 'name': 'L. A. Hemaspaandra'}]","1169":"[{'authorId': '1704511', 'name': 'L. A. Hemaspaandra'}]","1170":"[{'authorId': '1704511', 'name': 'L. A. Hemaspaandra'}]","1171":"[{'authorId': '1845794923', 'name': 'Timo Spinde'}, {'authorId': '2140442370', 'name': 'Jan-David Krieger'}, {'authorId': '8837621', 'name': 'Terry Ruas'}, {'authorId': '1978832932', 'name': 'Jelena Mitrovi\u0107'}, {'authorId': '1409955806', 'name': 'Franz G\u00f6tz-Hahn'}, {'authorId': '1705519', 'name': 'Akiko Aizawa'}, {'authorId': '145151838', 'name': 'Bela Gipp'}]","1172":"[{'authorId': '145948903', 'name': 'Raj Kumar Gupta'}, {'authorId': '40341306', 'name': 'Yinping Yang'}]","1173":"[{'authorId': '1413032419', 'name': 'Felix H\u00f6hne'}, {'authorId': '1468571086', 'name': 'S\u00f6ren Schmitt'}, {'authorId': '1807342', 'name': 'R. V. Stee'}]","1174":"[{'authorId': '1704511', 'name': 'L. A. Hemaspaandra'}]","1175":"[{'authorId': '1704511', 'name': 'L. A. Hemaspaandra'}]","1176":"[{'authorId': '1704511', 'name': 'L. A. Hemaspaandra'}]","1177":"[{'authorId': '1704511', 'name': 'L. A. Hemaspaandra'}]","1178":"[{'authorId': '69485491', 'name': 'Douglas A. Ferguson'}, {'authorId': '70406276', 'name': 'C. Greer'}]","1179":"[{'authorId': '2107123917', 'name': 'Y. Du'}, {'authorId': '48324301', 'name': 'Lingzi Zhu'}, {'authorId': '152826472', 'name': 'B. Cheng'}]","1180":"[{'authorId': '123883096', 'name': 'Tiara Astra Parahita'}, {'authorId': '83016974', 'name': 'Tur Rahardjo'}]","1181":"[{'authorId': '1704511', 'name': 'L. A. Hemaspaandra'}]","1182":"[{'authorId': '46208659', 'name': 'Emily Allaway'}, {'authorId': '145311801', 'name': 'M. Srikanth'}, {'authorId': '145590324', 'name': 'K. McKeown'}]","1183":"[{'authorId': '1727055797', 'name': 'Chenyan Jia'}, {'authorId': '7247867', 'name': 'Ruibo Liu'}]","1184":"[{'authorId': '108318235', 'name': 'Dan Allan'}, {'authorId': '2471227', 'name': 'T. Caswell'}, {'authorId': '2066714619', 'name': 'Stuart Campbell'}, {'authorId': '6172385', 'name': 'M. Rakitin'}]","1185":"[{'authorId': '33767228', 'name': 'F. Smith'}]","1186":"[{'authorId': '145800151', 'name': 'Kai Shu'}, {'authorId': '3122003', 'name': 'Limeng Cui'}, {'authorId': '2893721', 'name': 'Suhang Wang'}, {'authorId': '145948198', 'name': 'Dongwon Lee'}, {'authorId': '38746648', 'name': 'Huan Liu'}]","1187":"[{'authorId': '2500309', 'name': 'Federico Monti'}, {'authorId': '51484149', 'name': 'F. Frasca'}, {'authorId': '1775620', 'name': 'D. Eynard'}, {'authorId': '73695554', 'name': 'Damon Mannion'}, {'authorId': '1732570', 'name': 'M. Bronstein'}]","1188":"[{'authorId': '51067816', 'name': 'Julio C. S. Reis'}, {'authorId': '2054951144', 'name': 'Andr\u00e9 Correia'}, {'authorId': '1781883', 'name': 'Fabricio Murai'}, {'authorId': '1685147', 'name': 'Adriano Veloso'}, {'authorId': '1869561', 'name': 'Fabr\u00edcio Benevenuto'}, {'authorId': '49943757', 'name': 'E. Cambria'}]","1189":"[{'authorId': '2131876092', 'name': 'Shuo Yang'}, {'authorId': '145800151', 'name': 'Kai Shu'}, {'authorId': '2893721', 'name': 'Suhang Wang'}, {'authorId': '34943859', 'name': 'Renjie Gu'}, {'authorId': '1739875', 'name': 'Fan Wu'}, {'authorId': '38746648', 'name': 'Huan Liu'}]","1190":"[{'authorId': '15161448', 'name': 'Chuhan Wu'}, {'authorId': '2397264', 'name': 'Fangzhao Wu'}, {'authorId': '148048326', 'name': 'Suyu Ge'}, {'authorId': '50329599', 'name': 'Tao Qi'}, {'authorId': '1731776', 'name': 'Yongfeng Huang'}, {'authorId': '144076239', 'name': 'Xing Xie'}]","1191":"[{'authorId': '1490776655', 'name': 'Xinyi Zhou'}, {'authorId': '2281410', 'name': 'R. Zafarani'}]","1192":"[{'authorId': '1490776655', 'name': 'Xinyi Zhou'}, {'authorId': '2281410', 'name': 'R. Zafarani'}, {'authorId': '145800151', 'name': 'Kai Shu'}, {'authorId': '145896397', 'name': 'Huan Liu'}]","1193":"[{'authorId': '15161448', 'name': 'Chuhan Wu'}, {'authorId': '2397264', 'name': 'Fangzhao Wu'}, {'authorId': '92701189', 'name': 'Mingxiao An'}, {'authorId': '50535300', 'name': 'Jianqiang Huang'}, {'authorId': '1731776', 'name': 'Yongfeng Huang'}, {'authorId': '144076239', 'name': 'Xing Xie'}]","1194":"[{'authorId': '2153269078', 'name': 'Taehyun Kim'}]","1195":"[{'authorId': '2072585356', 'name': 'Y. Jang'}, {'authorId': '101529839', 'name': 'Changhyeon Park'}, {'authorId': '3042861', 'name': 'Yeong-Seok Seo'}]","1196":"[{'authorId': '112994432', 'name': 'Svenja Boberg'}, {'authorId': '2927682', 'name': 'T. Quandt'}, {'authorId': '1491141802', 'name': 'Tim Schatto-Eckrodt'}, {'authorId': '2960582', 'name': 'L. Frischlich'}]","1197":"[{'authorId': '2102580078', 'name': 'Maysoon Alkhair'}, {'authorId': '2549464', 'name': 'Karima Meftouh'}, {'authorId': '1825885', 'name': 'Kamel Sma\u00efli'}, {'authorId': '2760575', 'name': 'Nouha Othman'}]","1198":"[{'authorId': '145800151', 'name': 'Kai Shu'}, {'authorId': '82723305', 'name': 'Deepak Mahudeswaran'}, {'authorId': '2893721', 'name': 'Suhang Wang'}, {'authorId': '38746648', 'name': 'Huan Liu'}]","1199":"[{'authorId': '143737692', 'name': 'Kanish Shah'}, {'authorId': '51254643', 'name': 'Henil Patel'}, {'authorId': '117949047', 'name': 'D. Sanghvi'}, {'authorId': '152314530', 'name': 'Manan Shah'}]","1200":"[{'authorId': '2522002', 'name': 'M. Bastos'}, {'authorId': '2222242', 'name': 'Dan Mercea'}]","1201":"[{'authorId': '145800151', 'name': 'Kai Shu'}, {'authorId': '47155134', 'name': 'Xinyi Zhou'}, {'authorId': '2893721', 'name': 'Suhang Wang'}, {'authorId': '2281410', 'name': 'R. Zafarani'}, {'authorId': '38746648', 'name': 'Huan Liu'}]","1202":"[{'authorId': '47829900', 'name': 'Fan Yang'}, {'authorId': '41075161', 'name': 'Shiva K. Pentyala'}, {'authorId': '3228458', 'name': 'Sina Mohseni'}, {'authorId': '3432460', 'name': 'Mengnan Du'}, {'authorId': '1498527026', 'name': 'Hao Yuan'}, {'authorId': '145716315', 'name': 'Rhema Linder'}, {'authorId': '1777991', 'name': 'E. Ragan'}, {'authorId': '1743600', 'name': 'Shuiwang Ji'}, {'authorId': '48539382', 'name': 'Xia Hu'}]","1203":"[{'authorId': '47230275', 'name': 'Zhixuan Zhou'}, {'authorId': '67096741', 'name': 'Huankang Guan'}, {'authorId': '48648832', 'name': 'Meghana Moorthy Bhat'}, {'authorId': '39756252', 'name': 'Justin Hsu'}]","1204":"[{'authorId': '2164604', 'name': 'Shervin Minaee'}, {'authorId': '2583391', 'name': 'Nal Kalchbrenner'}, {'authorId': '49943757', 'name': 'E. Cambria'}, {'authorId': '1620486779', 'name': 'Narjes Nikzad'}, {'authorId': '89845455', 'name': 'M. Chenaghlu'}, {'authorId': '1800422', 'name': 'Jianfeng Gao'}]","1205":"[{'authorId': '47340073', 'name': 'W. Ahmed'}, {'authorId': '3318580', 'name': 'S. Lugovic'}]","1206":"[{'authorId': '24965937', 'name': 'P. Mallick'}, {'authorId': '2109301', 'name': 'Sushruta Mishra'}, {'authorId': '95632124', 'name': 'G. Chae'}]","1207":"[{'authorId': '1470736988', 'name': 'Daniel Thilo Schroeder'}, {'authorId': '3403160', 'name': 'Konstantin Pogorelov'}, {'authorId': '2006766', 'name': 'J. Langguth'}]","1208":"[{'authorId': '144035423', 'name': 'Muhammad Umer'}, {'authorId': '2067180046', 'name': 'Zainab Imtiaz'}, {'authorId': '48621790', 'name': 'S. Ullah'}, {'authorId': '1403306506', 'name': 'A. Mehmood'}, {'authorId': '32016133', 'name': 'G. Choi'}, {'authorId': '1791452', 'name': 'Byung-Won On'}]","1209":"[{'authorId': '1759771', 'name': 'Ceren Budak'}]","1210":"[{'authorId': '2074163529', 'name': 'Patrick Mueller'}, {'authorId': '2065507199', 'name': 'M. Lehmann'}, {'authorId': '51395208', 'name': 'Alexander Braun'}]","1211":"[{'authorId': '65822158', 'name': 'M. S. Sadiq'}, {'authorId': '145512752', 'name': 'C. Ruan'}, {'authorId': '33888341', 'name': 'H. Nawaz'}, {'authorId': '145547956', 'name': 'Shahid Ullah'}, {'authorId': '144385977', 'name': 'Wenlong He'}]","1212":"[{'authorId': '48352549', 'name': 'Ashok B. Mehta'}]","1213":"[{'authorId': '48352549', 'name': 'Ashok B. Mehta'}]","1214":"[{'authorId': '1470952862', 'name': 'Wenyuan Zhang'}, {'authorId': '3273102', 'name': 'Shubi Zhang'}, {'authorId': '145534763', 'name': 'N. Ding'}, {'authorId': '50095250', 'name': 'Lucas Holden'}, {'authorId': '2108684741', 'name': 'Xiaoming Wang'}, {'authorId': '14144676', 'name': 'Nanshan Zheng'}]","1215":"[{'authorId': '2092080154', 'name': 'Cedric Tompkin'}, {'authorId': '3083208', 'name': 'S. Leinss'}]","1216":"[{'authorId': '2070207816', 'name': 'P. Parthiban'}]","1217":"[{'authorId': '134677241', 'name': 'Rajasri Sen Jaiswal'}, {'authorId': '1486266234', 'name': 'T. K.'}, {'authorId': '1992580975', 'name': 'Mukundan M.'}, {'authorId': '1905936393', 'name': 'Richa Dobal'}]","1218":"[{'authorId': '97340839', 'name': 'K. Wilgan'}, {'authorId': '6262445', 'name': 'M. A. Siddique'}, {'authorId': '1760512', 'name': 'T. Strozzi'}, {'authorId': '70469021', 'name': 'A. Geiger'}, {'authorId': '3308569', 'name': 'Othmar Frey'}]","1219":"[{'authorId': '2153388567', 'name': 'Ying Zhang'}, {'authorId': '8276249', 'name': 'Xichao Dong'}, {'authorId': '2055448289', 'name': 'W. Xiong'}, {'authorId': '145805149', 'name': 'Cheng Hu'}]","1220":"[{'authorId': '1516153736', 'name': 'L. J. Mpoporo'}, {'authorId': '21504196', 'name': 'P. Owolawi'}, {'authorId': '1392944179', 'name': 'A. O. Ayo'}]","1221":"[{'authorId': '8276249', 'name': 'Xichao Dong'}, {'authorId': '2055448289', 'name': 'W. Xiong'}, {'authorId': '2153388567', 'name': 'Ying Zhang'}, {'authorId': '145805149', 'name': 'Cheng Hu'}, {'authorId': '3038488', 'name': 'Feifeng Liu'}]","1222":"[{'authorId': '93292205', 'name': 'Hassan Shehzad'}, {'authorId': '118714619', 'name': 'Dr.M. Raquibuz Zaman'}, {'authorId': '1571330460', 'name': 'Shane Zahra'}]","1223":"[{'authorId': '2149528910', 'name': 'X. Lv'}, {'authorId': '2108117701', 'name': 'Yongwei Zhang'}, {'authorId': '2088919454', 'name': 'Quanhu Shi'}, {'authorId': '1398219914', 'name': 'Murat Temiz'}, {'authorId': '1384134905', 'name': 'A. El-makadema'}]","1224":"[{'authorId': '66130056', 'name': 'H. Brenot'}, {'authorId': '49925092', 'name': 'W. Rohm'}, {'authorId': '37117987', 'name': 'M. Ka\u010dma\u0159\u00edk'}, {'authorId': '144680380', 'name': 'G. M\u00f6ller'}, {'authorId': '144419084', 'name': 'A. S\u00e1'}, {'authorId': '95324731', 'name': 'Damian Tondas'}, {'authorId': '2652069', 'name': 'Luk\u00e1s Rapant'}, {'authorId': '33067090', 'name': 'R. Biondi'}, {'authorId': '47148545', 'name': 'T. Manning'}, {'authorId': '95708252', 'name': 'C. Champollion'}]","1225":"[{'authorId': '2071448', 'name': 'Riham S. Elhabyan'}, {'authorId': '38414070', 'name': 'Wei Shi'}, {'authorId': '1398291284', 'name': 'M. St-Hilaire'}]","1226":"[{'authorId': '51199643', 'name': 'Laura Ana Maria Bostan'}, {'authorId': '9277025', 'name': 'Evgeny Kim'}, {'authorId': '66339110', 'name': 'Roman Klinger'}]","1227":"[{'authorId': '145481292', 'name': 'Christian Reuter'}, {'authorId': '2056333459', 'name': 'Katrin Hartwig'}, {'authorId': '2140672709', 'name': 'Jan Kirchner'}, {'authorId': '65766993', 'name': 'N. Schlegel'}]","1228":"[{'authorId': '2451541', 'name': 'Lindsay D. Grace'}, {'authorId': '117249001', 'name': 'B. Hone'}]","1229":"[{'authorId': '1724289', 'name': 'M. Ochs'}, {'authorId': '2023168', 'name': 'D. Mestre'}, {'authorId': '3450314', 'name': 'G. Montcheuil'}, {'authorId': '2940117', 'name': 'Jean-Marie Pergandi'}, {'authorId': '7687048', 'name': 'J. Saubesty'}, {'authorId': '3424544', 'name': 'E. Lombardo'}, {'authorId': '2081828140', 'name': 'Daniel Francon'}, {'authorId': '2652453', 'name': 'P. Blache'}]","1230":"[{'authorId': '2043747821', 'name': 'Adi Prasetyo'}, {'authorId': '1389965544', 'name': 'Bayu Dwi Septianto'}, {'authorId': '3225014', 'name': 'G. F. Shidik'}, {'authorId': '1389964076', 'name': 'A. Z. Fanani'}]","1231":"[{'authorId': '22423711', 'name': 'Samuli Laato'}, {'authorId': '143886814', 'name': 'A. Islam'}, {'authorId': '9256301', 'name': 'M. Islam'}, {'authorId': '143824696', 'name': 'E. Whelan'}]","1232":"[{'authorId': '22423711', 'name': 'Samuli Laato'}, {'authorId': '143886814', 'name': 'A. Islam'}, {'authorId': '9256301', 'name': 'M. Islam'}, {'authorId': '143824696', 'name': 'E. Whelan'}]","1233":"[{'authorId': '1816926', 'name': 'Joshua M. Scacco'}, {'authorId': '1903596', 'name': 'Ashley Muddiman'}]","1234":"[{'authorId': '143866320', 'name': 'Yong Fang'}, {'authorId': '2149258754', 'name': 'Jian Gao'}, {'authorId': '152497361', 'name': 'Cheng Huang'}, {'authorId': '2140199018', 'name': 'Hua Peng'}, {'authorId': '3077661', 'name': 'R. Wu'}]","1235":"[{'authorId': '1381942264', 'name': 'F. Rubio'}, {'authorId': '143655012', 'name': 'F. Valero'}, {'authorId': '1399657057', 'name': 'C. Llopis-Albert'}]","1236":"[{'authorId': '2061766', 'name': 'C. Chuan'}, {'authorId': '14542280', 'name': 'W. Tsai'}, {'authorId': '10997173', 'name': 'Sumi Cho'}]","1237":"[{'authorId': '1562306480', 'name': 'Sachin Kumar'}, {'authorId': '1453606397', 'name': 'Rohan Asthana'}, {'authorId': '1453603987', 'name': 'S. Upadhyay'}, {'authorId': '1453602758', 'name': 'Nidhi Upreti'}, {'authorId': '2065449224', 'name': 'Mohammad Akbar'}]","1238":"[{'authorId': '10682650', 'name': 'Zhicong Lu'}, {'authorId': '2142454943', 'name': 'Yue Jiang'}, {'authorId': '2110373982', 'name': 'Cheng Lu'}, {'authorId': '1687465', 'name': 'M. Naaman'}, {'authorId': '1961958', 'name': 'Daniel J. Wigdor'}]","1239":"[{'authorId': '1397142019', 'name': 'M. N. Al-Ameen'}, {'authorId': '1784058278', 'name': 'Tanjina Tamanna'}, {'authorId': '1752288089', 'name': 'Swapnil Nandy'}, {'authorId': '144053994', 'name': 'M. Ahsan'}, {'authorId': '40486345', 'name': 'Priyank Chandra'}, {'authorId': '145867840', 'name': 'Syed Ishtiaque Ahmed'}]","1240":"[{'authorId': '29789123', 'name': 'Theodora A. Maniou'}, {'authorId': '3199137', 'name': 'A. Veglis'}]","1241":"[{'authorId': '7574907', 'name': 'Wei Zakharov'}, {'authorId': '2108732100', 'name': 'Haiyan Li'}, {'authorId': '32771155', 'name': 'M. Fosmire'}]","1242":"[{'authorId': '145429868', 'name': 'E. Loos'}, {'authorId': '102771518', 'name': 'J. Nijenhuis'}]","1243":"[{'authorId': '2023820630', 'name': 'Ben Chen'}, {'authorId': '14238797', 'name': 'B. Chen'}, {'authorId': '39349533', 'name': 'D. Gao'}, {'authorId': '2109402489', 'name': 'Qijin Chen'}, {'authorId': '2064461546', 'name': 'Chengfu Huo'}, {'authorId': '15571760', 'name': 'Xiaonan Meng'}, {'authorId': '5381159', 'name': 'Weijun Ren'}, {'authorId': '2145500045', 'name': 'Yang Zhou'}]","1244":"[{'authorId': '1416080660', 'name': 'S. M. Jones-Jang'}, {'authorId': '2111327271', 'name': 'Dam Hee Kim'}, {'authorId': '1916603', 'name': 'K. Kenski'}]","1245":"[{'authorId': '2149547874', 'name': 'Donghee Shin'}]","1246":"[{'authorId': '1807047', 'name': 'Soon Ae Chun'}, {'authorId': '3299380', 'name': 'R. Holowczak'}, {'authorId': '30879890', 'name': 'Kannan Dharan'}, {'authorId': '2108693699', 'name': 'Ruoyu Wang'}, {'authorId': '1387719720', 'name': 'Soumaydeep Basu'}, {'authorId': '144395353', 'name': 'J. Geller'}]","1247":"[{'authorId': '2047162040', 'name': 'Shan Jiang'}, {'authorId': '33974871', 'name': 'Ronald E. Robertson'}, {'authorId': '35497150', 'name': 'Christo Wilson'}]","1248":"[{'authorId': '2413860', 'name': 'David Holtz'}, {'authorId': '2413779', 'name': 'Sinan Aral'}]","1249":"[{'authorId': '101628510', 'name': 'J. B\u00f8lstad'}]","1250":"[{'authorId': '2047162040', 'name': 'Shan Jiang'}, {'authorId': '33974871', 'name': 'Ronald E. Robertson'}, {'authorId': '35497150', 'name': 'Christo Wilson'}]","1251":"[{'authorId': '31839935', 'name': 'Jennifer Bussell'}]","1252":"[{'authorId': '66611626', 'name': 'Stefano Costalli'}, {'authorId': '116556550', 'name': 'F. Negri'}]","1253":"[{'authorId': '39033024', 'name': 'Maximilian Wich'}, {'authorId': '1930406072', 'name': 'Jan Bauer'}, {'authorId': '1711829', 'name': 'Georg Groh'}]","1254":"[{'authorId': '2621402', 'name': 'Yair Ghitza'}, {'authorId': '144389145', 'name': 'A. Gelman'}]","1255":"[{'authorId': '11804993', 'name': 'C. Hazlett'}, {'authorId': '91026515', 'name': 'L. Wainstein'}]","1256":"[{'authorId': '50498832', 'name': 'Xun Pang'}, {'authorId': '1739044133', 'name': 'Licheng Liu'}, {'authorId': '2110316755', 'name': 'Yiqing Xu'}]","1257":"[{'authorId': '2333880', 'name': 'Alexander J. Stewart'}, {'authorId': '48837352', 'name': 'M. Mosleh'}, {'authorId': '40607009', 'name': 'M. Diakonova'}, {'authorId': '9549601', 'name': 'A. Arechar'}, {'authorId': '2157480', 'name': 'David G. Rand'}, {'authorId': '2533201', 'name': 'J. Plotkin'}]","1258":"[{'authorId': '144003355', 'name': 'A. Deb'}, {'authorId': '3349623', 'name': 'Luca Luceri'}, {'authorId': '9552744', 'name': 'Adam Badawy'}, {'authorId': '48898287', 'name': 'Emilio Ferrara'}]","1259":"[{'authorId': '6297724', 'name': 'Q. Grundy'}]","1260":"[{'authorId': '2391773', 'name': 'A. Mattei'}, {'authorId': '4409094', 'name': 'B. D. De Stavola'}, {'authorId': '3011947', 'name': 'F. Mealli'}]","1261":"[{'authorId': '1392593539', 'name': 'Markus Knoche'}, {'authorId': '2065851753', 'name': 'Radovan Popovi\u0107'}, {'authorId': '2101037', 'name': 'F. Lemmerich'}, {'authorId': '1743043', 'name': 'M. Strohmaier'}]","1262":"[{'authorId': '3435730', 'name': 'Zahra Fatemi'}, {'authorId': '2392370', 'name': 'E. Zheleva'}]","1263":"[{'authorId': '6143933', 'name': 'Hannah Li'}, {'authorId': '2107895438', 'name': 'Geng Zhao'}, {'authorId': '1790944', 'name': 'R. Johari'}, {'authorId': '2888943', 'name': 'G. Weintraub'}]","1264":"[{'authorId': '2144800', 'name': 'Pak-Hang Wong'}]","1265":"[{'authorId': '118982178', 'name': 'K. Umarova'}, {'authorId': '2261457', 'name': 'Eni Mustafaraj'}]","1266":"[{'authorId': '2067735040', 'name': 'Michael Freeman'}, {'authorId': '50390534', 'name': 'S. Robinson'}, {'authorId': '2055390', 'name': 'S. Scholtes'}]","1267":"[{'authorId': '2706156', 'name': 'D. Potnis'}, {'authorId': '2385741', 'name': 'I. Tahamtan'}]","1268":"[{'authorId': '2943892', 'name': 'N. Diakopoulos'}]","1269":"[{'authorId': '3363483', 'name': 'Jack Bandy'}, {'authorId': '2943892', 'name': 'N. Diakopoulos'}]","1270":"[{'authorId': '20443332', 'name': 'Oren Soffer'}]","1271":"[{'authorId': '1404609254', 'name': 'Sandra Gonz\u00e1lez-Bail\u00f3n'}, {'authorId': '46617468', 'name': 'M. De Domenico'}]","1272":"[{'authorId': '47388653', 'name': 'D. Schiff'}]","1273":"[{'authorId': '2003244', 'name': 'Ahmed Al-Rawi'}]"},"searchQuery":{"0":"['linguistic bias']","1":"['linguistic bias', 'phrasing bias']","2":"['linguistic bias', 'news bias']","3":"['linguistic bias']","4":"['linguistic bias']","5":"['linguistic bias']","6":"['linguistic bias']","7":"['linguistic bias']","8":"['linguistic bias']","9":"['linguistic bias', 'news bias']","10":"['linguistic bias', 'media bias']","11":"['linguistic bias']","12":"['linguistic bias', 'news bias', 'media bias', 'news slant', 'slanted coverage']","13":"['linguistic bias']","14":"['linguistic bias']","15":"['linguistic bias']","16":"['linguistic bias', 'informational bias', 'news bias', 'media bias', 'news articles', 'political bias interference']","17":"['linguistic bias', 'news bias', 'media bias']","18":"['linguistic bias']","19":"['linguistic bias']","20":"['linguistic bias']","21":"['linguistic bias']","22":"['linguistic bias']","23":"['linguistic bias']","24":"['linguistic bias', 'text level context bias', 'news bias', 'media bias']","25":"['linguistic bias']","26":"['linguistic bias', 'semantic bias', 'phrasing bias']","27":"['linguistic bias']","28":"['linguistic bias']","29":"['linguistic bias']","30":"['linguistic bias']","31":"['linguistic bias', 'epistemological bias']","32":"['linguistic bias']","33":"['linguistic bias']","34":"['linguistic bias', 'semantic bias']","35":"['linguistic bias']","36":"['linguistic bias']","37":"['linguistic bias']","38":"['linguistic bias']","39":"['linguistic bias', 'text level context bias', 'news bias', 'media bias', 'political bias interference']","40":"['linguistic bias']","41":"['linguistic bias']","42":"['linguistic bias', 'media bias', 'political bias interference']","43":"['linguistic bias']","44":"['linguistic bias']","45":"['linguistic bias']","46":"['linguistic bias']","47":"['linguistic bias']","48":"['linguistic bias', 'semantic bias', 'news bias']","49":"['linguistic bias']","50":"['linguistic bias']","51":"['linguistic bias']","52":"['linguistic bias', 'semantic bias']","53":"['linguistic bias', 'semantic bias']","54":"['linguistic bias']","55":"['linguistic bias', 'media bias']","56":"['linguistic bias', 'phrasing bias']","57":"['linguistic bias']","58":"['linguistic bias']","59":"['linguistic bias']","60":"['linguistic bias']","61":"['linguistic bias']","62":"['linguistic bias']","63":"['linguistic bias']","64":"['linguistic bias', 'semantic bias']","65":"['linguistic bias']","66":"['linguistic bias', 'semantic bias']","67":"['linguistic bias']","68":"['linguistic bias']","69":"['linguistic bias', 'semantic bias', 'level of bias awareness']","70":"['linguistic bias']","71":"['linguistic bias']","72":"['linguistic bias']","73":"['linguistic bias']","74":"['linguistic bias']","75":"['linguistic bias']","76":"['linguistic bias']","77":"['linguistic bias', 'phrasing bias']","78":"['linguistic bias', 'semantic bias']","79":"['linguistic bias']","80":"['linguistic bias']","81":"['linguistic bias']","82":"['linguistic bias']","83":"['linguistic bias']","84":"['linguistic bias']","85":"['linguistic bias', 'news bias']","86":"['linguistic bias']","87":"['linguistic bias']","88":"['linguistic bias']","89":"['linguistic bias']","90":"['linguistic bias']","91":"['linguistic bias', 'semantic bias']","92":"['linguistic bias', 'semantic bias']","93":"['framing bias', 'semantic bias']","94":"['framing bias', 'news bias', 'news slant']","95":"['framing bias', 'connotation bias', 'news bias', 'media bias']","96":"['framing bias', 'coverage bias', 'news bias', 'media bias', 'perception of news']","97":"['framing bias']","98":"['framing bias', 'echo chambers', 'news bias', 'media bias']","99":"['framing bias']","100":"['framing bias', 'semantic bias', 'statement bias', 'text level context bias', 'media bias']","101":"['framing bias']","102":"['framing bias']","103":"['framing bias']","104":"['framing bias']","105":"['framing bias', 'news bias']","106":"['framing bias']","107":"['framing bias']","108":"['framing bias']","109":"['framing bias']","110":"['framing bias']","111":"['framing bias']","112":"['framing bias']","113":"['framing bias', 'news bias']","114":"['framing bias']","115":"['epistemological bias']","116":"['epistemological bias']","117":"['epistemological bias']","118":"['epistemological bias']","119":"['epistemological bias']","120":"['epistemological bias', 'connotation bias', 'phrasing bias']","121":"['epistemological bias', 'connotation bias', 'phrasing bias']","122":"['epistemological bias', 'connotation bias', 'phrasing bias']","123":"['epistemological bias', 'connotation bias', 'phrasing bias']","124":"['epistemological bias', 'connotation bias', 'phrasing bias']","125":"['epistemological bias', 'connotation bias', 'text level context bias', 'phrasing bias']","126":"['epistemological bias', 'connotation bias', 'phrasing bias']","127":"['epistemological bias', 'connotation bias', 'phrasing bias']","128":"['epistemological bias', 'connotation bias', 'phrasing bias']","129":"['epistemological bias', 'connotation bias', 'phrasing bias']","130":"['epistemological bias', 'connotation bias', 'phrasing bias']","131":"['epistemological bias', 'connotation bias', 'phrasing bias']","132":"['epistemological bias', 'connotation bias', 'phrasing bias']","133":"['epistemological bias', 'connotation bias', 'phrasing bias']","134":"['epistemological bias', 'connotation bias', 'phrasing bias']","135":"['epistemological bias', 'connotation bias', 'text level context bias', 'phrasing bias']","136":"['epistemological bias', 'connotation bias', 'phrasing bias']","137":"['epistemological bias']","138":"['epistemological bias']","139":"['epistemological bias', 'connotation bias', 'phrasing bias']","140":"['epistemological bias']","141":"['epistemological bias', 'connotation bias', 'phrasing bias']","142":"['epistemological bias', 'connotation bias']","143":"['epistemological bias']","144":"['epistemological bias', 'connotation bias', 'phrasing bias']","145":"['epistemological bias', 'connotation bias', 'phrasing bias']","146":"['epistemological bias', 'connotation bias', 'phrasing bias']","147":"['epistemological bias', 'connotation bias', 'phrasing bias']","148":"['epistemological bias', 'connotation bias', 'phrasing bias']","149":"['epistemological bias', 'connotation bias']","150":"['epistemological bias', 'connotation bias', 'phrasing bias']","151":"['epistemological bias', 'connotation bias', 'phrasing bias']","152":"['epistemological bias', 'connotation bias']","153":"['epistemological bias', 'connotation bias']","154":"['epistemological bias']","155":"['epistemological bias']","156":"['epistemological bias', 'connotation bias', 'phrasing bias']","157":"['epistemological bias', 'connotation bias', 'omission bias', 'phrasing bias']","158":"['epistemological bias']","159":"['epistemological bias']","160":"['epistemological bias']","161":"['epistemological bias']","162":"['epistemological bias']","163":"['epistemological bias']","164":"['epistemological bias']","165":"['semantic bias']","166":"['semantic bias']","167":"['semantic bias']","168":"['semantic bias']","169":"['semantic bias']","170":"['semantic bias']","171":"['semantic bias']","172":"['semantic bias']","173":"['semantic bias']","174":"['semantic bias']","175":"['semantic bias', 'political bias interference']","176":"['semantic bias']","177":"['semantic bias']","178":"['semantic bias']","179":"['semantic bias']","180":"['semantic bias', 'text level context bias']","181":"['semantic bias']","182":"['semantic bias']","183":"['semantic bias']","184":"['semantic bias']","185":"['semantic bias']","186":"['semantic bias']","187":"['semantic bias']","188":"['semantic bias']","189":"['semantic bias']","190":"['semantic bias']","191":"['semantic bias', 'news bias', 'media bias', 'news slant', 'slanted coverage']","192":"['semantic bias']","193":"['semantic bias']","194":"['semantic bias']","195":"['semantic bias']","196":"['semantic bias']","197":"['semantic bias']","198":"['semantic bias']","199":"['semantic bias']","200":"['semantic bias']","201":"['semantic bias', 'phrasing bias']","202":"['semantic bias']","203":"['semantic bias']","204":"['semantic bias']","205":"['semantic bias', 'phrasing bias', 'news bias', 'media bias', 'news slant', 'slanted coverage']","206":"['semantic bias']","207":"['semantic bias']","208":"['semantic bias']","209":"['semantic bias']","210":"['semantic bias']","211":"['semantic bias']","212":"['semantic bias', 'selection bias']","213":"['semantic bias']","214":"['semantic bias', 'proximity bias']","215":"['semantic bias']","216":"['semantic bias']","217":"['semantic bias']","218":"['semantic bias']","219":"['semantic bias']","220":"['semantic bias']","221":"['semantic bias']","222":"['semantic bias']","223":"['semantic bias']","224":"['semantic bias']","225":"['semantic bias']","226":"['semantic bias']","227":"['semantic bias']","228":"['semantic bias']","229":"['semantic bias']","230":"['semantic bias']","231":"['semantic bias']","232":"['semantic bias']","233":"['semantic bias', 'proximity bias']","234":"['semantic bias']","235":"['semantic bias']","236":"['semantic bias']","237":"['semantic bias']","238":"['semantic bias']","239":"['semantic bias']","240":"['semantic bias']","241":"['semantic bias']","242":"['semantic bias', 'phrasing bias']","243":"['semantic bias']","244":"['semantic bias']","245":"['semantic bias']","246":"['semantic bias', 'echo chambers']","247":"['semantic bias']","248":"['semantic bias', 'text level context bias', 'news bias']","249":"['semantic bias']","250":"['semantic bias']","251":"['semantic bias']","252":"['semantic bias']","253":"['semantic bias', 'news bias', 'media bias']","254":"['semantic bias']","255":"['semantic bias']","256":"['semantic bias']","257":"['semantic bias', 'selection bias']","258":"['semantic bias']","259":"['semantic bias']","260":"['semantic bias']","261":"['semantic bias']","262":"['semantic bias']","263":"['semantic bias']","264":"['semantic bias']","265":"['semantic bias']","266":"['semantic bias']","267":"['semantic bias']","268":"['semantic bias']","269":"['semantic bias']","270":"['semantic bias']","271":"['semantic bias']","272":"['semantic bias']","273":"['semantic bias', 'text level context bias']","274":"['semantic bias']","275":"['semantic bias']","276":"['semantic bias']","277":"['semantic bias']","278":"['semantic bias']","279":"['semantic bias']","280":"['semantic bias']","281":"['semantic bias', 'level of bias awareness']","282":"['semantic bias']","283":"['semantic bias']","284":"['semantic bias']","285":"['semantic bias']","286":"['semantic bias']","287":"['semantic bias']","288":"['semantic bias']","289":"['semantic bias']","290":"['semantic bias']","291":"['semantic bias']","292":"['semantic bias']","293":"['semantic bias']","294":"['semantic bias']","295":"['semantic bias']","296":"['semantic bias']","297":"['semantic bias']","298":"['semantic bias']","299":"['semantic bias', 'level of bias awareness']","300":"['semantic bias', 'news bias']","301":"['semantic bias']","302":"['semantic bias']","303":"['semantic bias']","304":"['semantic bias', 'level of bias awareness']","305":"['semantic bias']","306":"['semantic bias']","307":"['semantic bias']","308":"['semantic bias']","309":"['semantic bias', 'phrasing bias']","310":"['semantic bias']","311":"['semantic bias']","312":"['semantic bias']","313":"['semantic bias']","314":"['semantic bias']","315":"['semantic bias']","316":"['semantic bias']","317":"['semantic bias']","318":"['semantic bias']","319":"['semantic bias']","320":"['semantic bias']","321":"['semantic bias']","322":"['semantic bias']","323":"['semantic bias']","324":"['semantic bias']","325":"['semantic bias']","326":"['semantic bias', 'level of bias awareness']","327":"['semantic bias']","328":"['semantic bias']","329":"['semantic bias']","330":"['semantic bias']","331":"['semantic bias', 'text level context bias']","332":"['semantic bias']","333":"['semantic bias']","334":"['semantic bias']","335":"['semantic bias']","336":"['semantic bias']","337":"['semantic bias']","338":"['semantic bias']","339":"['semantic bias']","340":"['semantic bias']","341":"['semantic bias']","342":"['semantic bias']","343":"['semantic bias']","344":"['semantic bias']","345":"['semantic bias']","346":"['semantic bias']","347":"['semantic bias']","348":"['semantic bias']","349":"['semantic bias']","350":"['semantic bias']","351":"['semantic bias']","352":"['semantic bias']","353":"['semantic bias']","354":"['semantic bias']","355":"['semantic bias']","356":"['semantic bias']","357":"['semantic bias']","358":"['semantic bias']","359":"['semantic bias']","360":"['semantic bias']","361":"['semantic bias']","362":"['semantic bias']","363":"['semantic bias']","364":"['semantic bias']","365":"['semantic bias', 'phrasing bias']","366":"['semantic bias']","367":"['semantic bias']","368":"['semantic bias']","369":"['semantic bias']","370":"['semantic bias']","371":"['semantic bias']","372":"['semantic bias', 'proximity bias']","373":"['semantic bias', 'level of bias awareness']","374":"['semantic bias']","375":"['semantic bias']","376":"['semantic bias', 'proximity bias']","377":"['semantic bias']","378":"['semantic bias']","379":"['semantic bias']","380":"['semantic bias']","381":"['semantic bias']","382":"['semantic bias']","383":"['semantic bias']","384":"['semantic bias']","385":"['semantic bias']","386":"['semantic bias']","387":"['semantic bias']","388":"['semantic bias', 'text level context bias']","389":"['connotation bias', 'media bias']","390":"['connotation bias']","391":"['connotation bias']","392":"['connotation bias']","393":"['connotation bias']","394":"['connotation bias']","395":"['connotation bias']","396":"['connotation bias']","397":"['connotation bias']","398":"['connotation bias', 'phrasing bias']","399":"['connotation bias']","400":"['connotation bias', 'phrasing bias']","401":"['connotation bias']","402":"['connotation bias']","403":"['connotation bias']","404":"['connotation bias']","405":"['connotation bias']","406":"['connotation bias']","407":"['connotation bias']","408":"['political ideology']","409":"['political ideology', 'news bias', 'media bias', 'news articles']","410":"['political ideology', 'news bias', 'media bias', 'news articles']","411":"['echo chambers']","412":"['echo chambers']","413":"['echo chambers']","414":"['echo chambers']","415":"['echo chambers']","416":"['echo chambers']","417":"['echo chambers']","418":"['echo chambers']","419":"['echo chambers']","420":"['echo chambers', 'news bias']","421":"['echo chambers', 'media bias']","422":"['echo chambers']","423":"['echo chambers', 'news slant']","424":"['echo chambers']","425":"['echo chambers']","426":"['echo chambers']","427":"['echo chambers']","428":"['echo chambers']","429":"['echo chambers']","430":"['echo chambers']","431":"['echo chambers']","432":"['echo chambers']","433":"['echo chambers']","434":"['echo chambers']","435":"['echo chambers']","436":"['echo chambers']","437":"['echo chambers']","438":"['echo chambers']","439":"['echo chambers', 'news slant']","440":"['echo chambers']","441":"['echo chambers']","442":"['echo chambers']","443":"['echo chambers']","444":"['echo chambers']","445":"['echo chambers']","446":"['echo chambers']","447":"['echo chambers']","448":"['echo chambers']","449":"['echo chambers']","450":"['echo chambers']","451":"['echo chambers']","452":"['echo chambers']","453":"['echo chambers']","454":"['echo chambers']","455":"['echo chambers']","456":"['echo chambers']","457":"['echo chambers']","458":"['echo chambers', 'news slant']","459":"['echo chambers']","460":"['echo chambers']","461":"['echo chambers']","462":"['echo chambers', 'news bias', 'news articles']","463":"['echo chambers', 'news articles']","464":"['echo chambers']","465":"['echo chambers']","466":"['echo chambers']","467":"['echo chambers']","468":"['echo chambers']","469":"['echo chambers']","470":"['echo chambers']","471":"['echo chambers']","472":"['echo chambers']","473":"['echo chambers']","474":"['echo chambers']","475":"['echo chambers']","476":"['echo chambers']","477":"['echo chambers']","478":"['echo chambers']","479":"['echo chambers']","480":"['echo chambers', 'gatekeeping']","481":"['echo chambers', 'news bias', 'political bias interference']","482":"['echo chambers']","483":"['echo chambers']","484":"['echo chambers']","485":"['echo chambers']","486":"['echo chambers']","487":"['echo chambers']","488":"['echo chambers']","489":"['echo chambers']","490":"['echo chambers', 'news articles']","491":"['echo chambers']","492":"['echo chambers']","493":"['echo chambers']","494":"['echo chambers']","495":"['echo chambers']","496":"['echo chambers']","497":"['echo chambers']","498":"['echo chambers']","499":"['echo chambers']","500":"['echo chambers']","501":"['echo chambers']","502":"['echo chambers']","503":"['echo chambers']","504":"['echo chambers']","505":"['echo chambers']","506":"['echo chambers']","507":"['echo chambers']","508":"['echo chambers']","509":"['echo chambers']","510":"['echo chambers']","511":"['echo chambers']","512":"['echo chambers']","513":"['echo chambers']","514":"['echo chambers']","515":"['echo chambers']","516":"['echo chambers']","517":"['echo chambers']","518":"['echo chambers']","519":"['echo chambers']","520":"['echo chambers']","521":"['echo chambers']","522":"['echo chambers']","523":"['echo chambers']","524":"['echo chambers']","525":"['echo chambers']","526":"['echo chambers']","527":"['echo chambers']","528":"['echo chambers']","529":"['echo chambers']","530":"['echo chambers']","531":"['echo chambers']","532":"['echo chambers']","533":"['echo chambers']","534":"['echo chambers']","535":"['echo chambers']","536":"['echo chambers']","537":"['echo chambers']","538":"['echo chambers']","539":"['level of involvement']","540":"['cognitive bias']","541":"['cognitive bias', 'informational bias']","542":"['cognitive bias']","543":"['cognitive bias']","544":"['emotional involvement']","545":"['emotional involvement']","546":"['source reputation']","547":"['source reputation', 'news articles']","548":"['source reputation']","549":"['source reputation']","550":"['source reputation']","551":"['source reputation']","552":"['source reputation']","553":"['source reputation']","554":"['source reputation']","555":"['source reputation']","556":"['source reputation']","557":"['source reputation']","558":"['source reputation']","559":"['source reputation']","560":"['source reputation']","561":"['source reputation']","562":"['source reputation']","563":"['source reputation']","564":"['source reputation']","565":"['source reputation']","566":"['source reputation']","567":"['source reputation']","568":"['source reputation']","569":"['source reputation', 'news bias', 'news slant']","570":"['source reputation']","571":"['source reputation']","572":"['source reputation']","573":"['source reputation']","574":"['source reputation']","575":"['source reputation']","576":"['source reputation']","577":"['source reputation']","578":"['source reputation']","579":"['source reputation']","580":"['source reputation']","581":"['source reputation']","582":"['level of bias awareness']","583":"['level of bias awareness']","584":"['level of bias awareness']","585":"['level of bias awareness']","586":"['level of bias awareness', 'news bias', 'media bias', 'news slant']","587":"['level of bias awareness']","588":"['level of bias awareness']","589":"['level of bias awareness']","590":"['level of bias awareness']","591":"['level of bias awareness']","592":"['level of bias awareness']","593":"['level of bias awareness']","594":"['level of bias awareness']","595":"['level of bias awareness', 'text level context bias']","596":"['level of bias awareness']","597":"['level of bias awareness']","598":"['level of bias awareness']","599":"['level of bias awareness']","600":"['level of bias awareness']","601":"['level of bias awareness']","602":"['level of bias awareness']","603":"['level of bias awareness']","604":"['level of bias awareness']","605":"['level of bias awareness']","606":"['level of bias awareness']","607":"['level of bias awareness']","608":"['level of bias awareness']","609":"['level of bias awareness']","610":"['level of bias awareness', 'news bias']","611":"['level of bias awareness']","612":"['level of bias awareness']","613":"['level of bias awareness']","614":"['level of bias awareness']","615":"['level of bias awareness']","616":"['level of bias awareness']","617":"['level of bias awareness']","618":"['level of bias awareness']","619":"['level of bias awareness']","620":"['level of bias awareness']","621":"['level of bias awareness', 'text level context bias']","622":"['level of bias awareness']","623":"['level of bias awareness']","624":"['level of bias awareness']","625":"['level of bias awareness']","626":"['level of bias awareness']","627":"['level of bias awareness']","628":"['level of bias awareness']","629":"['level of bias awareness']","630":"['level of bias awareness']","631":"['level of bias awareness']","632":"['level of bias awareness']","633":"['limited cognitive resources']","634":"['limited cognitive resources']","635":"['limited cognitive resources']","636":"['limited cognitive resources']","637":"['limited cognitive resources']","638":"['limited cognitive resources']","639":"['limited cognitive resources']","640":"['limited cognitive resources']","641":"['limited cognitive resources']","642":"['limited cognitive resources']","643":"['limited cognitive resources']","644":"['limited cognitive resources']","645":"['limited cognitive resources']","646":"['limited cognitive resources']","647":"['limited cognitive resources']","648":"['limited cognitive resources']","649":"['limited cognitive resources', 'limited mental resources']","650":"['limited cognitive resources']","651":"['limited cognitive resources']","652":"['limited cognitive resources']","653":"['limited cognitive resources']","654":"['limited cognitive resources']","655":"['limited cognitive resources']","656":"['limited cognitive resources']","657":"['limited cognitive resources']","658":"['limited cognitive resources']","659":"['limited cognitive resources']","660":"['limited cognitive resources']","661":"['limited cognitive resources']","662":"['limited cognitive resources']","663":"['limited cognitive resources']","664":"['limited cognitive resources']","665":"['limited cognitive resources']","666":"['limited cognitive resources']","667":"['limited cognitive resources']","668":"['limited cognitive resources']","669":"['limited cognitive resources', 'limited mental resources']","670":"['limited cognitive resources']","671":"['limited cognitive resources']","672":"['limited cognitive resources']","673":"['limited cognitive resources']","674":"['limited cognitive resources']","675":"['limited cognitive resources']","676":"['limited cognitive resources']","677":"['limited cognitive resources']","678":"['limited cognitive resources']","679":"['limited cognitive resources']","680":"['limited cognitive resources']","681":"['limited cognitive resources']","682":"['limited cognitive resources']","683":"['limited cognitive resources']","684":"['limited cognitive resources']","685":"['limited cognitive resources']","686":"['limited cognitive resources']","687":"['limited cognitive resources']","688":"['limited mental resources']","689":"['limited mental resources']","690":"['limited mental resources']","691":"['limited mental resources']","692":"['limited mental resources']","693":"['limited mental resources']","694":"['limited mental resources']","695":"['omission bias']","696":"['omission bias']","697":"['omission bias']","698":"['omission bias']","699":"['omission bias']","700":"['omission bias']","701":"['omission bias']","702":"['omission bias']","703":"['omission bias']","704":"['omission bias']","705":"['omission bias']","706":"['omission bias']","707":"['omission bias']","708":"['omission bias']","709":"['omission bias', 'phrasing bias']","710":"['omission bias']","711":"['omission bias']","712":"['omission bias']","713":"['omission bias']","714":"['omission bias']","715":"['omission bias']","716":"['omission bias']","717":"['informational bias']","718":"['informational bias']","719":"['informational bias']","720":"['informational bias']","721":"['informational bias']","722":"['informational bias']","723":"['informational bias', 'selection bias']","724":"['informational bias']","725":"['informational bias']","726":"['statement bias']","727":"['statement bias']","728":"['statement bias']","729":"['statement bias', 'news bias', 'media bias', 'news slant', 'slanted coverage']","730":"['statement bias']","731":"['statement bias']","732":"['statement bias']","733":"['statement bias']","734":"['statement bias']","735":"['statement bias']","736":"['statement bias']","737":"['statement bias']","738":"['statement bias', 'text level context bias', 'news bias', 'media bias']","739":"['statement bias']","740":"['statement bias']","741":"['statement bias']","742":"['statement bias']","743":"['statement bias']","744":"['statement bias']","745":"['statement bias']","746":"['statement bias']","747":"['text level context bias']","748":"['text level context bias']","749":"['text level context bias']","750":"['text level context bias']","751":"['text level context bias']","752":"['text level context bias']","753":"['text level context bias']","754":"['text level context bias']","755":"['text level context bias']","756":"['text level context bias']","757":"['text level context bias']","758":"['text level context bias']","759":"['text level context bias']","760":"['text level context bias']","761":"['text level context bias']","762":"['text level context bias']","763":"['text level context bias', 'news articles']","764":"['text level context bias']","765":"['text level context bias']","766":"['text level context bias']","767":"['text level context bias']","768":"['text level context bias']","769":"['text level context bias']","770":"['text level context bias']","771":"['text level context bias']","772":"['text level context bias']","773":"['text level context bias']","774":"['text level context bias']","775":"['text level context bias']","776":"['text level context bias']","777":"['text level context bias']","778":"['text level context bias']","779":"['text level context bias']","780":"['text level context bias']","781":"['text level context bias']","782":"['text level context bias']","783":"['text level context bias']","784":"['text level context bias']","785":"['text level context bias']","786":"['text level context bias']","787":"['text level context bias']","788":"['text level context bias', 'phrasing bias']","789":"['text level context bias']","790":"['text level context bias', 'news bias']","791":"['text level context bias']","792":"['text level context bias']","793":"['text level context bias']","794":"['text level context bias']","795":"['text level context bias']","796":"['text level context bias']","797":"['text level context bias', 'phrasing bias']","798":"['text level context bias']","799":"['text level context bias']","800":"['text level context bias']","801":"['text level context bias', 'news bias']","802":"['text level context bias']","803":"['text level context bias']","804":"['text level context bias']","805":"['text level context bias']","806":"['text level context bias']","807":"['text level context bias']","808":"['text level context bias']","809":"['text level context bias']","810":"['text level context bias']","811":"['text level context bias']","812":"['text level context bias', 'phrasing bias']","813":"['text level context bias']","814":"['text level context bias']","815":"['text level context bias']","816":"['text level context bias']","817":"['text level context bias']","818":"['text level context bias']","819":"['text level context bias']","820":"['text level context bias']","821":"['text level context bias']","822":"['text level context bias']","823":"['text level context bias']","824":"['text level context bias']","825":"['text level context bias']","826":"['text level context bias']","827":"['text level context bias']","828":"['text level context bias']","829":"['text level context bias']","830":"['text level context bias']","831":"['text level context bias']","832":"['text level context bias']","833":"['text level context bias']","834":"['text level context bias']","835":"['text level context bias']","836":"['text level context bias']","837":"['text level context bias']","838":"['text level context bias']","839":"['text level context bias']","840":"['text level context bias']","841":"['text level context bias']","842":"['text level context bias']","843":"['text level context bias']","844":"['text level context bias']","845":"['text level context bias']","846":"['text level context bias']","847":"['text level context bias']","848":"['text level context bias']","849":"['text level context bias']","850":"['text level context bias']","851":"['text level context bias']","852":"['text level context bias']","853":"['text level context bias']","854":"['text level context bias']","855":"['text level context bias']","856":"['text level context bias']","857":"['text level context bias']","858":"['text level context bias']","859":"['text level context bias']","860":"['text level context bias']","861":"['text level context bias']","862":"['text level context bias']","863":"['phrasing bias']","864":"['phrasing bias']","865":"['phrasing bias']","866":"['phrasing bias']","867":"['phrasing bias']","868":"['phrasing bias']","869":"['phrasing bias']","870":"['phrasing bias']","871":"['phrasing bias']","872":"['phrasing bias']","873":"['phrasing bias']","874":"['phrasing bias']","875":"['phrasing bias']","876":"['phrasing bias']","877":"['phrasing bias']","878":"['phrasing bias']","879":"['phrasing bias']","880":"['phrasing bias']","881":"['phrasing bias']","882":"['phrasing bias']","883":"['phrasing bias']","884":"['phrasing bias']","885":"['phrasing bias']","886":"['phrasing bias']","887":"['phrasing bias']","888":"['phrasing bias']","889":"['phrasing bias']","890":"['phrasing bias']","891":"['phrasing bias']","892":"['phrasing bias']","893":"['phrasing bias']","894":"['phrasing bias']","895":"['phrasing bias']","896":"['phrasing bias']","897":"['phrasing bias']","898":"['phrasing bias']","899":"['phrasing bias']","900":"['phrasing bias']","901":"['phrasing bias']","902":"['phrasing bias']","903":"['phrasing bias']","904":"['phrasing bias']","905":"['phrasing bias']","906":"['phrasing bias']","907":"['phrasing bias']","908":"['phrasing bias']","909":"['phrasing bias']","910":"['phrasing bias']","911":"['phrasing bias']","912":"['phrasing bias']","913":"['phrasing bias']","914":"['phrasing bias']","915":"['phrasing bias']","916":"['phrasing bias']","917":"['phrasing bias']","918":"['phrasing bias']","919":"['phrasing bias']","920":"['phrasing bias']","921":"['phrasing bias']","922":"['phrasing bias']","923":"['phrasing bias']","924":"['phrasing bias']","925":"['phrasing bias']","926":"['phrasing bias']","927":"['phrasing bias']","928":"['phrasing bias']","929":"['phrasing bias']","930":"['phrasing bias']","931":"['phrasing bias']","932":"['phrasing bias']","933":"['phrasing bias']","934":"['phrasing bias']","935":"['coverage bias']","936":"['coverage bias']","937":"['coverage bias']","938":"['coverage bias']","939":"['coverage bias']","940":"['coverage bias']","941":"['coverage bias']","942":"['coverage bias', 'news bias', 'media bias', 'news articles', 'news slant', 'slanted coverage', 'perception of news']","943":"['coverage bias']","944":"['coverage bias']","945":"['coverage bias']","946":"['coverage bias']","947":"['coverage bias']","948":"['coverage bias']","949":"['coverage bias']","950":"['coverage bias']","951":"['coverage bias']","952":"['coverage bias']","953":"['coverage bias']","954":"['coverage bias']","955":"['coverage bias']","956":"['coverage bias']","957":"['coverage bias']","958":"['coverage bias']","959":"['coverage bias']","960":"['coverage bias']","961":"['coverage bias']","962":"['proximity bias']","963":"['proximity bias']","964":"['proximity bias']","965":"['proximity bias']","966":"['proximity bias']","967":"['proximity bias']","968":"['proximity bias']","969":"['proximity bias']","970":"['proximity bias']","971":"['proximity bias']","972":"['proximity bias']","973":"['proximity bias']","974":"['proximity bias']","975":"['selection bias']","976":"['selection bias']","977":"['selection bias']","978":"['selection bias']","979":"['reporting level bias']","980":"['reporting level bias']","981":"['news bias']","982":"['news bias']","983":"['news bias']","984":"['news bias']","985":"['news bias']","986":"['news bias', 'media bias']","987":"['news bias', 'news articles', 'perception of news']","988":"['news bias', 'news articles', 'political bias interference']","989":"['news bias']","990":"['news bias']","991":"['news bias', 'political bias interference']","992":"['news bias', 'media bias']","993":"['news bias']","994":"['news bias']","995":"['news bias', 'news slant', 'slanted coverage']","996":"['news bias']","997":"['news bias']","998":"['news bias', 'media bias', 'news articles']","999":"['news bias', 'media bias', 'news articles']","1000":"['news bias', 'media bias', 'news articles']","1001":"['news bias', 'media bias', 'news analysis']","1002":"['news bias']","1003":"['news bias']","1004":"['news bias']","1005":"['news bias']","1006":"['news bias']","1007":"['news bias', 'news articles']","1008":"['news bias']","1009":"['news bias']","1010":"['news bias']","1011":"['news bias']","1012":"['news bias']","1013":"['news bias']","1014":"['news bias', 'media bias']","1015":"['news bias']","1016":"['news bias']","1017":"['news bias']","1018":"['news bias']","1019":"['news bias']","1020":"['news bias']","1021":"['news bias']","1022":"['news bias']","1023":"['news bias', 'political bias interference']","1024":"['news bias']","1025":"['news bias']","1026":"['news bias']","1027":"['news bias', 'perception of news']","1028":"['news bias']","1029":"['news bias']","1030":"['news bias']","1031":"['news bias']","1032":"['news bias']","1033":"['news bias']","1034":"['news bias']","1035":"['news bias', 'media bias']","1036":"['news bias', 'media bias']","1037":"['news bias']","1038":"['news bias']","1039":"['news bias']","1040":"['news bias']","1041":"['news bias']","1042":"['news bias']","1043":"['news bias']","1044":"['news bias', 'media bias']","1045":"['news bias']","1046":"['news bias']","1047":"['news bias', 'media bias']","1048":"['news bias']","1049":"['news bias']","1050":"['news bias']","1051":"['news bias']","1052":"['news bias']","1053":"['news bias']","1054":"['news bias']","1055":"['news bias']","1056":"['media bias']","1057":"['media bias']","1058":"['media bias']","1059":"['media bias']","1060":"['media bias']","1061":"['media bias']","1062":"['media bias']","1063":"['media bias']","1064":"['media bias']","1065":"['media bias']","1066":"['media bias']","1067":"['media bias']","1068":"['media bias']","1069":"['media bias']","1070":"['media bias']","1071":"['media bias']","1072":"['media bias']","1073":"['media bias']","1074":"['media bias']","1075":"['media bias']","1076":"['media bias']","1077":"['media bias']","1078":"['media bias']","1079":"['news articles']","1080":"['news articles', 'news analysis']","1081":"['news articles']","1082":"['news articles']","1083":"['news articles']","1084":"['news articles']","1085":"['news articles']","1086":"['news articles']","1087":"['news articles']","1088":"['news articles']","1089":"['news articles', 'news analysis']","1090":"['news articles']","1091":"['news articles', 'perception of news']","1092":"['news articles']","1093":"['news articles']","1094":"['news articles']","1095":"['news articles']","1096":"['news articles']","1097":"['news articles', 'news analysis']","1098":"['news articles']","1099":"['news articles']","1100":"['news articles']","1101":"['news articles']","1102":"['news articles']","1103":"['news articles', 'news analysis']","1104":"['news articles']","1105":"['news articles']","1106":"['news articles', 'news slant']","1107":"['news articles']","1108":"['news articles']","1109":"['news articles']","1110":"['news articles', 'news slant']","1111":"['news articles']","1112":"['news articles']","1113":"['news articles']","1114":"['news articles']","1115":"['news articles']","1116":"['news articles']","1117":"['news articles']","1118":"['news articles', 'news analysis']","1119":"['news articles']","1120":"['news articles', 'news analysis']","1121":"['news articles']","1122":"['news articles']","1123":"['news articles']","1124":"['news articles']","1125":"['news articles', 'news analysis']","1126":"['news articles']","1127":"['news articles']","1128":"['news articles']","1129":"['news articles']","1130":"['news articles']","1131":"['news articles']","1132":"['news articles']","1133":"['news articles']","1134":"['news articles']","1135":"['news articles']","1136":"['news articles']","1137":"['news articles']","1138":"['news articles']","1139":"['news articles']","1140":"['news articles']","1141":"['news articles']","1142":"['news articles']","1143":"['news articles', 'news analysis']","1144":"['news articles']","1145":"['news articles']","1146":"['news articles']","1147":"['news articles']","1148":"['news articles']","1149":"['news articles']","1150":"['news articles']","1151":"['news articles']","1152":"['news articles']","1153":"['news articles']","1154":"['news articles']","1155":"['news articles']","1156":"['news articles']","1157":"['news articles']","1158":"['news slant']","1159":"['news slant']","1160":"['news slant']","1161":"['news slant']","1162":"['news slant']","1163":"['news slant', 'slanted coverage']","1164":"['news slant', 'slanted coverage']","1165":"['news slant', 'slanted coverage']","1166":"['news slant']","1167":"['news slant']","1168":"['news slant']","1169":"['news slant']","1170":"['news slant']","1171":"['news slant']","1172":"['news slant']","1173":"['news slant']","1174":"['news slant']","1175":"['news slant']","1176":"['news slant']","1177":"['news slant']","1178":"['news slant']","1179":"['news slant', 'perception of news']","1180":"['news slant', 'slanted coverage']","1181":"['news slant']","1182":"['news slant']","1183":"['news slant']","1184":"['news slant']","1185":"['news slant']","1186":"['news slant']","1187":"['news slant', 'news analysis']","1188":"['news slant']","1189":"['news slant']","1190":"['news slant']","1191":"['news slant']","1192":"['news slant']","1193":"['news slant']","1194":"['news analysis']","1195":"['news analysis']","1196":"['news analysis']","1197":"['news analysis']","1198":"['news analysis']","1199":"['news analysis']","1200":"['news analysis']","1201":"['news analysis']","1202":"['news analysis']","1203":"['news analysis']","1204":"['news analysis']","1205":"['news analysis']","1206":"['news analysis']","1207":"['news analysis']","1208":"['news analysis']","1209":"['news analysis']","1210":"['slanted coverage']","1211":"['slanted coverage']","1212":"['slanted coverage']","1213":"['slanted coverage']","1214":"['slanted coverage']","1215":"['slanted coverage']","1216":"['slanted coverage']","1217":"['slanted coverage']","1218":"['slanted coverage']","1219":"['slanted coverage']","1220":"['slanted coverage']","1221":"['slanted coverage']","1222":"['slanted coverage']","1223":"['slanted coverage']","1224":"['slanted coverage']","1225":"['slanted coverage']","1226":"['perception of news']","1227":"['perception of news']","1228":"['perception of news']","1229":"['perception of news']","1230":"['perception of news']","1231":"['perception of news']","1232":"['perception of news']","1233":"['perception of news']","1234":"['perception of news']","1235":"['perception of news']","1236":"['perception of news']","1237":"['perception of news']","1238":"['perception of news']","1239":"['perception of news']","1240":"['perception of news']","1241":"['perception of news']","1242":"['perception of news']","1243":"['perception of news']","1244":"['perception of news']","1245":"['perception of news']","1246":"['political bias interference']","1247":"['political bias interference']","1248":"['political bias interference']","1249":"['political bias interference']","1250":"['political bias interference']","1251":"['political bias interference']","1252":"['political bias interference']","1253":"['political bias interference']","1254":"['political bias interference']","1255":"['political bias interference']","1256":"['political bias interference']","1257":"['political bias interference']","1258":"['political bias interference']","1259":"['political bias interference']","1260":"['political bias interference']","1261":"['political bias interference']","1262":"['political bias interference']","1263":"['political bias interference']","1264":"['political bias interference']","1265":"['political bias interference']","1266":"['gatekeeping']","1267":"['gatekeeping']","1268":"['gatekeeping']","1269":"['gatekeeping']","1270":"['gatekeeping']","1271":"['gatekeeping']","1272":"['gatekeeping']","1273":"['gatekeeping']"},"authors_clear":{"0":"K. Madanagopal, James Caverlee","1":"Eva Vanmassenhove, D. Shterionov, M. Gwilliam","2":"Timo Spinde, L. Rudnitckaia, Jelena Mitrovi\u0107, Felix Hamborg, ichael Granitzer, Bela Gipp, K. Donnay","3":"Alex Warstadt, Samuel R. Bowman","4":"Isabel Papadimitriou, Dan Jurafsky","5":"S. Borchmann","6":"Reid Pryzant, Dallas Card, Dan Jurafsky, Victor Veitch, Dhanya Sridhar","7":"Tal Linzen","8":"Maria Antoniak, D. Mimno","9":"Chang Li, Dan Goldwasser","10":"Julia Mendelsohn, Yulia Tsvetkov, Dan Jurafsky","11":"K. Deshpande, Shimei Pan, James R. Foulds","12":"Timo Spinde, Bela Gipp","13":"Christoph Alt, Aleksandra Gabryszak, Leonhard Hennig","14":"Christoph Alt, Aleksandra Gabryszak, Leonhard Hennig","15":"Debora Nozza, Claudia Volpetti, E. Fersini","16":"Lisa Fan, M. White, Eva Sharma, Ruisi Su, Prafulla Kumar Choubey, Ruihong Huang, Lu Wang","17":"I. Yahav, O. Shehory, D. Schwartz","18":"T. Berg","19":"Aparna Garimella, Carmen Banea, E. Hovy, Rada Mihalcea","20":"Elad Ben-Zaken, Shauli Ravfogel, Yoav Goldberg","21":"Julian Salazar, Davis Liang, Toan Q. Nguyen, Katrin Kirchhoff","22":"R. Thomas McCoy, Junghyun Min, Tal Linzen","23":"Candace Ross, B. Katz, Andrei Barbu","24":"R. Baly, Georgi Karadzhov, Jisun An, Haewoon Kwak, Yoan Dinkov, Ahmed Ali, James R. Glass, Preslav Nakov","25":"Robik Shrestha, Kushal Kafle, Christopher Kanan","26":"C. Fisher, Kyong-sun Jin, Rose M. Scott","27":"Shauli Ravfogel, Yoav Goldberg, Tal Linzen","28":"Gabriel Grand, Y. Belinkov","29":"Qian Yang, Zhouyuan Huo, Dinghan Shen, Yong Cheng, Wenlin Wang, Guoyin Wang, L. Carin","30":"M. R. Makiuchi, Tifani Warnita, K. Uto, Koichi Shinoda","31":"L. Windsor, J. Cupit, Alistair Windsor","32":"Danielle Saunders, B. Byrne","33":"Marion Bartl, M. Nissim, Albert Gatt","34":"Samson Tan, Shafiq R. Joty, Min-Yen Kan, R. Socher","35":"T. Sumers, Mark K. Ho, R. Hawkins, Karthik Narasimhan, T. Griffiths","36":"Alex Warstadt, Yian Zhang, Haau-Sing Li, Haokun Liu, Samuel R. Bowman","37":"Shengyu Zhang, Tan Jiang, Tan Wang, Kun Kuang, Zhou Zhao, Jianke Zhu, Jin Yu, Hongxia Yang, Fei Wu","38":"Isabel Papadimitriou, Dan Jurafsky","39":"Wei-Fan Chen, Khalid Al Khatib, Henning Wachsmuth, Benno Stein","40":"R. Thomas McCoy, Erin Grant, P. Smolensky, T. Griffiths, Tal Linzen","41":"Peide Liu, Weiqiao Liu","42":"Aseel Addawood, Adam Badawy, Kristina Lerman, Emilio Ferrara","43":"Peide Liu, Weiqiao Liu","44":"Eva Vanmassenhove, D. Shterionov, Andy Way","45":"Ben Krause, Akhilesh Deepak Gotmare, Bryan McCann, N. Keskar, Shafiq R. Joty, R. Socher, Nazneen Rajani","46":"Charles Lovering, Rohan Jha, Tal Linzen, Ellie Pavlick","47":"Boli Chen, Yao Fu, Guangwei Xu, Pengjun Xie, Chuanqi Tan, Mosha Chen, L. Jing","48":"Xavier Ferrer Aran, T. Nuenen, J. Such, N. Criado","49":"Long Chen, Xin Yan, Jun Xiao, Hanwang Zhang, Shiliang Pu, Yueting Zhuang","50":"Paul Pu Liang, Irene Z Li, Emily Zheng, Y. Lim, R. Salakhutdinov, Louis-Philippe Morency","51":"Qiao Huang, Xin Xia, D. Lo, G. Murphy","52":"Shivang Chopra, Ramit Sawhney, Puneet Mathur, R. Shah","53":"Christoph Alt, Marc H\u00fcbner, Leonhard Hennig","54":"Forrest Davis, Marten van Schijndel","55":"Luke Breitfeller, Emily Ahn, Aldrian Obaja Muis, David Jurgens, Yulia Tsvetkov","56":"Vinodkumar Prabhakaran, B. Hutchinson, Margaret Mitchell","57":"Surafel Melaku Lakew, Mattia Antonino Di Gangi, Marcello Federico","58":"D. Dediu, R. Janssen, S. Moisik","59":"Rahma Chaabouni, E. Kharitonov, A. Lazaric, Emmanuel Dupoux, Marco Baroni","60":"Dhanya Sridhar, L. Getoor","61":"Henning Wachsmuth, Till Werner","62":"Xuejing Zhou, Wanli Peng, Boya Yang, Juan Wen, Yiming Xue, P. Zhong","63":"Pratyay Banerjee, Tejas Gokhale, Yezhou Yang, Chitta Baral","64":"Noga Zaslavsky, Mora Maldonado, Jennifer Culbertson","65":"Philine Zeinert, Nanna Inie, Leon Derczynski","66":"Elliot Murphy","67":"R. Munro, Alex (Carmen) Morrison","68":"G. Lupyan, Morten H. Christiansen","69":"Tong Niu, Mohit Bansal","70":"Tiago Pimentel, Brian Roark, S. Wichmann, Ryan Cotterell, Dami\u00e1n E. Blasi","71":"Tianyi Zhang, Tatsunori B. Hashimoto","72":"Jason Wei, Clara Meister, Ryan Cotterell","73":"J. Vaes, M. Latrofa, Caterina Suitner, L. Arcuri","74":"Abeba Birhane, Vinay Uday Prabhu, Emmanuel Kahembwe","75":"Utkarsh Sarawgi, Wazeer Zulfikar, Nouran Soliman, P. Maes","76":"Mansi Agarwal, Maitree Leekha, Ramit Sawhney, R. Shah","77":"Lifeng Jin, William Schuler","78":"Andr\u00e9 F. T. Martins, Tsvetomila Mihaylova, Nikita Nangia, Vlad Niculae","79":"Danielle Saunders, Rosie Sallis, B. Byrne","80":"Rui Hou, Ver\u00f3nica P\u00e9rez-Rosas, S. Loeb, Rada Mihalcea","81":"Xudong Han, Timothy Baldwin, Trevor Cohn","82":"Will Merrill, Lenny Khazan, Noah Amsel, Yiding Hao, S. Mendelsohn, R. Frank","83":"Jennifer Culbertson, K. Schuler","84":"Xiaoke Cao, L. Lei, J. Wen","85":"J. Ortega","86":"Maria M. Hedblom","87":"Hieu-Thi Luong, J. Yamagishi","88":"P. Schwaller, Riccardo Petraglia, Valerio Zullo, Vishnu H. Nair, Rico H\u00e4uselmann, Riccardo Pisoni, C. Bekas, A. Iuliano, T. Laino","89":"Vijit Malik, Sunipa Dev, A. Nishi, Nanyun Peng, Kai-Wei Chang","90":"Nicolas Ballier, S. Canu, C. Petitjean, G. Gasso, C. Balhana, T. Alexopoulou, Thomas Gaillat","91":"M. Schouwstra, H. D. Swart, Bill Thompson","92":"Hexiang Hu, Ishan Misra, L. V. D. Maaten","93":"Haewoon Kwak, Jisun An, Yong-Yeol Ahn","94":"Negar Mokhberian, A. Abeliuk, Patrick Cummings, Kristina Lerman","95":"Reid Pryzant, Richard Diehl Martinez, Nathan Dass, S. Kurohashi, Dan Jurafsky, Diyi Yang","96":"Timo Spinde, Felix Hamborg, K. Donnay, Angelica Becerra, Bela Gipp","97":"Y. Kafai, C. Proctor, Debora Lui","98":"Matteo Cinelli, Gianmarco De Francisci Morales, Alessandro Galeazzi, Walter Quattrociocchi, M. Starnini","99":"A. Willis","100":"Maarten Sap, Saadia Gabriel, Lianhui Qin, Dan Jurafsky, Noah A. Smith, Yejin Choi","101":"Eirini Ntoutsi, P. Fafalios, U. Gadiraju, Vasileios Iosifidis, W. Nejdl, Maria-Esther Vidal, S. Ruggieri, F. Turini, S. Papadopoulos, Emmanouil Krasanakis, I. Kompatsiaris, K. Kinder-Kurlanda, Claudia Wagner, F. Karimi, Miriam Fern\u00e1ndez, Harith Alani, Bettina Berendt, Tina Kruegel, C. Heinze, Klaus Broelemann, Gjergji Kasneci, T. Tiropanis, Steffen Staab","102":"T. Hofmeester, J. Cromsigt, J. Odden, H. Andr\u00e9n, J. Kindberg, J. Linnell","103":"Rohit Girdhar, D. Ramanan","104":"K. Morimoto, Andrei Ardelean, Ming-Lo Wu, A. Ulku, I. M. Antolovi\u0107, C. Bruschini, E. Charbon","105":"L. E. Celis, Sayash Kapoor, F. Salehi, Nisheeth K. Vishnoi","106":"R. Doescher, M. Acosta, A. Alessandri, P. Anthoni, A. Arneth, T. Arsouze, Tommi Bergmann, R. Bernadello, S. Bousetta, L. Caron, G. Carver, M. Castrillo, F. Catalano, I. Cvijanovic, P. Davini, E. Dekker, F. Doblas-Reyes, D. Docquier, P. Echevarria, U. Fladrich, R. Fuentes\u2010Franco, M. Gr\u00f6ger, Jost v. Hardenberg, Jenny Hieronymus, M. Karami, J. Keskinen, T. Koenigk, R. Makkonen, F. Massonnet, M. M\u00e9n\u00e9goz, P. Miller, E. Moreno\u2010Chamarro, L. Nieradzik, T. van Noije, P. Nolan, D. O'Donnell, P. Ollinaho, G. V. D. van den Oord, P. Ortega, Oriol Tint\u00f3 Prims, A. Ramos, T. Reerink, C. Rousset, Y. Ruprich\u2010Robert, Philipp Le Sager, T. Schmith, R. Schr\u00f6dner, F. Serva, V. Sicardi, M. Sloth Madsen, Benjamin Smith, T. Tian, \u00c9. Tourigny, P. Uotila, M. Vancoppenolle, Shiyu Wang, D. W\u00e5rlind, U. Will\u00e9n, K. Wyser, Shuting Yang, Xavier Yepes-Arb\u00f3s, Qiong Zhang","107":"C. Gratton, R. Coalson, A. Dworetsky, B. Adeyemo, Timothy O. Laumann, G. Wig, Tania S. Kong, G. Gratton, M. Fabiani, D. Barch, D. Tranel, \u00d3. Miranda-Dom\u00ednguez, D. Fair, N. Dosenbach, A. Snyder, J. Perlmutter, S. Petersen, M. C. Campbell","108":"Xianhang Cheng, Zhenzhong Chen","109":"Taiji Suzuki","110":"Nanyu Chen, Min Liu, Ya Xu","111":"Michael A. Katell, Meg Young, Dharma Dailey, Bernease Herman, Vivian Guetler, Aaron Tam, Corinne Binz, Daniella Raz, P. Krafft","112":"Hashim A. Hashim","113":"Benjamin Schiller, Johannes Daxenberger, Iryna Gurevych","114":"Aviram Bar-Haim, L. Wolf","115":"Milagros Miceli, Julian Posada, Tianling Yang","116":"Jon Leefmann","117":"M. Coeckelbergh","118":"Milagros Miceli, Julian Posada, Tianling Yang","119":"A. Shadrova","120":"M. Makhortykh, Aleksandra Urman, R. Ulloa","121":"Michael F\u00e4rber, Frederic Bartscherer","122":null,"123":"Keita Kurita, Nidhi Vyas, Ayush Pareek, A. Black, Yulia Tsvetkov","124":"Baris Kirdemir, Joseph Kready, Esther Mead, Muhammad Nihal Hussain, Nidhi Agarwal","125":"Susan Leavy, G. Meaney, Karen Wade, Derek Greene","126":"Fabian Haak, Philipp Schaer","127":"Toshihiro Kamishima, S. Akaho, Yukino Baba, H. Kashima","128":"Francisco Gu\u00ed\u00f1ez, Javier Ruiz, M. I. S\u00e1nchez","129":"Joel Escud\u00e9 Font, M. Costa-juss\u00e0","130":"Simone Diniz Junqueira Barbosa, Phoebe Chen, A. Cuzzocrea, Xiaoyong Du, Orhun Kara, Ting Liu, K. Sivalingam, D. \u015al\u0119zak, T. Washio, Xiaokang Yang, Junsong Yuan, R. Prates, Ludovico Boratto, Stefano Faralli, M. Marras, G. Stilo","131":"Christine Basta, M. Costa-juss\u00e0, Noe Casas","132":"Giannis Konstantakis, Giannis Promponas, Manthos Dretakis, P. Papadakos","133":"Won Ik Cho, Jiwon Kim, Seokhwan Kim, N. Kim","134":"Flavien Prost, Nithum Thain, Tolga Bolukbasi","135":"Yasmeen Hitti, Eunbee Jang, I. Moreno, C. Pelletier","136":"Jo\u00e3o Sedoc, L. Ungar","137":"Nicholas Asher, Soumya Paul, Chris Russell","138":"T. Nantsou, E. Kapotis, G. Tombras","139":"G. M. D. Nunzio, Alessandro Fabris, Gianmaria Silvello, Gian Antonio Susto","140":"Rajiv Movva","141":"Bin Han, C. Shah, Daniel Saelid","142":"Joanna Misztal-Radecka, B. Indurkhya","143":"Nicholas Asher, Soumya Paul, Chris Russell","144":"Sahil Verma, Ruoyuan Gao, C. Shah","145":"E. Gerritse, A. D. Vries","146":"W. Silva, Marcos A. Spalenza, Jean-R\u00e9mi Bourguet, E. Oliveira","147":"Yinchuan Xu, Junlin Yang","148":"Xingce Bao, Qianqian Qiao","149":"Rakesh Chada","150":"Felipe Alfaro, M. Costa-juss\u00e0, Jos\u00e9 A. R. Fonollosa","151":"Tobias D. Krafft, Marc P. Hauer, K. Zweig","152":"Dimitris Paraschakis, Bengt J. Nilsson","153":"J. Bhaskaran, Isha Bhallamudi","154":"A. Doyle","155":"G. Origgi","156":"Bo Liu","157":"Frank Soboczenski, T. Trikalinos, J. Kuiper, R. Bias, Byron C. Wallace, I. Marshall","158":"Luca Russo, S. Russo","159":"Ramit Debnath, Sarah C. Darby, R. Bardhan, Kamiar Mohaddes, Minna Sunikka-Blank","160":"J. Kline, Avram Aelony, Brian Carpenter, P. Barford","161":"Jonas Andersson Schwarz","162":"Elija Perrier","163":"Aida Rahmattalabi, Alice Xiang","164":"Freydis Vogel, Heisawn Jeong, Susan A. Yoon, Stian H\u00e5klev, L\u00e9onore V. Guillain, N. Abassi, S. Wan, S. Wan, Anika Radkowitsch, F. Fischer, C. Hmelo\u2010Silver","165":"R. Englert, J\u00f6rg Muschiol","166":"Ziyi Chen, Dilong Li, Wentao Fan, H. Guan, Cheng Wang, Jonathan Li","167":"Maria De-Arteaga, Alexey Romanov, H. Wallach, J. Chayes, C. Borgs, A. Chouldechova, S. C. Geyik, K. Kenthapadi, A. Kalai","168":"Xenia Ohmer, P. K\u00f6nig, M. Franke","169":"Tao Yu, Chien-Sheng Wu, Xi Victoria Lin, Bailin Wang, Y. Tan, Xinyi Yang, Dragomir Radev, R. Socher, Caiming Xiong","170":"Zheng Zhang, Luyao Liu, Yadan Luo, Zi Huang, Fumin Shen, H. Shen, Guangming Lu","171":"Jang Hyun Cho, Utkarsh Mall, K. Bala, B. Hariharan","172":"Ruifei He, Jihan Yang, Xiaojuan Qi","173":"Reza Azad, A. Fayjie, C. Kauffmann, I. B. Ayed, M. Pedersoli, J. Dolz","174":"Dong Zhang, Hanwang Zhang, Jinhui Tang, Xiansheng Hua, Qianru Sun","175":"Ruibo Liu, Chenyan Jia, Jason Wei, Guangxuan Xu, Lili Wang, Soroush Vosoughi","176":"Jinyu Yang, Weizhi An, Sheng Wang, Xinliang Zhu, Chao-chao Yan, Junzhou Huang","177":"Shaobo Min, Hantao Yao, Hongtao Xie, Chaoqun Wang, Zhengjun Zha, Yongdong Zhang","178":"Shuang Li, Mixue Xie, Fangrui Lv, Chi Harold Liu, Jian Liang, C. Qin, Wei Li","179":"Jieyu Zhao, Subhabrata Mukherjee, Saghar Hosseini, Kai-Wei Chang, Ahmed Hassan Awadallah","180":"Emily Dinan, Angela Fan, Ledell Yu Wu, J. Weston, Douwe Kiela, Adina Williams","181":"Aishan Liu, Jiakai Wang, Xianglong Liu, Bowen Cao, Chongzhi Zhang, Hang Yu","182":"Haewoon Kwak, Jisun An, Elise Jing, Yong-Yeol Ahn","183":"Tianlu Wang, Xi Victoria Lin, Nazneen Rajani, Vicente Ordonez, Caimng Xiong","184":"Amir Pouran Ben Veyseh, Tuan Ngo Nguyen, T. Nguyen","185":"M. Hashemi, M. Hall","186":"Weiwei Wang, Yuming Shen, Haofeng Zhang, Yazhou Yao, Li Liu","187":"N. Ousidhoum, Yangqiu Song, Dit-Yan Yeung","188":"Christoph Kamann, Burkhard G\u00fcssefeld, Robin Hutmacher, J. H. Metzen, C. Rother","189":"Fengmao Lv, Haiyang Liu, Yichen Wang, Jiayi Zhao, Guowu Yang","190":"Sunipa Dev, J. M. Phillips","191":"Felix Hamborg","192":"Fumin Shen, Xiaoping Zhou, Jun Yu, Yang Yang, Li Liu, H. Shen","193":"Seung-Jae Shin, Kyungwoo Song, Joonho Jang, Hyemi Kim, Weonyoung Joo, Il-Chul Moon","194":"Muhammad Waleed Gondal, Manuel W\u00fcthrich, \u00d0or\u00f0e Miladinovic, Francesco Locatello, M. Breidt, V. Volchkov, J. Akpo, Olivier Bachem, B. Sch\u00f6lkopf, Stefan Bauer","195":"Jasdeep Singh, Bryan McCann, R. Socher, Caiming Xiong","196":"Akanksha Paul, N. C. Krishnan, Prateek Munjal","197":"Mina Rezaei, Haojin Yang, C. Meinel","198":"Bailin Wang, Ivan Titov, Mirella Lapata","199":"Lukas Hoyer, Mauricio Mu\u00f1oz, P. Katiyar, A. Khoreva, Volker Fischer","200":"Shima Asaadi, Saif M. Mohammad, Svetlana Kiritchenko","201":"Siyao Li, Deren Lei, Pengda Qin, William Yang Wang","202":"Chris J. M. Yoon, G. Hamarneh, Rafeef Garbi","203":"Taylor R. Hayes, J. Henderson","204":"W. L. Cava, Jason H. Moore","205":"Felix Hamborg, Anastasia Zhukova, Bela Gipp","206":"Alexa Tompary, S. Thompson-Schill","207":"J. Pfau, Albert T. Young, Maria L. Wei, Michael J. Keiser","208":"Rakefet Ackerman, A. Gal, Tomer Sagi, Roee Shraga","209":"A. Steiner, Alexander Kolesnikov, Xiaohua Zhai, Ross Wightman, Jakob Uszkoreit, L. Beyer","210":"Xudong Wang, Long Lian, Zhongqi Miao, Ziwei Liu, Stella X. Yu","211":"Jacob Andreas","212":"Deven Santosh Shah, H. A. Schwartz, Dirk Hovy","213":"Deng-Ping Fan, Tengpeng Li, Zheng Lin, Ge-Peng Ji, Dingwen Zhang, Ming-Ming Cheng, H. Fu, Jianbing Shen","214":"Hongwei Wang, Miao Zhao, Xing Xie, Wenjie Li, M. Guo","215":"V. Guizilini, Rui Hou, Jie Li, Rares Ambrus, Adrien Gaidon","216":"P. Kirichenko, Pavel Izmailov, A. G. Wilson","217":"Dat T. Huynh, Ehsan Elhamifar","218":"Dongnan Liu, Donghao Zhang, Yang Song, Fan Zhang, L. O'Donnell, Heng Huang, Mei Chen, Weidong (Tom) Cai","219":"Shiming Chen, Wenjie Wang, Beihao Xia, Qinmu Peng, Xinge You, Feng Zheng, L. Shao","220":"Yicong Li, Xun Yang, Xindi Shang, Tat-Seng Chua","221":"Sunipa Dev, Tao Li, J. M. Phillips, Vivek Srikumar","222":"Liang Zhao, Tao Yang, Jie Zhang, Zhikui Chen, Yi Yang, Z. J. Wang","223":"Pengyu Cheng, Weituo Hao, Siyang Yuan, Shijing Si, L. Carin","224":"R. Gao, Xingsong Hou, Jie Qin, Jiaxin Chen, Li Liu, F. Zhu, Zhao Zhang, L. Shao","225":"Yuming Shen, Jie Qin, Lei Huang","226":"Deng-Ping Fan, Zheng Lin, Ge-Peng Ji, Dingwen Zhang, H. Fu, Ming-Ming Cheng","227":"B. Billot, D. Greve, K. Leemput, B. Fischl, J. E. Iglesias, Adrian V. Dalca","228":"Jin Ye, Junjun He, Xiaojiang Peng, Wenhao Wu, Y. Qiao","229":"Junnan Zhu, Yu Zhou, Jiajun Zhang, Haoran Li, Chengqing Zong, Changliang Li","230":"Wenhu Chen, Jianshu Chen, Pengda Qin, Xifeng Yan, William Yang Wang","231":"Yujia Zhou, Zhicheng Dou, Ji-rong Wen","232":"Peirong Ma, Xiao Hu","233":"Vaibhav Kumar, Tenzin Singhay Bhotia, Tanmoy Chakraborty","234":"Simone Conia, R. Navigli","235":"Qianyu Feng, Guoliang Kang, Hehe Fan, Yezhou Yang","236":"A. Pujari, Ansh Mittal, Anshuman Padhi, Anshul Jain, Mukesh K. Jadon, Vikas Kumar","237":"Nader Asadi, M. Hosseinzadeh, M. Eftekhari","238":"Meng Liu, P. Thomas","239":"Shaobo Min, Hantao Yao, Hongtao Xie, Zhengjun Zha, Yongdong Zhang","240":"Ganesh Jawahar, Djam\u00e9 Seddah","241":"Peter Shaw, Ming-Wei Chang, Panupong Pasupat, Kristina Toutanova","242":"Rishabh Bhardwaj, Navonil Majumder, Soujanya Poria","243":"Donghyeon Baek, Youngmin Oh, Bumsub Ham","244":"Fabio Cermelli, Massimiliano Mancini, S. R. Bul\u00f2, E. Ricci, B. Caputo","245":"Guangrui Li, Guoliang Kang, Wu Liu, Yunchao Wei, Yi Yang","246":"T. Radicioni, E. Pavan, T. Squartini, F. Saracco","247":"Shruti Jadon","248":"Po-Sen Huang, Huan Zhang, Ray Jiang, Robert Stanforth, Johannes Welbl, Jack W. Rae, Vishal Maini, Dani Yogatama, Pushmeet Kohli","249":"Nicolas Spatola, Olga A. Wudarczyk","250":"Suhyeon Lee, Junhyuk Hyun, Hongje Seong, Euntai Kim","251":"L. E. Celis, Anay Mehrotra, Nisheeth K. Vishnoi","252":"Qi Han, Kai Zhao, Jun Xu, Mingg-Ming Cheng","253":"Timo Spinde, Christina Kreuter, W. Gaissmaier, Felix Hamborg, Bela Gipp, H. Giese","254":"Zia Khan, N. Yahya, K. Alsaih, S. Ali, F. M\u00e9riaudeau","255":"Yubo Zhang, Hao Tan, Mohit Bansal","256":"Minghao Chen, Hongyang Xue, Deng Cai","257":"Markus Nagel, Mart van Baalen, Tijmen Blankevoort, M. Welling","258":"Haim Dubossarsky, Simon Hengchen, Nina Tahmasebi, Dominik Schlechtweg","259":"Bin Wen, Jie Luo, Xianglong Liu, Lei Huang","260":"Hossein ARABI, Guodong Zeng, Guoyan Zheng, H. Zaidi","261":"Lonesome Malambo, S. Popescu, N. Ku, W. Rooney, T. Zhou, S. Moore","262":"M. Shahdloo, Emin \u00c7elik, T. \u00c7ukur","263":"Patrick Esser, Robin Rombach, B. Ommer","264":"Zhuang Liu, Hanzi Mao, Chaozheng Wu, Christoph Feichtenhofer, Trevor Darrell, Saining Xie","265":"Muzammal Naseer, Kanchana Ranasinghe, S. Khan, Munawar Hayat, F. Khan, Ming-Hsuan Yang","266":"M. Schlichtkrull, Nicola De Cao, Ivan Titov","267":"Yen-Chang Hsu, Yilin Shen, Hongxia Jin, Z. Kira","268":"Santiago Ontan'on, J. Ainslie, V. Cvicek, Zachary Kenneth Fisher","269":"Kuansan Wang, Zhihong Shen, Chiyuan Huang, Chieh-Han Wu, Yuxiao Dong, Anshul Kanakia","270":"Md. Amirul Islam, M. Kowal, Patrick Esser, Sen Jia, B. Ommer, K. Derpanis, Neil D. B. Bruce","271":"J. Yu, Yuan Chai, Yue Hu, Qi Wu","272":"V. Hellendoorn, Charles Sutton, Rishabh Singh, Petros Maniatis, David Bieber","273":"Yu Chen, Lingfei Wu, Mohammed J. Zaki","274":"Arantxa Casanova, Pedro H. O. Pinheiro, Negar Rostamzadeh, C. Pal","275":"Dongling Xiao, Han Zhang, Yukun Li, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang","276":"Anne Lauscher, Goran Glavas, Simone Paolo Ponzetto, Ivan Vulic","277":"Dongnan Liu, Donghao Zhang, Yang Song, Fan Zhang, L. O'Donnell, Heng Huang, Mei Chen, Weidong (Tom) Cai","278":"S. Z. Dadaneh, Shahin Boluki, Mingzhang Yin, Mingyuan Zhou, Xiaoning Qian","279":"W. La Cava, Jason H. Moore","280":"Mingxing Zhang, Yang Yang, Hanwang Zhang, Yanli Ji, H. Shen, Tat-Seng Chua","281":"Shuwen Xiao, Zhou Zhao, Zijian Zhang, Ziyu Guan, Deng Cai","282":"Sai Kumar Dwivedi, Vikram Gupta, Rahul Mitra, Shuaib Ahmed, Arjun Jain","283":"Jaap Jumelet, Willem H. Zuidema, D. Hupkes","284":"Sunghyun Park, Seung-won Hwang, Fuxiang Chen, J. Choo, Jung-Woo Ha, Sunghun Kim, Jinyeong Yim","285":"Debasmit Das, C. S. G. Lee","286":"Albert Zhao, Tong He, Yitao Liang, Haibin Huang, Guy Van den Broeck, Stefano Soatto","287":"Daisuke Oba, Naoki Yoshinaga, Shoetsu Sato, Satoshi Akasaki, M. Toyoda","288":"Senthil Purushwalkam, A. Gupta","289":"Drew A. Hudson, Christopher D. Manning","290":"Jesse Mu, Jacob Andreas","291":"Drew A. Hudson, Christopher D. Manning","292":"Ning Xie, Farley Lai, Derek Doran, Asim Kadav","293":"Hong-xiang Chen, Kunhong Li, Zhiheng Fu, Mengyi Liu, Zonghao Chen, Yulan Guo","294":"Min Zeng, Min Li, Fang-Xiang Wu, Yaohang Li, Yi Pan","295":"Ziyi Chen, Cheng Wang, Jonathan Li, Nianci Xie, Yanyong Han, Jixiang Du","296":"Ziyi Yang, Yinfei Yang, Daniel Matthew Cer, Jax Law, Eric F Darve","297":"Noah Arthurs, AJ Alvero","298":"A. Wong, Safa Cicek, Stefano Soatto","299":"Chuan Qin, Hengshu Zhu, Tong Xu, Chen Zhu, Chao Ma, Enhong Chen, Hui Xiong","300":"Christopher Thomas, Adriana Kovashka","301":"Jingtao Zhan, Jiaxin Mao, Yiqun Liu, Min Zhang, Shaoping Ma","302":"Liang Qiu, Yizhou Zhao, Weiyan Shi, Yuan Liang, Feng Shi, Tao Yuan, Zhou Yu, Song-Chun Zhu","303":"Rocco Tripodi, M. Warglien, S. Sullam, Deborah Paci","304":"Mustafa Sercan Amac, Semih Yagcioglu, Aykut Erdem, Erkut Erdem","305":"S. Sajedi, Xiao Liang","306":"Zhou Yang, Muhammad Hilmi Asyrofi, D. Lo","307":"G. Dimauro, L. Simone","308":"Wuyang Chen, Zhiding Yu, Shalini De Mello, Sifei Liu, J. \u00c1lvarez, Zhangyang Wang, Anima Anandkumar","309":"Eunjin Chun, E. Kaan","310":"Shengwei An, Rishabh Singh, Sasa Misailovic, R. Samanta","311":"Zichun Su, Jialin Jiang","312":"J. Pfau, Albert T. Young, Jerome Wei, Maria L. Wei, Michael J. Keiser","313":"Xinpeng Li, Dan Zhang, Mao Ye, Xue Li, Q. Dou, Qiao Lv","314":"Zhong Ji, Biying Cui, Yunlong Yu, Yanwei Pang, Zhongfei Zhang","315":"Gengwei Zhang, Guoliang Kang, Yunchao Wei, Yi Yang","316":"Ahram Song, Jaewan Choi","317":"Zili Wang","318":"Jiabo Huang, Yang Liu, S. Gong, Hailin Jin","319":"T. Lindsey, Jin-Ju Lee","320":"Luoqiu Li, Xiang Chen, Hongbin Ye, Zhen Bi, Shumin Deng, Ningyu Zhang, Huajun Chen","321":"Y. Zhang, Zilei Wang","322":"Lucas O. Teixeira, R. M. Pereira, Diego Bertolini, Luiz Oliveira, L. Nanni, Yandre M. G. Costa","323":"Sarim Zafar, Muhammad Zubair Malik, G. Walia","324":"M. Virgolin, T. Alderliesten, C. Witteveen, P. Bosman","325":"Melvin Wevers, M. Koolen","326":"Liang Hu, Gang Wu, Yongheng Xing, Feng Wang","327":"Shuai Lin, Pan Zhou, Zi-Yuan Hu, Shuojia Wang, Ruihui Zhao, Yefeng Zheng, Liang Lin, E. Xing, Xiaodan Liang","328":"L. Machado, Renato Rocha Souza, Maria da Gra\u00e7a de Melo Sim\u00f5es","329":"J. Minot, Nicholas Cheney, Marc E. Maier, Danne C. Elbers, C. Danforth, P. Dodds","330":"Maoguo Gong, Xiangming Jiang, Hao Li, K. Tan","331":"P. Schramowski, Cigdem Turan, Sophie F. Jentzsch, C. Rothkopf, K. Kersting","332":"Jianhong Wang, Yuan Zhang, Tae-Kyun Kim, Yunjie Gu","333":"Shir Gur, Ameen Ali, L. Wolf","334":"Chaoqun Wang, Xuejin Chen, Shaobo Min, Xiaoyan Sun, Houqiang Li","335":"P. Dimmock","336":"Massimo Stella","337":"Apoorv Khandelwal, Luca Weihs, R. Mottaghi, Aniruddha Kembhavi","338":"Pranav Agarwal, Alejandro Betancourt, V. Panagiotou, Natalia D\u00edaz Rodr\u00edguez","339":"Jiawei Zhou, Tahira Naseem, Ram\u00f3n Fern\u00e1ndez Astudillo, Radu Florian","340":"Rafael Felix, Ben Harwood, M. Sasdelli, G. Carneiro","341":"Poorya Zaremoodi, Gholamreza Haffari","342":"Melissa Ailem, Bowen Zhang, Fei Sha","343":"Shrey Desai, Ahmed Aly","344":"Gengcong Yang, Jingyi Zhang, Yong Zhang, Baoyuan Wu, Yujiu Yang","345":"Ying Da Wang, Mehdi Shabaninejad, R. Armstrong, P. Mostaghimi","346":"L. Ismailova, S. Kosikov, K. Zinchenko, Viacheslav Wolfengagen","347":"Zhanming Guan, Bin Wu, Bai Wang, Hezi Liu","348":"Xinyu Xiao, Lingfeng Wang, Kun Ding, Shiming Xiang, Chunhong Pan","349":"Ruiyi Zhang, Changyou Chen, Zhe Gan, Zheng Wen, Wenlin Wang, L. Carin","350":"M. Aurnague, D. Stosic","351":"Ningyu Zhang, Luoqiu Li, Shumin Deng, Haiyang Yu, Xu Cheng, Wei Zhang, Huajun Chen","352":"Mina Rezaei, Haojin Yang, Konstantin Harmuth, C. Meinel","353":"Rinu Chacko, D. Jain, Manasi S. Patwardhan, Abhishek Puri, Shirish S. Karande, B. Rai","354":"Jiamin Wu, Tianzhu Zhang, Zhengjun Zha, Jiebo Luo, Yongdong Zhang, Feng Wu","355":"William Thong, Cees G. M. Snoek","356":"Laura Oberl\u00e4nder, K. Reich, Roman Klinger","357":"Yaza Wainakh, Moiz Rauf, Michael Pradel","358":"M\u00e1t\u00e9 \u00c1kos T\u00fcndik, Val\u00e9r Kasz\u00e1s, Gy\u00f6rgy Szasz\u00e1k","359":"Andr\u00e9 Ferreira Cruz, Gil Rocha, Henrique Lopes Cardoso","360":"Xianyou Zhu, X. Wang, Haochen Zhao, Tingrui Pei, Linai Kuang, Lei Wang","361":"Manoj Reddy Dareddy, Mahashweta Das, Hao Yang","362":"Han-Jia Ye, De-Chuan Zhan, Yuan Jiang, Zhi-Hua Zhou","363":"Yang Hu, Guihua Wen, Adriane P. Chapman, Pei Yang, Mingnan Luo, Yingxue Xu, Dan Dai, Wendy Hall","364":"Rohan Padhye, Caroline Lemieux, Koushik Sen, Mike Papadakis, Y. L. Traon","365":"Arka Sadhu, Kan Chen, R. Nevatia","366":"Jacob Russin, Jason Jo, R. O\u2019Reilly, Y. Bengio","367":"Mohammad Darwich, S. Noah, N. Omar, Nurul Aida Osman, Ibrahim Said, Ahmad","368":"Xiangxi Jiang, Liqiang Ding, Mohammad Havaei, A. Jesson, S. Matwin","369":"Binyuan Hui, Ruiying Geng, Qiyu Ren, Binhua Li, Yongbin Li, Jian Sun, Fei Huang, Luo Si, Pengfei Zhu, Xiaodan Zhu","370":"Shiming Chen, Ziming Hong, Yang Liu, Guosen Xie, Baigui Sun, Hao Li, Qinmu Peng, Ke Lu, Xinge You","371":"Jiwen Tang, Zheng Zhang, Lijun Zhao, P. Tang","372":"Saurabh Kulshreshtha, Jos\u00e9 Luis Redondo Garc\u00eda, Ching-Yun Chang","373":"Lukas Hoyer, Dengxin Dai, L. Gool","374":"Hantao Yao, Shaobo Min, Yongdong Zhang, Changsheng Xu","375":"Arjun D Desai, Francesco Caliv\u00e1, C. Iriondo, Naji Khosravan, Aliasghar Mortazi, S. Jambawalikar, D. Torigian, J. Ellerman, M. Ak\u00e7akaya, U. Bagci, R. Tibrewala, I. Flament, Matthew S Obrien, S. Majumdar, Mathias Perslev, A. Pai, C. Igel, E. Dam, S. Gaj, Mingrui Yang, Kunio Nakamura, Xiaojuan Li, C. Deniz, V. Juras, R. Regatte, G. Gold, B. Hargreaves, V. Pedoia, A. Chaudhari","376":"Madeleine Y. Stepper, B. Rolke, Elisabeth Hein","377":"Jianmo Ni, Chun-Nan Hsu, Amilcare Gentili, Julian McAuley","378":"Jeroen van Doorenmalen, Vlado Menkovski","379":"Sajad Norouzi, Keyi Tang, Yanshuai Cao","380":"Xiaogang Wang, Qianru Sun, Tat-Seng Chua, M. Ang","381":"Lulu Zhao, Weihao Zeng, Weiran Xu, Jun Guo","382":"Xiaoyan Jiang, Yongbin Gao, Zhijun Fang, Peng Wang, Bo Huang","383":"Alex Lamb, Di He, Anirudh Goyal, Guolin Ke, Chien-Feng Liao, M. Ravanelli, Yoshua Bengio","384":"G. Franchi, Nacim Belkhir, Mai Lan Ha, Yufei Hu, Andrei Bursuc, V. Blanz, Angela Yao","385":"Mingjie Li, Fuyu Wang, Xiaojun Chang, Xiaodan Liang","386":"Youngtaek Oh, Dong-jin Kim, I. Kweon","387":"Daniel Loureiro, Kiamehr Rezaee, Mohammad Taher Pilehvar, Jos\u00e9 Camacho-Collados","388":"Yoav Levine, Noam Wies, Daniel Jannai, D. Navon, Yedid Hoshen, A. Shashua","389":"Xinyao Ma, Maarten Sap, Hannah Rashkin, Yejin Choi","390":"Ninareh Mehrabi, Fred Morstatter, N. Saxena, Kristina Lerman, A. Galstyan","391":"J. Sterne, J. Savovi\u0107, M. Page, R. Elbers, N. Blencowe, I. Boutron, C. Cates, Hung-Yuan Cheng, M. Corbett, S. Eldridge, J. Emberson, M. Hern\u00e1n, S. Hopewell, A. Hr\u00f5bjartsson, D. Junqueira, P. J\u00fcni, J. Kirkham, T. Lasserson, Tianjing Li, A. McAleenan, B. Reeves, S. Shepperd, I. Shrier, L. Stewart, K. Tilling, I. White, P. Whiting, J. Higgins","392":"Maarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi, Noah A. Smith","393":"Nicole Shadowen","394":"Aki Koivula, P. R\u00e4s\u00e4nen, Outi Sarpila","395":"Sunipa Dev, Tao Li, J. M. Phillips, Vivek Srikumar","396":"M. Borovcnik","397":"H. Kumar, B. Harish, H. Darshan","398":"S. Karve, Lyle Ungar, Jo\u00e3o Sedoc","399":"P. Rochat","400":"Sandeep Attree","401":"Chan Young Park, Xinru Yan, Anjalie Field, Yulia Tsvetkov","402":"Chris. Miller, M. Poston","403":"Pei Zhou, Weijia Shi, Jieyu Zhao, Kuan-Hao Huang, Muhao Chen, Ryan Cotterell, Kai-Wei Chang","404":"Prasetya Ajie Utama, N. Moosavi, Iryna Gurevych","405":"Mihaela Vorvoreanu, Lingyi Zhang, Yun-Han Huang, C. Hilderbrand, Zoe Steine-Hanson, M. Burnett","406":"Christopher Clark, Mark Yatskar, Luke Zettlemoyer","407":"Jochen Sieg, Florian Flachsenberg, M. Rarey","408":"Nan Xi, Di Ma, Marcus Liou, Zachary C. Steinert-Threlkeld, Jason Anastasopoulos, Jungseock Joo","409":"R. Baly, Giovanni Da San Martino, James R. Glass, Preslav Nakov","410":"R. Baly, Georgi Karadzhov, Abdelrhman Saleh, James R. Glass, Preslav Nakov","411":"Julie Jiang, Xiang Ren, Emilio Ferrara","412":"Fabian Baumann, Philipp Lorenz-Spreen, I. Sokolov, M. Starnini","413":"Julie Jiang, Xiang Ren, Emilio Ferrara","414":"Daejin Choi, Selin Chun, H. Oh, Jinyoung Han, T. Kwon","415":"Yingqiang Ge, Shuyang Zhao, H. Zhou, Changhua Pei, Fei Sun, Wenwu Ou, Yongfeng Zhang","416":"Federico Cinus, Marco Minici, Corrado Monti, F. Bonchi","417":"Rui Luo, Buddhika Nettasinghe, V. Krishnamurthy","418":"Bohan Jiang, Mansooreh Karami, Lu Cheng, T. Black, Huan Liu","419":"F. Alatawi, Lu Cheng, Anique Tahir, Mansooreh Karami, Bohan Jiang, T. Black, Huan Liu","420":"Matteo Cinelli, G. D. F. Morales, Alessandro Galeazzi, Walter Quattrociocchi, M. Starnini","421":"Xin Wang, Shaoting Tang, Zhiming Zheng, Feng Fu","422":"Shelley Boulianne, Karolina Koc-Michalska, Bruce Bimber","423":"Brent Kitchens, Steven L. Johnson, Peter Gray","424":"S. Gadarian","425":"Xiaohui Wang, Yunya Song","426":"Jonathan Bright, Nahema Marchal, B. Ganesh, S. Rudinac","427":"Christopher Torres-Lugo, Kai-Cheng Yang, F. Menczer","428":"I. Kozitsin, A. Chkhartishvili","429":"Gabriel Martinez, N. Tenev","430":"B. Phillips, C. Bauch","431":"E. Noordeh, Roman Levin, Ruochen Jiang, Harris Shadmany","432":"Homa Hosseinmardi, Amir Ghasemian, A. Clauset, David M. Rothschild, M. Mobius, D. Watts","433":"G. D. F. Morales, Corrado Monti, M. Starnini","434":"K. Sasahara, Wen Chen, Hao Peng, G. Ciampaglia, A. Flammini, F. Menczer","435":"K. Sasahara, Wen Chen, Hao Peng, G. Ciampaglia, A. Flammini, F. Menczer","436":"Mina Young Pedersen, S. Smets, Thomas \u00c5gotnes","437":"Nikita Duseja, Harsh Jhamtani","438":"Marten Risius, Okan Ayding\u00fcl, Maximilian Haug","439":"Jiyoung Han, Youngin Lee, Junbum Lee, M. Cha","440":"Moritz Markgraf, Manfred Schoch","441":"Emanuele Brugnoli, Matteo Cinelli, Fabiana Zollo, Walter Quattrociocchi, A. Scala","442":"Yves Costa Netto, A. Ma\u00e7ada","443":"Nynke M. D. Niezink","444":"A. Peruzzi, Fabiana Zollo, Ana Luc\u00eda Schmidt, Walter Quattrociocchi","445":"Alessandro Cossard, G. D. F. Morales, Kyriaki Kalimeri, Yelena Mejova, D. Paolotti, M. Starnini","446":"Kuan-Chieh Lo, Shih-Chieh Dai, Aiping Xiong, Jing Jiang, Lun-Wei Ku","447":"Youngseung Jeon, Bogoan Kim, Aiping Xiong, Dongwon Lee, Kyungsik Han","448":"Tim Donkers, J. Ziegler","449":"Antonela Tommasel, J. M. Rodr\u00edguez, D. Godoy","450":"Virginia Morini, Laura Pollacci, Giulio Rossetti","451":"Giacomo Villa, G. Pasi, Marco Viviani","452":"Matan Orbach, Yonatan Bilu, Assaf Toledo, D. Lahav, Michal Jacovi, R. Aharonov, N. Slonim","453":"W. Cota, Silvio C. Ferreira, R. Pastor-Satorras, M. Starnini","454":"An Nguyen, H. Vu","455":"Duilio Balsamo, Valeria Gelardi, Chengyuan Han, D. Rama, Abhishek Samantray, C. Zucca, M. Starnini","456":"Henrique Ferraz de Arruda, Alexandre Benatti, Filipi Nascimento Silva, C. H. Comin, L. da Fontoura Costa","457":"Renee Bowen, Danil Dmitriev, S. Galperti","458":"Ruibo Liu, Lili Wang, Chenyan Jia, Soroush Vosoughi","459":"Rohit Kumar Kaliyar, Anurag Goswami, Pratik Narang","460":"T. Radicioni, T. Squartini, E. Pavan, F. Saracco","461":"Uthsav Chitra, C. Musco","462":"Francesco Pierri, C. Piccardi, S. Ceri","463":"Rohit Kumar Kaliyar, Anurag Goswami, Pratik Narang","464":"R. P. Curiel, Humberto Gonz'alez Ram'irez","465":"Siqi Wu, P. Resnick","466":"D. Lauer","467":"Ho-Chun Herbert Chang, Emily Chen, Meiqing Zhang, Goran Muri\u0107, Emilio Ferrara","468":"Dimitris Kalimeris, Smriti Bhagat, Shankar Kalyanaraman, Udi Weinsberg","469":"Lisa Oswald, Jonathan Bright","470":"Ray Jiang, S. Chiappa, Tor Lattimore, A. Gy\u00f6rgy, Pushmeet Kohli","471":"H. Prasetya, T. Murata","472":"Tian Yang, S\u00edlvia Maj\u00f3-V\u00e1zquez, R. Nielsen, Sandra Gonz\u00e1lez-Bail\u00f3n","473":"Yan Xia, T. H. Chen, Mikko Kivel\u00e4","474":"Dana McKay, S. Makri, M. Gutierrez-Lopez, A. MacFarlane, S. Missaoui, Colin Porlezza, Glenda Cooper","475":"C. Blex, T. Yasseri","476":"Longzhao Liu, Xin Wang, Yihui Zheng, Wenyi Fang, Shaoting Tang, Zhiming Zheng","477":"Huyen T. Le, Raven S. Maragh, Brian Ekdale, Andrew C. High, T. Havens, Zubair Shafiq","478":"Stefano Guarino, Noemi Trino, Alessandro Celestini, A. Chessa, Gianni Riotta","479":"Daniel R\u00f6chert, German Neubaum, Bj\u00f6rn Ross, Florian Brachten, Stefan Stieglitz","480":"K. Allison, K. Bussey","481":"Wen Chen, D. Pacheco, Kai-Cheng Yang, F. Menczer","482":"Alexandre Benatti, H. F. D. Arruda, F. N. Silva, C. H. Comin, L. D. Costa","483":"A. Shahin, Sultan Almotairi","484":"T. Abdelzaher, Heng Ji, Jinyang Li, Chaoqi Yang, John Dellaverson, Lixian Zhang, Chao Xu, B. Szymanski","485":"Lukas Schwengerer","486":"L. Fell, A. Gibson, P. Bruza, Pamela Hoyte","487":"Inayathullah Ghori, Debaditya Roy, R. John, Krishna Mohan Chalavadi","488":"E. Kang, Cin Young Hur, Yong Soon Choi","489":"Dimitar Nikolov, A. Flammini, F. Menczer","490":"Benjamin D. Horne, Jeppe N\u00f8rregaard, Sibel Adali","491":"Anders Edelbo Lillie, Emil Refsgaard Middelboe","492":"Urbano Reviglio","493":"A. Dash, Animesh Mukherjee, Saptarshi Ghosh","494":"Yong Min, Tingjun Jiang, Cheng Jin, Qu Li, Xiaogang Jin","495":"Neil Thurman","496":"Wenjun Mei, F. Bullo, Ge Chen, F. D\u00f6rfler","497":"Thomas H\u00e4ussler","498":"A. Bagavathi, Pedram Bashiri, S. Reid, Matthew Phillips, S. Krishnan","499":"Alexis M. Elder","500":"A. Abdi, T. Tsang, P. Abolmaesumi","501":"Wei Li, Xu Tan","502":"W. Dutton, Bianca C. Reisdorf, Grant Blank, Elizabeth Dubois, Laleah Fernandez","503":"S. Engel, Linda Lee-Davies","504":"Francesco Pierri, C. Piccardi, S. Ceri","505":"Shayan A. Tabrizi, A. Shakery","506":"Dimitris Sacharidis","507":"Timotheus Kampik, A. Najjar","508":"R. Bierig, Simon Caton","509":"Rob Walton, D. D. Roure","510":"Geoffrey E. Hinton","511":"F. Santos, Yphtach Lelkes, S. Levin","512":"A. F. Peralta, J'anos Kert'esz, G. I\u00f1iguez","513":"Marialisa Scat\u00e0, Alessandro Di Stefano, Aurelio La Corte, P. Lio\u2019","514":"Matteo Cinelli, Emanuele Brugnoli, A. L. Schmidt, Fabiana Zollo, Walter Quattrociocchi, A. Scala","515":"Emilio Ferrara, Herbert Chang, Emily Chen, Goran Muri\u0107, Jaimin Patel","516":"Heather Z. Brooks, M. Porter","517":"Hilah Geva, Gal Oestreicher-Singer, M. Saar-Tsechansky","518":"Jie Gao, G. Schoenebeck, Fang-Yi Yu","519":"R. Luzsa, S. Mayr","520":"Echo Ho, A. D. Campo, H. Hoelzl","521":"Cedric Waterschoot, A. V. D. Bosch, E. Hemel","522":"M. Saadatmand, Elham Fathipour, Alireza Noei Sarcheshmeh","523":"Amin Mekacher, Antonis Papasavva","524":"Nika Haghtalab, M. Jackson, Ariel D. Procaccia","525":"Mehwish Nasim, Derek Weber, Tobin South, Simon Jonathan Tuke, N. Bean, Lucia Falzon, Lewis Mitchell","526":"A. Bracci","527":"Michele Travierso","528":"Yan Xia, T. H. Chen, Mikko Kivel\u00e4","529":"Dawoud Al Kindi, M. Househ, T. Alam, Zubair Shah","530":"Joseph L. Clarke","531":"Stefan Stieglitz","532":"Christopher Torres-Lugo, Kai-Cheng Yang, F. Menczer","533":"Sebastian Schams, Jan Hauffa, Maximilian Schmidt, Georg Groh","534":"Niccol\u00f2 Di Marco, Matteo Cinelli, Walter Quattrociocchi","535":"Amy Perfors, D. Navarro","536":"Muhammad Al Atiqi, Shuang Chang, H. Deguchi","537":"N. Tkachenko, Weisi Guo","538":"Jacques Bara, Omer Lev, P. Turrini","539":"J. Shine, M. Breakspear, P. Bell, K. E. Ehgoetz Martens, R. Shine, O. Koyejo, O. Sporns, R. Poldrack","540":"Emily Wall, J. Stasko, A. Endert","541":"Evanthia Dimara, S. Franconeri, C. Plaisant, A. Bezerianos, Pierre Dragicevic","542":"A. Caraban, E. Karapanos, Daniel Gon\u00e7alves, Pedro F. Campos","543":"M. Kinsey, S. Gwynne, E. Kuligowski, M. Kinateder","544":"Bryan Dosono, Bryan C. Semaan","545":"Peiyang Li, Huan Liu, Yajing Si, Cunbo Li, Fali Li, Xuyang Zhu, Xiaoye Huang, Yin Zeng, D. Yao, Yangsong Zhang, Peng Xu","546":"Jernej Mihelj, Y. Zhang, A. Kos, Urban Sedlar","547":"Antino Kim, Patricia L. Moravec, A. Dennis","548":"Lenin Guaya-Delgado, E. Pallar\u00e8s-Segarra, A. M. Mezher, J. Forn\u00e9","549":"M. Gerosa, I. Wiese, Bianca Trinkenreich, Georg J. P. Link, G. Robles, Christoph Treude, Igor Steinmacher, A. Sarma","550":"Yasir Hussain, Huang Zhiqiu, M. Akbar, Ahmed Alsanad, A. Alsanad, Asif Nawaz, I. A. Khan, Z. Khan","551":"Marios Kokkodis, Theodoros Lappas","552":"Ana Reyes-Menendez, Jos\u00e9 Ram\u00f3n Saura, J. Mart\u00ednez\u2010Naval\u00f3n","553":"Jie Cui, Xiaoyu Zhang, Hong Zhong, Zuobin Ying, Lu Liu","554":"A. Cartwright, E. Cartwright","555":"I. Howley, Gaurav Tomar, Oliver Ferschke, C. Ros\u00e9","556":"Sadika Amreen, Andrey Karnauch, A. Mockus","557":"A. Alami, M. Cohn, A. Wasowski","558":"Thomas Morstyn, M. Mcculloch","559":"Haoyan Sun, Ming Fan, Yong Tan","560":"Gary E. Bolton, D. Kusterer, J. Mans","561":"Liviu-Adrian Hirtan, C. Dobre, H. Gonz\u00e1lez-V\u00e9lez","562":"Zhou Su, Qifan Qi, Qichao Xu, Song Guo, Xiaowei Wang","563":"S. Slussarenko, G. Pryde","564":"Zhou Su, Yuntao Wang, Qichao Xu, M. Fei, Yu-Chu Tian, Ning Zhang","565":"Li Chen, S. Yao, Kaijie Zhu","566":"Dapeng Tao, Jun Cheng, Zhengtao Yu, Kun Yue, Lizhen Wang","567":"Farhan Ullah, Hamad Naeem, Sohail Jabbar, S. Khalid, M. Latif, F. Al-turjman, L. Mostarda","568":"T. Rasool, Wasi Haider Butt, A. Shaukat, M. Akram","569":"Junting Ye, S. Skiena","570":"Adamu Sani Yahaya, N. Javaid, M. Javed, M. Shafiq, W. Z. Khan, M. Aalsalem","571":"Affaf Shahid, Umair Sarfraz, Muhammad Waseem Malik, Muhammad Sohaib Iftikhar, A. Jamal, N. Javaid","572":"Leonard Przybilla, Maxi Rahn, Manuel Wiesche, H. Krcmar","573":"S. Mahmood, Anwar Ghani, Ali Daud, S. Shamshirband","574":"B. Khan, F. Anwar, R. F. Olanrewaju, Bisma Rasool Pampori, R. Mir","575":"Atia Javaid, M. Zahid, Ishtiaq Ali, R. U. Khan, Zainib Noshad, N. Javaid","576":"M. Careem, A. Dutta","577":"Chunyuan Yuan, Qianwen Ma, W. Zhou, Jizhong Han, Songlin Hu","578":"Gene M. Alarcon, Anthony M. Gibson, Charles Walter, R. Gamble, Tyler J. Ryan, Sarah A. Jessup, Brian Boyd, August A. Capiola","579":"Zhen Shao, Yue Guo, Xiaotong Li, S. Barnes","580":"Ryan Kennedy, Philip D. Waggoner, M. Ward","581":"Davide Ceolin, G. Primiero","582":"Aikaterini Soumelidou, A. Tsohou","583":"Jiao Sun, Nanyun Peng","584":"Himan Abdollahpouri, M. Mansoury, R. Burke, B. Mobasher","585":"R. Sloan, Richard Warner","586":"Felix Hamborg, Anastasia Zhukova, K. Donnay, Bela Gipp","587":"A. Jesson, S. Mindermann, Y. Gal, Uri Shalit","588":"A. Bierema, Anne-Marie Hoskinson, R. Moscarella, Alex Lyford, Kevin C. Haudek, John E. Merrill, M. Urban-Lurain","589":"Gabriel Mittag, Saman Zadtootaghaj, Thilo Michael, Babak Naderi, S. M\u00f6ller","590":"Meric Altug Gemalmaz, M. Yin","591":"Daniel B. Dodgson, J. Raymond","592":"Ahsan Mahmood, H. Khan, Muhammad Ramzan","593":"Himan Abdollahpouri, M. Mansoury, R. Burke, B. Mobasher","594":"Victor M. van Santen, H. Amrouch, J. Henkel","595":"Zuohui Fu, Yikun Xian, Ruoyuan Gao, Jieyu Zhao, Qiaoying Huang, Yingqiang Ge, Shuyuan Xu, Shijie Geng, C. Shah, Yongfeng Zhang, Gerard de Melo","596":"Ke Yang, Biao Huang, Julia Stoyanovich, Sebastian Schelter","597":"Feiyang Pan, Xiang Ao, Pingzhong Tang, Min Lu, Dapeng Liu, Lei Xiao, Qing He","598":"Xinyi Dai, Jiawei Hou, Qing Liu, Yunjia Xi, Ruiming Tang, Weinan Zhang, Xiuqiang He, Jun Wang, Yong Yu","599":"Sheng Hu, Yuqing Ma, Xianglong Liu, Yanlu Wei, Shihao Bai","600":"Sudhir K. Satpathy, S. Mathew, Raghavan Kumar, Vikram B. Suresh, M. Anders, H. Kaul, A. Agarwal, S. Hsu, R. Krishnamurthy, V. De","601":"T. Glushkova, Chrysoula Zerva, Ricardo Rei, Andr\u00e9 Martins","602":"M. Cordel, Shaojing Fan, Zhiqi Shen, M. Kankanhalli","603":"N. Gkanatsios, Vassilis Pitsikalis, P. Maragos","604":"D. Molinari, A. R. Scorzini, C. Arrighi, F. Carisi, F. Castelli, A. Domeneghetti, Alice Gallazzi, M. Galliani, F. Grelot, P. Kellermann, H. Kreibich, G. Mohor, Markus Mosimann, S. Natho, Claire Richert, K. Schroeter, A. Thieken, A. Zischg, F. Ballio","605":"Heba Khdr, H. Amrouch, J. Henkel","606":"Ananth Balashankar, Alyssa Lees, Chris Welty, L. Subramanian","607":"R. P\u00f3voa, N. Louren\u00e7o, R. Martins, A. Canelas, N. Horta, J. Goes","608":"Woojoo Lee, Tae-Wook Kang, Jae-Jin Lee, Kyuseung Han, Joongheon Kim, Massoud Pedram","609":"An Yan, Bill Howe","610":"Wenlong Sun, Sami Khenissi, O. Nasraoui, Patrick Shafto","611":"Lin Gu, Deze Zeng, Sheng Tao, Song Guo, Hai Jin, Albert Y. Zomaya, W. Zhuang","612":"Samuel Tuhkanen, J. Pekkanen, E. Lehtonen, Otto Lappi","613":"Jesperi Rantanen, L. Ruotsalainen, M. Kirkko-Jaakkola, M. M\u00e4kel\u00e4","614":"Ziyi Kou, Yang Zhang, Lanyu Shang, Dong Wang","615":"Marina Dabic, Timothy Kiessling","616":"Yuxuan Han, Jiaolong Yang, Ying Fu","617":"Jacob Hadnett-Hunter, George Nicolaou, E. O'Neill, M. Proulx","618":"M. O\u2019Driscoll, C. Harry, C. Donnelly, A. Cori, I. Dorigatti","619":"L. Quaglietta, M. Porto","620":"Abdalla Abdelrahman, H. Hassanein, N. Ali","621":"Vidhisha Balachandran, Artidoro Pagnoni, Jay Yoon Lee, Dheeraj Rajagopal, J. Carbonell, Yulia Tsvetkov","622":"Minghong Cai, Jinghua Zhu","623":"Andrew Thirlwell, Ognjen Arandjelov\u00edc","624":"Emma Beauxis-Aussalet","625":"Rahim Khan, M. Zakarya, Zhiyuan Tan, Muhammad Usman, M. Jan, Mukhtaj Khan","626":"Katarina Kosteli\u0107","627":"Laura Schelenz","628":"M. Alipour, Sophie Dupuy-Chessa, Eline Jongmans","629":"Maurilio Monsu, M. Comin","630":"S. Ravichandran, Drona Khurana, B. Venkatesh, N. U. Edakunni","631":"Guillermo Ant\u00fanez-Calistro, Mariana Siniscalchi, F. Silveira, Conrado Rossi-Aicardi","632":"Jie Yang, Chao-Kai Wen, Shi Jin, Xiao Li","633":"Shaoyang Men, P. Charg\u00e9, Yide Wang, Jianzhong Li","634":"Falk Lieder, T. Griffiths","635":"Hesameddin Mokhtarzadeh, Amirhossein Taherpour, A. Taherpour, S. Gazor","636":"Ouhao Chen, Slava Kalyuga","637":"Xin Liu, Xueyan Zhang","638":"Xin Liu, H. Ding, Su Hu","639":"Florian Brachten, Felix Br\u00fcnker, Nicholas R. J. Frick, Bj\u00f6rn Ross, Stefan Stieglitz","640":"Ke Zhang, S. Leng, Xin Peng, Li Pan, Sabita Maharjan, Yan Zhang","641":"Zhiqun Song, Xin Wang, Yutao Liu, Zhongzhao Zhang","642":"Woping Xu, Runhe Qiu, Xueqin Jiang","643":"Boyang Liu, Jin Wang, Shuai Ma, Fuhui Zhou, Yujiao Ma, G. Lu","644":"Rami Halloush, Mohammed D. Halloush, Islam T. Almalkawi, A. Musa, H. Salameh","645":"Christine Salahub, Holly A. Lockhart, Blaire Dube, Naseem Al-Aidroos, Stephen M. Emrich","646":"I. A. Sohu, Asif Ahmed Rahimoon, Amjad Ali Junejo, Arsalan Ahmed Sohu, Sadam Hussain Junejo","647":"Christine Salahub, Holly A. Lockhart, Blaire Dube, Naseem Al-Aidroos, Stephen M. Emrich","648":"Ryan Smith, K. Friston, Christopher Whyte","649":"K. Denecke, Sayan Vaaheesan, Aaganya Arulnathan","650":"D. Do, M. V. Nguyen, Furqan Jameel, R. J\u00e4ntti, I. S. Ansari","651":"Mark K. Ho, David Abel, Jonathan D. Cohen, M. Littman, T. Griffiths","652":"S. Ladouce, D. Donaldson, P. Dudchenko, M. Ietswaart","653":"Neda Afzaliseresht, Yuan Miao, Sandra Michalska, Qing Liu, Hua Wang","654":"Liangtian Wan, Lu Sun, Xiangjie Kong, Yuyuan Yuan, Keyi Sun, Feng Xia","655":"Miguel Ramlatchan","656":"Ahmed Al-Tahmeesschi, Miguel L\u00f3pez-Ben\u00edtez, Dhaval K. Patel, Janne J. Lehtom\u00e4ki, K. Umebayashi","657":"Zhijin Qin, Xiangwei Zhou, Lin Zhang, Yue Gao, Ying-Chang Liang, Geoffrey Y. Li","658":"Sebastian Musslick, Andrew M. Saxe, A. N. Hoskin, Daniel Reichman, Jonathan D. Cohen","659":"A. Baddeley, G. Hitch, R. Allen","660":"A. Owens, C. Ballard, M. Beigi, C. Kalafatis, H. Brooker, G. Lavelle, K. Br\u00f8nnick, J. Sauer, S. Boddington, Latha Velayudhan, D. Aarsland","661":"Spencer Frazier, Mark O. Riedl","662":"Giancarlo Kerg, Bhargav Kanuparthi, Anirudh Goyal, Kyle Goyette, Yoshua Bengio, Guillaume Lajoie","663":"T. Haid, P. Federolf","664":"F. Tang, Long Chen, Xu Li, L. Yang, Luoyi Fu","665":"Mononito Goswami, Lujie Chen, A. Dubrawski","666":"Peyman Toreini, Moritz Langner, A. Maedche","667":"V. R. Bejjanki, R. Aslin","668":"Justus Robertson, A. Kokkinakis, J. Hook, B. Kirman, Florian Block, M. Ursu, Sagarika Patra, Simon Demediuk, Anders Drachen, Oluseyi Olarewaju","669":"Patricia L\u00f3pez de Frutos, R. Rodr\u00edguez, Danlin Zhang, Shutao Zheng, J. Ca\u00f1as, Enrique Mu\u00f1oz-de-Escalona","670":"Oscar J. Romero","671":"A. S. Nobandegani, Kevin da Silva Castanheira, Timothy O'Donnell, T. Shultz","672":"Rub\u00e9n Moreno-Bote, J. Ram\u00edrez-Ruiz, Jan Drugowitsch, B. Hayden","673":"Oscar J. Romero","674":"M. Gaafar, M. Shaghaghi, R. Adve, Z. Ding","675":"B. Wu, Murat Cubuktepe, Suda Bharadwaj, U. Topcu","676":"Hemant Purohit, C. Castillo, Rahul Pandey","677":"A. Joykutty, B. Baranidharan","678":"Hector Palada, A. Neal, D. Strayer, T. Ballard, A. Heathcote","679":"Ryan Smith, P. Schwartenbeck, Thomas Parr, Karl J. Friston","680":"Ryan Smith, P. Schwartenbeck, Thomas Parr, Karl J. Friston","681":"Carlos Correa, Mark K. Ho, Frederick Callaway, T. Griffiths","682":"D. Jaiswal, Arijit Chowdhury, Tanushree Banerjee, D. Chatterjee","683":"M. Imani, Zhuowen Zou, Samuel Bosch, Sanjay Anantha Rao, Sahand Salamat, Venkatesh Kumar, Yeseong Kim, T. Simunic","684":"Xiaodi Liu, Zengwen Wang, Shitao Zhang, Jiashu Liu","685":"Ma\u0142gorzata Wasilewska, H. Bogucka","686":"Alexander P. Christensen, Yoed N. Kenett","687":"K. Lloyd, Adam N. Sanborn, David Leslie, S. Lewandowsky","688":"Ashish Sharma, M. Choudhury, Tim Althoff, Amit Sharma","689":"Avani Agarwal, Sahil Sharma, Vijay Kumar, M. Kaur","690":"Yaguang Lin, Xiaoming Wang, Fei Hao, Yichuan Jiang, Yulei Wu, G. Min, Daojing He, Sencun Zhu, Wei Zhao","691":"Lada Kohoutov\u00e1, Juyeon Heo, Sungmin Cha, Sungwoo Lee, Taesup Moon, T. Wager, Choong-Wan Woo","692":"Ping Wang, Luobing Dong, Yueshen Xu, Wei Liu, Ningning Jing","693":"M. McCaul, D. Ernstzen, H. Temmingh, B. Draper, M. Galloway, T. Kredo","694":"Daniel Pimentel, Maxwell Foxman, Donna Z. Davis, David M. Markowitz","695":"J. A. Garc\u00eda, R. Rodr\u00edguez-S\u00e1nchez, J. Fdez-Valdivia","696":"Tianyi Zhang, Felix Wu, Arzoo Katiyar, Kilian Q. Weinberger, Yoav Artzi","697":"D. Y. Lee, Jeffrey R. Harring, L. Stapleton","698":"Terrence D. Hill, A. Davis, J. M. Roos, M. French","699":"S. Pohl, Benjamin Becker","700":"\u00c1. Fern\u00e1ndez-Carrillo, Zdenek Patocka, L. Dobrovoln\u00fd, A. Franco-Nieto, B. Revilla-Romero","701":"M. G\u00f6tz, Klaus Maier-Hein","702":"Sahith N. Dambekodi, Spencer Frazier, Prithviraj Ammanabrolu, Mark O. Riedl","703":"D. Elms","704":"Martin Krucek, Kamil Kr\u00e1l, K. Cushman, Azim Missarov, J. Kellner","705":"E. Graf, A. Theakston, D. Freudenthal, E. Lieven","706":"Laura Blattner, Scott Nelson, Jann Spiess","707":"Shangtong Zhang, R. Laroche, H. V. Seijen, S. Whiteson, R\u00e9mi Tachet des Combes","708":"Sara Javadi, A. Bahrampour, M. M. Saber, B. Garrusi, M. Baneshi","709":"Ming Qian, Jessie Liu, Chaofeng Li, Liming Pals","710":"M. Cummings, Songpo Li","711":"Panpan Zhang, L. Bao, Dongmei Guo, Lin Wu, Qianqian Li, Hui Liu, Zhixin Xue, Zhicai Li","712":"Robert E Kelly, M. Hoptman, G. Alexopoulos, F. Gunning, M. McKeown","713":"Max J. Pachali, P. Kurz, Thomas Otter","714":"M. Jo, B. Osmanoglu","715":"Douglas Zytko, Leanne DeVreugd","716":"S. Pohl, Benjamin Becker","717":"Esther van den Berg, K. Markert","718":"Jieyu Zhao, Tianlu Wang, Mark Yatskar, Ryan Cotterell, Vicente Ordonez, Kai-Wei Chang","719":"M. Tschannen, Josip Djolonga, Paul K. Rubenstein, S. Gelly, Mario Lucic","720":"Jiaming Song, S. Ermon","721":"Ben Poole, Sherjil Ozair, A\u00e4ron van den Oord, Alexander A. Alemi, G. Tucker","722":"Hila Gonen, Yoav Goldberg","723":"R. Hughes, J. Heron, J. Sterne, K. Tilling","724":"R\u00e9mi Cad\u00e8ne, Corentin Dancette, H. Ben-younes, M. Cord, Devi Parikh","725":"Jesse Vig, Sebastian Gehrmann, Y. Belinkov, Sharon Qian, D. Nevo, Yaron Singer, S. Shieber","726":"Cynthia L. Foronda, Margo Fernandez-Burgos, Catherine Nadeau, Courtney N Kelley, Myrthle N Henry","727":"Priyanka Nanayakkara, J. Hullman, N. Diakopoulos","728":"Su Lin Blodgett, Solon Barocas, Hal Daum'e, H. Wallach","729":"Timo Spinde, L. Rudnitckaia, K. Sinha, Bela Gipp, Timo Spinde, L. Rudnitckaia, K. Sinha, Felix Hamborg, Bela Gipp, K. Donnay","730":"P. Terhorst, J. Kolf, Marco Huber, Florian Kirchbuchner, N. Damer, A. Morales, Julian Fierrez, Arjan Kuijper","731":"Walid Krichene, Steffen Rendle","732":"Adnan Darwiche, Auguste Hirth","733":"Kevin Roitero, Michael Soprano, Shaoyang Fan, Damiano Spina, S. Mizzaro, Gianluca Demartini","734":"Erenay Dayanik, Sebastian Pad\u00f3","735":"Harini Suresh, J. Guttag","736":"Hui Jin, Guido Mont\u00fafar","737":"R. Auksztulewicz, N. Myers, J. Schnupp, A. Nobre","738":"Wei-Fan Chen, Khalid Al Khatib, Benno Stein, Henning Wachsmuth","739":"Y. Ho","740":"Navoneel Chakrabarty, Sanket Biswas","741":"C. Arg\u00fcelles, A. Schneider, T. Yuan","742":"Emily Sheng, Josh Arnold, Zhou Yu, Kai-Wei Chang, Nanyun Peng","743":"Stefania Bracci, J. Ritchie, Ioannis Kalfas, H. P. Op de Beeck","744":"Sabine Wehnert, Sayed Anisul Hoque, W. Fenske, G. Saake","745":"Nikolaos Ignatiadis, Stefan Wager","746":"Pei Zhou, Rahul Khanna, Bill Yuchen Lin, Daniel Ho, J. Pujara, Xiang Ren","747":"Liang Wang, Jinlong Liu, Jingming Liu","748":"Neelakshi Sarma, Ranbir Sanasam Singh, D. Goswami","749":"Gun Hee Cho, Y. Choi","750":"Ananya, N. Parthasarthi, Sameer Singh","751":"Yiwei Wang, Muhao Chen, Wenxuan Zhou, Yujun Cai, Yuxuan Liang, Dayiheng Liu, Baosong Yang, Juncheng Liu, Bryan Hooi","752":"Shanshan Li, Canhua Qiu, Mingming Jiang","753":"Shang Gao, M. Alawad, Noah Schaefferkoetter, Lynne Penberthy, Xiao-Cheng Wu, E. Durbin, Linda Coyle, A. Ramanathan, G. Tourassi","754":"Shikha Bordia, Samuel R. Bowman","755":"Yusu Qian, Urwa Muaz, Ben Zhang, J. Hyun","756":"Anjalie Field, Yulia Tsvetkov","757":"Zihang Dai, Zhilin Yang, Yiming Yang, J. Carbonell, Quoc V. Le, R. Salakhutdinov","758":"Xinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei Huang, Kewei Tu","759":"Filipo Sharevski, Amy Devine, Emma Pieroni, Peter Jachim","760":"G. Fosgate","761":"Lalitha Kameswari, Dama Sravani, R. Mamidi","762":"Rui Zhang, Tao Yu, H. Er, Sungrok Shim, Eric Xue, Xi Victoria Lin, Tianze Shi, Caiming Xiong, R. Socher, Dragomir R. Radev","763":"Ali Furkan Biten, Llu\u00eds G\u00f3mez, Mar\u00e7al Rusi\u00f1ol, Dimosthenis Karatzas","764":"Courtney Mansfield, Ming Sun, Ming Sun, Yuzong Liu, Ankur Gandhe, Bj\u00f6rn Hoffmeister","765":"M.A. Dibitso, P. Owolawi, S. Ojo","766":"Carmen De Maio, G. Fenza, Mariacristina Gallo, V. Loia, Alberto Volpe","767":"Zhen Xu, Albert D. Ritzhaupt, Feng-shou Tian, K. Umapathy","768":"J. Dhamala, Tony Sun, Varun Kumar, Satyapriya Krishna, Yada Pruksachatkun, Kai-Wei Chang, Rahul Gupta","769":"Pedro L. Rodriguez, A. Spirling","770":"Yi Tay, V. Tran, Sebastian Ruder, Jai Gupta, Hyung Won Chung, Dara Bahri, Zhen Qin, Simon Baumgartner, Cong Yu, Donald Metzler","771":"Aparna Garimella, Akhash Amarnath, K. Kumar, Akash Pramod Yalla, Anandhavelu Natarajan, Niyati Chhaya, Balaji Vasan Srinivasan","772":"Niklas Rach, Klaus Weber, Yuchi Yang, Stefan Ultes, E. Andr\u00e9, W. Minker","773":"J. Xie, Renato Ferreira Pinto Junior, Graeme Hirst, Yang Xu","774":"Filip Grali'nski, Tomasz Stanislawek, Anna Wr'oblewska, Dawid Lipi'nski, Agnieszka Kaliska, Paulina Rosalska, Bartosz Topolski, P. Biecek","775":"Jianfei Yu, Jing Jiang, Li Yang, Rui Xia","776":"W. Guo, Aylin Caliskan","777":"Ye Liu, Kazuma Hashimoto, Yingbo Zhou, Semih Yavuz, Caiming Xiong, Philip S. Yu","778":"Fangsheng Wu, Mengnan Du, Chao Fan, Ruixiang Tang, Yang Yang, A. Mostafavi, Xia Hu","779":"Chandler May, Alex Wang, Shikha Bordia, Samuel R. Bowman, Rachel Rudinger","780":"A. Akbik, Tanja Bergmann, Roland Vollgraf","781":"Masahiro Kaneko, D. Bollegala","782":"Angana Chakraborty, B. Morgenstern, S. Bandyopadhyay","783":"Y. Tan, L. E. Celis","784":"Hainan Zhang, Yanyan Lan, Liang Pang, J. Guo, Xueqi Cheng","785":"Sara Giuliani, Giuseppe Romana, Massimiliano Rossi","786":"Xingdi Yuan, Jie Fu, Marc-Alexandre C\u00f4t\u00e9, Yi Tay, C. Pal, Adam Trischler","787":"Xuhui Zhou, Yue Zhang, Leyang Cui, Dandan Huang","788":"A. Bruguier, Rohit Prabhavalkar, G. Pundak, T. Sainath","789":"Emily Sheng, Kai-Wei Chang, P. Natarajan, Nanyun Peng","790":"P. Schramowski, Cigdem Turan, Sophie F. Jentzsch, C. Rothkopf, K. Kersting","791":"S. Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, F. Khan, M. Shah","792":"Mingshuang Luo, Shuang Yang, S. Shan, Xilin Chen","793":"Lora Aroyo, Lucas Dixon, Nithum Thain, Olivia Redfield, R. Rosen","794":"Vikas Raunak, Siddharth Dalmia, Vivek Gupta, Florian Metze","795":"F. K\u00fcnzler, Varun Mishra, Jan-Niklas Kramer, D. Kotz, E. Fleisch, T. Kowatsch","796":"Yassien Shaalan, Xiuzhen Zhang, Jeffrey Chan, Mahsa Salehi","797":"P. Schramowski, Cigdem Turan, Nico Andersen, C. Rothkopf, K. Kersting","798":"L. Burnard","799":"S. Veer, L. Riste, S. Cheraghi-Sohi, D. Phipps, M. Tully, Kyle Bozentko, Sarah Atwood, Alex Hubbard, Carl Wiper, M. Oswald, N. Peek","800":"Yuwei Fang, S. Sun, Zhe Gan, R. Pillai, Shuohang Wang, Jingjing Liu","801":"Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, Yejin Choi","802":"Martina Scholger","803":"A. Johri","804":"Yanping Fu, Yun Liu, Sheng-Lung Peng","805":"Mun Kit Ho, S. Tatinati, Andy W. H. Khong","806":"Tiago Santos, F. Lemmerich, M. Strohmaier, D. Helic","807":"J. G\u00f3mez-P\u00e9rez, R. Denaux, Andres Garcia-Silva","808":"Sajib Sen, D. Dasgupta, Kishor Datta Gupta","809":"Kaiyu Huang, Keli Xiao, Fengran Mo, Bo Jin, Zhuang Liu, Degen Huang","810":"Wen Zhang, Lean Yu, Taketoshi Yoshida, Qing Wang","811":"Alexander Junge, L. Jensen","812":"P. Schramowski, Cigdem Turan, Nico Andersen, C. Rothkopf, K. Kersting","813":"Yong Zhao, Tianyan Zhou, Zhuo Chen, Jian Wu","814":"Hanmeng Liu, Leyang Cui, Jian Liu, Yue Zhang","815":"Jun He, Liqun Wang, Liu Liu, Jiao Feng, Hao Wu","816":"Haiyan Yin, Dingcheng Li, Xu Li, P. Li","817":"Jingang Liu, Chunhe Xia, Haihua Yan, Zhipu Xie, Jie Sun","818":"Kaiming Nie, Wanbin Zha, Xiaolin Shi, Jiawen Li, Jiangtao Xu, Jianguo Ma","819":"Yiwei Zhu, Shilin Wang, Zheng Huang, Kai Chen","820":"Shi-Qiu Guo, Kenny Q. Zhu","821":"A. Varghese, Tao Hong, Chelsea Hunter, George Agyeman-Badu, Michelle Cawley","822":"Shenggang Hu, Jabir Alshehabi Al-Ani, K. Hughes, Nicole Denier, Alla Konnikov, Lei Ding, Jinhan Xie, Yang Hu, Monideepa Tarafdar, Bei, Jiang, Linglong Kong, Hongsheng Dai","823":"Liang Zhao, Hexin Cao, Yunsong Zhao","824":"Li Lu, L. Deng, J. Ke, Congwei Liao, Shengxiang Huang","825":"Luigi Fassio, Longyang Lin, R. De Rose, M. Lanuzza, F. Crupi, M. Alioto","826":"Anas El-Alem, K. Chokmani, I. Laurion, Salah E. El-Adlouni, S. Raymond, C. Ratte-Fortin","827":"N. Bajwa, Cornelius J. K\u00f6nig","828":"Jan Kinne, Janna Axenbeck","829":"Anne Lauscher, B. Ko, Bailey Kuehl, Sophie Johnson, David Jurgens, Arman Cohan, Kyle Lo","830":"S. Ghorbani, Yashesh Gaur, Yu Shi, Jinyu Li","831":"Yi Wang","832":"Nuhil Mehdy, C. Kennington, Hoda Mehrpouyan","833":"Zden\u011bk Kasner, Simon Mille, Ondrej Dusek","834":"Yimin Huang, Shilin Wang, Cheng-Yu Gu, Zheng Huang, Kai Chen","835":"Guixian Xu, Y. Meng, Xiaokai Zhou, Ziheng Yu, Xu Wu, Lijun Zhang","836":"Francesco Pierri, C. Piccardi, S. Ceri","837":"Xi Liu, Gaojing Zhou, Rui Zhang, Xiaolin Wei","838":"Sawan Kumar, Kalpit Dixit, Kashif Shah","839":"Jaesung Bae, Taejun Bak, Young-Sun Joo, Hoon-Young Cho","840":"Daniel Loureiro, Kiamehr Rezaee, Mohammad Taher Pilehvar, Jos\u00e9 Camacho-Collados","841":"Longyin Zhang, Fang Kong, Guodong Zhou","842":"Peng Wu, Xiangteng He, Mingqian Tang, Yiliang Lv, Jing Liu","843":"N. Fay, B. Walker, Y. Kashima, Andrew Perfors","844":"Zhichao Li, H. Gurgel, N. Dessay, Luojia Hu, Lei Xu, Peng Gong","845":"L. Salekhova, A. Danilov, N. Spiridonova, N. Anyameluhor","846":"Youhyun Shin, Sang-goo Lee","847":"O. Berger\u2010Tal, B. B. M. Wong, U. Candolin, J. Barber","848":"Caiwei Ma, N. Au, Lianping Ren","849":"Burak Ayd\u0131n, J. Algina","850":"Ritu Bibyan, Sameer Anand, Ajay Jaiswal","851":"Qianlong Wang, Jiangtao Ren","852":"Guangyao Pang, Keda Lu, Xiaoying Zhu, Jie He, Zhiyi Mo, Zizhen Peng, Baoxing Pu","853":"Junjie Pan, Lin Wu, Xiang Yin, Pengfei Wu, Chenchang Xu, Zejun Ma","854":"I. Salman, Pilar Rodr\u00edguez, Burak Turhan, Ayse Tosun, Arda Gureller","855":"N. Jain, Maja Popovic, Declan Groves, Eva Vanmassenhove","856":"Lixue Zou, Xiwen Liu, Wray L. Buntine, Yanli Liu","857":"A. Hayden, Sarah Elaine Eaton, Katherine Crossman, L. Penaluna, Bartlomiej A. Lenart","858":"Tao Wang, Jiangyan Yi, Ruibo Fu, J. Tao, Zhengqi Wen","859":"Doruk Kilitcioglu, Serdar Kadioglu","860":"Jiaqi Guo, Ziliang Si, Yu Wang, Qian Liu, Ming Fan, Jian-Guang Lou, Z. Yang, Ting Liu","861":"Joe Barrow, R. Jain, N. Lipka, Franck Dernoncourt, Vlad I. Morariu, Varun Manjunatha, D. Oard, P. Resnik, Henning Wachsmuth","862":"Chang Li","863":"Adithya Renduchintala, Denise D\u00edaz, Kenneth Heafield, Xian Li, Mona T. Diab","864":"Taichi Murayama, Shoko Wakamiya, E. Aramaki","865":"Tanvi Dadu, Kartikey Pant, R. Mamidi","866":"Tianyu Liu, Xin Zheng, Baobao Chang, Zhifang Sui","867":"Tao Yang, Rujing Yao, Qing Yin, Qiang Tian, Ou Wu","868":"Todd R Ferretti, K. McRae","869":"Yuanqing Gu, Hidehito Honda, T. Matsuka, K. Ueda","870":"Lanna Lima, V. Furtado, E. Furtado, V. Almeida","871":"Yugang Ji, C. Shi, Fuzhen Zhuang, Philip S. Yu","872":"Maria Krommyda, A. Rigos, Kostas Bouklas, A. Amditis","873":"Matan Halevy, Camille Harris, A. Bruckman, Diyi Yang, A. Howard","874":"Ibrahim Abu Farha, Walid Magdy","875":"Nitish Gupta, Sameer Singh, Matt Gardner","876":"Zheng Zhang, Pan Zhou","877":"M. Han, Linhao Dong, Zhenlin Liang, Meng Cai, Shiyu Zhou, Zejun Ma, Bo Xu","878":"Julia Suter, Letitia Parcalabescu, A. Frank","879":"Jiuxiang Gu, Handong Zhao, Zhe L. Lin, Sheng Li, Jianfei Cai, Mingyang Ling","880":"Eni Mustafaraj, Emma Lurie, Claire Devine","881":"Eliza M. Grames, Andrew N. Stillman, M. Tingley, C. Elphick","882":"Kathryn Bousquet, T. Swaab, D. Long","883":"Chris Dyer, G\u00e1bor Melis, P. Blunsom","884":"Shulin Liu, Y. Li, F. Zhang, Tao Yang, Xinpeng Zhou","885":"Saeed Najafipour, S. Hosseini, Wen Hua, M. Kangavari, Xiaofang Zhou","886":"Michael S. Lin, Yun Liang, Joanne X. Xue, B. Pan, Ashley Schroeder","887":"Helen Ngo, Cooper D. Raterink, J. Ara'ujo, Ivan Zhang, Carol Chen, Adrien Morisot, Nick Frosst","888":"A. Evtushenko, J. Kleinberg","889":"Dong Huk Park, Samaneh Azadi, Xihui Liu, Trevor Darrell, Anna Rohrbach","890":"Xinyang Zhang, Chenwei Zhang, Xin Dong, Jingbo Shang, Jiawei Han","891":"Alissa Ostapenko, S. Wintner, Melinda Fricke, Yulia Tsvetkov","892":"Hao Zhang, Jie Wang","893":"Wuwei Lan, Chao Jiang, Wei Xu","894":"Sheikh Muhammad Sarwar, Felipe Moraes, Jiepu Jiang, James Allan","895":"M. Song, L. Jing, Lin Xiao","896":"Wei-Fan Chen, S. Syed, Benno Stein, Matthias Hagen, Martin Potthast","897":"Ding Zhao, T. Sainath, David Rybach, Pat Rondon, Deepti Bhatia, Bo Li, Ruoming Pang","898":"Alexander Martin, A. Holtz, K. Abels, D. Adger, Jennifer Culbertson","899":"Asaf Cidon, Lior Gavish, Itay Bleier, Nadia Korshun, M. Schweighauser, Alexey Tsitkin","900":"M. Corley, S. Haywood","901":"M. Markus","902":"X. Zu, Fei Xie, Xiaojian Liu","903":"D. Filimonov, R. Gadde, A. Rastrow","904":"Mahjabeen Akter, M. S. Rahman, M. Z. Iqbal, M. R. Selim","905":"Jennifer Culbertson, M. Schouwstra, S. Kirby","906":"Maria Kyriacou, K. Conklin, Dominic Thompson","907":"V. Solovyev, Marina I. Solnyshkina, E. Gafiyatova, D. McNamara, Vladimir Ivanov","908":"Jianri Li, Jae-whan Lee, Woosang Song, Ki-young Shin, Byung-Hyun Go","909":"S. Yanisky-Ravid, C. Martens","910":"Jesse A Harris","911":"A. Ram, Kurt P. Eiselt","912":"Abdulrahman Alatawi, Weifeng Xu, Dianxiang Xu","913":"Bojana Ristic, S. Mancini, Nicola Molinaro","914":"Suzanne Petryk, Lisa Dunlap, Keyan Nasseri, Joseph E. Gonzalez, Trevor Darrell, Anna Rohrbach","915":"Xiaoqiang Wang, Yanqing Liu, Jinyu Li, Veljko Miljanic, Sheng Zhao, H. Khalil","916":"Matei Ionita, Yury Kashnitsky, Ken Krige, Vladimir Larin, Denis Logvinenko, Atanas Atanasov","917":"Cas W. Coopmans, Helen de Hoop, K. Kaushik, P. Hagoort, Andrea E. Martin","918":"T. Bickmore, Dhaval Parmar, Everlyne Kimani, S. \u00d3lafsson","919":"Yi Ting Huang, Zoe Ovans","920":"Ke Wu, Gilad Asharov, E. Shi","921":"Jinghui Lu, Linyi Yang, Brian Mac Namee, Yue Zhang","922":"B. McSkimming, Sean Mackay, Adrienne Decker","923":"Yiheng Huang, Liqiang He, Lei Han, Guangsen Wang, Dan Su","924":"Yeslam Al\u2010Saggaf","925":"James O'Neill, Polina Rozenshtein, Ryuichi Kiryo, Motoko Kubota, D. Bollegala","926":"Aditi Chaudhary, Zaid A. W. Sheikh, David R. Mortensen, Antonios Anastasopoulos, Graham Neubig","927":"A. Varol, Veysel Kocaman, Hasham Ul Haq, David Talby","928":"Amanda Bertsch, Steven Bethard","929":"Charlotte Rochereau, B. Sagot, Emmanuel Dupoux","930":"Andrew Chia","931":"Yiyun Zhao, Jian Gang Ngui, Lucy Hall Hartley, Steven Bethard","932":"Ashok Thillaisundaram","933":"A. Perera, A. Aleti, C. Tantithamthavorn, Jirayus Jiarpakdee, Burak Turhan, Lisa Kuhn, Katie Walker","934":"Xiaohan Lan, Yitian Yuan, Xin Wang, Long Chen, Zhi Wang, Lin Ma, Wenwu Zhu","935":"Shuo Wang, Zhaopeng Tu, Zhixing Tan, Shuming Shi, Maosong Sun, Yang Liu","936":"Yu Bai, Song Mei, Huan Wang, Caiming Xiong","937":"Yuan-Jyue Chen, Christopher N. Takahashi, Lee Organick, Callista Bee, S. Ang, P. Weiss, Bill J Peck, G. Seelig, L. Ceze, K. Strauss","938":"Vishnu Vardhan Chetlur, Harpreet S. Dhillon","939":"Himan Abdollahpouri, R. Burke, B. Mobasher","940":"Himan Abdollahpouri, M. Mansoury, R. Burke, B. Mobasher","941":"Ludovico Boratto, G. Fenu, M. Marras","942":"Felix Hamborg, Anastasia Zhukova, Bela Gipp","943":"Yuan-Jyue Chen, Christopher N. Takahashi, Lee Organick, Kendall Stewart, S. Ang, P. Weiss, Bill J Peck, G. Seelig, L. Ceze, K. Strauss","944":"A. Keil, J. Buckley, K. O\u2019Brien, K. Ferguson, Shanshan Zhao, A. White","945":"Liangyuan Hu","946":"Xiaozhi Wang, Xu Han, Zhiyuan Liu, Maosong Sun, Peng Li","947":"B. Bauer-Marschallinger, V. Freeman, S. Cao, C. Paulik, S. Schaufler, Tobias Stachl, S. Modanesi, C. Massari, L. Ciabatta, L. Brocca, W. Wagner","948":"J. Kattge, G. B\u00f6nisch, S. D\u00edaz, S. Lavorel, I. Prentice, P. Leadley, S. Tautenhahn, G. D. Werner, T. Aakala, M. Abedi, A. Acosta, G. Adamidis, Kairi Adamson, Masahiro Aiba, C. Albert, J. Alc\u00e1ntara, Carolina Alc\u00e1zar C, Izabela Aleixo, Hamada E. Ali, Bernard Amiaud, C. Ammer, M. Amoroso, M. Anand, C. Anderson, N. Anten, J. Antos, D. Apgaua, T. Ashman, Degi Harja Asmara, G. Asner, Michael J. Aspinwall, O. Atkin, I. Aubin, L. Baastrup\u2010Spohr, Khadijeh Bahalkeh, M. Bahn, T. Baker, W. Baker, J. Bakker, D. Baldocchi, J. Baltzer, A. Banerjee, A. Baranger, J. Barlow, D. R. Barneche, Z. Baruch, D. Bastianelli, J. Battles, W. Bauerle, M. Bauters, E. Bazzato, Michael Beckmann, H. Beeckman, C. Beierkuhnlein, R. Bekker, Gavin Belfry, M. Belluau, Mirela Beloiu, R. Benavides, Lahcen Benomar, Mary Lee Berdugo-Lattke, E. Berenguer, R. Bergamin, Joana Bergmann, Marcos Bergmann Carlucci, L. Berner, M. Bernhardt\u2010R\u00f6mermann, C. Bigler, Anne D. Bjorkman, Chris J. Blackman, C. Blanco, B. Blonder, D. Blumenthal, Kelly T Bocanegra-Gonz\u00e1lez, P. Boeckx, S. Bohlman, K. B\u00f6hning\u2010Gaese, L. Boisvert\u2010Marsh, W. Bond, B. Bond\u2010Lamberty, A. Boom, C. Boonman, Kauane Bordin, E. Boughton, V. Boukili, D. Bowman, S. Bravo, Marco R. Brendel, M. Broadley, K. Brown, H. Bruelheide, F. Brumnich, H. H. Bruun, David Bruy, S. Buchanan, S. F. Bucher, N. Buchmann, R. Buitenwerf, D. Bunker, Jana B\u00fcrger, S. Burrascano, D. Burslem, B. Butterfield, Chaeho Byun, M. Marques, M. Scalon, M. Caccianiga, M. Cadotte, M. Cailleret, James S. Camac, J. Camarero, C. Campany, G. Campetella, J. A. Campos, Laura V. Cano-Arboleda, R. Canullo, M. Carbognani, Fabio Carvalho, F. Casanoves, B. Castagneyrol, J. Catford, J. Cavender-Bares, B. Cerabolini, M. Cervellini, Eduardo Chac\u00f3n\u2010Madrigal, K. Chapin, F. Chapin, S. Chelli, Si\u2010Chong Chen, Anping Chen, P. Cherubini, F. Chianucci, B. Choat, Kyong-Sook Chung, M. Chytr\u00fd, D. Ciccarelli, L. Coll, Courtney G Collins, L. Conti, D. Coomes, J. Cornelissen, W. Cornwell, P. Corona, M. Coyea, J. Craine, D. Craven, J. Cromsigt, Anik\u00f3 Csecserits, K. \u010cufar, M. Cuntz, A. C. da Silva, K. Dahlin, M. Dainese, I. Dalke, M. Dalle Fratte, Anh Tuan Dang-Le, J. Danihelka, M. Dannoura, Samantha K. Dawson, Arend Jacobus de Beer, A. D. de Frutos, J. R. De Long, Benjamin Dechant, S. Delagrange, N. Delpierre, G. Derroire, A. S. Dias, Milton H. D\u00edaz-Toribio, P. Dimitrakopoulos, M. Dobrowolski, D. Doktor, P. D\u0159evojan, N. Dong, J. Dransfield, S. Dressler, L. Duarte, \u00c9. Ducouret, S. Dullinger, W. Durka, R. Duursma, O. Dymova, A. E\u2010Vojtk\u00f3, R. L. Eckstein, H. Ejtehadi, J. Elser, T. Emilio, K. Engemann, Mohammad Bagher Erfanian, Alexandra Erfmeier, Adriane Esquivel\u2010Muelbert, G. Esser, M. Estiarte, T. Domingues, W. Fagan, J. Fag\u00fandez, D. Falster, Ying Fan, Jingyun Fang, E. Farris, Fatih Fazlioglu, Yanhao Feng, F. Fernandez-Mendez, C. Ferrara, J. Ferreira, A. Fidelis, B. Finegan, J. Firn, T. Flowers, D. Flynn, V. Fontana, E. Forey, Cristiane Forgiarini, L. Fran\u00e7ois, Marcelo Frangipani, D. Frank, C\u00e9dric Frenette-Dussault, G. T. Freschet, Ellen L. Fry, N. Fyllas, G. G. Mazzochini, S. Gachet, R. Gallagher, G. Ganade, Francesca Ganga, P. Garc\u00eda\u2010Palacios, V. Gargaglione, E. Garnier, J. Garrido, A. L. de Gasper, G. Gea\u2010Izquierdo, D. Gibson, A. Gillison, A. Giroldo, Mary-Claire Glasenhardt, S. Gleason, Mariana Gliesch, E. Goldberg, Bastian G\u00f6ldel, E. Gonzalez-Akre, J. Gonz\u00e1lez-And\u00fajar, Andr\u00e9s Gonz\u00e1lez-Melo, A. Gonz\u00e1lez-Robles, B. Graae, E. Granda, Sarah J. Graves, W. Green, T. Gregor, N. Gross, G. Guerin, A. G\u00fcnther, \u00c1. Guti\u00e9rrez, Lillie Haddock, Anna L. Haines, Jefferson S. Hall, A. Hambuckers, W. Han, S. Harrison, W. Hattingh, J. Hawes, Tianhua He, Pengcheng He, J. M. Heberling, A. Helm, S. Hempel, J. Hentschel, B. H\u00e9rault, A. Here\u0219, K. Herz, M. Heuertz, T. Hickler, P. Hietz, P. Higuchi, A. Hipp, A. Hirons, M. Hock, J. Hogan, K. Holl, O. Honnay, Daniel Hornstein, E. Hou, Nate Hough-Snee, K. Hovstad, T. Ichie, B. Igi\u0107, E. Illa, M. Isaac, M. Ishihara, L. Ivanov, Larissa Ivanova, C. Iversen, J. Izquierdo, R. B. Jackson, B. Jackson, H. Jactel, A. Jagodzi\u0144ski, Ute Jandt, S. Jansen, T. Jenkins, A. Jentsch, J. R. P. Jespersen, Guo-Feng Jiang, Jesper Liengaard Johansen, David Johnson, E. Jokela, C. Joly, G. Jordan, G. Joseph, D. Junaedi, R. Junker, E. Justes, R. Kabzems, J. Kane, Z. Kaplan, T. Kattenborn, L. Kavelenova, E. Kearsley, Anne Kempel, T. Kenzo, A. Kerkhoff, Mohammed Ibrahim Khalil, N. Kinlock, W. D. Kissling, K. Kitajima, T. Kitzberger, R. Kj\u00f8ller, T. Klein, M. Kleyer, J. Klime\u0161ov\u00e1, Joice Klipel, B. Kloeppel, S. Klotz, J. Knops, T. Kohyama, F. Koike, J. Kollmann, B. Komac, K. Komatsu, C. K\u00f6nig, Nathan J B Kraft, K. Kramer, H. Kreft, I. K\u00fchn, D. Kumarathunge, J. Kuppler, H. Kurokawa, Y. Kurosawa, Shem Kuyah, J. Laclau, Benoit Lafleur, E. Lallai, E. Lamb, A. Lamprecht, D. Larkin, D. Laughlin, Y. Le Bagousse-Pinguet, G. le Maire, P. C. le Roux, E. le Roux, Tali D. Lee, F. Lens, S. Lewis, B. Lhotsky, Yuanzhi Li, Xin'e Li, J. Lichstein, Mario Liebergesell, J. Y. Lim, Yan-Shih Lin, J. Linares, Chunjiang Liu, Daijun Liu, Udayangani Liu, Stuart W. Livingstone, J. Llusi\u00e0, Madelon Lohbeck, \u00c1lvaro L\u00f3pez-Garc\u00eda, G. Lopez-Gonzalez, Zde\u0148ka Lososov\u00e1, F. Louault, B. Luk\u00e1cs, P. Luke\u0161, Yunjian Luo, M. Lussu, Siyan Ma, Camilla Maciel Rabelo Pereira, M. Mack, V. Maire, A. M\u00e4kel\u00e4, H. M\u00e4kinen, A. C. M. Malhado, A. Mallik, P. Manning, S. Manzoni, Z. Marchetti, L. Marchino, Vin\u00edcius Marcilio-Silva, Eric Marcon, M. Marignani, Lars Markesteijn, Adam R. Martin, C. Mart\u00ednez-Garza, J. Mart\u00ednez\u2010Vilalta, T. Ma\u0161kov\u00e1, Kelly E. Mason, N. Mason, T. Massad, J. Masse, I. Mayrose, James K McCarthy, M. L. McCormack, K. McCulloh, Ian R. McFadden, B. McGill, M. McPartland, J. Medeiros, B. Medlyn, P. Meerts, Z. Mehrabi, P. Meir, F. Melo, Maurizio Mencuccini, C. Meredieu, J. Messier, I. M\u00e9sz\u00e1ros, J. Metsaranta, S. Michaletz, Chrysanthi Michelaki, S. Migalina, R. Milla, Jesse E. D. Miller, V. Minden, R. Ming, K. Mokany, A. Moles, A. Moln\u00e1r, J. Molofsky, Martin Molz, R. Montgomery, A. Monty, L. Moravcov\u00e1, \u00c1lvaro Moreno-Mart\u00ednez, M. Moretti, A. Mori, S. Mori, D. Morris, J. Morrison, L. Mucina, Sandra Mueller, C. Muir, S. M\u00fcller, F. Munoz, I. Myers-Smith, R. Myster, M. Nagano, S. Naidu, Ayyappan Narayanan, Balachandran Natesan, Luka Negoita, A. Nelson, E. Neuschulz, J. Ni, G. Niedrist, Jhon Nieto, \u00dc. Niinemets, R. Nolan, H. Nottebrock, Y. Nouvellon, A. Novakovskiy, K. Nystuen, A. O'Grady, K. O\u2019Hara, A. O\u2019Reilly-Nugent, S. Oakley, W. Oberhuber, T. Ohtsuka, R. Oliveira, Kinga \u00d6llerer, M. Olson, V. Onipchenko, Y. Onoda, Renske E. Onstein, J. Ordo\u00f1ez, N. Osada, I. Ostonen, G. Ottaviani, S. Otto, G. Overbeck, W. Ozinga, A. Pahl, C. E. T. Paine, R. Pakeman, A. Papageorgiou, Evgeniya Parfionova, M. P\u00e4rtel, Marco Patacca, S. Paula, Juraj Paule, H. Pauli, J. Pausas, B. Peco","949":"Ning Yu, Ke Li, Peng Zhou, J. Malik, Larry Davis, Mario Fritz","950":"Fabrice Harel-Canada, Lingxiao Wang, Muhammad Ali Gulzar, Quanquan Gu, Miryung Kim","951":"Ling Liu, Yiqing Zhou, W. Zhuang, Jinhong Yuan, Lin Tian","952":"Damian Szklarczyk, Annika L. Gable, Katerina C. Nastou, D. Lyon, Rebecca Kirsch, Sampo Pyysalo, N. Doncheva, M. Legeay, T. Fang, P. Bork, L. Jensen, C. V. Mering","953":"Ali Jahanian, Lucy Chai, Phillip Isola","954":"N. Lenssen, G. Schmidt, J. Hansen, M. Menne, Avraham Persin, R. Ruedy, Daniel Zyss","955":"Joshua Feldman, Joe Davison, Alexander M. Rush","956":"C. Blanco, Evan Janzen, Abe Pressman, R. Saha, I. Chen","957":"S. M. Moosavi, A. Nandy, K. Jablonka, D. Ongari, J. Janet, Peter G. Boyd, Yongjin Lee, B. Smit, H. Kulik","958":"Amanda Coston, Neel Guha, Derek Ouyang, L. Lu, A. Chouldechova, Daniel E. Ho","959":"V. Steen, C. Elphick, M. Tingley","960":"Zhongjun (Mark) Jin, Mengjing Xu, Chenkai Sun, Abolfazl Asudeh, H. V. Jagadish","961":"Yin Lin, Yifan Guan, Abolfazl Asudeh, H. V. Jagadish","962":"Jie Liu, Xiao Yan, XINYAN DAI, Zhirong Li, James Cheng, Ming Yang","963":"Shubham Sharma, Yunfeng Zhang, J. Aliaga, Djallel Bouneffouf, Vinod Muthusamy, K. Varshney","964":"Zhi Da, Umit G. Gurun, B. Li, M. Warachka","965":"Sebastian Anzinger, Christian Bretthauer, J. Manz, U. Krumbein, A. Dehe","966":"Emily Wall, Arup Arcalgud, Kuhu Gupta, Andrew Jo","967":"Guiming Zhang","968":"Yizhu Jiao, Yun Xiong, Jiawei Zhang, Yao Zhang, Tianqi Zhang, Yangyong Zhu","969":"Felix Beierle, T. Eichinger","970":"A. S\u00eerbu, D. Pedreschi, F. Giannotti, J. Kert\u00e9sz","971":"H. Takeuchi, K. Yoshikawa, Y. Takei, Y. Oki, S. Kikuchi, H. Ikeda, S. Soldini, N. Ogawa, Y. Mimasu, G. Ono, F. Terui, N. Sakatani, M. Yamada, T. Kouyama, S. Kameda, T. Saiki, Y. Tsuda","972":"M. S. Rahman, J. Yau","973":"Doug J. Chung, Byungyeon Kim, Byoung G. Park","974":"Suhyeong Choi, Seongbo Shim, Youngsoo Shin","975":"Zohreh Ovaisi, Ragib Ahsan, Yifan Zhang, K. Vasilaky, E. Zheleva","976":"Yae Jee Cho, Jianyu Wang, Gauri Joshi","977":"Zhe Zhao, Lichan Hong, Li Wei, Jilin Chen, A. Nath, Shawn Andrews, Aditee Kumthekar, M. Sathiamoorthy, Xinyang Yi, Ed H. Chi","978":"D. Darriba, D. Posada, Alexey M. Kozlov, A. Stamatakis, Benoit Morel, T. Flouri","979":"T. Papakonstantinou, A. Nikolakopoulou, J. Higgins, M. Egger, G. Salanti","980":"Yuchi Tian, Ziyuan Zhong, Vicente Ordonez, G. Kaiser, Baishakhi Ray","981":"Michael F\u00e4rber, A. Jatowt","982":"Preslav Nakov, H. Sencar, Jisun An, Haewoon Kwak","983":"Chenguang Zhu, Ziyi Yang, R. Gmyr, Michael Zeng, Xuedong Huang","984":"Jamell Dacon, Haochen Liu","985":"Jingwei Yi, Fangzhao Wu, Chuhan Wu, Qifei Li, Guang-zhong Sun, Xing Xie","986":"Timo Spinde, Felix Hamborg, Bela Gipp","987":"Benjamin D. Horne, Dorit Nevo, J. O'Donovan, Jin-Hee Cho, Sibel Adali","988":"Rama Rohit Reddy Gangula, Suma Reddy Duggenpudi, R. Mamidi","989":"Chenguang Zhu, Ziyi Yang, R. Gmyr, Michael Zeng, Xuedong Huang","990":"Marco Morik, Ashudeep Singh, Jessica Hong, T. Joachims","991":"Wen Chen, Diogo Pacheco, Kai-Cheng Yang, F. Menczer","992":"Melvin Wevers","993":"Chuhan Wu, Fangzhao Wu, Xiting Wang, Yongfeng Huang, Xing Xie","994":"Calum Thornhill, Quentin Meeus, J. Peperkamp, Bettina Berendt","995":"Timo Spinde","996":"Yingtong Dou, Kai Shu, Congyin Xia, Philip S. Yu, Lichao Sun","997":"Jihyung Moon, Won Ik Cho, Junbum Lee","998":"So-jeong Lim, A. Jatowt, Michael F\u00e4rber, M. Yoshikawa","999":"Jeppe N\u00f8rregaard, Benjamin D. Horne, Sibel Adali","1000":"Antino Kim, A. Dennis","1001":"Patricia L. Moravec, Randall K. Minas, A. Dennis","1002":"Lia Bozarth, Ceren Budak","1003":"Yotam Shmargad, Samara Klar","1004":"Marina Danchovsky Ibrishimova, K. F. Li","1005":"Federica Lago, Quoc-Tin Phan, G. Boato","1006":"Mahak Goindani, Jennifer Neville","1007":"Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng Gao, Yejin Choi","1008":"Katherine A. Keith, David D. Jensen, Brendan O\u2019Connor","1009":"Rava Azeredo da Silveira, Yeji Sung, M. Woodford","1010":"Taehee Jung, Dongyeop Kang, L. Mentch, E. Hovy","1011":"Yoan Dinkov, Ahmed Ali, Ivan Koychev, Preslav Nakov","1012":"Tao Qi, Fangzhao Wu, Chuhan Wu, Yongfeng Huang","1013":"M. A. Britt, J. Rouet, Dylan Blaum, K. Millis","1014":"Franziska Zimmer, Katrin Scheibe, M. Stock, Wolfgang G. Stock","1015":"Yijun Duan, A. Jatowt","1016":"Ye Ma, Lu Zong, Yikang Yang, Jionglong Su","1017":"Shaina Raza, Chen Ding","1018":"Weichang Wu, Huanxi Liu, Xiaohu Zhang, Yu Liu, H. Zha","1019":"Kirsten E. Martin","1020":"S. Kucinskas, Florian S. Peters","1021":"Anne Lauscher, Rafik Takieddin, Simone Paolo Ponzetto, Goran Glavas","1022":"Fantahun Gereme, William Zhu","1023":"Galen Cassebeer Weld, M. Glenski, Tim Althoff","1024":"Miguel A. Alonso, David Vilares, C. G\u00f3mez-Rodr\u00edguez, Jes\u00fas Vilares","1025":"Ruey-Cheng Chen, Qingyao Ai, Gaya K. Jayasinghe, W. Bruce Croft","1026":"Matt Grenander, Yue Dong, J. C. Cheung, Annie Louis","1027":"M. Behroozi, Chris Parnin, Titus Barik","1028":"Elissa M. Redmiles, Sean Kross, Michelle L. Mazurek","1029":"Ziyi Yang, Chenguang Zhu, R. Gmyr, Michael Zeng, Xuedong Huang","1030":"Anu Shrestha, Francesca Spezzano","1031":"M. Cha, Wei Gao, Cheng-Te Li","1032":"Ana-Andreea Stoica, Jessy Xinyi Han, A. Chaintreau","1033":"Bin Guo, Yasan Ding, Yueheng Sun, Shuai Ma, Ke Li","1034":"A. S. C. Melo, L. Marinho, Adriano Veloso","1035":"Vivek K. Singh, M. Chayko, Raj Inamdar, Diana Floegel","1036":"T. G. van der Meer, M. Hameleers","1037":"Svitlana Volkova, Ellyn Ayton, Dustin L. Arendt, Zhuanyi Huang, Brian Hutchinson","1038":"Marija Stanojevic, Jumanah Alshehri, Eduard Constantin Dragut, Z. Obradovic","1039":"Abdelrhman Saleh, R. Baly, Alberto Barr\u00f3n-Cede\u00f1o, Giovanni Da San Martino, Mitra Mohtarami, Preslav Nakov, James R. Glass","1040":"Hani Al-Omari, Malak Abdullah, Ola Altiti, Samira Shaikh","1041":"Xinzhi Wang, Luyao Kou, V. Sugumaran, Xiangfeng Luo, Hui Zhang","1042":"Jaynil Gaglani, Yash Gandhi, Shubham Gogate, Aparna Halbe","1043":"James McInerney, B. Brost, Praveen Chandar, Rishabh Mehrotra, Ben Carterette","1044":"Timo Spinde, Manuel Plank, Jan-David Krieger, Terry Ruas, Bela Gipp, Akiko Aizawa","1045":"S. KrishnapriyaK., K. Vangara, Michael C. King, V\u00edtor Albiero, K. Bowyer","1046":"Eduardo M. Hargreaves, C. Agosti, D. Menasch\u00e9, G. Neglia, Alexandre Reiffers, E. Altman","1047":"S. Ganguly, Juhi Kulshrestha, Jisun An, Haewoon Kwak","1048":"Brendan Spillane, S. Lawless, V. Wade","1049":"Ali H\u00fcrriyeto\u01e7lu, Hristo Tanev, Vanni Zavarella, J. Piskorski, R. Yeniterzi, Deniz Yuret, Aline Villavicencio","1050":"Chenguang Zhu, Ziyi Yang, R. Gmyr, Michael Zeng, Xuedong Huang","1051":"Lukas Gebhard, Felix Hamborg","1052":"E. Pitoura, G. Koutrika, K. Stefanidis","1053":"Pinelopi Papalampidi, Frank Keller, Lea Frermann, Mirella Lapata","1054":"Thomas Nygren, J. Folkeryd, Caroline Liberg, Mona Guath","1055":"A. Pandey, V. Tikkiwal","1056":"Samantha D'Alonzo, Max Tegmark","1057":"Marzieh Mozafari, R. Farahbakhsh, N. Crespi","1058":"O. Papakyriakopoulos, J. M. Serrano, Simon Hegelich","1059":"P. Drozdowski, C. Rathgeb, A. Dantcheva, N. Damer, C. Busch","1060":"Thomas Davidson, Debasmita Bhattacharya, Ingmar Weber","1061":"O. Papakyriakopoulos, Simon Hegelich, J. M. Serrano, Fabienne Marco","1062":"Pinkesh Badjatiya, Manish Gupta, Vasudeva Varma","1063":"P. Stefanov, Kareem Darwish, Atanas Atanasov, Preslav Nakov","1064":"Pascal J\u00fcrgens, Birgit Stark, M. Magin","1065":"Yiyi Li, Ying Xie","1066":"Zijian Wang, Scott A. Hale, David Ifeoluwa Adelani, Przemyslaw A. Grabowicz, Timo Hartmann, Fabian Fl\u00f6ck, David Jurgens","1067":"S. Ernala, M. Birnbaum, Kristin A. Candan, A. Rizvi, W. A. Sterling, J. Kane, M. Choudhury","1068":"Binny Mathew, Punyajoy Saha, Seid Muhie Yimam, Chris Biemann, P. Goyal, Animesh Mukherjee","1069":"Yigal Godler, Zvi Reich, Boaz Miller","1070":"Stevie Chancellor, M. Birnbaum, E. Caine, V. Silenzio, M. Choudhury","1071":"Quentin J. Leclerc, Naomi M. Fuller, Lisa E. Knight, S. Funk, G. Knight","1072":"Jakob Ohme, T. Araujo, C. D. De Vreese, J. Piotrowski","1073":"Y. Gerrard, H. Thornham","1074":"S. Vaudenay","1075":"K. Saha, A. Bayraktaroglu, A. Campbell, N. Chawla, M. Choudhury, S. D\u2019Mello, A. Dey, Ge Gao, Julie M. Gregg, Krithika Jagannath, G. Mark, Gonzalo J. Mart\u00ednez, Stephen M. Mattingly, E. Moskal, Anusha Sirigiri, A. Striegel, Dong Whi Yoo","1076":"T. Hellstr\u00f6m, V. Dignum, Suna Bensch","1077":"Daniela Jaramillo-Dent, M. A. P\u00e9rez-Rodr\u00edguez","1078":"Jae Yeon Kim, Carlos Ortiz, S. Nam, Sarah Santiago, Vivek Datta","1079":"Giovanni Da San Martino, A. Barr'on-Cedeno, Henning Wachsmuth, R. Petrov, Preslav Nakov","1080":"Bilal Ghanem, Paolo Rosso, Francisco Rangel","1081":"Xin Du, Kumiko Tanaka-Ishii","1082":"Prafulla Kumar Choubey, A. Lee, Ruihong Huang, Lu Wang","1083":"Aytu\u011f Onan, Mansur Alp To\u00e7o\u011flu","1084":"Beakcheol Jang, Inhwan Kim, Jong Wook Kim","1085":"Charlotte Rudnik, Thibault Ehrhart, Olivier Ferret, Denis Teyssou, Raphael Troncy, Xavier Tannier","1086":"Roshni Chakraborty, Maitry Bhavsar, Sourav Kumar Dandapat, Joydeep Chandra","1087":"Felix Hamborg, Corinna Breitinger, Bela Gipp","1088":"A. Singh, M. Shashi","1089":"Soonh Taj, Baby Bakhtawer Shaikh, Areej Fatemah Meghji","1090":"T. Traylor, Jerey Straub, Gurmeet, Nicholas Snell","1091":"Anne Oeldorf-Hirsch, Mike Schmierbach, A. Appelman, Michael P. Boyle","1092":"P. Patwa, Shivam Sharma, Srinivas Pykl, V. Guptha, G. Kumari, Md. Shad Akhtar, Asif Ekbal, A. Das, Tanmoy Chakraborty","1093":"Wei Li, Jingjing Xu, Yancheng He, Shengli Yan, Yunfang Wu, Xu Sun","1094":"Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang","1095":"Fangzhao Wu, Ying Qiao, Jiun-Hung Chen, Chuhan Wu, Tao Qi, Jianxun Lian, Danyang Liu, Xing Xie, Jianfeng Gao, Winnie Wu, M. Zhou","1096":"Bilal Ghanem, Simone Paolo Ponzetto, Paolo Rosso, Francisco Rangel","1097":"Vivek Kumar Singh, Isha Ghosh, Darshan Sonagara","1098":"Gautam Kishore Shahi, D. Nandini","1099":"Xinyi Zhou, Apurva Mulay, Emilio Ferrara, R. Zafarani","1100":"Xinyi Zhou, Jindi Wu, R. Zafarani","1101":"Alexander R. Fabbri, Irene Li, Tianwei She, Suyi Li, Dragomir R. Radev","1102":"Yaqing Wang, Weifeng Yang, Fenglong Ma, Jin Xu, Bin Zhong, Qiang Deng, Jing Gao","1103":"Giovanni Da San Martino, Seunghak Yu, Alberto Barr\u00f3n-Cede\u00f1o, R. Petrov, Preslav Nakov","1104":"T. Ruokolainen, Pekka Kauppinen, Miikka Silfverberg, Krister Lind\u00e9n","1105":"Danyang Liu, Jianxun Lian, Shiyin Wang, Ying Qiao, Jiun-Hung Chen, Guang-zhong Sun, Xing Xie","1106":"Dhruv Khattar, Jaipal Singh Goud, Manish Gupta, Vasudeva Varma","1107":"Johannes Kiesel, Maria Mestre, Rishabh Shukla, Emmanuel Vincent, Payam Adineh, D. Corney, Benno Stein, Martin Potthast","1108":"Tao Qi, Fangzhao Wu, Chuhan Wu, Yongfeng Huang, Xing Xie","1109":"Shivangi Singhal, Anubha Kabra, Mohit Sharma, R. Shah, Tanmoy Chakraborty, P. Kumaraguru","1110":"Chuhan Wu, Fangzhao Wu, Mingxiao An, Jianqiang Huang, Yongfeng Huang, Xing Xie","1111":"Nguyen Vo, Kyumin Lee","1112":"Anastasia Giahanou, E. R\u00edssola, Bilal Ghanem, F. Crestani, Paolo Rosso","1113":"Heng-Shiou Sheu, Sheng Li","1114":"Xiaotao Gu, Yuning Mao, Jiawei Han, Jialu Liu, Hongkun Yu, You Wu, Cong Yu, Daniel Finnie, Jiaqi Zhai, Nicholas Zukoski","1115":"Siva Charan Reddy Gangireddy, D. P, Cheng Long, Tanmoy Chakraborty","1116":"Savvas Zannettou, Mai ElSherief, E. Belding-Royer, Shirin Nilizadeh, G. Stringhini","1117":"Christiaan Burggraaff, D. Trilling","1118":"Hamid Karimi, Jiliang Tang","1119":"Fatemeh Torabi Asr, M. Taboada","1120":"Saloni Mohan, Sahitya Mullapudi, Sudheer Sammeta, Parag Vijayvergia, D. Anastasiu","1121":"F. Salem, Roaa Al Feel, Shady Elbassuoni, Mohamad Jaber, May Farah","1122":"Alberto Barr\u00f3n-Cede\u00f1o, Giovanni Da San Martino, Israa Jaradat, Preslav Nakov","1123":"Sameer Dhoju, Md Main Uddin Rony, M. A. Kabir, Naeemul Hassan","1124":"Sonia Castelo, Thais G. Almeida, Anas Elghafari, A\u00e9cio Santos, Kien Pham, E. Nakamura, J. Freire","1125":"W. Souma, I. Vodenska, H. Aoyama","1126":"Adrien Benamira, Benjamin Devillers, Etienne Lesot, Ayush Ray, Manal Saadi, Fragkiskos D. Malliaros","1127":"Kevin Joseph, Hui Jiang","1128":"Archita Pathak, R. Srihari","1129":"Bogdan Gliwa, Iwona Mochol, Maciej Biesek, Aleksander Wawer","1130":"Zeynep Akkalyoncu Yilmaz, Wei Yang, Haotian Zhang, Jimmy J. Lin","1131":"Sara Ahmadian, Alessandro Epasto, Ravi Kumar, Mohammad Mahdian","1132":"Gurinder Singh, Bhawna Kumar, Loveleen Gaur, Ankur Tyagi","1133":"Chong Feng, Muzammil Khan, Arif Ur Rahman, Arshad Ahmad","1134":"Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel M. Ziegler, Ryan J. Lowe, Chelsea Voss, Alec Radford, Dario Amodei, Paul Christiano","1135":"Lea Frermann, A. Klementiev","1136":"Saravanapriya Manoharan, R. Senthilkumar","1137":"M. Schonlau, Rosie Yuyan Zou","1138":"Yunan Ye, Hengzhi Pei, Boxin Wang, Pin-Yu Chen, Yada Zhu, Jun Xiao, Bo Li","1139":"Xinyi Li, Yinchuan Li, Hongyang Yang, Liuqing Yang, Xiao-Yang Liu","1140":"K. Kousha, M. Thelwall","1141":"Duc Minh Nguyen, T. Do, A. Calderbank, N. Deligiannis","1142":"Danyang Liu, Ting Bai, Jianxun Lian, Guang-zhong Sun, Wayne Xin Zhao, Ji-rong Wen, Xing Xie","1143":"Bhavika Bhutani, Neha Rastogi, Priyanshu Sehgal, Archana Purwar","1144":"Francesco Pierri, Alessandro Artoni, S. Ceri","1145":"Sneh Kalra, J. S. Prasad","1146":"Ritika Singh, Satwinder Singh","1147":"G. Brena, M. Brambilla, S. Ceri, Marco Di Giovanni, Francesco Pierri, Giorgia Ramponi","1148":"Panayiotis Smeros, C. Castillo, K. Aberer","1149":"Dongwhan Kim, Joonhwan Lee","1150":"Leen Al Qadi, Hozayfa El Rifai, Safa Obaid, Ashraf Elnagar","1151":"Gautam Kishore Shahi","1152":"Bastian von Beschwitz, Donald B. Keim, M. Massa","1153":"Sunidhi Sharma, D. Sharma","1154":"Pranav Bharadwaj, Zongru Shao","1155":"Yiangos Papanastasiou","1156":"Manling Li, Lingyu Zhang, Heng Ji, R. Radke","1157":"Jan Christian Blaise Cruz, J. A. Tan, C. Cheng","1158":"Philine Widmer, Elliott Ash, S. Galletta, S. Galletta","1159":"M. Mosleh, Cameron Martel, Dean Eckles, David G. Rand","1160":"Shiri Melumad, R. Meyer, Yoon Duk Kim","1161":"Stephen Bradshaw, C. O'Riordan, Riad Cheikh","1162":"M. Ledwich, Anna Zaitsev","1163":"Ankur Sharma, N. Kaur, Anirban Sen, Aaditeshwar Seth","1164":"Felix Hamborg, Timo Spinde, Kim Heinser, K. Donnay, Bela Gipp","1165":"Felix Hamborg, Kim Heinser, Anastasia Zhukova, K. Donnay, Bela Gipp","1166":"L. A. Hemaspaandra","1167":"Felix H\u00f6hne, S\u00f6ren Schmitt, R. V. Stee","1168":"L. A. Hemaspaandra","1169":"L. A. Hemaspaandra","1170":"L. A. Hemaspaandra","1171":"Timo Spinde, Jan-David Krieger, Terry Ruas, Jelena Mitrovi\u0107, Franz G\u00f6tz-Hahn, Akiko Aizawa, Bela Gipp","1172":"Raj Kumar Gupta, Yinping Yang","1173":"Felix H\u00f6hne, S\u00f6ren Schmitt, R. V. Stee","1174":"L. A. Hemaspaandra","1175":"L. A. Hemaspaandra","1176":"L. A. Hemaspaandra","1177":"L. A. Hemaspaandra","1178":"Douglas A. Ferguson, C. Greer","1179":"Y. Du, Lingzi Zhu, B. Cheng","1180":"Tiara Astra Parahita, Tur Rahardjo","1181":"L. A. Hemaspaandra","1182":"Emily Allaway, M. Srikanth, K. McKeown","1183":"Chenyan Jia, Ruibo Liu","1184":"Dan Allan, T. Caswell, Stuart Campbell, M. Rakitin","1185":"F. Smith","1186":"Kai Shu, Limeng Cui, Suhang Wang, Dongwon Lee, Huan Liu","1187":"Federico Monti, F. Frasca, D. Eynard, Damon Mannion, M. Bronstein","1188":"Julio C. S. Reis, Andr\u00e9 Correia, Fabricio Murai, Adriano Veloso, Fabr\u00edcio Benevenuto, E. Cambria","1189":"Shuo Yang, Kai Shu, Suhang Wang, Renjie Gu, Fan Wu, Huan Liu","1190":"Chuhan Wu, Fangzhao Wu, Suyu Ge, Tao Qi, Yongfeng Huang, Xing Xie","1191":"Xinyi Zhou, R. Zafarani","1192":"Xinyi Zhou, R. Zafarani, Kai Shu, Huan Liu","1193":"Chuhan Wu, Fangzhao Wu, Mingxiao An, Jianqiang Huang, Yongfeng Huang, Xing Xie","1194":"Taehyun Kim","1195":"Y. Jang, Changhyeon Park, Yeong-Seok Seo","1196":"Svenja Boberg, T. Quandt, Tim Schatto-Eckrodt, L. Frischlich","1197":"Maysoon Alkhair, Karima Meftouh, Kamel Sma\u00efli, Nouha Othman","1198":"Kai Shu, Deepak Mahudeswaran, Suhang Wang, Huan Liu","1199":"Kanish Shah, Henil Patel, D. Sanghvi, Manan Shah","1200":"M. Bastos, Dan Mercea","1201":"Kai Shu, Xinyi Zhou, Suhang Wang, R. Zafarani, Huan Liu","1202":"Fan Yang, Shiva K. Pentyala, Sina Mohseni, Mengnan Du, Hao Yuan, Rhema Linder, E. Ragan, Shuiwang Ji, Xia Hu","1203":"Zhixuan Zhou, Huankang Guan, Meghana Moorthy Bhat, Justin Hsu","1204":"Shervin Minaee, Nal Kalchbrenner, E. Cambria, Narjes Nikzad, M. Chenaghlu, Jianfeng Gao","1205":"W. Ahmed, S. Lugovic","1206":"P. Mallick, Sushruta Mishra, G. Chae","1207":"Daniel Thilo Schroeder, Konstantin Pogorelov, J. Langguth","1208":"Muhammad Umer, Zainab Imtiaz, S. Ullah, A. Mehmood, G. Choi, Byung-Won On","1209":"Ceren Budak","1210":"Patrick Mueller, M. Lehmann, Alexander Braun","1211":"M. S. Sadiq, C. Ruan, H. Nawaz, Shahid Ullah, Wenlong He","1212":"Ashok B. Mehta","1213":"Ashok B. Mehta","1214":"Wenyuan Zhang, Shubi Zhang, N. Ding, Lucas Holden, Xiaoming Wang, Nanshan Zheng","1215":"Cedric Tompkin, S. Leinss","1216":"P. Parthiban","1217":"Rajasri Sen Jaiswal, T. K., Mukundan M., Richa Dobal","1218":"K. Wilgan, M. A. Siddique, T. Strozzi, A. Geiger, Othmar Frey","1219":"Ying Zhang, Xichao Dong, W. Xiong, Cheng Hu","1220":"L. J. Mpoporo, P. Owolawi, A. O. Ayo","1221":"Xichao Dong, W. Xiong, Ying Zhang, Cheng Hu, Feifeng Liu","1222":"Hassan Shehzad, Dr.M. Raquibuz Zaman, Shane Zahra","1223":"X. Lv, Yongwei Zhang, Quanhu Shi, Murat Temiz, A. El-makadema","1224":"H. Brenot, W. Rohm, M. Ka\u010dma\u0159\u00edk, G. M\u00f6ller, A. S\u00e1, Damian Tondas, Luk\u00e1s Rapant, R. Biondi, T. Manning, C. Champollion","1225":"Riham S. Elhabyan, Wei Shi, M. St-Hilaire","1226":"Laura Ana Maria Bostan, Evgeny Kim, Roman Klinger","1227":"Christian Reuter, Katrin Hartwig, Jan Kirchner, N. Schlegel","1228":"Lindsay D. Grace, B. Hone","1229":"M. Ochs, D. Mestre, G. Montcheuil, Jean-Marie Pergandi, J. Saubesty, E. Lombardo, Daniel Francon, P. Blache","1230":"Adi Prasetyo, Bayu Dwi Septianto, G. F. Shidik, A. Z. Fanani","1231":"Samuli Laato, A. Islam, M. Islam, E. Whelan","1232":"Samuli Laato, A. Islam, M. Islam, E. Whelan","1233":"Joshua M. Scacco, Ashley Muddiman","1234":"Yong Fang, Jian Gao, Cheng Huang, Hua Peng, R. Wu","1235":"F. Rubio, F. Valero, C. Llopis-Albert","1236":"C. Chuan, W. Tsai, Sumi Cho","1237":"Sachin Kumar, Rohan Asthana, S. Upadhyay, Nidhi Upreti, Mohammad Akbar","1238":"Zhicong Lu, Yue Jiang, Cheng Lu, M. Naaman, Daniel J. Wigdor","1239":"M. N. Al-Ameen, Tanjina Tamanna, Swapnil Nandy, M. Ahsan, Priyank Chandra, Syed Ishtiaque Ahmed","1240":"Theodora A. Maniou, A. Veglis","1241":"Wei Zakharov, Haiyan Li, M. Fosmire","1242":"E. Loos, J. Nijenhuis","1243":"Ben Chen, B. Chen, D. Gao, Qijin Chen, Chengfu Huo, Xiaonan Meng, Weijun Ren, Yang Zhou","1244":"S. M. Jones-Jang, Dam Hee Kim, K. Kenski","1245":"Donghee Shin","1246":"Soon Ae Chun, R. Holowczak, Kannan Dharan, Ruoyu Wang, Soumaydeep Basu, J. Geller","1247":"Shan Jiang, Ronald E. Robertson, Christo Wilson","1248":"David Holtz, Sinan Aral","1249":"J. B\u00f8lstad","1250":"Shan Jiang, Ronald E. Robertson, Christo Wilson","1251":"Jennifer Bussell","1252":"Stefano Costalli, F. Negri","1253":"Maximilian Wich, Jan Bauer, Georg Groh","1254":"Yair Ghitza, A. Gelman","1255":"C. Hazlett, L. Wainstein","1256":"Xun Pang, Licheng Liu, Yiqing Xu","1257":"Alexander J. Stewart, M. Mosleh, M. Diakonova, A. Arechar, David G. Rand, J. Plotkin","1258":"A. Deb, Luca Luceri, Adam Badawy, Emilio Ferrara","1259":"Q. Grundy","1260":"A. Mattei, B. D. De Stavola, F. Mealli","1261":"Markus Knoche, Radovan Popovi\u0107, F. Lemmerich, M. Strohmaier","1262":"Zahra Fatemi, E. Zheleva","1263":"Hannah Li, Geng Zhao, R. Johari, G. Weintraub","1264":"Pak-Hang Wong","1265":"K. Umarova, Eni Mustafaraj","1266":"Michael Freeman, S. Robinson, S. Scholtes","1267":"D. Potnis, I. Tahamtan","1268":"N. Diakopoulos","1269":"Jack Bandy, N. Diakopoulos","1270":"Oren Soffer","1271":"Sandra Gonz\u00e1lez-Bail\u00f3n, M. De Domenico","1272":"D. Schiff","1273":"Ahmed Al-Rawi"}}